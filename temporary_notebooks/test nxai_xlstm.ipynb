{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a14811",
   "metadata": {},
   "source": [
    "# Cell width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94552ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d92ef3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8e34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "\n",
    "# sys.path.append('..')\n",
    "from omegaconf import OmegaConf\n",
    "from pprint import pprint\n",
    "from dacite import from_dict\n",
    "from dacite import Config as DaciteConfig\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from abc import abstractmethod\n",
    "\n",
    "from xlstm.xlstm_block_stack import xLSTMBlockStack, xLSTMBlockStackConfig\n",
    "from xlstm.utils import WeightDecayOptimGroupMixin\n",
    "\n",
    "from xlstm_moex.data.download import get_historical_data, get_historical_candels\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79adc0",
   "metadata": {},
   "source": [
    "# Fucntions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfb9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLRScheduler(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, last_epoch=-1):\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_lr(self) -> list[float]:\n",
    "        \"\"\"Returns the current learning rate for each parameter group.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def reinitialize(self, **kwargs) -> None:\n",
    "        \"\"\"Reinitializes the learning rate scheduler.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class LinearWarmupCosineAnnealing(BaseLRScheduler):\n",
    "    def __init__(self, optimizer, warmup_steps, decay_until_step, max_lr, min_lr, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_until_step = decay_until_step\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_lr(step, warmup_steps, decay_until_step, max_lr, min_lr):\n",
    "        if step < warmup_steps:\n",
    "            return max_lr * step / warmup_steps\n",
    "        if step > decay_until_step:\n",
    "            return min_lr\n",
    "        if warmup_steps <= step < decay_until_step:\n",
    "            decay_ratio = (step - warmup_steps) / (decay_until_step - warmup_steps)\n",
    "            assert 0.0 <= decay_ratio <= 1.0\n",
    "            coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
    "            return min_lr + coeff * (max_lr - min_lr)\n",
    "        else:\n",
    "            return min_lr\n",
    "\n",
    "    def get_lr(self) -> list[float]:\n",
    "        \"\"\"Returns the current learning rate for each parameter group.\"\"\"\n",
    "        step = self.last_epoch\n",
    "        return (\n",
    "            self.compute_lr(step, self.warmup_steps, self.decay_until_step, self.max_lr, self.min_lr)\n",
    "            for _ in self.optimizer.param_groups\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a733e2",
   "metadata": {},
   "source": [
    "# Init config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2cbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlstm_cfg = f\"\"\" \n",
    "# mlstm_block:\n",
    "#   mlstm:\n",
    "#     conv1d_kernel_size: 4\n",
    "#     qkv_proj_blocksize: 1\n",
    "#     num_heads: 1\n",
    "#     proj_factor: 1\n",
    "# slstm_block:\n",
    "#   slstm:\n",
    "#     backend: {'cuda' if torch.cuda.is_available() else 'vanilla'} #! only vanilla here works\n",
    "#     num_heads: 1\n",
    "#     conv1d_kernel_size: 0\n",
    "#     bias_init: powerlaw_blockdependent\n",
    "#   feedforward:\n",
    "#     proj_factor: 1.2\n",
    "#     act_fn: gelu\n",
    "# context_length: 50\n",
    "# num_blocks: 2\n",
    "# embedding_dim: 1 # same as `in_features` in Pytorch LSTM\n",
    "# slstm_at: [1] #[1] # for [] it also works, so if no sLSTM is in the stack\n",
    "# \"\"\"\n",
    "\n",
    "xlstm_cfg = f\"\"\" \n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'} #! only vanilla here works\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 256\n",
    "num_blocks: 7\n",
    "embedding_dim: 128\n",
    "add_post_blocks_norm: False\n",
    "slstm_at: [1] #[1] # for [] it also works, so if no sLSTM is in the stack\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f502f8c",
   "metadata": {},
   "source": [
    "# Init XLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea0fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': True, 'with_cuda': True, 'extra_ldflags': ['-L/home/nick/anaconda3/envs/nxai_xlstm/lib', '-lcublas'], 'extra_cflags': ['-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__'], 'extra_cuda_cflags': ['-Xptxas=\"-v\"', '-gencode', 'arch=compute_80,code=compute_80', '-res-usage', '--use_fast_math', '-O3', '-Xptxas -O3', '--extra-device-vectorization', '-DSLSTM_HIDDEN_SIZE=128', '-DSLSTM_BATCH_SIZE=8', '-DSLSTM_NUM_HEADS=4', '-DSLSTM_NUM_STATES=4', '-DSLSTM_DTYPE_B=float', '-DSLSTM_DTYPE_R=__nv_bfloat16', '-DSLSTM_DTYPE_W=__nv_bfloat16', '-DSLSTM_DTYPE_G=__nv_bfloat16', '-DSLSTM_DTYPE_S=__nv_bfloat16', '-DSLSTM_DTYPE_A=float', '-DSLSTM_NUM_GATES=4', '-DSLSTM_SIMPLE_AGG=true', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL_VALID=false', '-DSLSTM_GRADIENT_RECURRENT_CLIPVAL=0.0', '-DSLSTM_FORWARD_CLIPVAL_VALID=false', '-DSLSTM_FORWARD_CLIPVAL=0.0', '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_BFLOAT16_OPERATORS__', '-U__CUDA_NO_BFLOAT16_CONVERSIONS__', '-U__CUDA_NO_BFLOAT162_OPERATORS__', '-U__CUDA_NO_BFLOAT162_CONVERSIONS__']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/nick/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/nick/.cache/torch_extensions/py311_cu121/slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0/build.ninja...\n",
      "Building extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module slstm_HS128BS8NH4NS4DBfDRbDWbDGbDSbDAfNG4SA1GRCV0GRC0d0FCV0FC0d0...\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.create(xlstm_cfg)\n",
    "cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(cfg), config=DaciteConfig(strict=True))\n",
    "xlstm_stack = xLSTMBlockStack(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64fdc7",
   "metadata": {},
   "source": [
    "# Inspect config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2209e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "pprint(cfg.embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048a604",
   "metadata": {},
   "source": [
    "# Inspect layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dae4b998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xLSTMBlockStack(\n",
       "  (blocks): ModuleList(\n",
       "    (0): mLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): mLSTMLayer(\n",
       "        (proj_up): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (q_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (k_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (v_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (mlstm_cell): mLSTMCell(\n",
       "          (igate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (fgate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (outnorm): MultiHeadLayerNorm()\n",
       "        )\n",
       "        (ogate_act_fn): SiLU()\n",
       "        (proj_down): Linear(in_features=256, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): sLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): sLSTMLayer(\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (fgate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (igate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (zgate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (ogate): LinearHeadwiseExpand(in_features=128, num_heads=4, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (slstm_cell): sLSTMCell_cuda(function=slstm, hidden_size=128, num_heads=4)\n",
       "        (group_norm): MultiHeadLayerNorm()\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn_norm): LayerNorm()\n",
       "      (ffn): GatedFeedForward(\n",
       "        (proj_up): Linear(in_features=128, out_features=384, bias=False)\n",
       "        (proj_down): Linear(in_features=192, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2-6): 5 x mLSTMBlock(\n",
       "      (xlstm_norm): LayerNorm()\n",
       "      (xlstm): mLSTMLayer(\n",
       "        (proj_up): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (q_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (k_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (v_proj): LinearHeadwiseExpand(in_features=256, num_heads=64, expand_factor_up=1, bias=False, trainable_weight=True, trainable_bias=True, )\n",
       "        (conv1d): CausalConv1d(\n",
       "          (conv): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)\n",
       "        )\n",
       "        (conv_act_fn): SiLU()\n",
       "        (mlstm_cell): mLSTMCell(\n",
       "          (igate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (fgate): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (outnorm): MultiHeadLayerNorm()\n",
       "        )\n",
       "        (ogate_act_fn): SiLU()\n",
       "        (proj_down): Linear(in_features=256, out_features=128, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_blocks_norm): Identity()\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlstm_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2d5e86",
   "metadata": {},
   "source": [
    "# Generate synthetic examlpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9400311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 256, 128).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "678475b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 128])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e53df36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1, :].view(2,1,128).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108fe3c4",
   "metadata": {},
   "source": [
    "# Check model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69e54f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstm_stack = xlstm_stack.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d30941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    y, states_dict = xlstm_stack.step(x[:, i, :].view(2,1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30c0e8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlstm_state': (tensor([[[[ 5.4874e-06, -1.2764e-06, -4.2204e-06,  ..., -1.7712e-05,\n",
       "             -2.4697e-06, -7.9438e-06],\n",
       "            [ 4.2978e-05, -9.9968e-06, -3.3054e-05,  ..., -1.3872e-04,\n",
       "             -1.9342e-05, -6.2216e-05],\n",
       "            [-2.4128e-05,  5.6123e-06,  1.8557e-05,  ...,  7.7881e-05,\n",
       "              1.0859e-05,  3.4929e-05],\n",
       "            ...,\n",
       "            [-1.0465e-05,  2.4343e-06,  8.0490e-06,  ...,  3.3780e-05,\n",
       "              4.7100e-06,  1.5150e-05],\n",
       "            [-3.4788e-05,  8.0919e-06,  2.6756e-05,  ...,  1.1229e-04,\n",
       "              1.5657e-05,  5.0361e-05],\n",
       "            [-1.0198e-05,  2.3721e-06,  7.8432e-06,  ...,  3.2916e-05,\n",
       "              4.5896e-06,  1.4763e-05]],\n",
       "  \n",
       "           [[ 1.1881e-04, -4.0994e-04,  2.5100e-04,  ...,  1.2454e-06,\n",
       "             -2.5543e-04,  3.8301e-04],\n",
       "            [ 1.7321e-04, -5.9762e-04,  3.6592e-04,  ...,  1.8156e-06,\n",
       "             -3.7237e-04,  5.5836e-04],\n",
       "            [ 7.2518e-05, -2.5021e-04,  1.5320e-04,  ...,  7.6015e-07,\n",
       "             -1.5590e-04,  2.3377e-04],\n",
       "            ...,\n",
       "            [ 2.0607e-05, -7.1100e-05,  4.3534e-05,  ...,  2.1600e-07,\n",
       "             -4.4302e-05,  6.6429e-05],\n",
       "            [-3.2479e-05,  1.1206e-04, -6.8614e-05,  ..., -3.4045e-07,\n",
       "              6.9824e-05, -1.0470e-04],\n",
       "            [-1.3097e-04,  4.5191e-04, -2.7670e-04,  ..., -1.3729e-06,\n",
       "              2.8158e-04, -4.2222e-04]],\n",
       "  \n",
       "           [[ 1.9692e-04, -1.3150e-05,  1.0729e-04,  ...,  3.7522e-04,\n",
       "              4.8295e-05,  1.8662e-04],\n",
       "            [-2.1512e-04,  1.4366e-05, -1.1720e-04,  ..., -4.0990e-04,\n",
       "             -5.2758e-05, -2.0387e-04],\n",
       "            [-9.6857e-05,  6.4680e-06, -5.2770e-05,  ..., -1.8455e-04,\n",
       "             -2.3754e-05, -9.1789e-05],\n",
       "            ...,\n",
       "            [-9.4312e-05,  6.2981e-06, -5.1384e-05,  ..., -1.7970e-04,\n",
       "             -2.3130e-05, -8.9378e-05],\n",
       "            [-1.2983e-04,  8.6699e-06, -7.0735e-05,  ..., -2.4738e-04,\n",
       "             -3.1840e-05, -1.2304e-04],\n",
       "            [ 1.8608e-05, -1.2427e-06,  1.0138e-05,  ...,  3.5457e-05,\n",
       "              4.5637e-06,  1.7635e-05]],\n",
       "  \n",
       "           [[-5.4367e-05, -4.0511e-04, -9.4968e-05,  ..., -2.6166e-04,\n",
       "             -4.4386e-06, -2.4104e-04],\n",
       "            [-4.3100e-05, -3.2116e-04, -7.5288e-05,  ..., -2.0744e-04,\n",
       "             -3.5188e-06, -1.9109e-04],\n",
       "            [ 1.3977e-05,  1.0415e-04,  2.4415e-05,  ...,  6.7270e-05,\n",
       "              1.1411e-06,  6.1969e-05],\n",
       "            ...,\n",
       "            [ 1.3907e-06,  1.0363e-05,  2.4293e-06,  ...,  6.6934e-06,\n",
       "              1.1354e-07,  6.1660e-06],\n",
       "            [ 5.9665e-06,  4.4459e-05,  1.0422e-05,  ...,  2.8716e-05,\n",
       "              4.8711e-07,  2.6453e-05],\n",
       "            [ 8.6750e-06,  6.4641e-05,  1.5153e-05,  ...,  4.1751e-05,\n",
       "              7.0823e-07,  3.8462e-05]]],\n",
       "  \n",
       "  \n",
       "          [[[-2.4331e-05, -1.3676e-05,  1.1046e-05,  ...,  7.1812e-05,\n",
       "              3.7987e-05,  3.4354e-05],\n",
       "            [-1.4164e-04, -7.9613e-05,  6.4307e-05,  ...,  4.1805e-04,\n",
       "              2.2114e-04,  1.9999e-04],\n",
       "            [ 1.7568e-04,  9.8748e-05, -7.9763e-05,  ..., -5.1854e-04,\n",
       "             -2.7430e-04, -2.4806e-04],\n",
       "            ...,\n",
       "            [ 4.2534e-06,  2.3907e-06, -1.9311e-06,  ..., -1.2554e-05,\n",
       "             -6.6409e-06, -6.0058e-06],\n",
       "            [ 6.5182e-05,  3.6637e-05, -2.9594e-05,  ..., -1.9239e-04,\n",
       "             -1.0177e-04, -9.2037e-05],\n",
       "            [-1.0723e-04, -6.0274e-05,  4.8686e-05,  ...,  3.1651e-04,\n",
       "              1.6743e-04,  1.5141e-04]],\n",
       "  \n",
       "           [[ 1.4901e-04, -8.9038e-05,  2.2690e-04,  ...,  1.7878e-04,\n",
       "              2.3076e-04,  1.2214e-04],\n",
       "            [-2.3186e-04,  1.3854e-04, -3.5305e-04,  ..., -2.7818e-04,\n",
       "             -3.5905e-04, -1.9004e-04],\n",
       "            [ 2.6655e-05, -1.5927e-05,  4.0587e-05,  ...,  3.1980e-05,\n",
       "              4.1278e-05,  2.1848e-05],\n",
       "            ...,\n",
       "            [-7.8172e-06,  4.6709e-06, -1.1903e-05,  ..., -9.3789e-06,\n",
       "             -1.2106e-05, -6.4074e-06],\n",
       "            [-7.6446e-06,  4.5677e-06, -1.1640e-05,  ..., -9.1718e-06,\n",
       "             -1.1838e-05, -6.2659e-06],\n",
       "            [ 4.6285e-05, -2.7656e-05,  7.0478e-05,  ...,  5.5532e-05,\n",
       "              7.1677e-05,  3.7938e-05]],\n",
       "  \n",
       "           [[-4.3245e-05, -8.2412e-06, -3.0433e-05,  ...,  6.4366e-05,\n",
       "              3.9305e-05, -3.5553e-05],\n",
       "            [-3.8275e-05, -7.2941e-06, -2.6936e-05,  ...,  5.6969e-05,\n",
       "              3.4788e-05, -3.1467e-05],\n",
       "            [ 2.0669e-05,  3.9389e-06,  1.4546e-05,  ..., -3.0764e-05,\n",
       "             -1.8786e-05,  1.6993e-05],\n",
       "            ...,\n",
       "            [-8.4317e-05, -1.6068e-05, -5.9337e-05,  ...,  1.2550e-04,\n",
       "              7.6635e-05, -6.9320e-05],\n",
       "            [ 5.3778e-06,  1.0248e-06,  3.7846e-06,  ..., -8.0043e-06,\n",
       "             -4.8878e-06,  4.4213e-06],\n",
       "            [ 4.0627e-05,  7.7423e-06,  2.8591e-05,  ..., -6.0469e-05,\n",
       "             -3.6926e-05,  3.3401e-05]],\n",
       "  \n",
       "           [[ 4.2450e-06, -3.8220e-05, -9.1577e-05,  ...,  1.1215e-04,\n",
       "             -6.7087e-05,  1.6913e-04],\n",
       "            [ 3.1429e-06, -2.8297e-05, -6.7802e-05,  ...,  8.3037e-05,\n",
       "             -4.9670e-05,  1.2522e-04],\n",
       "            [-1.6711e-06,  1.5046e-05,  3.6050e-05,  ..., -4.4151e-05,\n",
       "              2.6410e-05, -6.6581e-05],\n",
       "            ...,\n",
       "            [ 1.0422e-06, -9.3833e-06, -2.2483e-05,  ...,  2.7535e-05,\n",
       "             -1.6471e-05,  4.1523e-05],\n",
       "            [ 3.5420e-06, -3.1890e-05, -7.6411e-05,  ...,  9.3582e-05,\n",
       "             -5.5977e-05,  1.4112e-04],\n",
       "            [-7.2793e-07,  6.5539e-06,  1.5704e-05,  ..., -1.9232e-05,\n",
       "              1.1504e-05, -2.9003e-05]]]], device='cuda:0',\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[[ 2.7608e-04],\n",
       "            [ 2.1623e-03],\n",
       "            [-1.2139e-03],\n",
       "            [-4.1895e-04],\n",
       "            [-1.7014e-03],\n",
       "            [-6.6401e-04],\n",
       "            [ 6.2111e-04],\n",
       "            [ 4.4712e-04],\n",
       "            [ 2.3477e-04],\n",
       "            [ 8.8621e-04],\n",
       "            [-3.6356e-04],\n",
       "            [ 4.5780e-04],\n",
       "            [ 6.5757e-04],\n",
       "            [ 1.7146e-04],\n",
       "            [-2.3261e-03],\n",
       "            [-2.6057e-03],\n",
       "            [ 1.7585e-03],\n",
       "            [-2.0602e-03],\n",
       "            [ 2.0379e-04],\n",
       "            [-1.3245e-03],\n",
       "            [-5.5536e-04],\n",
       "            [ 9.6102e-04],\n",
       "            [-7.0384e-04],\n",
       "            [ 2.2512e-03],\n",
       "            [-1.2940e-03],\n",
       "            [ 1.4963e-03],\n",
       "            [-6.9811e-04],\n",
       "            [-3.1317e-03],\n",
       "            [-6.2475e-04],\n",
       "            [ 2.2022e-03],\n",
       "            [ 4.2320e-03],\n",
       "            [ 2.9390e-03],\n",
       "            [ 5.3418e-04],\n",
       "            [ 2.0369e-03],\n",
       "            [-3.7784e-03],\n",
       "            [-3.0118e-03],\n",
       "            [-1.1762e-04],\n",
       "            [-1.2887e-03],\n",
       "            [ 3.3368e-05],\n",
       "            [-2.8913e-03],\n",
       "            [ 4.1378e-03],\n",
       "            [-1.7976e-03],\n",
       "            [-8.2947e-04],\n",
       "            [ 2.0879e-03],\n",
       "            [-2.0026e-03],\n",
       "            [ 9.3078e-05],\n",
       "            [-1.6552e-04],\n",
       "            [ 1.1724e-03],\n",
       "            [-1.8628e-03],\n",
       "            [-1.9626e-03],\n",
       "            [-4.5503e-04],\n",
       "            [-1.0372e-03],\n",
       "            [-2.8685e-03],\n",
       "            [ 5.5825e-04],\n",
       "            [ 8.7814e-04],\n",
       "            [ 1.4235e-03],\n",
       "            [ 1.8838e-03],\n",
       "            [-1.2668e-03],\n",
       "            [ 1.2308e-03],\n",
       "            [ 5.8887e-04],\n",
       "            [-1.6074e-03],\n",
       "            [-5.2653e-04],\n",
       "            [-1.7503e-03],\n",
       "            [-5.1307e-04]],\n",
       "  \n",
       "           [[ 3.8582e-03],\n",
       "            [ 5.6247e-03],\n",
       "            [ 2.3549e-03],\n",
       "            [ 1.2069e-03],\n",
       "            [ 3.3654e-03],\n",
       "            [ 3.8958e-03],\n",
       "            [ 1.8683e-03],\n",
       "            [-2.3820e-03],\n",
       "            [-1.8009e-04],\n",
       "            [ 2.7283e-03],\n",
       "            [ 1.4760e-03],\n",
       "            [-1.9471e-03],\n",
       "            [ 1.5524e-03],\n",
       "            [-1.7060e-03],\n",
       "            [ 1.1877e-03],\n",
       "            [ 2.6172e-03],\n",
       "            [ 1.3283e-04],\n",
       "            [ 1.1014e-03],\n",
       "            [ 2.0119e-04],\n",
       "            [-3.9448e-05],\n",
       "            [-7.8317e-04],\n",
       "            [-5.7702e-03],\n",
       "            [-1.4190e-03],\n",
       "            [-4.1757e-03],\n",
       "            [ 1.8905e-03],\n",
       "            [-8.0302e-05],\n",
       "            [ 6.7760e-04],\n",
       "            [ 5.2269e-05],\n",
       "            [ 4.0683e-03],\n",
       "            [ 1.0410e-03],\n",
       "            [-1.2067e-03],\n",
       "            [ 4.9330e-05],\n",
       "            [ 1.5181e-03],\n",
       "            [ 3.1408e-03],\n",
       "            [ 9.8748e-04],\n",
       "            [-1.8988e-03],\n",
       "            [ 4.7141e-04],\n",
       "            [-1.8109e-03],\n",
       "            [ 9.7368e-04],\n",
       "            [ 1.4652e-03],\n",
       "            [ 7.0446e-04],\n",
       "            [ 2.5992e-03],\n",
       "            [-8.0435e-04],\n",
       "            [-8.5857e-04],\n",
       "            [-2.0807e-03],\n",
       "            [ 1.6718e-03],\n",
       "            [-9.7068e-04],\n",
       "            [-4.4529e-03],\n",
       "            [-3.1527e-03],\n",
       "            [-1.1132e-03],\n",
       "            [ 3.1015e-03],\n",
       "            [ 2.4152e-03],\n",
       "            [-2.1577e-03],\n",
       "            [-1.5958e-03],\n",
       "            [-1.0280e-03],\n",
       "            [-2.4745e-03],\n",
       "            [-1.8250e-03],\n",
       "            [ 1.4629e-04],\n",
       "            [ 7.3443e-03],\n",
       "            [-2.5122e-03],\n",
       "            [ 9.5244e-04],\n",
       "            [ 6.6917e-04],\n",
       "            [-1.0547e-03],\n",
       "            [-4.2532e-03]],\n",
       "  \n",
       "           [[-1.8684e-03],\n",
       "            [ 2.0410e-03],\n",
       "            [ 9.1896e-04],\n",
       "            [-1.6814e-03],\n",
       "            [-8.6926e-04],\n",
       "            [-4.9777e-04],\n",
       "            [ 6.9829e-04],\n",
       "            [ 4.6657e-04],\n",
       "            [-2.8236e-03],\n",
       "            [-1.4628e-03],\n",
       "            [ 1.3150e-03],\n",
       "            [-8.6884e-04],\n",
       "            [ 2.8843e-04],\n",
       "            [-3.5942e-04],\n",
       "            [-6.7017e-04],\n",
       "            [ 1.9142e-03],\n",
       "            [ 1.4801e-03],\n",
       "            [-3.6859e-03],\n",
       "            [ 8.6833e-04],\n",
       "            [ 6.9103e-04],\n",
       "            [ 2.9048e-03],\n",
       "            [ 1.2014e-03],\n",
       "            [ 2.4870e-03],\n",
       "            [ 2.2164e-03],\n",
       "            [ 1.8008e-03],\n",
       "            [ 2.6936e-03],\n",
       "            [-1.1899e-03],\n",
       "            [-1.1362e-03],\n",
       "            [ 3.3643e-04],\n",
       "            [-3.7503e-03],\n",
       "            [-3.8435e-04],\n",
       "            [-4.3593e-03],\n",
       "            [-6.8870e-04],\n",
       "            [-1.1972e-03],\n",
       "            [ 1.7481e-03],\n",
       "            [ 2.0302e-03],\n",
       "            [-8.3553e-04],\n",
       "            [ 5.0815e-04],\n",
       "            [-2.3064e-03],\n",
       "            [ 1.5463e-03],\n",
       "            [ 1.5747e-03],\n",
       "            [-2.6824e-03],\n",
       "            [-1.6243e-03],\n",
       "            [-8.9566e-04],\n",
       "            [ 7.4245e-05],\n",
       "            [-4.9516e-04],\n",
       "            [ 1.1560e-03],\n",
       "            [ 5.7637e-04],\n",
       "            [ 1.2876e-03],\n",
       "            [ 1.3989e-03],\n",
       "            [ 2.2228e-03],\n",
       "            [-7.3625e-04],\n",
       "            [ 1.7464e-03],\n",
       "            [-2.0899e-03],\n",
       "            [-4.2256e-03],\n",
       "            [ 8.0615e-05],\n",
       "            [-1.1387e-04],\n",
       "            [-1.5181e-03],\n",
       "            [ 6.3408e-04],\n",
       "            [-7.3528e-04],\n",
       "            [-5.4463e-04],\n",
       "            [ 8.9482e-04],\n",
       "            [ 1.2318e-03],\n",
       "            [-1.7655e-04]],\n",
       "  \n",
       "           [[-3.8446e-03],\n",
       "            [-3.0479e-03],\n",
       "            [ 9.8840e-04],\n",
       "            [ 5.2323e-03],\n",
       "            [-1.2138e-03],\n",
       "            [ 4.6541e-04],\n",
       "            [-5.9364e-04],\n",
       "            [ 9.1899e-04],\n",
       "            [-2.3866e-03],\n",
       "            [-1.9490e-03],\n",
       "            [-2.1124e-03],\n",
       "            [-1.2585e-03],\n",
       "            [-2.3281e-04],\n",
       "            [ 1.1924e-03],\n",
       "            [-9.5968e-04],\n",
       "            [-1.9987e-03],\n",
       "            [ 1.3445e-03],\n",
       "            [ 2.4344e-03],\n",
       "            [ 3.3196e-03],\n",
       "            [ 1.6639e-03],\n",
       "            [ 1.0796e-03],\n",
       "            [ 1.8343e-03],\n",
       "            [ 2.9373e-03],\n",
       "            [ 2.3490e-03],\n",
       "            [ 9.5056e-04],\n",
       "            [ 6.7359e-04],\n",
       "            [-8.6671e-05],\n",
       "            [ 1.2617e-04],\n",
       "            [-1.5351e-03],\n",
       "            [ 2.8904e-04],\n",
       "            [-2.1986e-03],\n",
       "            [ 9.5534e-04],\n",
       "            [-1.2245e-04],\n",
       "            [ 2.8076e-03],\n",
       "            [ 3.8572e-04],\n",
       "            [ 8.0471e-04],\n",
       "            [-1.3686e-03],\n",
       "            [ 2.9820e-05],\n",
       "            [ 1.9844e-03],\n",
       "            [ 2.8210e-03],\n",
       "            [ 6.2759e-03],\n",
       "            [ 5.1319e-03],\n",
       "            [-9.8201e-05],\n",
       "            [ 3.5556e-03],\n",
       "            [ 4.1937e-03],\n",
       "            [ 1.6453e-03],\n",
       "            [ 5.0788e-04],\n",
       "            [-1.0825e-03],\n",
       "            [ 1.5470e-03],\n",
       "            [-1.5864e-03],\n",
       "            [ 2.3326e-03],\n",
       "            [-2.9377e-03],\n",
       "            [ 1.7219e-03],\n",
       "            [-4.7732e-03],\n",
       "            [-2.7160e-03],\n",
       "            [-1.2846e-03],\n",
       "            [-1.7569e-03],\n",
       "            [-1.9580e-03],\n",
       "            [ 7.9647e-04],\n",
       "            [-5.7302e-03],\n",
       "            [-2.0346e-03],\n",
       "            [ 9.8347e-05],\n",
       "            [ 4.2192e-04],\n",
       "            [ 6.1346e-04]]],\n",
       "  \n",
       "  \n",
       "          [[[ 2.4982e-04],\n",
       "            [ 1.4543e-03],\n",
       "            [-1.8039e-03],\n",
       "            [ 7.7998e-04],\n",
       "            [-2.8575e-04],\n",
       "            [-4.7009e-04],\n",
       "            [-1.1035e-04],\n",
       "            [ 6.3002e-04],\n",
       "            [ 1.5202e-04],\n",
       "            [ 5.2911e-04],\n",
       "            [-3.3054e-04],\n",
       "            [ 1.0157e-03],\n",
       "            [-1.1538e-03],\n",
       "            [-1.2092e-03],\n",
       "            [-1.4172e-03],\n",
       "            [ 3.5688e-04],\n",
       "            [ 9.7523e-04],\n",
       "            [ 6.4120e-04],\n",
       "            [ 1.7334e-03],\n",
       "            [-9.0818e-04],\n",
       "            [-7.6733e-04],\n",
       "            [ 1.4071e-03],\n",
       "            [-9.2605e-05],\n",
       "            [ 1.7577e-04],\n",
       "            [ 1.5978e-03],\n",
       "            [ 2.4052e-04],\n",
       "            [-7.3397e-04],\n",
       "            [-2.3867e-03],\n",
       "            [-3.1912e-04],\n",
       "            [ 2.2908e-04],\n",
       "            [ 1.5586e-03],\n",
       "            [ 3.8022e-03],\n",
       "            [-1.9335e-04],\n",
       "            [ 2.7069e-03],\n",
       "            [-3.3619e-03],\n",
       "            [-3.1713e-03],\n",
       "            [-5.4365e-04],\n",
       "            [-1.2267e-03],\n",
       "            [ 8.6646e-04],\n",
       "            [-1.2658e-03],\n",
       "            [ 1.3067e-03],\n",
       "            [ 1.7227e-03],\n",
       "            [-2.0387e-03],\n",
       "            [ 1.5230e-03],\n",
       "            [ 2.1784e-03],\n",
       "            [ 1.5992e-04],\n",
       "            [ 1.0405e-03],\n",
       "            [-9.4578e-04],\n",
       "            [-1.4372e-03],\n",
       "            [-1.2968e-03],\n",
       "            [-6.2143e-04],\n",
       "            [-5.1876e-04],\n",
       "            [-1.1410e-03],\n",
       "            [-4.5042e-04],\n",
       "            [ 1.8650e-04],\n",
       "            [ 2.5805e-03],\n",
       "            [ 1.2132e-03],\n",
       "            [ 1.4054e-03],\n",
       "            [ 3.8849e-04],\n",
       "            [-2.3456e-04],\n",
       "            [-7.7673e-04],\n",
       "            [-4.3674e-05],\n",
       "            [-6.6928e-04],\n",
       "            [ 1.1011e-03]],\n",
       "  \n",
       "           [[-3.6402e-03],\n",
       "            [ 5.6640e-03],\n",
       "            [-6.5114e-04],\n",
       "            [ 3.2678e-04],\n",
       "            [ 5.6414e-03],\n",
       "            [ 4.7739e-03],\n",
       "            [ 4.0496e-03],\n",
       "            [-4.7434e-03],\n",
       "            [-1.2026e-03],\n",
       "            [ 4.3972e-03],\n",
       "            [-8.0133e-05],\n",
       "            [-1.1505e-03],\n",
       "            [ 1.6252e-03],\n",
       "            [-1.4728e-03],\n",
       "            [ 1.0094e-03],\n",
       "            [ 2.6484e-03],\n",
       "            [-1.8341e-04],\n",
       "            [ 3.1917e-04],\n",
       "            [ 1.5373e-05],\n",
       "            [ 5.5205e-04],\n",
       "            [-2.4315e-03],\n",
       "            [-4.6965e-03],\n",
       "            [ 1.3835e-03],\n",
       "            [-3.0694e-03],\n",
       "            [ 5.4443e-03],\n",
       "            [-1.7226e-04],\n",
       "            [ 1.0632e-03],\n",
       "            [ 3.3784e-04],\n",
       "            [ 2.7404e-03],\n",
       "            [ 3.6797e-04],\n",
       "            [-1.3043e-03],\n",
       "            [-4.8545e-04],\n",
       "            [ 1.2722e-03],\n",
       "            [ 3.1309e-03],\n",
       "            [ 2.9636e-03],\n",
       "            [-1.2255e-03],\n",
       "            [ 1.6186e-03],\n",
       "            [ 1.0212e-03],\n",
       "            [ 3.9029e-04],\n",
       "            [ 1.0000e-04],\n",
       "            [ 3.1474e-04],\n",
       "            [ 2.3637e-03],\n",
       "            [-1.5819e-03],\n",
       "            [ 1.2880e-04],\n",
       "            [-4.0595e-04],\n",
       "            [-2.6759e-05],\n",
       "            [-1.5859e-04],\n",
       "            [-2.3426e-03],\n",
       "            [-6.8476e-04],\n",
       "            [-1.9057e-03],\n",
       "            [-7.3424e-04],\n",
       "            [ 4.7437e-03],\n",
       "            [-2.9060e-03],\n",
       "            [-2.2384e-03],\n",
       "            [-1.3439e-03],\n",
       "            [-3.4787e-03],\n",
       "            [-1.6601e-03],\n",
       "            [-2.0680e-04],\n",
       "            [ 6.6109e-03],\n",
       "            [-1.7878e-03],\n",
       "            [-1.0635e-04],\n",
       "            [ 1.9096e-04],\n",
       "            [ 1.8675e-04],\n",
       "            [-1.1307e-03]],\n",
       "  \n",
       "           [[-9.7784e-04],\n",
       "            [-8.6546e-04],\n",
       "            [ 4.6736e-04],\n",
       "            [-1.9996e-03],\n",
       "            [-5.4786e-04],\n",
       "            [-1.8622e-03],\n",
       "            [-1.1231e-03],\n",
       "            [ 1.9822e-04],\n",
       "            [-2.1465e-03],\n",
       "            [ 4.3478e-04],\n",
       "            [ 1.6918e-03],\n",
       "            [-1.1772e-03],\n",
       "            [-2.2195e-05],\n",
       "            [-7.7037e-04],\n",
       "            [-2.0452e-03],\n",
       "            [ 1.9331e-03],\n",
       "            [ 6.7849e-04],\n",
       "            [-2.4374e-03],\n",
       "            [-9.2251e-04],\n",
       "            [ 9.3053e-04],\n",
       "            [ 3.8996e-03],\n",
       "            [ 1.7936e-03],\n",
       "            [ 3.4723e-03],\n",
       "            [ 1.9683e-03],\n",
       "            [ 2.2217e-03],\n",
       "            [ 3.9868e-03],\n",
       "            [-2.8343e-03],\n",
       "            [-9.2453e-04],\n",
       "            [-1.2666e-03],\n",
       "            [-4.0236e-03],\n",
       "            [-3.2799e-03],\n",
       "            [ 9.8861e-06],\n",
       "            [-4.2020e-04],\n",
       "            [-1.6683e-03],\n",
       "            [ 4.0981e-03],\n",
       "            [ 2.9084e-03],\n",
       "            [-1.0778e-03],\n",
       "            [ 1.9637e-04],\n",
       "            [-1.6896e-03],\n",
       "            [ 7.6126e-04],\n",
       "            [ 1.5627e-03],\n",
       "            [-2.6554e-03],\n",
       "            [-1.4614e-03],\n",
       "            [-8.2320e-04],\n",
       "            [ 2.5569e-04],\n",
       "            [-2.9827e-04],\n",
       "            [ 1.2553e-03],\n",
       "            [ 1.1094e-03],\n",
       "            [ 1.1391e-03],\n",
       "            [ 1.2863e-03],\n",
       "            [ 1.6047e-03],\n",
       "            [-4.8864e-04],\n",
       "            [ 1.9288e-03],\n",
       "            [-1.4559e-03],\n",
       "            [-3.9611e-03],\n",
       "            [ 5.2251e-04],\n",
       "            [-6.5004e-04],\n",
       "            [-9.5112e-04],\n",
       "            [ 7.2124e-04],\n",
       "            [-9.2894e-04],\n",
       "            [ 1.4210e-03],\n",
       "            [-1.9065e-03],\n",
       "            [ 1.2160e-04],\n",
       "            [ 9.1864e-04]],\n",
       "  \n",
       "           [[-1.7476e-03],\n",
       "            [-1.2939e-03],\n",
       "            [ 6.8796e-04],\n",
       "            [ 3.3912e-03],\n",
       "            [-1.3779e-03],\n",
       "            [ 2.1461e-04],\n",
       "            [-9.0123e-04],\n",
       "            [ 8.8814e-04],\n",
       "            [-1.8864e-03],\n",
       "            [-1.5598e-03],\n",
       "            [-1.8535e-03],\n",
       "            [ 8.5927e-04],\n",
       "            [-5.4456e-04],\n",
       "            [ 1.1173e-03],\n",
       "            [-4.5042e-04],\n",
       "            [-1.3123e-03],\n",
       "            [ 1.4039e-03],\n",
       "            [ 2.6648e-03],\n",
       "            [ 3.9458e-03],\n",
       "            [ 1.5234e-03],\n",
       "            [ 1.3229e-03],\n",
       "            [ 2.3254e-03],\n",
       "            [ 2.3362e-03],\n",
       "            [ 2.3167e-03],\n",
       "            [ 1.6073e-04],\n",
       "            [ 2.3889e-04],\n",
       "            [-1.1998e-03],\n",
       "            [ 7.7246e-04],\n",
       "            [-1.0039e-03],\n",
       "            [ 6.2068e-04],\n",
       "            [-2.3163e-04],\n",
       "            [-1.2898e-03],\n",
       "            [-8.5890e-04],\n",
       "            [ 1.5209e-03],\n",
       "            [-8.0890e-04],\n",
       "            [ 3.4803e-03],\n",
       "            [ 2.9582e-03],\n",
       "            [-3.6589e-04],\n",
       "            [-3.8682e-03],\n",
       "            [ 3.8294e-04],\n",
       "            [ 5.8284e-03],\n",
       "            [ 7.6976e-03],\n",
       "            [ 2.3573e-03],\n",
       "            [ 3.9125e-03],\n",
       "            [ 2.7939e-03],\n",
       "            [ 1.1098e-03],\n",
       "            [ 5.5652e-04],\n",
       "            [-2.2830e-03],\n",
       "            [-3.1241e-05],\n",
       "            [ 7.8873e-04],\n",
       "            [-2.3132e-03],\n",
       "            [-3.4050e-03],\n",
       "            [ 1.8433e-03],\n",
       "            [-9.3361e-03],\n",
       "            [-4.5011e-03],\n",
       "            [-2.8527e-03],\n",
       "            [-1.3837e-03],\n",
       "            [-1.2856e-03],\n",
       "            [ 9.1937e-04],\n",
       "            [-5.9588e-03],\n",
       "            [-9.4508e-04],\n",
       "            [-4.2905e-04],\n",
       "            [-1.4582e-03],\n",
       "            [ 2.9968e-04]]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       "  tensor([[[[-0.0486]],\n",
       "  \n",
       "           [[ 0.0763]],\n",
       "  \n",
       "           [[-0.0067]],\n",
       "  \n",
       "           [[-0.0025]]],\n",
       "  \n",
       "  \n",
       "          [[[-0.0486]],\n",
       "  \n",
       "           [[ 0.0763]],\n",
       "  \n",
       "           [[-0.0067]],\n",
       "  \n",
       "           [[-0.0025]]]], device='cuda:0', grad_fn=<MaximumBackward0>)),\n",
       " 'conv_state': (tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0172, -0.2684,  0.1761,  ...,  0.3680, -0.4299, -0.1354]],\n",
       "  \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.5152, -0.8060, -0.8263,  ..., -0.0824,  0.8335, -0.6172]]],\n",
       "         device='cuda:0', grad_fn=<CopySlices>),)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_dict['block_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f050a8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2925ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4978,  1.5445,  1.2798, -1.4677, -2.1897,  0.7250,  0.6384,\n",
       "          -0.3543, -0.6553, -0.5294,  0.9895,  0.8925,  0.0369,  0.3600,\n",
       "           1.0671, -0.8967,  0.7769,  1.7208, -0.9602, -2.3994, -0.3734,\n",
       "          -0.0866,  1.4061,  0.0087, -0.7891, -0.0173, -1.9538, -0.3937,\n",
       "          -0.5488, -0.5184,  1.9376, -0.7643, -0.7506,  1.1501, -0.1561,\n",
       "           0.4513, -1.2406, -0.9217,  0.3434,  0.6700, -0.2392,  0.1344,\n",
       "          -0.0117, -0.9852, -1.2051,  0.3428, -0.1593, -1.8795, -0.0729,\n",
       "           1.1581,  0.8664,  0.4295, -0.0295,  0.2280,  1.7564,  0.3873,\n",
       "          -0.2153,  1.3113,  0.0999,  0.7173, -1.0597, -2.2170,  1.2809,\n",
       "          -1.7322,  0.5820,  1.3519,  0.9275, -0.4028,  0.1005,  0.5075,\n",
       "          -0.2481,  0.8091,  0.7399, -0.1949,  0.4818, -0.6697,  0.0183,\n",
       "           0.0428, -0.2187, -1.7713,  1.3467, -1.7573,  0.5467,  1.1787,\n",
       "           1.0028, -0.7336,  1.9220,  0.9596, -0.5030, -1.3327,  1.2682,\n",
       "           0.0318,  0.2944, -0.4946, -1.2384, -0.1656, -0.3940,  1.0485,\n",
       "          -0.4632, -1.1228, -0.5251,  0.5717,  0.2948, -0.4290,  0.0289,\n",
       "          -0.8129,  0.2868,  1.6683, -1.0464,  2.5269,  1.0870,  0.5450,\n",
       "           0.6013, -0.2129,  0.6708,  0.0966, -1.1242,  0.5395, -1.8758,\n",
       "          -0.4532, -1.4618,  0.8290, -1.4697, -1.6924,  1.1864, -0.0253,\n",
       "          -0.5767,  0.8827]],\n",
       "\n",
       "        [[ 0.9334, -1.2102, -0.0377, -0.9914,  1.1374, -0.6964, -2.1566,\n",
       "           0.0867, -1.2958, -0.8911, -0.4628, -0.1006,  1.1174, -1.4709,\n",
       "          -0.0618,  0.4479, -0.5596, -1.1242,  0.0741,  0.0120, -0.1888,\n",
       "           0.8209, -0.7181, -1.2087,  0.1952, -0.1759, -1.9716,  0.1519,\n",
       "           0.8163, -1.1344, -2.8472,  0.8609,  1.1940,  0.7629,  1.2135,\n",
       "           0.0656, -0.9970,  0.0897,  1.6817, -1.7808,  0.5168,  0.3522,\n",
       "          -1.0580,  1.0344,  0.2993,  1.1969,  1.0318,  0.2166, -0.1280,\n",
       "          -0.7411, -1.6344, -0.2734,  1.6382,  0.9097, -0.2570, -0.1459,\n",
       "           0.2190, -0.1522, -0.8757, -0.9675,  0.6123,  0.5670, -1.0976,\n",
       "           0.6741, -1.1917, -0.0072, -0.5910, -0.7187, -1.1439, -1.5196,\n",
       "           0.0703, -0.2792,  0.6984, -1.1594, -0.3775, -0.2540,  0.0112,\n",
       "           1.6391, -0.0964,  0.3535,  0.4311,  1.7643,  1.2465,  1.1254,\n",
       "          -0.5507,  1.0061,  1.1580,  0.6267,  0.5892,  0.0884,  0.1545,\n",
       "           0.9896,  0.4511,  1.7102,  0.8337, -0.1289, -1.5180,  0.6231,\n",
       "           0.0507, -1.5795, -1.3735,  2.8177,  0.8232, -0.5468,  0.5911,\n",
       "           0.0849, -1.4707,  2.3111, -0.5652,  0.2453,  0.1099,  1.5030,\n",
       "           0.7650,  0.2854,  1.1034, -0.7298, -0.8161, -2.6155,  0.7264,\n",
       "           0.3519,  1.5335,  0.7074, -0.1672, -0.3217, -0.4971, -0.0633,\n",
       "          -0.0332, -0.7820]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18339dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.8171e-01,  7.5984e-01,  1.3308e+00, -8.0911e-01, -7.1669e-01,\n",
       "           1.2324e-01,  6.4953e-01,  1.9917e-01, -2.8007e-02,  2.0094e-01,\n",
       "           8.0642e-01,  1.5618e+00, -3.5212e-01,  3.7325e-02,  9.7363e-01,\n",
       "          -6.5723e-01, -6.3216e-01, -2.7189e-01, -6.8714e-01, -2.0393e+00,\n",
       "          -3.4308e-02,  9.7309e-01, -2.3616e-01, -3.9586e-01, -6.4092e-02,\n",
       "           9.2531e-01, -2.7790e+00, -6.8198e-01, -1.6832e-02, -2.0715e-01,\n",
       "           2.5983e+00, -7.3946e-01, -1.0449e+00,  7.0546e-01,  1.0123e+00,\n",
       "           7.0937e-01, -5.6492e-01, -1.9830e+00, -2.7441e-01,  8.7571e-01,\n",
       "           1.7398e-02,  9.0983e-01,  1.3253e-01,  4.8852e-02, -1.4840e+00,\n",
       "          -2.9523e-02,  1.3925e+00,  1.0114e-01,  3.2748e-01,  1.0978e+00,\n",
       "          -8.5351e-01, -3.0628e-01, -4.6161e-01, -3.8436e-01,  1.0335e+00,\n",
       "           6.7830e-01, -3.3133e-01,  6.6896e-01, -4.6368e-01,  7.4131e-01,\n",
       "          -1.6848e+00, -1.2495e+00,  1.8919e+00, -6.0618e-01,  2.2224e+00,\n",
       "           9.6635e-01,  4.2401e-01,  1.1269e+00, -1.1653e-01,  1.1286e+00,\n",
       "          -1.2535e+00,  8.7811e-01,  6.8122e-01,  1.4079e+00, -6.4005e-01,\n",
       "          -4.5989e-01,  1.5494e-01,  2.7774e-03,  6.3177e-02, -1.0466e+00,\n",
       "           5.7080e-01, -9.7741e-01, -3.1996e-01,  1.3899e+00,  1.0370e+00,\n",
       "          -6.5162e-01,  4.1860e-01,  1.9799e+00,  1.0571e+00, -1.4456e+00,\n",
       "           1.4473e+00, -7.6656e-01,  7.1982e-01, -5.5781e-01, -1.1384e-01,\n",
       "          -8.1582e-01, -2.9180e-01,  9.1907e-01, -7.8861e-01, -9.0185e-01,\n",
       "           1.9076e-01, -6.4722e-01, -1.4857e-02,  1.6904e-01,  1.0597e+00,\n",
       "           6.2165e-01, -2.3145e-02,  3.5268e-01, -7.2788e-01,  2.1487e+00,\n",
       "           9.6088e-01,  1.2678e+00,  4.6572e-01, -1.4514e+00,  8.1127e-02,\n",
       "           6.4038e-01, -8.9556e-01,  4.9515e-02, -2.6099e-01, -7.8746e-01,\n",
       "          -2.9623e-01,  5.9028e-01, -1.9566e+00, -5.5886e-01,  1.3593e+00,\n",
       "           1.6644e-01, -7.0879e-01,  5.1795e-01]],\n",
       "\n",
       "        [[-6.9481e-01, -3.3496e-01, -2.7828e+00, -8.0376e-01,  4.3376e-01,\n",
       "          -1.0741e+00, -1.5963e+00, -8.8417e-01, -6.5766e-01, -5.2060e-01,\n",
       "          -1.0565e+00, -8.1344e-01,  7.3373e-01, -1.1279e+00, -1.2273e+00,\n",
       "          -7.7926e-01,  4.7679e-02, -7.0081e-01,  2.5808e-01, -3.0838e-01,\n",
       "          -6.4613e-01,  1.6163e+00, -9.1016e-01, -8.0878e-01, -6.8357e-02,\n",
       "          -1.4478e-01, -1.0830e+00,  5.8447e-01, -1.6431e-01, -3.1648e-01,\n",
       "          -2.2837e+00,  6.7378e-01,  3.5603e-01, -5.4729e-01,  1.6685e+00,\n",
       "           4.0609e-01,  2.6830e-01,  1.5550e+00,  1.6027e+00, -1.4875e+00,\n",
       "           1.3778e-03, -7.5260e-01, -7.1929e-01,  9.8138e-01, -3.0450e-01,\n",
       "           5.9015e-01,  1.0246e+00,  6.9005e-01,  3.4637e-03, -8.3053e-01,\n",
       "           4.4276e-01, -4.4566e-01,  1.1101e+00, -4.1343e-02,  6.3975e-01,\n",
       "          -1.0715e+00, -3.8311e-01, -8.0375e-01,  3.5566e-01, -3.7449e-02,\n",
       "           8.8641e-01, -8.9410e-01, -1.2865e+00,  5.0383e-01, -1.0347e-01,\n",
       "           1.0908e-01, -1.6730e+00, -4.2485e-01, -4.7244e-01,  3.3324e-01,\n",
       "           5.4684e-01, -4.0130e-02,  1.0211e+00, -3.9064e-01,  1.2668e+00,\n",
       "          -7.2437e-01,  1.2207e+00,  1.2659e-01, -7.8922e-01,  1.0378e-01,\n",
       "          -1.2252e-01,  1.2038e+00,  1.1310e+00,  2.1365e-01, -1.8951e-01,\n",
       "          -2.4226e-01,  5.3730e-01,  6.2443e-01,  1.8596e-01,  8.4706e-01,\n",
       "           6.7549e-01,  7.2867e-01,  5.5951e-01,  1.9297e+00, -4.9332e-01,\n",
       "          -8.3681e-02, -1.1987e+00,  6.4985e-01,  9.8057e-02, -1.4477e+00,\n",
       "          -7.4657e-01,  1.5699e+00, -1.2217e-02, -1.7952e-01,  3.4638e-01,\n",
       "          -6.4114e-01, -1.3560e-01,  1.3614e+00,  4.8611e-01, -7.4796e-01,\n",
       "           1.8114e-01,  1.2593e+00,  9.7829e-02, -6.6460e-02,  1.6142e+00,\n",
       "          -5.4310e-01,  2.1800e-02, -1.9007e+00, -8.7532e-01, -2.6255e-01,\n",
       "           2.4655e-01,  1.8631e+00, -1.2244e-01, -9.0577e-01, -9.0693e-01,\n",
       "          -1.1550e-02,  9.7653e-01, -6.5556e-02]]], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1, :].view(2,1,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "941e9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = xlstm_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a517df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8839,  0.6531, -0.8390, -0.1645,  1.6704,  0.5127, -0.0529,  0.2271,\n",
       "         -2.5904,  1.3150,  0.3769, -0.1745,  0.2888,  0.9407, -0.1206,  0.6557,\n",
       "          0.1330,  0.1118,  0.4273,  0.5373, -0.3927, -0.0368, -0.3819,  1.1103,\n",
       "          0.2225,  0.5210, -0.3059, -0.2255, -0.9224, -0.4568, -2.2560,  1.0137,\n",
       "         -0.1084, -0.6037,  0.5965, -0.5597, -0.5377, -0.5736,  0.8941, -2.7295,\n",
       "          1.3067,  0.7518,  0.9739,  0.5398, -0.4596,  0.3005, -0.3543, -0.9072,\n",
       "          0.3558,  0.1623,  0.5433, -0.9490,  0.1389, -1.0022, -1.1491, -0.3044,\n",
       "         -0.1395, -0.2475, -0.1755,  0.2795,  1.3190,  0.0260, -0.0259, -0.6402,\n",
       "         -0.3443, -1.1712,  0.2273, -0.3507,  1.4633, -0.2927,  1.0462,  1.0782,\n",
       "          0.0841, -0.4016,  0.4079,  0.1693,  0.1225,  0.6326,  0.0118, -1.4028,\n",
       "         -1.1295,  0.6233,  0.1547,  0.0442, -0.7434, -0.5714, -0.8025,  0.6202,\n",
       "          0.8696,  1.3488,  0.3080,  0.0314, -0.9079, -0.9560, -0.4306,  0.1162,\n",
       "         -0.6938,  0.3198, -0.6172, -0.0802,  0.4478,  0.6517,  0.3259, -0.6607,\n",
       "         -0.0058, -0.8933, -1.3278, -0.9682, -1.3721, -0.1751, -1.1058,  0.5873,\n",
       "          1.0897, -0.5731, -0.8285,  0.6343,  0.3317, -1.0103,  0.2368,  1.2283,\n",
       "         -0.5585, -1.4380, -0.4125,  0.0473, -0.3615, -0.7621, -2.7164, -0.4451],\n",
       "        [-0.3827,  0.6727, -0.3629,  0.4629,  0.0308,  0.8585, -1.8790, -0.6913,\n",
       "         -0.9136, -0.2676, -1.9039,  0.3693, -1.2268, -1.0328, -0.0491,  0.6238,\n",
       "         -1.5192, -1.8714,  1.8139, -0.1238,  0.2295, -0.6171,  0.7421,  0.6322,\n",
       "          0.7471, -0.9088, -0.9387,  0.0782, -0.1878,  0.5642, -0.6711,  0.9300,\n",
       "          0.2423, -0.0376,  0.4959,  0.3500,  0.3852,  2.1136,  0.1459,  0.8818,\n",
       "         -0.6836, -0.0776,  0.5029, -0.0239,  0.6573, -0.1307, -0.1154, -0.9019,\n",
       "         -0.5382,  0.7179,  0.3475,  1.2513, -0.8723,  1.6007,  0.4090, -1.0772,\n",
       "          1.9917, -1.8331,  1.0468,  1.0652, -0.4125,  0.2769,  0.0759, -1.5849,\n",
       "          0.8636,  0.5630,  1.4489,  0.5942, -1.9542,  0.9873, -0.1048,  0.2065,\n",
       "          1.6200,  1.4928, -1.3015, -1.9462,  1.8560,  0.9927, -0.9948, -2.2841,\n",
       "         -0.5198, -0.2991,  1.0433, -0.7337, -0.5173, -0.4010, -1.0583, -1.5304,\n",
       "         -0.6108, -0.7000, -1.5357,  0.1049, -0.3842, -0.3203,  0.3014, -1.0532,\n",
       "         -0.2254, -1.3821, -0.3260,  0.1846,  1.9155, -0.7575,  0.2046, -1.1032,\n",
       "         -0.3164, -0.4936, -1.0507, -2.2490,  1.4500, -0.6602,  0.6414,  0.6353,\n",
       "          1.8056,  0.6655, -1.1536, -1.6325,  0.5948,  1.4622, -0.8092,  0.4165,\n",
       "          0.4700, -0.3251, -0.3940,  0.7203,  1.4847, -0.2178, -0.5617,  0.9877]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a376563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.8777e-01,  7.0733e-01, -1.1354e+00,  6.8297e-02,  1.2867e+00,\n",
       "          8.6632e-01,  8.6892e-01,  9.2484e-01, -1.2396e+00,  1.7039e+00,\n",
       "         -1.0790e+00, -1.0183e+00, -6.6037e-01,  3.6460e-01,  9.4218e-01,\n",
       "         -9.8400e-02, -1.5814e+00,  4.7198e-01,  1.7564e+00,  1.6153e+00,\n",
       "          2.3493e-01,  2.9874e-01, -6.3176e-01,  7.8221e-01,  2.1035e+00,\n",
       "          3.4908e-01, -2.4726e+00,  9.4857e-01, -6.0690e-01,  6.2530e-01,\n",
       "         -4.8214e+00,  1.9170e+00, -3.0467e-01, -5.0227e-01,  8.7043e-01,\n",
       "         -4.5736e-01,  4.8147e-03, -5.5708e-01,  2.0257e-01, -2.0661e+00,\n",
       "          9.1403e-01,  1.8090e+00,  2.6168e-01,  1.3294e+00, -2.0494e+00,\n",
       "         -1.7052e+00, -5.7928e-01, -7.9424e-01,  9.7212e-01,  2.6963e-01,\n",
       "          2.0599e+00,  3.2527e-02,  1.6426e+00, -1.7454e+00,  1.4678e+00,\n",
       "         -6.0697e-01,  5.2550e-01,  4.7229e-01, -5.6340e-01, -1.4185e+00,\n",
       "          1.2872e+00, -1.8675e+00, -5.2358e-01, -6.4815e-01, -3.6819e-01,\n",
       "         -1.1029e+00,  3.5903e-01, -6.5322e-01,  2.1855e+00, -9.8429e-01,\n",
       "          4.7338e-02,  1.9631e+00,  2.3712e-01, -3.2350e-01,  1.0997e+00,\n",
       "         -1.3424e+00,  4.0225e-01,  2.9826e+00,  1.8755e+00,  3.0315e-01,\n",
       "         -2.6439e+00,  1.1850e+00, -1.6624e-01,  2.4756e+00, -1.8235e+00,\n",
       "         -1.2479e+00, -3.8709e-01, -3.6853e-03,  4.8232e-01,  9.0048e-01,\n",
       "         -4.8087e-01, -1.9007e+00, -8.6864e-01, -1.6412e+00, -2.4140e-01,\n",
       "         -1.2030e-01, -5.9634e-01,  2.2609e-01, -8.4867e-01, -5.4964e-01,\n",
       "          9.4604e-01,  1.1193e-01,  1.7950e+00, -7.7007e-01, -2.2277e+00,\n",
       "         -1.0216e+00, -2.3193e+00, -7.6367e-01, -9.2248e-01, -4.1240e-01,\n",
       "         -1.2538e+00, -4.0597e-01,  2.0933e+00, -3.2336e-01, -1.0468e+00,\n",
       "          1.2108e+00,  1.7244e+00, -1.7337e+00, -6.0633e-02,  2.0858e+00,\n",
       "         -2.4479e+00, -3.4970e+00, -1.5893e+00,  2.1653e+00,  1.1738e+00,\n",
       "         -5.0309e-01, -1.7179e+00,  8.2249e-01],\n",
       "        [-7.7607e-01,  7.9096e-01, -4.5531e-01,  1.3640e+00, -4.1790e-01,\n",
       "          1.6173e+00, -9.0503e-01, -1.1564e+00, -1.6561e+00,  5.8542e-01,\n",
       "         -2.8300e+00,  3.3120e-02,  4.6051e-02, -5.8380e-01, -2.8246e-01,\n",
       "          6.9055e-01, -1.9752e+00, -1.8799e+00,  4.1304e+00,  7.7659e-01,\n",
       "         -1.0225e+00,  1.2650e+00, -6.0231e-01,  1.1616e+00,  1.4708e+00,\n",
       "         -1.5379e+00, -8.1291e-01, -2.2182e+00,  1.1417e+00,  5.1248e-03,\n",
       "         -2.2913e+00,  3.8535e-01, -2.8455e-01, -9.9707e-01,  1.1484e-01,\n",
       "          2.4217e-01,  5.8775e-02,  1.9382e+00, -3.7781e-01, -1.2148e+00,\n",
       "         -1.1922e+00,  1.6484e+00,  6.2771e-01, -1.3431e+00,  2.3404e+00,\n",
       "          7.5461e-01,  1.0526e+00,  1.2947e+00,  2.4429e-02,  3.4572e-01,\n",
       "          7.3915e-01,  1.9359e-01, -1.1139e+00,  3.7749e+00,  2.4437e-01,\n",
       "         -9.9601e-01,  3.3257e+00, -1.9338e+00, -2.0381e-01,  7.6811e-01,\n",
       "         -7.5693e-01, -6.0249e-02, -4.9941e-01, -2.4407e+00,  9.3638e-01,\n",
       "          5.4791e-01,  1.1277e+00,  8.8687e-01, -2.1569e+00, -9.6181e-02,\n",
       "          7.3453e-02,  1.2264e-01,  7.5122e-01,  3.0090e+00, -6.6579e-01,\n",
       "         -2.5155e+00,  3.2339e+00, -9.9963e-01,  3.2716e-01, -1.9679e+00,\n",
       "         -4.3306e-01,  2.8259e-01,  1.6089e+00,  3.1172e-01, -2.4559e+00,\n",
       "         -9.8379e-01,  8.5528e-01, -1.4282e+00, -1.1079e+00, -2.0211e+00,\n",
       "          5.8212e-01, -8.9954e-01, -1.2386e+00, -2.2073e-01,  5.1236e-01,\n",
       "         -1.5990e+00,  9.2565e-03, -1.9688e+00, -4.5214e-01, -2.4236e-01,\n",
       "          1.6053e+00, -1.0878e+00,  2.6744e-01, -1.8616e+00, -1.2423e+00,\n",
       "         -2.5155e-01, -2.4363e+00, -3.7161e+00,  3.0693e+00, -1.8987e+00,\n",
       "          4.4557e-01,  1.0513e+00,  1.7520e+00,  9.4038e-01,  4.9629e-01,\n",
       "         -2.7692e+00,  1.9345e+00,  2.8626e+00,  6.3561e-01,  2.0574e+00,\n",
       "         -4.8814e-01, -3.9396e-01, -7.7253e-01,  6.5247e-01,  2.6302e+00,\n",
       "         -8.7039e-01,  7.7251e-01, -6.6832e-01]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df10283a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 128])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9840dbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8577, -1.1099, -0.3923,  ...,  0.0940,  0.0937,  0.7333],\n",
      "         [ 0.8142,  0.0359,  0.3861,  ..., -0.1010, -0.7600, -0.0066],\n",
      "         [ 2.4055, -1.4971,  0.7610,  ..., -0.5647,  1.4988, -1.2182],\n",
      "         ...,\n",
      "         [-1.9958,  0.2881,  0.2207,  ...,  0.1564, -1.6645, -0.3780],\n",
      "         [-0.4549,  0.3158, -0.3409,  ...,  0.4510, -0.3832,  1.3363],\n",
      "         [-0.8845, -0.6907,  0.5125,  ...,  1.1808, -1.4142,  1.1701]],\n",
      "\n",
      "        [[ 0.8740, -2.0196,  0.3545,  ..., -0.7747, -0.1946, -1.2063],\n",
      "         [-0.3995,  0.4758,  0.2324,  ...,  1.6014, -0.7852,  0.3335],\n",
      "         [ 0.2124, -0.1924, -0.0830,  ...,  0.5713,  1.6000,  1.5129],\n",
      "         ...,\n",
      "         [-0.1742,  1.3780, -0.5989,  ...,  0.0386, -0.5372,  1.5216],\n",
      "         [ 0.4534,  0.9240, -0.4873,  ...,  0.6691, -0.8149,  1.2498],\n",
      "         [-0.2121, -0.4231, -1.2146,  ...,  0.4834,  1.7986, -0.7707]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9fa31d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1480, -1.0595,  2.0452, -0.0863, -0.1370,  2.0175, -0.4361,\n",
      "          -0.1611, -1.5872,  1.1023, -2.6816,  0.6252,  1.0867, -1.2995,\n",
      "          -0.2884,  1.1804,  1.3891, -1.3155,  0.1274, -3.0621, -4.0834,\n",
      "           1.0835,  0.5426,  0.4090,  1.8845,  0.7048, -2.5606, -0.6336,\n",
      "          -0.5072, -0.1934, -0.1107,  4.0092, -0.6715, -0.6509, -1.7275,\n",
      "           0.2459,  0.1660,  1.4571, -1.2948, -2.2396, -1.9346, -0.5495,\n",
      "           1.1377, -0.1067,  0.4261, -0.1087, -0.5682,  5.4285,  0.8706,\n",
      "           1.8102, -1.4242,  0.7603, -0.2171, -1.3306, -0.8624,  1.6319,\n",
      "          -0.9979, -0.4409,  0.2527, -0.4009, -2.9918, -2.7180,  0.6599,\n",
      "          -0.0263, -0.8976,  1.0564,  0.7353, -0.1279, -0.2253, -0.8580,\n",
      "           1.5953, -1.0426,  2.8536, -2.9724, -2.6748,  0.6674,  0.2355,\n",
      "           0.4488,  3.3318, -1.6286,  0.3944, -1.5674,  0.0701,  0.0965,\n",
      "           2.1487, -0.0439, -0.0311, -1.9621,  2.6495,  1.4265,  1.3333,\n",
      "           0.7164, -3.4484, -1.8838, -0.6050,  2.5486, -0.8059, -0.5637,\n",
      "           0.1255,  0.2867,  0.6235,  2.1331, -2.1081, -0.1586, -1.8509,\n",
      "          -0.0214,  0.9245,  0.3611, -0.9547,  1.1558, -1.0693, -2.4451,\n",
      "           0.7093, -0.5890,  0.1410,  1.3126, -0.6508, -1.4434, -0.5006,\n",
      "          -2.7367, -0.5864, -0.4888,  0.2231, -1.1984,  1.2541,  2.6641,\n",
      "          -1.4962,  0.1091],\n",
      "         [-2.0870, -0.0983,  0.5668, -0.4324,  1.0654, -0.6384, -0.2609,\n",
      "          -1.4670,  0.3880, -1.5677, -0.0985, -1.0433, -0.4949,  0.2063,\n",
      "           0.7126,  1.2308,  0.3282, -0.0658, -0.0805,  2.8441, -1.4153,\n",
      "           0.3099,  3.3654, -0.2192,  0.3791, -1.0280, -1.2306,  2.9627,\n",
      "          -1.2756, -0.4061, -2.5895, -3.1035, -1.0896,  0.1018, -1.4100,\n",
      "          -0.5312,  1.4615, -1.0449, -1.3888, -1.6502,  0.1526, -2.6744,\n",
      "          -0.1781,  0.7281, -0.7773, -1.0685, -0.9596, -1.4403, -0.9191,\n",
      "          -0.0148, -0.6152, -0.9176, -1.8729, -1.5484, -0.6618,  1.5877,\n",
      "           1.5973,  0.3003, -0.8633,  1.5330, -1.6578, -0.2430,  2.1612,\n",
      "           2.7347, -0.1967,  0.4263, -0.0972, -1.3968,  0.1985,  2.1294,\n",
      "          -0.5306,  1.1960, -0.5846, -0.6870,  0.1140, -1.5758,  1.1071,\n",
      "          -1.2173, -0.5227,  0.0138, -3.1062,  2.4040, -1.9325, -1.3027,\n",
      "          -0.0821, -0.2135, -1.1811, -0.1238, -0.4193, -3.6282,  2.0588,\n",
      "           1.2508, -0.2063,  0.7860, -1.3420, -0.5838,  1.5116, -0.7512,\n",
      "           0.1340,  0.4318,  0.0472, -1.5990,  0.3333,  1.4573, -0.1115,\n",
      "           1.3645, -1.3308,  1.7445, -0.5798,  0.1030,  2.8135,  1.4825,\n",
      "          -0.9390,  0.0997,  1.4260,  1.1132, -1.6760,  1.1526,  1.2560,\n",
      "          -2.2271,  2.4074,  1.8287, -0.6618, -1.5050,  1.4916,  0.1344,\n",
      "           0.9490, -2.4933]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pprint(y[:, -1, :].view(1, -1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93cac937",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ()\n",
    "for i in range(5):\n",
    "    t += (i,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8dd057cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a162b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 2, batch_first=True)\n",
    "inpt = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 5, 20)\n",
    "c0 = torch.randn(2, 5, 20)\n",
    "output, (hn, cn) = rnn(inpt, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f528b23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ea8955b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 20])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cb41ca31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2291,  0.0706, -0.2873, -0.0193,  0.0982,  0.1942,  0.0228, -0.1276,\n",
       "          0.0790,  0.0730, -0.1216,  0.0562,  0.1600,  0.1633, -0.0206, -0.0394,\n",
       "         -0.0367, -0.0733,  0.1518, -0.1802],\n",
       "        [-0.1929,  0.1946,  0.0548, -0.1062,  0.0587,  0.0891, -0.0085, -0.0888,\n",
       "          0.0230,  0.2114,  0.1167,  0.1953,  0.0377, -0.0480, -0.0815,  0.1854,\n",
       "          0.0207, -0.0434, -0.0672, -0.1421],\n",
       "        [-0.2902,  0.2361, -0.2112, -0.0509, -0.0608,  0.1652, -0.0098, -0.1355,\n",
       "          0.1445,  0.1078,  0.0399,  0.1191,  0.0123, -0.0428,  0.0851, -0.0684,\n",
       "         -0.2345, -0.0469,  0.2690,  0.1379],\n",
       "        [-0.2975,  0.0864,  0.1136, -0.1358,  0.0094,  0.1324,  0.0084, -0.1017,\n",
       "         -0.1106,  0.1565, -0.1292,  0.1546, -0.0853, -0.1034,  0.0358,  0.1535,\n",
       "         -0.0611, -0.0737, -0.1640, -0.1349],\n",
       "        [-0.0851,  0.1141,  0.2472, -0.2493, -0.1072,  0.0791, -0.1482, -0.1104,\n",
       "          0.1480,  0.1121,  0.0041,  0.1225,  0.1576,  0.0570, -0.0797, -0.0238,\n",
       "         -0.1713, -0.0056,  0.1925,  0.1231]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8205b2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2291,  0.0706, -0.2873, -0.0193,  0.0982,  0.1942,  0.0228, -0.1276,\n",
       "          0.0790,  0.0730, -0.1216,  0.0562,  0.1600,  0.1633, -0.0206, -0.0394,\n",
       "         -0.0367, -0.0733,  0.1518, -0.1802],\n",
       "        [-0.1929,  0.1946,  0.0548, -0.1062,  0.0587,  0.0891, -0.0085, -0.0888,\n",
       "          0.0230,  0.2114,  0.1167,  0.1953,  0.0377, -0.0480, -0.0815,  0.1854,\n",
       "          0.0207, -0.0434, -0.0672, -0.1421],\n",
       "        [-0.2902,  0.2361, -0.2112, -0.0509, -0.0608,  0.1652, -0.0098, -0.1355,\n",
       "          0.1445,  0.1078,  0.0399,  0.1191,  0.0123, -0.0428,  0.0851, -0.0684,\n",
       "         -0.2345, -0.0469,  0.2690,  0.1379],\n",
       "        [-0.2975,  0.0864,  0.1136, -0.1358,  0.0094,  0.1324,  0.0084, -0.1017,\n",
       "         -0.1106,  0.1565, -0.1292,  0.1546, -0.0853, -0.1034,  0.0358,  0.1535,\n",
       "         -0.0611, -0.0737, -0.1640, -0.1349],\n",
       "        [-0.0851,  0.1141,  0.2472, -0.2493, -0.1072,  0.0791, -0.1482, -0.1104,\n",
       "          0.1480,  0.1121,  0.0041,  0.1225,  0.1576,  0.0570, -0.0797, -0.0238,\n",
       "         -0.1713, -0.0056,  0.1925,  0.1231]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80ab75",
   "metadata": {},
   "source": [
    "# Model prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a64aaa",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd89b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xLSTMtime(WeightDecayOptimGroupMixin, nn.Module):\n",
    "    def __init__(self, input_size, output_size, xlstm_blockstack_config):\n",
    "        super(xLSTMtime, self).__init__()\n",
    "        self.fc_in = nn.Linear(in_features=input_size, out_features=xlstm_blockstack_config.embedding_dim)\n",
    "        self.xlstm = xLSTMBlockStack(xlstm_blockstack_config)\n",
    "        self.fc_out = nn.Linear(in_features=xlstm_blockstack_config.embedding_dim, out_features=output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = self.xlstm(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "    def forecast(self, input_seq, num_steps: int) -> list:\n",
    "        assert num_steps > 0, '`num_steps` should be greater than zero!'\n",
    "        batch_size, seq_len, in_features = input_seq.shape\n",
    "        res_preds = []\n",
    "        \n",
    "        for i in range(num_steps):\n",
    "            next_el = self.forward(input_seq)\n",
    "            next_el = next_el[:,-1,:].view(batch_size, 1, in_features)\n",
    "            res_preds.append(next_el)\n",
    "            input_seq = torch.cat((input_seq, next_el), dim=1)[:, 1:, :] # concatenate along `seq_len` axis\n",
    "        \n",
    "        res_preds = torch.cat(res_preds, dim=1).view(num_steps, in_features)\n",
    "        \n",
    "        return res_preds\n",
    "    \n",
    "    def _create_weight_decay_optim_groups(self, **kwargs):\n",
    "        weight_decay, no_weight_decay = super()._create_weight_decay_optim_groups(**kwargs)\n",
    "        # remove token embedding and add it to the correct group, accrording to the config\n",
    "        weight_decay = list(weight_decay)\n",
    "        removed = 0\n",
    "        for idx in range(len(weight_decay)):\n",
    "            if weight_decay[idx - removed] is self.token_embedding.weight:\n",
    "                weight_decay.pop(idx - removed)\n",
    "                removed += 1\n",
    "        weight_decay = tuple(weight_decay)\n",
    "        if self.config.weight_decay_on_embedding:\n",
    "            weight_decay += (self.token_embedding.weight,)\n",
    "        else:\n",
    "            no_weight_decay += (self.token_embedding.weight,)\n",
    "\n",
    "        return weight_decay, no_weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8084c46",
   "metadata": {},
   "source": [
    "## Test config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24440399",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cfg_str = f\"\"\"\n",
    "mlstm_block:\n",
    "  mlstm:\n",
    "    conv1d_kernel_size: 4\n",
    "    qkv_proj_blocksize: 4\n",
    "    num_heads: 4\n",
    "slstm_block:\n",
    "  slstm:\n",
    "    backend: {'cuda' if torch.cuda.is_available() else 'vanilla'} #! only vanilla here works\n",
    "    num_heads: 4\n",
    "    conv1d_kernel_size: 4\n",
    "    bias_init: powerlaw_blockdependent\n",
    "  feedforward:\n",
    "    proj_factor: 1.3\n",
    "    act_fn: gelu\n",
    "context_length: 100\n",
    "num_blocks: 4\n",
    "embedding_dim: 64\n",
    "add_post_blocks_norm: True\n",
    "slstm_at: [1] #[1] # for [] it also works, so if no sLSTM is in the stack\n",
    "\"\"\"\n",
    "\n",
    "training_cfg = {\n",
    "    'weight_decay': 0.1,\n",
    "    'lr_warmup_steps': 100,\n",
    "    'lr_decay_until_steps': 360,\n",
    "    'lr': 0.001,\n",
    "    'lr_decay_factor': 0.9,\n",
    "    'num_steps': 360,\n",
    "}\n",
    "\n",
    "test_cfg = OmegaConf.create(test_cfg_str)\n",
    "test_cfg = from_dict(data_class=xLSTMBlockStackConfig, data=OmegaConf.to_container(test_cfg), config=DaciteConfig(strict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d4386",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "077da337",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstmtime = xLSTMtime(\n",
    "    input_size=1,\n",
    "    output_size=1,\n",
    "    xlstm_blockstack_config=test_cfg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d35defdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstmtime = xlstmtime.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753fb551",
   "metadata": {},
   "source": [
    "## Test input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ebfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn(2, 50, 1).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbc4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = xlstmtime(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c81ba2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[:,-1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8382a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3219],\n",
       "        [-1.0757]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[:,-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2dc48",
   "metadata": {},
   "source": [
    "## Test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91860069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 00:31:28,852 - xlstm_moex.data.download - INFO - Finished downloading data, 1261 rows and 23 columns\n",
      "2024-10-14 00:31:28,863 - xlstm_moex.data.download - INFO - Saved to data/train/sber_20150901_20200901.csv\n"
     ]
    }
   ],
   "source": [
    "await get_historical_data(\n",
    "    output_filename='data/train/sber_20150901_20200901.csv',\n",
    "    stock='SBER',\n",
    "    start_date='2015-09-01',\n",
    "    end_date='2020-09-01'\n",
    ")\n",
    "\n",
    "# await get_historical_candels(\n",
    "#     output_filename='yndx_20150901_20200901_hourly.csv',\n",
    "#     stock='YNDX',\n",
    "#     start_date='2015-09-01',\n",
    "#     end_date='2020-09-01'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68474a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>value</th>\n",
       "      <th>volume</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>797.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>1992500.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>2015-09-01 09:00:00</td>\n",
       "      <td>2015-09-01 09:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>797.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>9389526.0</td>\n",
       "      <td>11766</td>\n",
       "      <td>2015-09-01 10:00:00</td>\n",
       "      <td>2015-09-01 10:58:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>1652036.0</td>\n",
       "      <td>2065</td>\n",
       "      <td>2015-09-01 11:00:00</td>\n",
       "      <td>2015-09-01 11:59:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>18560903.0</td>\n",
       "      <td>23464</td>\n",
       "      <td>2015-09-01 12:00:00</td>\n",
       "      <td>2015-09-01 12:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>791.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>787.0</td>\n",
       "      <td>3980384.0</td>\n",
       "      <td>5038</td>\n",
       "      <td>2015-09-01 13:00:00</td>\n",
       "      <td>2015-09-01 13:59:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    open  close   high    low       value  volume                begin  \\\n",
       "0  797.0  797.0  797.0  797.0   1992500.0    2500  2015-09-01 09:00:00   \n",
       "1  797.0  800.0  807.0  793.0   9389526.0   11766  2015-09-01 10:00:00   \n",
       "2  801.0  801.0  802.0  798.0   1652036.0    2065  2015-09-01 11:00:00   \n",
       "3  801.0  792.0  801.0  783.0  18560903.0   23464  2015-09-01 12:00:00   \n",
       "4  791.0  790.0  793.0  787.0   3980384.0    5038  2015-09-01 13:00:00   \n",
       "\n",
       "                   end  \n",
       "0  2015-09-01 09:59:59  \n",
       "1  2015-09-01 10:58:05  \n",
       "2  2015-09-01 11:59:06  \n",
       "3  2015-09-01 12:59:59  \n",
       "4  2015-09-01 13:59:59  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('yndx_20150901_20200901_hourly.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d5d8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_raw = (\n",
    "#     pd\n",
    "#     .read_csv('yndx_20150901_20200901_hourly.csv')\n",
    "#     .sort_values(by=['TRADEDATE'], ascending=[True])\n",
    "#     ['OPEN']\n",
    "#     .to_list()\n",
    "# )\n",
    "\n",
    "test_data_raw = (\n",
    "    pd\n",
    "    .read_csv('yndx_20150901_20200901_hourly.csv')\n",
    "    .sort_values(by=['begin'], ascending=[True])\n",
    "    ['open']\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "test_data = [\n",
    "    test_data_raw[i+1] - test_data_raw[i] for i in range(len(test_data_raw) - 1)\n",
    "]\n",
    "\n",
    "test_data_mean = np.mean(test_data)\n",
    "test_data_std = np.std(test_data)\n",
    "\n",
    "test_data = [(el - test_data_mean)/test_data_std for el in test_data]\n",
    "\n",
    "# test_data = [\n",
    "#     (test_data_raw[i+1] - test_data_raw[i])/test_data_raw[i] for i in range(len(test_data_raw) - 1)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "271bb3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12626"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e97c66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_examples = []\n",
    "y_examples = []\n",
    "for i in range(len(test_data) - 100 - 1):\n",
    "    X_examples.append(test_data[i:i+100])\n",
    "    y_examples.append(test_data[i+100])\n",
    "X_examples = np.array(X_examples)\n",
    "y_examples = np.array(y_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd1749bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02223163,  0.24412185, -0.02223163, ...,  0.24412185,\n",
       "         0.04435674,  0.11094511],\n",
       "       [ 0.24412185, -0.02223163, -0.68811534, ...,  0.04435674,\n",
       "         0.11094511,  0.04435674],\n",
       "       [-0.02223163, -0.68811534, -0.08882   , ...,  0.11094511,\n",
       "         0.04435674,  1.77565436],\n",
       "       ...,\n",
       "       [-0.54162092,  2.94760967, -2.04651809, ..., -2.00656506,\n",
       "        -3.37828549, -1.54044647],\n",
       "       [ 2.94760967, -2.04651809, -1.06101021, ..., -3.37828549,\n",
       "        -1.54044647,  0.31071022],\n",
       "       [-2.04651809, -1.06101021,  0.72355811, ..., -1.54044647,\n",
       "         0.31071022, -0.59489162]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7852ff94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04435674,  1.77565436, -1.02105719, ...,  0.31071022,\n",
       "       -0.59489162,  0.41725161])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f42f619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014312128962596412"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6aa3751f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.003085110828085"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f0e4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__()\n",
    "        self.X = torch.from_numpy(X.astype('float32')).to(device=device).reshape(-1, 100 , 1)\n",
    "        self.y = torch.from_numpy(y.astype('float32')).to(device=device)\n",
    "        print(self.X.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e312d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12525, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "dataset = TimeSeriesDataset(X=X_examples, y=y_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de0954d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0b8500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in dataloader:\n",
    "    print(X_batch.shape)\n",
    "    print(y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c32d32",
   "metadata": {},
   "source": [
    "## Test train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "573a1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(\n",
    "    xlstmtime.parameters(),\n",
    "    lr=training_cfg['lr'],\n",
    ")\n",
    "lr_scheduler = LinearWarmupCosineAnnealing(\n",
    "    optimizer,\n",
    "    training_cfg['lr_warmup_steps'],\n",
    "    training_cfg['lr_decay_until_steps'],\n",
    "    training_cfg['lr'],\n",
    "    training_cfg['lr_decay_factor'] * training_cfg['lr'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcf6a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(xlstmtime.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46dedc9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/360], Batch [5/196], Loss: 0.9646\n",
      "Epoch [1/360], Batch [10/196], Loss: 0.9817\n",
      "Epoch [1/360], Batch [15/196], Loss: 2.2933\n",
      "Epoch [1/360], Batch [20/196], Loss: 1.4015\n",
      "Epoch [1/360], Batch [25/196], Loss: 0.7827\n",
      "Epoch [1/360], Batch [30/196], Loss: 0.8648\n",
      "Epoch [1/360], Batch [35/196], Loss: 0.6643\n",
      "Epoch [1/360], Batch [40/196], Loss: 1.0194\n",
      "Epoch [1/360], Batch [45/196], Loss: 0.5376\n",
      "Epoch [1/360], Batch [50/196], Loss: 0.8918\n",
      "Epoch [1/360], Batch [55/196], Loss: 0.6637\n",
      "Epoch [1/360], Batch [60/196], Loss: 0.5079\n",
      "Epoch [1/360], Batch [65/196], Loss: 0.9679\n",
      "Epoch [1/360], Batch [70/196], Loss: 0.5983\n",
      "Epoch [1/360], Batch [75/196], Loss: 0.8783\n",
      "Epoch [1/360], Batch [80/196], Loss: 0.6654\n",
      "Epoch [1/360], Batch [85/196], Loss: 1.1761\n",
      "Epoch [1/360], Batch [90/196], Loss: 1.1226\n",
      "Epoch [1/360], Batch [95/196], Loss: 0.8961\n",
      "Epoch [1/360], Batch [100/196], Loss: 0.8152\n",
      "Epoch [1/360], Batch [105/196], Loss: 0.5586\n",
      "Epoch [1/360], Batch [110/196], Loss: 5.7590\n",
      "Epoch [1/360], Batch [115/196], Loss: 1.2156\n",
      "Epoch [1/360], Batch [120/196], Loss: 0.6102\n",
      "Epoch [1/360], Batch [125/196], Loss: 1.9463\n",
      "Epoch [1/360], Batch [130/196], Loss: 1.2373\n",
      "Epoch [1/360], Batch [135/196], Loss: 0.5973\n",
      "Epoch [1/360], Batch [140/196], Loss: 0.7398\n",
      "Epoch [1/360], Batch [145/196], Loss: 1.5376\n",
      "Epoch [1/360], Batch [150/196], Loss: 0.5347\n",
      "Epoch [1/360], Batch [155/196], Loss: 0.9197\n",
      "Epoch [1/360], Batch [160/196], Loss: 1.2389\n",
      "Epoch [1/360], Batch [165/196], Loss: 0.5931\n",
      "Epoch [1/360], Batch [170/196], Loss: 1.4957\n",
      "Epoch [1/360], Batch [175/196], Loss: 0.9142\n",
      "Epoch [1/360], Batch [180/196], Loss: 1.7807\n",
      "Epoch [1/360], Batch [185/196], Loss: 1.5189\n",
      "Epoch [1/360], Batch [190/196], Loss: 0.5773\n",
      "Epoch [1/360], Batch [195/196], Loss: 0.4824\n",
      "Epoch [2/360], Batch [5/196], Loss: 1.4806\n",
      "Epoch [2/360], Batch [10/196], Loss: 0.4512\n",
      "Epoch [2/360], Batch [15/196], Loss: 0.5316\n",
      "Epoch [2/360], Batch [20/196], Loss: 1.5269\n",
      "Epoch [2/360], Batch [25/196], Loss: 0.4674\n",
      "Epoch [2/360], Batch [30/196], Loss: 4.0233\n",
      "Epoch [2/360], Batch [35/196], Loss: 0.3657\n",
      "Epoch [2/360], Batch [40/196], Loss: 0.6166\n",
      "Epoch [2/360], Batch [45/196], Loss: 2.1647\n",
      "Epoch [2/360], Batch [50/196], Loss: 0.6886\n",
      "Epoch [2/360], Batch [55/196], Loss: 0.4722\n",
      "Epoch [2/360], Batch [60/196], Loss: 7.0023\n",
      "Epoch [2/360], Batch [65/196], Loss: 1.2772\n",
      "Epoch [2/360], Batch [70/196], Loss: 2.1972\n",
      "Epoch [2/360], Batch [75/196], Loss: 4.7487\n",
      "Epoch [2/360], Batch [80/196], Loss: 0.6762\n",
      "Epoch [2/360], Batch [85/196], Loss: 0.7267\n",
      "Epoch [2/360], Batch [90/196], Loss: 0.4629\n",
      "Epoch [2/360], Batch [95/196], Loss: 1.4312\n",
      "Epoch [2/360], Batch [100/196], Loss: 1.0375\n",
      "Epoch [2/360], Batch [105/196], Loss: 0.9759\n",
      "Epoch [2/360], Batch [110/196], Loss: 0.3750\n",
      "Epoch [2/360], Batch [115/196], Loss: 0.4552\n",
      "Epoch [2/360], Batch [120/196], Loss: 1.8640\n",
      "Epoch [2/360], Batch [125/196], Loss: 0.8497\n",
      "Epoch [2/360], Batch [130/196], Loss: 2.2253\n",
      "Epoch [2/360], Batch [135/196], Loss: 0.8410\n",
      "Epoch [2/360], Batch [140/196], Loss: 1.2001\n",
      "Epoch [2/360], Batch [145/196], Loss: 0.9840\n",
      "Epoch [2/360], Batch [150/196], Loss: 2.0580\n",
      "Epoch [2/360], Batch [155/196], Loss: 0.9605\n",
      "Epoch [2/360], Batch [160/196], Loss: 0.4132\n",
      "Epoch [2/360], Batch [165/196], Loss: 0.9227\n",
      "Epoch [2/360], Batch [170/196], Loss: 1.0323\n",
      "Epoch [2/360], Batch [175/196], Loss: 0.7486\n",
      "Epoch [2/360], Batch [180/196], Loss: 0.4557\n",
      "Epoch [2/360], Batch [185/196], Loss: 1.3977\n",
      "Epoch [2/360], Batch [190/196], Loss: 0.4855\n",
      "Epoch [2/360], Batch [195/196], Loss: 2.1410\n",
      "Epoch [3/360], Batch [5/196], Loss: 0.6214\n",
      "Epoch [3/360], Batch [10/196], Loss: 0.2119\n",
      "Epoch [3/360], Batch [15/196], Loss: 0.7977\n",
      "Epoch [3/360], Batch [20/196], Loss: 0.7463\n",
      "Epoch [3/360], Batch [25/196], Loss: 0.5520\n",
      "Epoch [3/360], Batch [30/196], Loss: 0.7146\n",
      "Epoch [3/360], Batch [35/196], Loss: 0.9373\n",
      "Epoch [3/360], Batch [40/196], Loss: 0.4729\n",
      "Epoch [3/360], Batch [45/196], Loss: 0.6358\n",
      "Epoch [3/360], Batch [50/196], Loss: 0.5476\n",
      "Epoch [3/360], Batch [55/196], Loss: 0.7600\n",
      "Epoch [3/360], Batch [60/196], Loss: 0.8076\n",
      "Epoch [3/360], Batch [65/196], Loss: 0.5605\n",
      "Epoch [3/360], Batch [70/196], Loss: 1.2213\n",
      "Epoch [3/360], Batch [75/196], Loss: 1.8277\n",
      "Epoch [3/360], Batch [80/196], Loss: 1.0050\n",
      "Epoch [3/360], Batch [85/196], Loss: 0.9354\n",
      "Epoch [3/360], Batch [90/196], Loss: 1.0433\n",
      "Epoch [3/360], Batch [95/196], Loss: 0.4612\n",
      "Epoch [3/360], Batch [100/196], Loss: 1.1421\n",
      "Epoch [3/360], Batch [105/196], Loss: 0.4283\n",
      "Epoch [3/360], Batch [110/196], Loss: 0.8113\n",
      "Epoch [3/360], Batch [115/196], Loss: 0.8512\n",
      "Epoch [3/360], Batch [120/196], Loss: 1.3488\n",
      "Epoch [3/360], Batch [125/196], Loss: 0.4645\n",
      "Epoch [3/360], Batch [130/196], Loss: 0.7600\n",
      "Epoch [3/360], Batch [135/196], Loss: 1.1551\n",
      "Epoch [3/360], Batch [140/196], Loss: 1.5069\n",
      "Epoch [3/360], Batch [145/196], Loss: 0.5022\n",
      "Epoch [3/360], Batch [150/196], Loss: 0.7675\n",
      "Epoch [3/360], Batch [155/196], Loss: 1.3496\n",
      "Epoch [3/360], Batch [160/196], Loss: 0.6377\n",
      "Epoch [3/360], Batch [165/196], Loss: 1.4352\n",
      "Epoch [3/360], Batch [170/196], Loss: 0.7469\n",
      "Epoch [3/360], Batch [175/196], Loss: 1.0397\n",
      "Epoch [3/360], Batch [180/196], Loss: 0.2661\n",
      "Epoch [3/360], Batch [185/196], Loss: 1.3965\n",
      "Epoch [3/360], Batch [190/196], Loss: 0.7215\n",
      "Epoch [3/360], Batch [195/196], Loss: 1.9116\n",
      "Epoch [4/360], Batch [5/196], Loss: 0.8371\n",
      "Epoch [4/360], Batch [10/196], Loss: 0.5608\n",
      "Epoch [4/360], Batch [15/196], Loss: 0.7480\n",
      "Epoch [4/360], Batch [20/196], Loss: 1.0009\n",
      "Epoch [4/360], Batch [25/196], Loss: 0.7135\n",
      "Epoch [4/360], Batch [30/196], Loss: 0.5468\n",
      "Epoch [4/360], Batch [35/196], Loss: 0.6065\n",
      "Epoch [4/360], Batch [40/196], Loss: 0.4154\n",
      "Epoch [4/360], Batch [45/196], Loss: 0.5363\n",
      "Epoch [4/360], Batch [50/196], Loss: 1.1085\n",
      "Epoch [4/360], Batch [55/196], Loss: 0.8656\n",
      "Epoch [4/360], Batch [60/196], Loss: 1.7638\n",
      "Epoch [4/360], Batch [65/196], Loss: 0.8076\n",
      "Epoch [4/360], Batch [70/196], Loss: 1.4466\n",
      "Epoch [4/360], Batch [75/196], Loss: 0.6079\n",
      "Epoch [4/360], Batch [80/196], Loss: 1.4690\n",
      "Epoch [4/360], Batch [85/196], Loss: 0.9342\n",
      "Epoch [4/360], Batch [90/196], Loss: 1.5158\n",
      "Epoch [4/360], Batch [95/196], Loss: 0.9520\n",
      "Epoch [4/360], Batch [100/196], Loss: 1.0387\n",
      "Epoch [4/360], Batch [105/196], Loss: 1.6347\n",
      "Epoch [4/360], Batch [110/196], Loss: 0.6752\n",
      "Epoch [4/360], Batch [115/196], Loss: 1.3788\n",
      "Epoch [4/360], Batch [120/196], Loss: 2.3906\n",
      "Epoch [4/360], Batch [125/196], Loss: 1.4017\n",
      "Epoch [4/360], Batch [130/196], Loss: 0.8476\n",
      "Epoch [4/360], Batch [135/196], Loss: 0.6750\n",
      "Epoch [4/360], Batch [140/196], Loss: 1.3211\n",
      "Epoch [4/360], Batch [145/196], Loss: 1.0104\n",
      "Epoch [4/360], Batch [150/196], Loss: 0.4098\n",
      "Epoch [4/360], Batch [155/196], Loss: 0.4942\n",
      "Epoch [4/360], Batch [160/196], Loss: 0.7669\n",
      "Epoch [4/360], Batch [165/196], Loss: 0.4997\n",
      "Epoch [4/360], Batch [170/196], Loss: 0.7406\n",
      "Epoch [4/360], Batch [175/196], Loss: 1.2241\n",
      "Epoch [4/360], Batch [180/196], Loss: 2.3748\n",
      "Epoch [4/360], Batch [185/196], Loss: 0.8245\n",
      "Epoch [4/360], Batch [190/196], Loss: 0.4901\n",
      "Epoch [4/360], Batch [195/196], Loss: 0.8762\n",
      "Epoch [5/360], Batch [5/196], Loss: 1.2101\n",
      "Epoch [5/360], Batch [10/196], Loss: 0.8343\n",
      "Epoch [5/360], Batch [15/196], Loss: 0.5579\n",
      "Epoch [5/360], Batch [20/196], Loss: 2.2122\n",
      "Epoch [5/360], Batch [25/196], Loss: 0.9255\n",
      "Epoch [5/360], Batch [30/196], Loss: 0.4411\n",
      "Epoch [5/360], Batch [35/196], Loss: 1.0231\n",
      "Epoch [5/360], Batch [40/196], Loss: 0.5263\n",
      "Epoch [5/360], Batch [45/196], Loss: 1.3544\n",
      "Epoch [5/360], Batch [50/196], Loss: 1.9160\n",
      "Epoch [5/360], Batch [55/196], Loss: 2.9201\n",
      "Epoch [5/360], Batch [60/196], Loss: 4.8943\n",
      "Epoch [5/360], Batch [65/196], Loss: 0.5696\n",
      "Epoch [5/360], Batch [70/196], Loss: 0.4978\n",
      "Epoch [5/360], Batch [75/196], Loss: 1.7619\n",
      "Epoch [5/360], Batch [80/196], Loss: 1.3244\n",
      "Epoch [5/360], Batch [85/196], Loss: 0.6247\n",
      "Epoch [5/360], Batch [90/196], Loss: 0.3829\n",
      "Epoch [5/360], Batch [95/196], Loss: 0.5153\n",
      "Epoch [5/360], Batch [100/196], Loss: 3.6129\n",
      "Epoch [5/360], Batch [105/196], Loss: 0.4159\n",
      "Epoch [5/360], Batch [110/196], Loss: 2.4981\n",
      "Epoch [5/360], Batch [115/196], Loss: 1.0325\n",
      "Epoch [5/360], Batch [120/196], Loss: 0.5274\n",
      "Epoch [5/360], Batch [125/196], Loss: 0.6301\n",
      "Epoch [5/360], Batch [130/196], Loss: 1.1697\n",
      "Epoch [5/360], Batch [135/196], Loss: 1.6392\n",
      "Epoch [5/360], Batch [140/196], Loss: 0.5368\n",
      "Epoch [5/360], Batch [145/196], Loss: 0.3697\n",
      "Epoch [5/360], Batch [150/196], Loss: 1.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/360], Batch [155/196], Loss: 1.1303\n",
      "Epoch [5/360], Batch [160/196], Loss: 1.3016\n",
      "Epoch [5/360], Batch [165/196], Loss: 0.6252\n",
      "Epoch [5/360], Batch [170/196], Loss: 0.5885\n",
      "Epoch [5/360], Batch [175/196], Loss: 0.4866\n",
      "Epoch [5/360], Batch [180/196], Loss: 0.5632\n",
      "Epoch [5/360], Batch [185/196], Loss: 1.4864\n",
      "Epoch [5/360], Batch [190/196], Loss: 0.7430\n",
      "Epoch [5/360], Batch [195/196], Loss: 0.6539\n",
      "Epoch [6/360], Batch [5/196], Loss: 0.6045\n",
      "Epoch [6/360], Batch [10/196], Loss: 0.5848\n",
      "Epoch [6/360], Batch [15/196], Loss: 0.6542\n",
      "Epoch [6/360], Batch [20/196], Loss: 2.3621\n",
      "Epoch [6/360], Batch [25/196], Loss: 1.1876\n",
      "Epoch [6/360], Batch [30/196], Loss: 0.6413\n",
      "Epoch [6/360], Batch [35/196], Loss: 0.9339\n",
      "Epoch [6/360], Batch [40/196], Loss: 1.4718\n",
      "Epoch [6/360], Batch [45/196], Loss: 0.6472\n",
      "Epoch [6/360], Batch [50/196], Loss: 0.8478\n",
      "Epoch [6/360], Batch [55/196], Loss: 1.3305\n",
      "Epoch [6/360], Batch [60/196], Loss: 0.4882\n",
      "Epoch [6/360], Batch [65/196], Loss: 0.9636\n",
      "Epoch [6/360], Batch [70/196], Loss: 1.0277\n",
      "Epoch [6/360], Batch [75/196], Loss: 1.3591\n",
      "Epoch [6/360], Batch [80/196], Loss: 0.7986\n",
      "Epoch [6/360], Batch [85/196], Loss: 0.8927\n",
      "Epoch [6/360], Batch [90/196], Loss: 1.2570\n",
      "Epoch [6/360], Batch [95/196], Loss: 1.4181\n",
      "Epoch [6/360], Batch [100/196], Loss: 1.2241\n",
      "Epoch [6/360], Batch [105/196], Loss: 0.4584\n",
      "Epoch [6/360], Batch [110/196], Loss: 0.4467\n",
      "Epoch [6/360], Batch [115/196], Loss: 2.1307\n",
      "Epoch [6/360], Batch [120/196], Loss: 1.1449\n",
      "Epoch [6/360], Batch [125/196], Loss: 0.4847\n",
      "Epoch [6/360], Batch [130/196], Loss: 1.5194\n",
      "Epoch [6/360], Batch [135/196], Loss: 0.8475\n",
      "Epoch [6/360], Batch [140/196], Loss: 1.6646\n",
      "Epoch [6/360], Batch [145/196], Loss: 0.3360\n",
      "Epoch [6/360], Batch [150/196], Loss: 0.5172\n",
      "Epoch [6/360], Batch [155/196], Loss: 1.0435\n",
      "Epoch [6/360], Batch [160/196], Loss: 0.6163\n",
      "Epoch [6/360], Batch [165/196], Loss: 1.9703\n",
      "Epoch [6/360], Batch [170/196], Loss: 0.7922\n",
      "Epoch [6/360], Batch [175/196], Loss: 0.6468\n",
      "Epoch [6/360], Batch [180/196], Loss: 1.2246\n",
      "Epoch [6/360], Batch [185/196], Loss: 0.5127\n",
      "Epoch [6/360], Batch [190/196], Loss: 0.8083\n",
      "Epoch [6/360], Batch [195/196], Loss: 0.5718\n",
      "Epoch [7/360], Batch [5/196], Loss: 0.9001\n",
      "Epoch [7/360], Batch [10/196], Loss: 1.7983\n",
      "Epoch [7/360], Batch [15/196], Loss: 1.2507\n",
      "Epoch [7/360], Batch [20/196], Loss: 2.1498\n",
      "Epoch [7/360], Batch [25/196], Loss: 0.6467\n",
      "Epoch [7/360], Batch [30/196], Loss: 0.8267\n",
      "Epoch [7/360], Batch [35/196], Loss: 1.6975\n",
      "Epoch [7/360], Batch [40/196], Loss: 0.7807\n",
      "Epoch [7/360], Batch [45/196], Loss: 0.7567\n",
      "Epoch [7/360], Batch [50/196], Loss: 0.5407\n",
      "Epoch [7/360], Batch [55/196], Loss: 0.5528\n",
      "Epoch [7/360], Batch [60/196], Loss: 0.9320\n",
      "Epoch [7/360], Batch [65/196], Loss: 1.2357\n",
      "Epoch [7/360], Batch [70/196], Loss: 0.7645\n",
      "Epoch [7/360], Batch [75/196], Loss: 1.2777\n",
      "Epoch [7/360], Batch [80/196], Loss: 0.5645\n",
      "Epoch [7/360], Batch [85/196], Loss: 0.5862\n",
      "Epoch [7/360], Batch [90/196], Loss: 0.7392\n",
      "Epoch [7/360], Batch [95/196], Loss: 0.6505\n",
      "Epoch [7/360], Batch [100/196], Loss: 1.6152\n",
      "Epoch [7/360], Batch [105/196], Loss: 0.5420\n",
      "Epoch [7/360], Batch [110/196], Loss: 1.2368\n",
      "Epoch [7/360], Batch [115/196], Loss: 1.1645\n",
      "Epoch [7/360], Batch [120/196], Loss: 0.5870\n",
      "Epoch [7/360], Batch [125/196], Loss: 7.5888\n",
      "Epoch [7/360], Batch [130/196], Loss: 1.4097\n",
      "Epoch [7/360], Batch [135/196], Loss: 2.2354\n",
      "Epoch [7/360], Batch [140/196], Loss: 0.9527\n",
      "Epoch [7/360], Batch [145/196], Loss: 0.4267\n",
      "Epoch [7/360], Batch [150/196], Loss: 0.3526\n",
      "Epoch [7/360], Batch [155/196], Loss: 0.6963\n",
      "Epoch [7/360], Batch [160/196], Loss: 1.3203\n",
      "Epoch [7/360], Batch [165/196], Loss: 0.8382\n",
      "Epoch [7/360], Batch [170/196], Loss: 1.4145\n",
      "Epoch [7/360], Batch [175/196], Loss: 0.6986\n",
      "Epoch [7/360], Batch [180/196], Loss: 0.6348\n",
      "Epoch [7/360], Batch [185/196], Loss: 1.3275\n",
      "Epoch [7/360], Batch [190/196], Loss: 1.2460\n",
      "Epoch [7/360], Batch [195/196], Loss: 0.6670\n",
      "Epoch [8/360], Batch [5/196], Loss: 0.5676\n",
      "Epoch [8/360], Batch [10/196], Loss: 0.6452\n",
      "Epoch [8/360], Batch [15/196], Loss: 0.8525\n",
      "Epoch [8/360], Batch [20/196], Loss: 0.9725\n",
      "Epoch [8/360], Batch [25/196], Loss: 1.5320\n",
      "Epoch [8/360], Batch [30/196], Loss: 0.5280\n",
      "Epoch [8/360], Batch [35/196], Loss: 1.0336\n",
      "Epoch [8/360], Batch [40/196], Loss: 2.6472\n",
      "Epoch [8/360], Batch [45/196], Loss: 1.3652\n",
      "Epoch [8/360], Batch [50/196], Loss: 1.0246\n",
      "Epoch [8/360], Batch [55/196], Loss: 1.6996\n",
      "Epoch [8/360], Batch [60/196], Loss: 1.2895\n",
      "Epoch [8/360], Batch [65/196], Loss: 1.1780\n",
      "Epoch [8/360], Batch [70/196], Loss: 0.9688\n",
      "Epoch [8/360], Batch [75/196], Loss: 1.4022\n",
      "Epoch [8/360], Batch [80/196], Loss: 1.0193\n",
      "Epoch [8/360], Batch [85/196], Loss: 0.6352\n",
      "Epoch [8/360], Batch [90/196], Loss: 0.5389\n",
      "Epoch [8/360], Batch [95/196], Loss: 0.5928\n",
      "Epoch [8/360], Batch [100/196], Loss: 0.6985\n",
      "Epoch [8/360], Batch [105/196], Loss: 0.2883\n",
      "Epoch [8/360], Batch [110/196], Loss: 0.7435\n",
      "Epoch [8/360], Batch [115/196], Loss: 0.6470\n",
      "Epoch [8/360], Batch [120/196], Loss: 0.2316\n",
      "Epoch [8/360], Batch [125/196], Loss: 0.3584\n",
      "Epoch [8/360], Batch [130/196], Loss: 1.2312\n",
      "Epoch [8/360], Batch [135/196], Loss: 1.3462\n",
      "Epoch [8/360], Batch [140/196], Loss: 1.6511\n",
      "Epoch [8/360], Batch [145/196], Loss: 0.7165\n",
      "Epoch [8/360], Batch [150/196], Loss: 0.5527\n",
      "Epoch [8/360], Batch [155/196], Loss: 0.5525\n",
      "Epoch [8/360], Batch [160/196], Loss: 0.4095\n",
      "Epoch [8/360], Batch [165/196], Loss: 0.3489\n",
      "Epoch [8/360], Batch [170/196], Loss: 1.6904\n",
      "Epoch [8/360], Batch [175/196], Loss: 0.7988\n",
      "Epoch [8/360], Batch [180/196], Loss: 1.2645\n",
      "Epoch [8/360], Batch [185/196], Loss: 0.5259\n",
      "Epoch [8/360], Batch [190/196], Loss: 1.0639\n",
      "Epoch [8/360], Batch [195/196], Loss: 2.0690\n",
      "Epoch [9/360], Batch [5/196], Loss: 0.6567\n",
      "Epoch [9/360], Batch [10/196], Loss: 0.5376\n",
      "Epoch [9/360], Batch [15/196], Loss: 1.4114\n",
      "Epoch [9/360], Batch [20/196], Loss: 0.7027\n",
      "Epoch [9/360], Batch [25/196], Loss: 1.2992\n",
      "Epoch [9/360], Batch [30/196], Loss: 1.4423\n",
      "Epoch [9/360], Batch [35/196], Loss: 0.6827\n",
      "Epoch [9/360], Batch [40/196], Loss: 0.6995\n",
      "Epoch [9/360], Batch [45/196], Loss: 1.6600\n",
      "Epoch [9/360], Batch [50/196], Loss: 0.6357\n",
      "Epoch [9/360], Batch [55/196], Loss: 1.2392\n",
      "Epoch [9/360], Batch [60/196], Loss: 0.3293\n",
      "Epoch [9/360], Batch [65/196], Loss: 1.1430\n",
      "Epoch [9/360], Batch [70/196], Loss: 0.7669\n",
      "Epoch [9/360], Batch [75/196], Loss: 1.8784\n",
      "Epoch [9/360], Batch [80/196], Loss: 1.0509\n",
      "Epoch [9/360], Batch [85/196], Loss: 0.9956\n",
      "Epoch [9/360], Batch [90/196], Loss: 0.3984\n",
      "Epoch [9/360], Batch [95/196], Loss: 0.5935\n",
      "Epoch [9/360], Batch [100/196], Loss: 0.6648\n",
      "Epoch [9/360], Batch [105/196], Loss: 0.5577\n",
      "Epoch [9/360], Batch [110/196], Loss: 3.4730\n",
      "Epoch [9/360], Batch [115/196], Loss: 0.7582\n",
      "Epoch [9/360], Batch [120/196], Loss: 1.0083\n",
      "Epoch [9/360], Batch [125/196], Loss: 3.4002\n",
      "Epoch [9/360], Batch [130/196], Loss: 0.8359\n",
      "Epoch [9/360], Batch [135/196], Loss: 0.4834\n",
      "Epoch [9/360], Batch [140/196], Loss: 1.3072\n",
      "Epoch [9/360], Batch [145/196], Loss: 0.8906\n",
      "Epoch [9/360], Batch [150/196], Loss: 0.9385\n",
      "Epoch [9/360], Batch [155/196], Loss: 0.6937\n",
      "Epoch [9/360], Batch [160/196], Loss: 2.0137\n",
      "Epoch [9/360], Batch [165/196], Loss: 1.1619\n",
      "Epoch [9/360], Batch [170/196], Loss: 0.9408\n",
      "Epoch [9/360], Batch [175/196], Loss: 0.3881\n",
      "Epoch [9/360], Batch [180/196], Loss: 1.0313\n",
      "Epoch [9/360], Batch [185/196], Loss: 0.6867\n",
      "Epoch [9/360], Batch [190/196], Loss: 0.6169\n",
      "Epoch [9/360], Batch [195/196], Loss: 0.6330\n",
      "Epoch [10/360], Batch [5/196], Loss: 1.1666\n",
      "Epoch [10/360], Batch [10/196], Loss: 0.4285\n",
      "Epoch [10/360], Batch [15/196], Loss: 0.6207\n",
      "Epoch [10/360], Batch [20/196], Loss: 1.4390\n",
      "Epoch [10/360], Batch [25/196], Loss: 0.8919\n",
      "Epoch [10/360], Batch [30/196], Loss: 0.2755\n",
      "Epoch [10/360], Batch [35/196], Loss: 0.9605\n",
      "Epoch [10/360], Batch [40/196], Loss: 0.6211\n",
      "Epoch [10/360], Batch [45/196], Loss: 0.7430\n",
      "Epoch [10/360], Batch [50/196], Loss: 0.8583\n",
      "Epoch [10/360], Batch [55/196], Loss: 0.4760\n",
      "Epoch [10/360], Batch [60/196], Loss: 0.8969\n",
      "Epoch [10/360], Batch [65/196], Loss: 0.5454\n",
      "Epoch [10/360], Batch [70/196], Loss: 0.9125\n",
      "Epoch [10/360], Batch [75/196], Loss: 0.7415\n",
      "Epoch [10/360], Batch [80/196], Loss: 1.6472\n",
      "Epoch [10/360], Batch [85/196], Loss: 1.1314\n",
      "Epoch [10/360], Batch [90/196], Loss: 1.9834\n",
      "Epoch [10/360], Batch [95/196], Loss: 1.2202\n",
      "Epoch [10/360], Batch [100/196], Loss: 1.0737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/360], Batch [105/196], Loss: 1.3508\n",
      "Epoch [10/360], Batch [110/196], Loss: 1.2060\n",
      "Epoch [10/360], Batch [115/196], Loss: 0.7074\n",
      "Epoch [10/360], Batch [120/196], Loss: 0.9858\n",
      "Epoch [10/360], Batch [125/196], Loss: 1.2727\n",
      "Epoch [10/360], Batch [130/196], Loss: 0.8966\n",
      "Epoch [10/360], Batch [135/196], Loss: 0.8664\n",
      "Epoch [10/360], Batch [140/196], Loss: 0.4887\n",
      "Epoch [10/360], Batch [145/196], Loss: 0.3381\n",
      "Epoch [10/360], Batch [150/196], Loss: 0.7886\n",
      "Epoch [10/360], Batch [155/196], Loss: 0.6471\n",
      "Epoch [10/360], Batch [160/196], Loss: 1.2029\n",
      "Epoch [10/360], Batch [165/196], Loss: 0.9662\n",
      "Epoch [10/360], Batch [170/196], Loss: 0.4456\n",
      "Epoch [10/360], Batch [175/196], Loss: 7.0238\n",
      "Epoch [10/360], Batch [180/196], Loss: 0.9610\n",
      "Epoch [10/360], Batch [185/196], Loss: 1.5999\n",
      "Epoch [10/360], Batch [190/196], Loss: 0.9445\n",
      "Epoch [10/360], Batch [195/196], Loss: 0.9224\n",
      "Epoch [11/360], Batch [5/196], Loss: 1.9508\n",
      "Epoch [11/360], Batch [10/196], Loss: 6.7057\n",
      "Epoch [11/360], Batch [15/196], Loss: 0.5429\n",
      "Epoch [11/360], Batch [20/196], Loss: 0.9653\n",
      "Epoch [11/360], Batch [25/196], Loss: 0.4375\n",
      "Epoch [11/360], Batch [30/196], Loss: 1.3078\n",
      "Epoch [11/360], Batch [35/196], Loss: 1.1174\n",
      "Epoch [11/360], Batch [40/196], Loss: 1.0241\n",
      "Epoch [11/360], Batch [45/196], Loss: 0.7681\n",
      "Epoch [11/360], Batch [50/196], Loss: 0.8350\n",
      "Epoch [11/360], Batch [55/196], Loss: 0.7700\n",
      "Epoch [11/360], Batch [60/196], Loss: 0.7290\n",
      "Epoch [11/360], Batch [65/196], Loss: 0.9192\n",
      "Epoch [11/360], Batch [70/196], Loss: 0.5693\n",
      "Epoch [11/360], Batch [75/196], Loss: 0.5654\n",
      "Epoch [11/360], Batch [80/196], Loss: 0.6719\n",
      "Epoch [11/360], Batch [85/196], Loss: 0.5866\n",
      "Epoch [11/360], Batch [90/196], Loss: 1.4982\n",
      "Epoch [11/360], Batch [95/196], Loss: 1.2760\n",
      "Epoch [11/360], Batch [100/196], Loss: 1.1997\n",
      "Epoch [11/360], Batch [105/196], Loss: 2.2538\n",
      "Epoch [11/360], Batch [110/196], Loss: 1.2185\n",
      "Epoch [11/360], Batch [115/196], Loss: 1.2701\n",
      "Epoch [11/360], Batch [120/196], Loss: 0.4966\n",
      "Epoch [11/360], Batch [125/196], Loss: 1.3815\n",
      "Epoch [11/360], Batch [130/196], Loss: 0.6201\n",
      "Epoch [11/360], Batch [135/196], Loss: 0.5605\n",
      "Epoch [11/360], Batch [140/196], Loss: 0.9959\n",
      "Epoch [11/360], Batch [145/196], Loss: 0.4995\n",
      "Epoch [11/360], Batch [150/196], Loss: 0.4215\n",
      "Epoch [11/360], Batch [155/196], Loss: 0.7946\n",
      "Epoch [11/360], Batch [160/196], Loss: 0.7629\n",
      "Epoch [11/360], Batch [165/196], Loss: 0.3194\n",
      "Epoch [11/360], Batch [170/196], Loss: 0.6056\n",
      "Epoch [11/360], Batch [175/196], Loss: 0.8249\n",
      "Epoch [11/360], Batch [180/196], Loss: 3.8549\n",
      "Epoch [11/360], Batch [185/196], Loss: 0.6372\n",
      "Epoch [11/360], Batch [190/196], Loss: 0.4371\n",
      "Epoch [11/360], Batch [195/196], Loss: 0.7083\n",
      "Epoch [12/360], Batch [5/196], Loss: 0.7810\n",
      "Epoch [12/360], Batch [10/196], Loss: 0.8277\n",
      "Epoch [12/360], Batch [15/196], Loss: 0.3071\n",
      "Epoch [12/360], Batch [20/196], Loss: 0.5306\n",
      "Epoch [12/360], Batch [25/196], Loss: 0.7678\n",
      "Epoch [12/360], Batch [30/196], Loss: 2.2129\n",
      "Epoch [12/360], Batch [35/196], Loss: 0.5837\n",
      "Epoch [12/360], Batch [40/196], Loss: 1.2867\n",
      "Epoch [12/360], Batch [45/196], Loss: 1.4710\n",
      "Epoch [12/360], Batch [50/196], Loss: 1.4334\n",
      "Epoch [12/360], Batch [55/196], Loss: 0.9369\n",
      "Epoch [12/360], Batch [60/196], Loss: 0.7406\n",
      "Epoch [12/360], Batch [65/196], Loss: 0.7718\n",
      "Epoch [12/360], Batch [70/196], Loss: 1.1781\n",
      "Epoch [12/360], Batch [75/196], Loss: 0.7686\n",
      "Epoch [12/360], Batch [80/196], Loss: 1.6373\n",
      "Epoch [12/360], Batch [85/196], Loss: 0.8941\n",
      "Epoch [12/360], Batch [90/196], Loss: 1.3390\n",
      "Epoch [12/360], Batch [95/196], Loss: 0.3483\n",
      "Epoch [12/360], Batch [100/196], Loss: 0.4239\n",
      "Epoch [12/360], Batch [105/196], Loss: 1.3293\n",
      "Epoch [12/360], Batch [110/196], Loss: 2.0743\n",
      "Epoch [12/360], Batch [115/196], Loss: 1.0359\n",
      "Epoch [12/360], Batch [120/196], Loss: 0.8016\n",
      "Epoch [12/360], Batch [125/196], Loss: 0.5918\n",
      "Epoch [12/360], Batch [130/196], Loss: 0.8547\n",
      "Epoch [12/360], Batch [135/196], Loss: 1.0135\n",
      "Epoch [12/360], Batch [140/196], Loss: 1.2442\n",
      "Epoch [12/360], Batch [145/196], Loss: 0.7297\n",
      "Epoch [12/360], Batch [150/196], Loss: 0.9807\n",
      "Epoch [12/360], Batch [155/196], Loss: 1.2515\n",
      "Epoch [12/360], Batch [160/196], Loss: 0.7587\n",
      "Epoch [12/360], Batch [165/196], Loss: 0.6346\n",
      "Epoch [12/360], Batch [170/196], Loss: 0.7646\n",
      "Epoch [12/360], Batch [175/196], Loss: 1.2291\n",
      "Epoch [12/360], Batch [180/196], Loss: 1.5292\n",
      "Epoch [12/360], Batch [185/196], Loss: 0.8761\n",
      "Epoch [12/360], Batch [190/196], Loss: 2.2917\n",
      "Epoch [12/360], Batch [195/196], Loss: 2.2476\n",
      "Epoch [13/360], Batch [5/196], Loss: 0.8666\n",
      "Epoch [13/360], Batch [10/196], Loss: 0.9587\n",
      "Epoch [13/360], Batch [15/196], Loss: 0.5516\n",
      "Epoch [13/360], Batch [20/196], Loss: 0.8343\n",
      "Epoch [13/360], Batch [25/196], Loss: 0.9255\n",
      "Epoch [13/360], Batch [30/196], Loss: 0.9621\n",
      "Epoch [13/360], Batch [35/196], Loss: 0.5805\n",
      "Epoch [13/360], Batch [40/196], Loss: 2.2249\n",
      "Epoch [13/360], Batch [45/196], Loss: 0.8302\n",
      "Epoch [13/360], Batch [50/196], Loss: 1.9698\n",
      "Epoch [13/360], Batch [55/196], Loss: 0.8651\n",
      "Epoch [13/360], Batch [60/196], Loss: 1.1975\n",
      "Epoch [13/360], Batch [65/196], Loss: 1.5515\n",
      "Epoch [13/360], Batch [70/196], Loss: 0.8655\n",
      "Epoch [13/360], Batch [75/196], Loss: 0.7674\n",
      "Epoch [13/360], Batch [80/196], Loss: 1.3014\n",
      "Epoch [13/360], Batch [85/196], Loss: 1.3660\n",
      "Epoch [13/360], Batch [90/196], Loss: 1.4861\n",
      "Epoch [13/360], Batch [95/196], Loss: 0.8522\n",
      "Epoch [13/360], Batch [100/196], Loss: 0.6858\n",
      "Epoch [13/360], Batch [105/196], Loss: 1.0690\n",
      "Epoch [13/360], Batch [110/196], Loss: 0.8050\n",
      "Epoch [13/360], Batch [115/196], Loss: 0.8248\n",
      "Epoch [13/360], Batch [120/196], Loss: 0.5444\n",
      "Epoch [13/360], Batch [125/196], Loss: 0.3654\n",
      "Epoch [13/360], Batch [130/196], Loss: 0.6620\n",
      "Epoch [13/360], Batch [135/196], Loss: 0.4008\n",
      "Epoch [13/360], Batch [140/196], Loss: 1.2781\n",
      "Epoch [13/360], Batch [145/196], Loss: 1.1347\n",
      "Epoch [13/360], Batch [150/196], Loss: 1.2206\n",
      "Epoch [13/360], Batch [155/196], Loss: 0.5221\n",
      "Epoch [13/360], Batch [160/196], Loss: 0.4494\n",
      "Epoch [13/360], Batch [165/196], Loss: 0.4064\n",
      "Epoch [13/360], Batch [170/196], Loss: 0.8315\n",
      "Epoch [13/360], Batch [175/196], Loss: 0.6372\n",
      "Epoch [13/360], Batch [180/196], Loss: 1.9320\n",
      "Epoch [13/360], Batch [185/196], Loss: 0.8395\n",
      "Epoch [13/360], Batch [190/196], Loss: 1.5736\n",
      "Epoch [13/360], Batch [195/196], Loss: 0.5241\n",
      "Epoch [14/360], Batch [5/196], Loss: 1.3490\n",
      "Epoch [14/360], Batch [10/196], Loss: 0.5588\n",
      "Epoch [14/360], Batch [15/196], Loss: 1.6612\n",
      "Epoch [14/360], Batch [20/196], Loss: 0.4898\n",
      "Epoch [14/360], Batch [25/196], Loss: 0.9927\n",
      "Epoch [14/360], Batch [30/196], Loss: 0.6006\n",
      "Epoch [14/360], Batch [35/196], Loss: 0.5502\n",
      "Epoch [14/360], Batch [40/196], Loss: 0.6534\n",
      "Epoch [14/360], Batch [45/196], Loss: 1.2367\n",
      "Epoch [14/360], Batch [50/196], Loss: 1.2116\n",
      "Epoch [14/360], Batch [55/196], Loss: 0.9402\n",
      "Epoch [14/360], Batch [60/196], Loss: 1.1913\n",
      "Epoch [14/360], Batch [65/196], Loss: 0.2645\n",
      "Epoch [14/360], Batch [70/196], Loss: 1.1937\n",
      "Epoch [14/360], Batch [75/196], Loss: 1.0306\n",
      "Epoch [14/360], Batch [80/196], Loss: 0.6385\n",
      "Epoch [14/360], Batch [85/196], Loss: 0.9268\n",
      "Epoch [14/360], Batch [90/196], Loss: 1.5712\n",
      "Epoch [14/360], Batch [95/196], Loss: 1.6895\n",
      "Epoch [14/360], Batch [100/196], Loss: 0.2998\n",
      "Epoch [14/360], Batch [105/196], Loss: 0.9779\n",
      "Epoch [14/360], Batch [110/196], Loss: 1.3103\n",
      "Epoch [14/360], Batch [115/196], Loss: 0.5549\n",
      "Epoch [14/360], Batch [120/196], Loss: 0.8179\n",
      "Epoch [14/360], Batch [125/196], Loss: 0.6457\n",
      "Epoch [14/360], Batch [130/196], Loss: 0.9555\n",
      "Epoch [14/360], Batch [135/196], Loss: 0.6969\n",
      "Epoch [14/360], Batch [140/196], Loss: 0.6721\n",
      "Epoch [14/360], Batch [145/196], Loss: 1.6013\n",
      "Epoch [14/360], Batch [150/196], Loss: 0.4018\n",
      "Epoch [14/360], Batch [155/196], Loss: 2.5370\n",
      "Epoch [14/360], Batch [160/196], Loss: 2.0928\n",
      "Epoch [14/360], Batch [165/196], Loss: 1.0176\n",
      "Epoch [14/360], Batch [170/196], Loss: 1.1398\n",
      "Epoch [14/360], Batch [175/196], Loss: 1.3144\n",
      "Epoch [14/360], Batch [180/196], Loss: 0.7016\n",
      "Epoch [14/360], Batch [185/196], Loss: 0.6216\n",
      "Epoch [14/360], Batch [190/196], Loss: 0.8709\n",
      "Epoch [14/360], Batch [195/196], Loss: 0.3912\n",
      "Epoch [15/360], Batch [5/196], Loss: 0.2725\n",
      "Epoch [15/360], Batch [10/196], Loss: 0.5637\n",
      "Epoch [15/360], Batch [15/196], Loss: 0.6083\n",
      "Epoch [15/360], Batch [20/196], Loss: 0.7607\n",
      "Epoch [15/360], Batch [25/196], Loss: 0.6219\n",
      "Epoch [15/360], Batch [30/196], Loss: 2.5231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/360], Batch [35/196], Loss: 0.4434\n",
      "Epoch [15/360], Batch [40/196], Loss: 1.3928\n",
      "Epoch [15/360], Batch [45/196], Loss: 2.7217\n",
      "Epoch [15/360], Batch [50/196], Loss: 0.4075\n",
      "Epoch [15/360], Batch [55/196], Loss: 0.8613\n",
      "Epoch [15/360], Batch [60/196], Loss: 1.0047\n",
      "Epoch [15/360], Batch [65/196], Loss: 7.4425\n",
      "Epoch [15/360], Batch [70/196], Loss: 1.2098\n",
      "Epoch [15/360], Batch [75/196], Loss: 0.8414\n",
      "Epoch [15/360], Batch [80/196], Loss: 1.7692\n",
      "Epoch [15/360], Batch [85/196], Loss: 0.3637\n",
      "Epoch [15/360], Batch [90/196], Loss: 1.0595\n",
      "Epoch [15/360], Batch [95/196], Loss: 0.6362\n",
      "Epoch [15/360], Batch [100/196], Loss: 2.7222\n",
      "Epoch [15/360], Batch [105/196], Loss: 1.2717\n",
      "Epoch [15/360], Batch [110/196], Loss: 0.6581\n",
      "Epoch [15/360], Batch [115/196], Loss: 0.7985\n",
      "Epoch [15/360], Batch [120/196], Loss: 2.2669\n",
      "Epoch [15/360], Batch [125/196], Loss: 0.9920\n",
      "Epoch [15/360], Batch [130/196], Loss: 1.1574\n",
      "Epoch [15/360], Batch [135/196], Loss: 1.3540\n",
      "Epoch [15/360], Batch [140/196], Loss: 0.8956\n",
      "Epoch [15/360], Batch [145/196], Loss: 0.6049\n",
      "Epoch [15/360], Batch [150/196], Loss: 0.3695\n",
      "Epoch [15/360], Batch [155/196], Loss: 1.1537\n",
      "Epoch [15/360], Batch [160/196], Loss: 0.3410\n",
      "Epoch [15/360], Batch [165/196], Loss: 0.6782\n",
      "Epoch [15/360], Batch [170/196], Loss: 0.7369\n",
      "Epoch [15/360], Batch [175/196], Loss: 0.8284\n",
      "Epoch [15/360], Batch [180/196], Loss: 1.9461\n",
      "Epoch [15/360], Batch [185/196], Loss: 0.7185\n",
      "Epoch [15/360], Batch [190/196], Loss: 0.7402\n",
      "Epoch [15/360], Batch [195/196], Loss: 0.5082\n",
      "Epoch [16/360], Batch [5/196], Loss: 0.3888\n",
      "Epoch [16/360], Batch [10/196], Loss: 1.0972\n",
      "Epoch [16/360], Batch [15/196], Loss: 0.5107\n",
      "Epoch [16/360], Batch [20/196], Loss: 1.3322\n",
      "Epoch [16/360], Batch [25/196], Loss: 1.1996\n",
      "Epoch [16/360], Batch [30/196], Loss: 0.8471\n",
      "Epoch [16/360], Batch [35/196], Loss: 0.3826\n",
      "Epoch [16/360], Batch [40/196], Loss: 1.2490\n",
      "Epoch [16/360], Batch [45/196], Loss: 0.6461\n",
      "Epoch [16/360], Batch [50/196], Loss: 0.9369\n",
      "Epoch [16/360], Batch [55/196], Loss: 0.8972\n",
      "Epoch [16/360], Batch [60/196], Loss: 2.0694\n",
      "Epoch [16/360], Batch [65/196], Loss: 0.5460\n",
      "Epoch [16/360], Batch [70/196], Loss: 0.7494\n",
      "Epoch [16/360], Batch [75/196], Loss: 0.4503\n",
      "Epoch [16/360], Batch [80/196], Loss: 0.8349\n",
      "Epoch [16/360], Batch [85/196], Loss: 0.9165\n",
      "Epoch [16/360], Batch [90/196], Loss: 0.6367\n",
      "Epoch [16/360], Batch [95/196], Loss: 1.0087\n",
      "Epoch [16/360], Batch [100/196], Loss: 0.7195\n",
      "Epoch [16/360], Batch [105/196], Loss: 0.5268\n",
      "Epoch [16/360], Batch [110/196], Loss: 0.6379\n",
      "Epoch [16/360], Batch [115/196], Loss: 0.7621\n",
      "Epoch [16/360], Batch [120/196], Loss: 1.3609\n",
      "Epoch [16/360], Batch [125/196], Loss: 0.2866\n",
      "Epoch [16/360], Batch [130/196], Loss: 0.5746\n",
      "Epoch [16/360], Batch [135/196], Loss: 0.5466\n",
      "Epoch [16/360], Batch [140/196], Loss: 0.4943\n",
      "Epoch [16/360], Batch [145/196], Loss: 1.8826\n",
      "Epoch [16/360], Batch [150/196], Loss: 0.3525\n",
      "Epoch [16/360], Batch [155/196], Loss: 1.6189\n",
      "Epoch [16/360], Batch [160/196], Loss: 1.5006\n",
      "Epoch [16/360], Batch [165/196], Loss: 0.8986\n",
      "Epoch [16/360], Batch [170/196], Loss: 0.8675\n",
      "Epoch [16/360], Batch [175/196], Loss: 1.6702\n",
      "Epoch [16/360], Batch [180/196], Loss: 0.7667\n",
      "Epoch [16/360], Batch [185/196], Loss: 1.5790\n",
      "Epoch [16/360], Batch [190/196], Loss: 0.4913\n",
      "Epoch [16/360], Batch [195/196], Loss: 1.8919\n",
      "Epoch [17/360], Batch [5/196], Loss: 0.7433\n",
      "Epoch [17/360], Batch [10/196], Loss: 1.0788\n",
      "Epoch [17/360], Batch [15/196], Loss: 0.6607\n",
      "Epoch [17/360], Batch [20/196], Loss: 0.9928\n",
      "Epoch [17/360], Batch [25/196], Loss: 0.6240\n",
      "Epoch [17/360], Batch [30/196], Loss: 1.2042\n",
      "Epoch [17/360], Batch [35/196], Loss: 0.9136\n",
      "Epoch [17/360], Batch [40/196], Loss: 0.3791\n",
      "Epoch [17/360], Batch [45/196], Loss: 1.3850\n",
      "Epoch [17/360], Batch [50/196], Loss: 0.4149\n",
      "Epoch [17/360], Batch [55/196], Loss: 1.2201\n",
      "Epoch [17/360], Batch [60/196], Loss: 0.7592\n",
      "Epoch [17/360], Batch [65/196], Loss: 0.6979\n",
      "Epoch [17/360], Batch [70/196], Loss: 0.9057\n",
      "Epoch [17/360], Batch [75/196], Loss: 1.3343\n",
      "Epoch [17/360], Batch [80/196], Loss: 0.6143\n",
      "Epoch [17/360], Batch [85/196], Loss: 0.3970\n",
      "Epoch [17/360], Batch [90/196], Loss: 2.2078\n",
      "Epoch [17/360], Batch [95/196], Loss: 0.7062\n",
      "Epoch [17/360], Batch [100/196], Loss: 1.4457\n",
      "Epoch [17/360], Batch [105/196], Loss: 0.4866\n",
      "Epoch [17/360], Batch [110/196], Loss: 0.6256\n",
      "Epoch [17/360], Batch [115/196], Loss: 0.7779\n",
      "Epoch [17/360], Batch [120/196], Loss: 0.8093\n",
      "Epoch [17/360], Batch [125/196], Loss: 0.6060\n",
      "Epoch [17/360], Batch [130/196], Loss: 0.9908\n",
      "Epoch [17/360], Batch [135/196], Loss: 1.4589\n",
      "Epoch [17/360], Batch [140/196], Loss: 0.9696\n",
      "Epoch [17/360], Batch [145/196], Loss: 1.1051\n",
      "Epoch [17/360], Batch [150/196], Loss: 0.6522\n",
      "Epoch [17/360], Batch [155/196], Loss: 1.0607\n",
      "Epoch [17/360], Batch [160/196], Loss: 0.7878\n",
      "Epoch [17/360], Batch [165/196], Loss: 0.7033\n",
      "Epoch [17/360], Batch [170/196], Loss: 0.6070\n",
      "Epoch [17/360], Batch [175/196], Loss: 0.8678\n",
      "Epoch [17/360], Batch [180/196], Loss: 0.9149\n",
      "Epoch [17/360], Batch [185/196], Loss: 0.5359\n",
      "Epoch [17/360], Batch [190/196], Loss: 1.1724\n",
      "Epoch [17/360], Batch [195/196], Loss: 0.5397\n",
      "Epoch [18/360], Batch [5/196], Loss: 0.9657\n",
      "Epoch [18/360], Batch [10/196], Loss: 0.7982\n",
      "Epoch [18/360], Batch [15/196], Loss: 1.7210\n",
      "Epoch [18/360], Batch [20/196], Loss: 0.5963\n",
      "Epoch [18/360], Batch [25/196], Loss: 0.8113\n",
      "Epoch [18/360], Batch [30/196], Loss: 1.1015\n",
      "Epoch [18/360], Batch [35/196], Loss: 1.7128\n",
      "Epoch [18/360], Batch [40/196], Loss: 1.2572\n",
      "Epoch [18/360], Batch [45/196], Loss: 1.2186\n",
      "Epoch [18/360], Batch [50/196], Loss: 1.0041\n",
      "Epoch [18/360], Batch [55/196], Loss: 1.0912\n",
      "Epoch [18/360], Batch [60/196], Loss: 0.8771\n",
      "Epoch [18/360], Batch [65/196], Loss: 1.2353\n",
      "Epoch [18/360], Batch [70/196], Loss: 2.2467\n",
      "Epoch [18/360], Batch [75/196], Loss: 0.7478\n",
      "Epoch [18/360], Batch [80/196], Loss: 0.4003\n",
      "Epoch [18/360], Batch [85/196], Loss: 3.1326\n",
      "Epoch [18/360], Batch [90/196], Loss: 0.7207\n",
      "Epoch [18/360], Batch [95/196], Loss: 0.9956\n",
      "Epoch [18/360], Batch [100/196], Loss: 0.8158\n",
      "Epoch [18/360], Batch [105/196], Loss: 0.5911\n",
      "Epoch [18/360], Batch [110/196], Loss: 0.9851\n",
      "Epoch [18/360], Batch [115/196], Loss: 0.5218\n",
      "Epoch [18/360], Batch [120/196], Loss: 0.7085\n",
      "Epoch [18/360], Batch [125/196], Loss: 0.4860\n",
      "Epoch [18/360], Batch [130/196], Loss: 0.9132\n",
      "Epoch [18/360], Batch [135/196], Loss: 0.8905\n",
      "Epoch [18/360], Batch [140/196], Loss: 0.5317\n",
      "Epoch [18/360], Batch [145/196], Loss: 0.8480\n",
      "Epoch [18/360], Batch [150/196], Loss: 0.9111\n",
      "Epoch [18/360], Batch [155/196], Loss: 1.9271\n",
      "Epoch [18/360], Batch [160/196], Loss: 2.0862\n",
      "Epoch [18/360], Batch [165/196], Loss: 0.4765\n",
      "Epoch [18/360], Batch [170/196], Loss: 0.8104\n",
      "Epoch [18/360], Batch [175/196], Loss: 0.8220\n",
      "Epoch [18/360], Batch [180/196], Loss: 2.1076\n",
      "Epoch [18/360], Batch [185/196], Loss: 0.5264\n",
      "Epoch [18/360], Batch [190/196], Loss: 1.3617\n",
      "Epoch [18/360], Batch [195/196], Loss: 0.6900\n",
      "Epoch [19/360], Batch [5/196], Loss: 1.1166\n",
      "Epoch [19/360], Batch [10/196], Loss: 1.0447\n",
      "Epoch [19/360], Batch [15/196], Loss: 0.9953\n",
      "Epoch [19/360], Batch [20/196], Loss: 0.8176\n",
      "Epoch [19/360], Batch [25/196], Loss: 1.1973\n",
      "Epoch [19/360], Batch [30/196], Loss: 0.4567\n",
      "Epoch [19/360], Batch [35/196], Loss: 1.6787\n",
      "Epoch [19/360], Batch [40/196], Loss: 0.4606\n",
      "Epoch [19/360], Batch [45/196], Loss: 0.5415\n",
      "Epoch [19/360], Batch [50/196], Loss: 2.0782\n",
      "Epoch [19/360], Batch [55/196], Loss: 1.5429\n",
      "Epoch [19/360], Batch [60/196], Loss: 0.7780\n",
      "Epoch [19/360], Batch [65/196], Loss: 0.5111\n",
      "Epoch [19/360], Batch [70/196], Loss: 0.6998\n",
      "Epoch [19/360], Batch [75/196], Loss: 1.5627\n",
      "Epoch [19/360], Batch [80/196], Loss: 0.4209\n",
      "Epoch [19/360], Batch [85/196], Loss: 1.5335\n",
      "Epoch [19/360], Batch [90/196], Loss: 0.5436\n",
      "Epoch [19/360], Batch [95/196], Loss: 0.7723\n",
      "Epoch [19/360], Batch [100/196], Loss: 0.8480\n",
      "Epoch [19/360], Batch [105/196], Loss: 1.0266\n",
      "Epoch [19/360], Batch [110/196], Loss: 0.7493\n",
      "Epoch [19/360], Batch [115/196], Loss: 1.2719\n",
      "Epoch [19/360], Batch [120/196], Loss: 0.7477\n",
      "Epoch [19/360], Batch [125/196], Loss: 1.8059\n",
      "Epoch [19/360], Batch [130/196], Loss: 0.5235\n",
      "Epoch [19/360], Batch [135/196], Loss: 0.6962\n",
      "Epoch [19/360], Batch [140/196], Loss: 1.3757\n",
      "Epoch [19/360], Batch [145/196], Loss: 0.8921\n",
      "Epoch [19/360], Batch [150/196], Loss: 0.7928\n",
      "Epoch [19/360], Batch [155/196], Loss: 0.5493\n",
      "Epoch [19/360], Batch [160/196], Loss: 1.4559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/360], Batch [165/196], Loss: 0.8760\n",
      "Epoch [19/360], Batch [170/196], Loss: 0.5934\n",
      "Epoch [19/360], Batch [175/196], Loss: 0.8759\n",
      "Epoch [19/360], Batch [180/196], Loss: 0.4869\n",
      "Epoch [19/360], Batch [185/196], Loss: 0.6019\n",
      "Epoch [19/360], Batch [190/196], Loss: 0.7585\n",
      "Epoch [19/360], Batch [195/196], Loss: 0.9489\n",
      "Epoch [20/360], Batch [5/196], Loss: 0.9191\n",
      "Epoch [20/360], Batch [10/196], Loss: 0.3962\n",
      "Epoch [20/360], Batch [15/196], Loss: 2.5336\n",
      "Epoch [20/360], Batch [20/196], Loss: 1.0792\n",
      "Epoch [20/360], Batch [25/196], Loss: 1.0255\n",
      "Epoch [20/360], Batch [30/196], Loss: 0.8665\n",
      "Epoch [20/360], Batch [35/196], Loss: 0.4885\n",
      "Epoch [20/360], Batch [40/196], Loss: 0.4681\n",
      "Epoch [20/360], Batch [45/196], Loss: 1.4761\n",
      "Epoch [20/360], Batch [50/196], Loss: 0.6733\n",
      "Epoch [20/360], Batch [55/196], Loss: 1.2541\n",
      "Epoch [20/360], Batch [60/196], Loss: 0.6301\n",
      "Epoch [20/360], Batch [65/196], Loss: 0.3328\n",
      "Epoch [20/360], Batch [70/196], Loss: 0.8546\n",
      "Epoch [20/360], Batch [75/196], Loss: 0.7874\n",
      "Epoch [20/360], Batch [80/196], Loss: 1.9354\n",
      "Epoch [20/360], Batch [85/196], Loss: 0.3330\n",
      "Epoch [20/360], Batch [90/196], Loss: 1.1451\n",
      "Epoch [20/360], Batch [95/196], Loss: 0.4986\n",
      "Epoch [20/360], Batch [100/196], Loss: 1.0500\n",
      "Epoch [20/360], Batch [105/196], Loss: 0.6474\n",
      "Epoch [20/360], Batch [110/196], Loss: 2.8157\n",
      "Epoch [20/360], Batch [115/196], Loss: 0.5768\n",
      "Epoch [20/360], Batch [120/196], Loss: 1.4892\n",
      "Epoch [20/360], Batch [125/196], Loss: 0.4710\n",
      "Epoch [20/360], Batch [130/196], Loss: 0.9532\n",
      "Epoch [20/360], Batch [135/196], Loss: 3.0384\n",
      "Epoch [20/360], Batch [140/196], Loss: 0.4448\n",
      "Epoch [20/360], Batch [145/196], Loss: 0.5245\n",
      "Epoch [20/360], Batch [150/196], Loss: 0.4316\n",
      "Epoch [20/360], Batch [155/196], Loss: 1.1819\n",
      "Epoch [20/360], Batch [160/196], Loss: 0.6207\n",
      "Epoch [20/360], Batch [165/196], Loss: 1.3335\n",
      "Epoch [20/360], Batch [170/196], Loss: 0.9392\n",
      "Epoch [20/360], Batch [175/196], Loss: 0.6987\n",
      "Epoch [20/360], Batch [180/196], Loss: 0.6115\n",
      "Epoch [20/360], Batch [185/196], Loss: 1.4414\n",
      "Epoch [20/360], Batch [190/196], Loss: 0.6985\n",
      "Epoch [20/360], Batch [195/196], Loss: 0.9736\n",
      "Epoch [21/360], Batch [5/196], Loss: 1.6864\n",
      "Epoch [21/360], Batch [10/196], Loss: 0.7373\n",
      "Epoch [21/360], Batch [15/196], Loss: 1.6020\n",
      "Epoch [21/360], Batch [20/196], Loss: 0.8160\n",
      "Epoch [21/360], Batch [25/196], Loss: 0.9261\n",
      "Epoch [21/360], Batch [30/196], Loss: 0.8484\n",
      "Epoch [21/360], Batch [35/196], Loss: 1.1281\n",
      "Epoch [21/360], Batch [40/196], Loss: 0.7858\n",
      "Epoch [21/360], Batch [45/196], Loss: 0.2705\n",
      "Epoch [21/360], Batch [50/196], Loss: 1.3089\n",
      "Epoch [21/360], Batch [55/196], Loss: 1.4585\n",
      "Epoch [21/360], Batch [60/196], Loss: 0.5291\n",
      "Epoch [21/360], Batch [65/196], Loss: 0.4139\n",
      "Epoch [21/360], Batch [70/196], Loss: 0.5407\n",
      "Epoch [21/360], Batch [75/196], Loss: 0.3243\n",
      "Epoch [21/360], Batch [80/196], Loss: 0.3838\n",
      "Epoch [21/360], Batch [85/196], Loss: 2.1167\n",
      "Epoch [21/360], Batch [90/196], Loss: 0.7657\n",
      "Epoch [21/360], Batch [95/196], Loss: 0.8859\n",
      "Epoch [21/360], Batch [100/196], Loss: 0.6071\n",
      "Epoch [21/360], Batch [105/196], Loss: 0.6032\n",
      "Epoch [21/360], Batch [110/196], Loss: 0.5488\n",
      "Epoch [21/360], Batch [115/196], Loss: 0.3136\n",
      "Epoch [21/360], Batch [120/196], Loss: 1.0204\n",
      "Epoch [21/360], Batch [125/196], Loss: 0.5602\n",
      "Epoch [21/360], Batch [130/196], Loss: 0.7630\n",
      "Epoch [21/360], Batch [135/196], Loss: 0.6426\n",
      "Epoch [21/360], Batch [140/196], Loss: 0.4669\n",
      "Epoch [21/360], Batch [145/196], Loss: 2.6752\n",
      "Epoch [21/360], Batch [150/196], Loss: 0.6679\n",
      "Epoch [21/360], Batch [155/196], Loss: 0.6297\n",
      "Epoch [21/360], Batch [160/196], Loss: 1.0617\n",
      "Epoch [21/360], Batch [165/196], Loss: 1.0295\n",
      "Epoch [21/360], Batch [170/196], Loss: 1.3530\n",
      "Epoch [21/360], Batch [175/196], Loss: 1.6508\n",
      "Epoch [21/360], Batch [180/196], Loss: 0.8621\n",
      "Epoch [21/360], Batch [185/196], Loss: 0.5343\n",
      "Epoch [21/360], Batch [190/196], Loss: 1.8509\n",
      "Epoch [21/360], Batch [195/196], Loss: 0.6319\n",
      "Epoch [22/360], Batch [5/196], Loss: 0.8649\n",
      "Epoch [22/360], Batch [10/196], Loss: 0.5720\n",
      "Epoch [22/360], Batch [15/196], Loss: 0.6384\n",
      "Epoch [22/360], Batch [20/196], Loss: 0.9871\n",
      "Epoch [22/360], Batch [25/196], Loss: 1.2309\n",
      "Epoch [22/360], Batch [30/196], Loss: 0.3783\n",
      "Epoch [22/360], Batch [35/196], Loss: 0.5228\n",
      "Epoch [22/360], Batch [40/196], Loss: 0.7012\n",
      "Epoch [22/360], Batch [45/196], Loss: 1.5636\n",
      "Epoch [22/360], Batch [50/196], Loss: 0.7212\n",
      "Epoch [22/360], Batch [55/196], Loss: 0.5382\n",
      "Epoch [22/360], Batch [60/196], Loss: 0.6461\n",
      "Epoch [22/360], Batch [65/196], Loss: 0.9045\n",
      "Epoch [22/360], Batch [70/196], Loss: 0.9563\n",
      "Epoch [22/360], Batch [75/196], Loss: 0.6878\n",
      "Epoch [22/360], Batch [80/196], Loss: 0.6036\n",
      "Epoch [22/360], Batch [85/196], Loss: 0.6438\n",
      "Epoch [22/360], Batch [90/196], Loss: 1.2492\n",
      "Epoch [22/360], Batch [95/196], Loss: 0.3736\n",
      "Epoch [22/360], Batch [100/196], Loss: 0.4434\n",
      "Epoch [22/360], Batch [105/196], Loss: 0.7144\n",
      "Epoch [22/360], Batch [110/196], Loss: 3.5512\n",
      "Epoch [22/360], Batch [115/196], Loss: 0.5814\n",
      "Epoch [22/360], Batch [120/196], Loss: 1.8532\n",
      "Epoch [22/360], Batch [125/196], Loss: 0.4825\n",
      "Epoch [22/360], Batch [130/196], Loss: 0.9500\n",
      "Epoch [22/360], Batch [135/196], Loss: 0.9678\n",
      "Epoch [22/360], Batch [140/196], Loss: 0.6571\n",
      "Epoch [22/360], Batch [145/196], Loss: 0.5737\n",
      "Epoch [22/360], Batch [150/196], Loss: 3.9049\n",
      "Epoch [22/360], Batch [155/196], Loss: 0.6800\n",
      "Epoch [22/360], Batch [160/196], Loss: 1.0677\n",
      "Epoch [22/360], Batch [165/196], Loss: 0.7940\n",
      "Epoch [22/360], Batch [170/196], Loss: 1.9411\n",
      "Epoch [22/360], Batch [175/196], Loss: 1.0206\n",
      "Epoch [22/360], Batch [180/196], Loss: 0.6097\n",
      "Epoch [22/360], Batch [185/196], Loss: 0.6699\n",
      "Epoch [22/360], Batch [190/196], Loss: 0.7268\n",
      "Epoch [22/360], Batch [195/196], Loss: 2.3111\n",
      "Epoch [23/360], Batch [5/196], Loss: 0.3979\n",
      "Epoch [23/360], Batch [10/196], Loss: 1.0753\n",
      "Epoch [23/360], Batch [15/196], Loss: 1.6436\n",
      "Epoch [23/360], Batch [20/196], Loss: 0.7657\n",
      "Epoch [23/360], Batch [25/196], Loss: 1.0053\n",
      "Epoch [23/360], Batch [30/196], Loss: 0.2517\n",
      "Epoch [23/360], Batch [35/196], Loss: 0.5898\n",
      "Epoch [23/360], Batch [40/196], Loss: 0.2454\n",
      "Epoch [23/360], Batch [45/196], Loss: 0.8315\n",
      "Epoch [23/360], Batch [50/196], Loss: 0.6917\n",
      "Epoch [23/360], Batch [55/196], Loss: 0.3044\n",
      "Epoch [23/360], Batch [60/196], Loss: 0.3228\n",
      "Epoch [23/360], Batch [65/196], Loss: 0.5558\n",
      "Epoch [23/360], Batch [70/196], Loss: 0.7564\n",
      "Epoch [23/360], Batch [75/196], Loss: 1.1496\n",
      "Epoch [23/360], Batch [80/196], Loss: 0.6907\n",
      "Epoch [23/360], Batch [85/196], Loss: 0.6644\n",
      "Epoch [23/360], Batch [90/196], Loss: 0.6453\n",
      "Epoch [23/360], Batch [95/196], Loss: 0.7288\n",
      "Epoch [23/360], Batch [100/196], Loss: 0.8259\n",
      "Epoch [23/360], Batch [105/196], Loss: 1.5743\n",
      "Epoch [23/360], Batch [110/196], Loss: 1.0936\n",
      "Epoch [23/360], Batch [115/196], Loss: 1.2826\n",
      "Epoch [23/360], Batch [120/196], Loss: 0.9802\n",
      "Epoch [23/360], Batch [125/196], Loss: 0.7471\n",
      "Epoch [23/360], Batch [130/196], Loss: 0.8802\n",
      "Epoch [23/360], Batch [135/196], Loss: 0.7045\n",
      "Epoch [23/360], Batch [140/196], Loss: 0.6481\n",
      "Epoch [23/360], Batch [145/196], Loss: 0.5743\n",
      "Epoch [23/360], Batch [150/196], Loss: 1.7343\n",
      "Epoch [23/360], Batch [155/196], Loss: 0.9317\n",
      "Epoch [23/360], Batch [160/196], Loss: 0.5594\n",
      "Epoch [23/360], Batch [165/196], Loss: 0.5496\n",
      "Epoch [23/360], Batch [170/196], Loss: 0.8810\n",
      "Epoch [23/360], Batch [175/196], Loss: 1.7038\n",
      "Epoch [23/360], Batch [180/196], Loss: 0.4316\n",
      "Epoch [23/360], Batch [185/196], Loss: 0.8017\n",
      "Epoch [23/360], Batch [190/196], Loss: 0.5594\n",
      "Epoch [23/360], Batch [195/196], Loss: 0.5723\n",
      "Epoch [24/360], Batch [5/196], Loss: 0.7536\n",
      "Epoch [24/360], Batch [10/196], Loss: 0.7231\n",
      "Epoch [24/360], Batch [15/196], Loss: 0.8761\n",
      "Epoch [24/360], Batch [20/196], Loss: 0.5028\n",
      "Epoch [24/360], Batch [25/196], Loss: 0.4055\n",
      "Epoch [24/360], Batch [30/196], Loss: 1.0794\n",
      "Epoch [24/360], Batch [35/196], Loss: 0.6753\n",
      "Epoch [24/360], Batch [40/196], Loss: 0.9390\n",
      "Epoch [24/360], Batch [45/196], Loss: 0.4463\n",
      "Epoch [24/360], Batch [50/196], Loss: 0.6077\n",
      "Epoch [24/360], Batch [55/196], Loss: 0.5818\n",
      "Epoch [24/360], Batch [60/196], Loss: 0.6373\n",
      "Epoch [24/360], Batch [65/196], Loss: 0.6535\n",
      "Epoch [24/360], Batch [70/196], Loss: 0.4352\n",
      "Epoch [24/360], Batch [75/196], Loss: 0.9913\n",
      "Epoch [24/360], Batch [80/196], Loss: 0.9247\n",
      "Epoch [24/360], Batch [85/196], Loss: 1.3585\n",
      "Epoch [24/360], Batch [90/196], Loss: 0.6827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/360], Batch [95/196], Loss: 1.6988\n",
      "Epoch [24/360], Batch [100/196], Loss: 0.8897\n",
      "Epoch [24/360], Batch [105/196], Loss: 0.7606\n",
      "Epoch [24/360], Batch [110/196], Loss: 0.3023\n",
      "Epoch [24/360], Batch [115/196], Loss: 0.3442\n",
      "Epoch [24/360], Batch [120/196], Loss: 0.7001\n",
      "Epoch [24/360], Batch [125/196], Loss: 1.3640\n",
      "Epoch [24/360], Batch [130/196], Loss: 0.6945\n",
      "Epoch [24/360], Batch [135/196], Loss: 0.4611\n",
      "Epoch [24/360], Batch [140/196], Loss: 1.8436\n",
      "Epoch [24/360], Batch [145/196], Loss: 1.2504\n",
      "Epoch [24/360], Batch [150/196], Loss: 0.5268\n",
      "Epoch [24/360], Batch [155/196], Loss: 1.2754\n",
      "Epoch [24/360], Batch [160/196], Loss: 0.7555\n",
      "Epoch [24/360], Batch [165/196], Loss: 1.0010\n",
      "Epoch [24/360], Batch [170/196], Loss: 0.5525\n",
      "Epoch [24/360], Batch [175/196], Loss: 0.6712\n",
      "Epoch [24/360], Batch [180/196], Loss: 1.2146\n",
      "Epoch [24/360], Batch [185/196], Loss: 0.4013\n",
      "Epoch [24/360], Batch [190/196], Loss: 0.6672\n",
      "Epoch [24/360], Batch [195/196], Loss: 0.5671\n",
      "Epoch [25/360], Batch [5/196], Loss: 0.7700\n",
      "Epoch [25/360], Batch [10/196], Loss: 0.8730\n",
      "Epoch [25/360], Batch [15/196], Loss: 0.8563\n",
      "Epoch [25/360], Batch [20/196], Loss: 0.9225\n",
      "Epoch [25/360], Batch [25/196], Loss: 0.6566\n",
      "Epoch [25/360], Batch [30/196], Loss: 1.7334\n",
      "Epoch [25/360], Batch [35/196], Loss: 1.1451\n",
      "Epoch [25/360], Batch [40/196], Loss: 0.5513\n",
      "Epoch [25/360], Batch [45/196], Loss: 0.7467\n",
      "Epoch [25/360], Batch [50/196], Loss: 0.9088\n",
      "Epoch [25/360], Batch [55/196], Loss: 0.8049\n",
      "Epoch [25/360], Batch [60/196], Loss: 0.5527\n",
      "Epoch [25/360], Batch [65/196], Loss: 1.3713\n",
      "Epoch [25/360], Batch [70/196], Loss: 0.9031\n",
      "Epoch [25/360], Batch [75/196], Loss: 0.7236\n",
      "Epoch [25/360], Batch [80/196], Loss: 0.7301\n",
      "Epoch [25/360], Batch [85/196], Loss: 1.0057\n",
      "Epoch [25/360], Batch [90/196], Loss: 0.5767\n",
      "Epoch [25/360], Batch [95/196], Loss: 0.6341\n",
      "Epoch [25/360], Batch [100/196], Loss: 0.6645\n",
      "Epoch [25/360], Batch [105/196], Loss: 1.1726\n",
      "Epoch [25/360], Batch [110/196], Loss: 0.5483\n",
      "Epoch [25/360], Batch [115/196], Loss: 0.4675\n",
      "Epoch [25/360], Batch [120/196], Loss: 0.5297\n",
      "Epoch [25/360], Batch [125/196], Loss: 0.7328\n",
      "Epoch [25/360], Batch [130/196], Loss: 0.6304\n",
      "Epoch [25/360], Batch [135/196], Loss: 0.9640\n",
      "Epoch [25/360], Batch [140/196], Loss: 1.1888\n",
      "Epoch [25/360], Batch [145/196], Loss: 0.8254\n",
      "Epoch [25/360], Batch [150/196], Loss: 0.7067\n",
      "Epoch [25/360], Batch [155/196], Loss: 0.5259\n",
      "Epoch [25/360], Batch [160/196], Loss: 1.1753\n",
      "Epoch [25/360], Batch [165/196], Loss: 0.4799\n",
      "Epoch [25/360], Batch [170/196], Loss: 0.9750\n",
      "Epoch [25/360], Batch [175/196], Loss: 0.5344\n",
      "Epoch [25/360], Batch [180/196], Loss: 0.7078\n",
      "Epoch [25/360], Batch [185/196], Loss: 0.6716\n",
      "Epoch [25/360], Batch [190/196], Loss: 0.7669\n",
      "Epoch [25/360], Batch [195/196], Loss: 7.1419\n",
      "Epoch [26/360], Batch [5/196], Loss: 0.7093\n",
      "Epoch [26/360], Batch [10/196], Loss: 0.5982\n",
      "Epoch [26/360], Batch [15/196], Loss: 0.4999\n",
      "Epoch [26/360], Batch [20/196], Loss: 0.7356\n",
      "Epoch [26/360], Batch [25/196], Loss: 1.3072\n",
      "Epoch [26/360], Batch [30/196], Loss: 0.6427\n",
      "Epoch [26/360], Batch [35/196], Loss: 0.7137\n",
      "Epoch [26/360], Batch [40/196], Loss: 0.9197\n",
      "Epoch [26/360], Batch [45/196], Loss: 1.9911\n",
      "Epoch [26/360], Batch [50/196], Loss: 1.0020\n",
      "Epoch [26/360], Batch [55/196], Loss: 1.7696\n",
      "Epoch [26/360], Batch [60/196], Loss: 2.1853\n",
      "Epoch [26/360], Batch [65/196], Loss: 0.9437\n",
      "Epoch [26/360], Batch [70/196], Loss: 1.0239\n",
      "Epoch [26/360], Batch [75/196], Loss: 0.4257\n",
      "Epoch [26/360], Batch [80/196], Loss: 0.8623\n",
      "Epoch [26/360], Batch [85/196], Loss: 1.1270\n",
      "Epoch [26/360], Batch [90/196], Loss: 1.0940\n",
      "Epoch [26/360], Batch [95/196], Loss: 0.7620\n",
      "Epoch [26/360], Batch [100/196], Loss: 0.9489\n",
      "Epoch [26/360], Batch [105/196], Loss: 0.5012\n",
      "Epoch [26/360], Batch [110/196], Loss: 0.5730\n",
      "Epoch [26/360], Batch [115/196], Loss: 0.8010\n",
      "Epoch [26/360], Batch [120/196], Loss: 1.3393\n",
      "Epoch [26/360], Batch [125/196], Loss: 0.7391\n",
      "Epoch [26/360], Batch [130/196], Loss: 1.1121\n",
      "Epoch [26/360], Batch [135/196], Loss: 0.7980\n",
      "Epoch [26/360], Batch [140/196], Loss: 1.0589\n",
      "Epoch [26/360], Batch [145/196], Loss: 0.8675\n",
      "Epoch [26/360], Batch [150/196], Loss: 0.7006\n",
      "Epoch [26/360], Batch [155/196], Loss: 1.2323\n",
      "Epoch [26/360], Batch [160/196], Loss: 1.6137\n",
      "Epoch [26/360], Batch [165/196], Loss: 1.2393\n",
      "Epoch [26/360], Batch [170/196], Loss: 0.4459\n",
      "Epoch [26/360], Batch [175/196], Loss: 0.8297\n",
      "Epoch [26/360], Batch [180/196], Loss: 1.0072\n",
      "Epoch [26/360], Batch [185/196], Loss: 0.5387\n",
      "Epoch [26/360], Batch [190/196], Loss: 2.7155\n",
      "Epoch [26/360], Batch [195/196], Loss: 0.3057\n",
      "Epoch [27/360], Batch [5/196], Loss: 0.3391\n",
      "Epoch [27/360], Batch [10/196], Loss: 0.8870\n",
      "Epoch [27/360], Batch [15/196], Loss: 1.3465\n",
      "Epoch [27/360], Batch [20/196], Loss: 0.7665\n",
      "Epoch [27/360], Batch [25/196], Loss: 0.7874\n",
      "Epoch [27/360], Batch [30/196], Loss: 0.8687\n",
      "Epoch [27/360], Batch [35/196], Loss: 0.7343\n",
      "Epoch [27/360], Batch [40/196], Loss: 1.0839\n",
      "Epoch [27/360], Batch [45/196], Loss: 0.6248\n",
      "Epoch [27/360], Batch [50/196], Loss: 1.0214\n",
      "Epoch [27/360], Batch [55/196], Loss: 0.4208\n",
      "Epoch [27/360], Batch [60/196], Loss: 0.6888\n",
      "Epoch [27/360], Batch [65/196], Loss: 0.7620\n",
      "Epoch [27/360], Batch [70/196], Loss: 0.6345\n",
      "Epoch [27/360], Batch [75/196], Loss: 0.9314\n",
      "Epoch [27/360], Batch [80/196], Loss: 0.6509\n",
      "Epoch [27/360], Batch [85/196], Loss: 0.7653\n",
      "Epoch [27/360], Batch [90/196], Loss: 4.8973\n",
      "Epoch [27/360], Batch [95/196], Loss: 0.7726\n",
      "Epoch [27/360], Batch [100/196], Loss: 1.1479\n",
      "Epoch [27/360], Batch [105/196], Loss: 0.3697\n",
      "Epoch [27/360], Batch [110/196], Loss: 1.3713\n",
      "Epoch [27/360], Batch [115/196], Loss: 0.6703\n",
      "Epoch [27/360], Batch [120/196], Loss: 1.3648\n",
      "Epoch [27/360], Batch [125/196], Loss: 0.7690\n",
      "Epoch [27/360], Batch [130/196], Loss: 1.2086\n",
      "Epoch [27/360], Batch [135/196], Loss: 0.7927\n",
      "Epoch [27/360], Batch [140/196], Loss: 1.4337\n",
      "Epoch [27/360], Batch [145/196], Loss: 2.0833\n",
      "Epoch [27/360], Batch [150/196], Loss: 0.5779\n",
      "Epoch [27/360], Batch [155/196], Loss: 1.6208\n",
      "Epoch [27/360], Batch [160/196], Loss: 0.9308\n",
      "Epoch [27/360], Batch [165/196], Loss: 0.5840\n",
      "Epoch [27/360], Batch [170/196], Loss: 0.5102\n",
      "Epoch [27/360], Batch [175/196], Loss: 0.6687\n",
      "Epoch [27/360], Batch [180/196], Loss: 0.7749\n",
      "Epoch [27/360], Batch [185/196], Loss: 0.6563\n",
      "Epoch [27/360], Batch [190/196], Loss: 0.5567\n",
      "Epoch [27/360], Batch [195/196], Loss: 0.9870\n",
      "Epoch [28/360], Batch [5/196], Loss: 0.3063\n",
      "Epoch [28/360], Batch [10/196], Loss: 0.6932\n",
      "Epoch [28/360], Batch [15/196], Loss: 0.4962\n",
      "Epoch [28/360], Batch [20/196], Loss: 0.5378\n",
      "Epoch [28/360], Batch [25/196], Loss: 1.4131\n",
      "Epoch [28/360], Batch [30/196], Loss: 0.9405\n",
      "Epoch [28/360], Batch [35/196], Loss: 0.6163\n",
      "Epoch [28/360], Batch [40/196], Loss: 0.7098\n",
      "Epoch [28/360], Batch [45/196], Loss: 0.4357\n",
      "Epoch [28/360], Batch [50/196], Loss: 0.5575\n",
      "Epoch [28/360], Batch [55/196], Loss: 0.3084\n",
      "Epoch [28/360], Batch [60/196], Loss: 1.1406\n",
      "Epoch [28/360], Batch [65/196], Loss: 2.2128\n",
      "Epoch [28/360], Batch [70/196], Loss: 0.5362\n",
      "Epoch [28/360], Batch [75/196], Loss: 0.9997\n",
      "Epoch [28/360], Batch [80/196], Loss: 0.6545\n",
      "Epoch [28/360], Batch [85/196], Loss: 1.4037\n",
      "Epoch [28/360], Batch [90/196], Loss: 1.3369\n",
      "Epoch [28/360], Batch [95/196], Loss: 0.5307\n",
      "Epoch [28/360], Batch [100/196], Loss: 0.7779\n",
      "Epoch [28/360], Batch [105/196], Loss: 1.7769\n",
      "Epoch [28/360], Batch [110/196], Loss: 0.8531\n",
      "Epoch [28/360], Batch [115/196], Loss: 0.5367\n",
      "Epoch [28/360], Batch [120/196], Loss: 2.3248\n",
      "Epoch [28/360], Batch [125/196], Loss: 0.7868\n",
      "Epoch [28/360], Batch [130/196], Loss: 1.1155\n",
      "Epoch [28/360], Batch [135/196], Loss: 0.6230\n",
      "Epoch [28/360], Batch [140/196], Loss: 0.7084\n",
      "Epoch [28/360], Batch [145/196], Loss: 1.2841\n",
      "Epoch [28/360], Batch [150/196], Loss: 0.8862\n",
      "Epoch [28/360], Batch [155/196], Loss: 1.1954\n",
      "Epoch [28/360], Batch [160/196], Loss: 1.4782\n",
      "Epoch [28/360], Batch [165/196], Loss: 1.4936\n",
      "Epoch [28/360], Batch [170/196], Loss: 0.4622\n",
      "Epoch [28/360], Batch [175/196], Loss: 2.7811\n",
      "Epoch [28/360], Batch [180/196], Loss: 1.0357\n",
      "Epoch [28/360], Batch [185/196], Loss: 1.0414\n",
      "Epoch [28/360], Batch [190/196], Loss: 0.4981\n",
      "Epoch [28/360], Batch [195/196], Loss: 0.3196\n",
      "Epoch [29/360], Batch [5/196], Loss: 0.9575\n",
      "Epoch [29/360], Batch [10/196], Loss: 0.6290\n",
      "Epoch [29/360], Batch [15/196], Loss: 2.0422\n",
      "Epoch [29/360], Batch [20/196], Loss: 0.5785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/360], Batch [25/196], Loss: 1.3065\n",
      "Epoch [29/360], Batch [30/196], Loss: 0.7532\n",
      "Epoch [29/360], Batch [35/196], Loss: 0.9417\n",
      "Epoch [29/360], Batch [40/196], Loss: 0.2774\n",
      "Epoch [29/360], Batch [45/196], Loss: 0.6264\n",
      "Epoch [29/360], Batch [50/196], Loss: 0.6902\n",
      "Epoch [29/360], Batch [55/196], Loss: 0.6446\n",
      "Epoch [29/360], Batch [60/196], Loss: 1.3620\n",
      "Epoch [29/360], Batch [65/196], Loss: 0.6314\n",
      "Epoch [29/360], Batch [70/196], Loss: 1.1120\n",
      "Epoch [29/360], Batch [75/196], Loss: 0.7866\n",
      "Epoch [29/360], Batch [80/196], Loss: 0.6716\n",
      "Epoch [29/360], Batch [85/196], Loss: 0.8853\n",
      "Epoch [29/360], Batch [90/196], Loss: 0.8199\n",
      "Epoch [29/360], Batch [95/196], Loss: 0.5223\n",
      "Epoch [29/360], Batch [100/196], Loss: 0.5293\n",
      "Epoch [29/360], Batch [105/196], Loss: 1.0531\n",
      "Epoch [29/360], Batch [110/196], Loss: 1.2518\n",
      "Epoch [29/360], Batch [115/196], Loss: 0.7745\n",
      "Epoch [29/360], Batch [120/196], Loss: 0.4539\n",
      "Epoch [29/360], Batch [125/196], Loss: 0.8199\n",
      "Epoch [29/360], Batch [130/196], Loss: 0.5595\n",
      "Epoch [29/360], Batch [135/196], Loss: 0.8733\n",
      "Epoch [29/360], Batch [140/196], Loss: 0.5843\n",
      "Epoch [29/360], Batch [145/196], Loss: 0.7233\n",
      "Epoch [29/360], Batch [150/196], Loss: 0.8443\n",
      "Epoch [29/360], Batch [155/196], Loss: 0.9231\n",
      "Epoch [29/360], Batch [160/196], Loss: 1.0624\n",
      "Epoch [29/360], Batch [165/196], Loss: 1.5726\n",
      "Epoch [29/360], Batch [170/196], Loss: 1.0774\n",
      "Epoch [29/360], Batch [175/196], Loss: 0.6629\n",
      "Epoch [29/360], Batch [180/196], Loss: 0.4693\n",
      "Epoch [29/360], Batch [185/196], Loss: 0.4704\n",
      "Epoch [29/360], Batch [190/196], Loss: 0.9391\n",
      "Epoch [29/360], Batch [195/196], Loss: 0.6157\n",
      "Epoch [30/360], Batch [5/196], Loss: 0.4973\n",
      "Epoch [30/360], Batch [10/196], Loss: 0.6562\n",
      "Epoch [30/360], Batch [15/196], Loss: 0.7930\n",
      "Epoch [30/360], Batch [20/196], Loss: 0.3519\n",
      "Epoch [30/360], Batch [25/196], Loss: 0.7007\n",
      "Epoch [30/360], Batch [30/196], Loss: 0.8012\n",
      "Epoch [30/360], Batch [35/196], Loss: 0.8320\n",
      "Epoch [30/360], Batch [40/196], Loss: 0.4769\n",
      "Epoch [30/360], Batch [45/196], Loss: 2.2412\n",
      "Epoch [30/360], Batch [50/196], Loss: 1.7151\n",
      "Epoch [30/360], Batch [55/196], Loss: 0.8376\n",
      "Epoch [30/360], Batch [60/196], Loss: 0.5741\n",
      "Epoch [30/360], Batch [65/196], Loss: 0.9721\n",
      "Epoch [30/360], Batch [70/196], Loss: 1.2054\n",
      "Epoch [30/360], Batch [75/196], Loss: 0.4714\n",
      "Epoch [30/360], Batch [80/196], Loss: 0.8179\n",
      "Epoch [30/360], Batch [85/196], Loss: 0.3829\n",
      "Epoch [30/360], Batch [90/196], Loss: 3.6392\n",
      "Epoch [30/360], Batch [95/196], Loss: 0.7627\n",
      "Epoch [30/360], Batch [100/196], Loss: 0.3482\n",
      "Epoch [30/360], Batch [105/196], Loss: 6.8601\n",
      "Epoch [30/360], Batch [110/196], Loss: 2.2780\n",
      "Epoch [30/360], Batch [115/196], Loss: 3.9804\n",
      "Epoch [30/360], Batch [120/196], Loss: 1.1076\n",
      "Epoch [30/360], Batch [125/196], Loss: 0.6762\n",
      "Epoch [30/360], Batch [130/196], Loss: 0.5392\n",
      "Epoch [30/360], Batch [135/196], Loss: 0.7358\n",
      "Epoch [30/360], Batch [140/196], Loss: 0.5452\n",
      "Epoch [30/360], Batch [145/196], Loss: 0.7739\n",
      "Epoch [30/360], Batch [150/196], Loss: 0.4648\n",
      "Epoch [30/360], Batch [155/196], Loss: 0.5870\n",
      "Epoch [30/360], Batch [160/196], Loss: 1.8686\n",
      "Epoch [30/360], Batch [165/196], Loss: 0.6299\n",
      "Epoch [30/360], Batch [170/196], Loss: 1.6109\n",
      "Epoch [30/360], Batch [175/196], Loss: 1.4680\n",
      "Epoch [30/360], Batch [180/196], Loss: 1.0406\n",
      "Epoch [30/360], Batch [185/196], Loss: 1.2887\n",
      "Epoch [30/360], Batch [190/196], Loss: 0.4729\n",
      "Epoch [30/360], Batch [195/196], Loss: 0.6416\n",
      "Epoch [31/360], Batch [5/196], Loss: 1.4200\n",
      "Epoch [31/360], Batch [10/196], Loss: 0.6861\n",
      "Epoch [31/360], Batch [15/196], Loss: 1.1291\n",
      "Epoch [31/360], Batch [20/196], Loss: 1.5667\n",
      "Epoch [31/360], Batch [25/196], Loss: 0.4784\n",
      "Epoch [31/360], Batch [30/196], Loss: 0.8463\n",
      "Epoch [31/360], Batch [35/196], Loss: 1.5172\n",
      "Epoch [31/360], Batch [40/196], Loss: 1.2916\n",
      "Epoch [31/360], Batch [45/196], Loss: 1.0465\n",
      "Epoch [31/360], Batch [50/196], Loss: 0.6020\n",
      "Epoch [31/360], Batch [55/196], Loss: 0.9759\n",
      "Epoch [31/360], Batch [60/196], Loss: 0.8466\n",
      "Epoch [31/360], Batch [65/196], Loss: 0.8850\n",
      "Epoch [31/360], Batch [70/196], Loss: 0.9227\n",
      "Epoch [31/360], Batch [75/196], Loss: 0.5378\n",
      "Epoch [31/360], Batch [80/196], Loss: 0.6440\n",
      "Epoch [31/360], Batch [85/196], Loss: 1.0467\n",
      "Epoch [31/360], Batch [90/196], Loss: 1.3478\n",
      "Epoch [31/360], Batch [95/196], Loss: 0.6892\n",
      "Epoch [31/360], Batch [100/196], Loss: 0.7492\n",
      "Epoch [31/360], Batch [105/196], Loss: 1.0224\n",
      "Epoch [31/360], Batch [110/196], Loss: 0.7070\n",
      "Epoch [31/360], Batch [115/196], Loss: 0.9924\n",
      "Epoch [31/360], Batch [120/196], Loss: 0.3917\n",
      "Epoch [31/360], Batch [125/196], Loss: 1.4015\n",
      "Epoch [31/360], Batch [130/196], Loss: 1.0721\n",
      "Epoch [31/360], Batch [135/196], Loss: 0.5277\n",
      "Epoch [31/360], Batch [140/196], Loss: 4.3419\n",
      "Epoch [31/360], Batch [145/196], Loss: 0.6877\n",
      "Epoch [31/360], Batch [150/196], Loss: 0.9708\n",
      "Epoch [31/360], Batch [155/196], Loss: 0.4039\n",
      "Epoch [31/360], Batch [160/196], Loss: 0.5881\n",
      "Epoch [31/360], Batch [165/196], Loss: 1.0814\n",
      "Epoch [31/360], Batch [170/196], Loss: 0.7365\n",
      "Epoch [31/360], Batch [175/196], Loss: 0.5154\n",
      "Epoch [31/360], Batch [180/196], Loss: 0.5407\n",
      "Epoch [31/360], Batch [185/196], Loss: 0.3292\n",
      "Epoch [31/360], Batch [190/196], Loss: 1.4723\n",
      "Epoch [31/360], Batch [195/196], Loss: 0.8806\n",
      "Epoch [32/360], Batch [5/196], Loss: 0.4871\n",
      "Epoch [32/360], Batch [10/196], Loss: 1.2704\n",
      "Epoch [32/360], Batch [15/196], Loss: 0.9882\n",
      "Epoch [32/360], Batch [20/196], Loss: 0.6458\n",
      "Epoch [32/360], Batch [25/196], Loss: 1.7344\n",
      "Epoch [32/360], Batch [30/196], Loss: 1.9452\n",
      "Epoch [32/360], Batch [35/196], Loss: 2.3712\n",
      "Epoch [32/360], Batch [40/196], Loss: 1.4852\n",
      "Epoch [32/360], Batch [45/196], Loss: 0.8388\n",
      "Epoch [32/360], Batch [50/196], Loss: 0.5181\n",
      "Epoch [32/360], Batch [55/196], Loss: 1.3780\n",
      "Epoch [32/360], Batch [60/196], Loss: 1.0846\n",
      "Epoch [32/360], Batch [65/196], Loss: 0.6584\n",
      "Epoch [32/360], Batch [70/196], Loss: 0.4920\n",
      "Epoch [32/360], Batch [75/196], Loss: 1.0843\n",
      "Epoch [32/360], Batch [80/196], Loss: 0.7564\n",
      "Epoch [32/360], Batch [85/196], Loss: 1.0043\n",
      "Epoch [32/360], Batch [90/196], Loss: 0.4359\n",
      "Epoch [32/360], Batch [95/196], Loss: 0.5181\n",
      "Epoch [32/360], Batch [100/196], Loss: 0.7279\n",
      "Epoch [32/360], Batch [105/196], Loss: 0.6519\n",
      "Epoch [32/360], Batch [110/196], Loss: 1.1125\n",
      "Epoch [32/360], Batch [115/196], Loss: 0.9309\n",
      "Epoch [32/360], Batch [120/196], Loss: 1.2994\n",
      "Epoch [32/360], Batch [125/196], Loss: 0.6613\n",
      "Epoch [32/360], Batch [130/196], Loss: 1.2380\n",
      "Epoch [32/360], Batch [135/196], Loss: 0.7417\n",
      "Epoch [32/360], Batch [140/196], Loss: 1.3768\n",
      "Epoch [32/360], Batch [145/196], Loss: 2.6043\n",
      "Epoch [32/360], Batch [150/196], Loss: 1.0246\n",
      "Epoch [32/360], Batch [155/196], Loss: 0.7722\n",
      "Epoch [32/360], Batch [160/196], Loss: 0.2657\n",
      "Epoch [32/360], Batch [165/196], Loss: 0.4565\n",
      "Epoch [32/360], Batch [170/196], Loss: 0.8593\n",
      "Epoch [32/360], Batch [175/196], Loss: 0.9049\n",
      "Epoch [32/360], Batch [180/196], Loss: 0.5211\n",
      "Epoch [32/360], Batch [185/196], Loss: 1.6828\n",
      "Epoch [32/360], Batch [190/196], Loss: 1.5710\n",
      "Epoch [32/360], Batch [195/196], Loss: 0.7065\n",
      "Epoch [33/360], Batch [5/196], Loss: 1.0931\n",
      "Epoch [33/360], Batch [10/196], Loss: 0.8711\n",
      "Epoch [33/360], Batch [15/196], Loss: 1.1326\n",
      "Epoch [33/360], Batch [20/196], Loss: 0.8069\n",
      "Epoch [33/360], Batch [25/196], Loss: 2.0994\n",
      "Epoch [33/360], Batch [30/196], Loss: 0.8482\n",
      "Epoch [33/360], Batch [35/196], Loss: 0.7092\n",
      "Epoch [33/360], Batch [40/196], Loss: 0.5982\n",
      "Epoch [33/360], Batch [45/196], Loss: 1.1152\n",
      "Epoch [33/360], Batch [50/196], Loss: 1.6580\n",
      "Epoch [33/360], Batch [55/196], Loss: 1.1141\n",
      "Epoch [33/360], Batch [60/196], Loss: 1.2298\n",
      "Epoch [33/360], Batch [65/196], Loss: 0.7894\n",
      "Epoch [33/360], Batch [70/196], Loss: 0.9242\n",
      "Epoch [33/360], Batch [75/196], Loss: 0.6648\n",
      "Epoch [33/360], Batch [80/196], Loss: 0.9559\n",
      "Epoch [33/360], Batch [85/196], Loss: 0.7946\n",
      "Epoch [33/360], Batch [90/196], Loss: 0.3851\n",
      "Epoch [33/360], Batch [95/196], Loss: 1.2771\n",
      "Epoch [33/360], Batch [100/196], Loss: 1.2921\n",
      "Epoch [33/360], Batch [105/196], Loss: 1.0123\n",
      "Epoch [33/360], Batch [110/196], Loss: 0.7206\n",
      "Epoch [33/360], Batch [115/196], Loss: 0.6680\n",
      "Epoch [33/360], Batch [120/196], Loss: 0.6599\n",
      "Epoch [33/360], Batch [125/196], Loss: 0.7735\n",
      "Epoch [33/360], Batch [130/196], Loss: 0.3603\n",
      "Epoch [33/360], Batch [135/196], Loss: 0.5314\n",
      "Epoch [33/360], Batch [140/196], Loss: 0.9083\n",
      "Epoch [33/360], Batch [145/196], Loss: 0.5087\n",
      "Epoch [33/360], Batch [150/196], Loss: 1.2351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/360], Batch [155/196], Loss: 1.7113\n",
      "Epoch [33/360], Batch [160/196], Loss: 0.6089\n",
      "Epoch [33/360], Batch [165/196], Loss: 0.5250\n",
      "Epoch [33/360], Batch [170/196], Loss: 0.5879\n",
      "Epoch [33/360], Batch [175/196], Loss: 1.3749\n",
      "Epoch [33/360], Batch [180/196], Loss: 0.7049\n",
      "Epoch [33/360], Batch [185/196], Loss: 0.7638\n",
      "Epoch [33/360], Batch [190/196], Loss: 0.5103\n",
      "Epoch [33/360], Batch [195/196], Loss: 0.4116\n",
      "Epoch [34/360], Batch [5/196], Loss: 0.7514\n",
      "Epoch [34/360], Batch [10/196], Loss: 4.0752\n",
      "Epoch [34/360], Batch [15/196], Loss: 0.6165\n",
      "Epoch [34/360], Batch [20/196], Loss: 1.1042\n",
      "Epoch [34/360], Batch [25/196], Loss: 0.6511\n",
      "Epoch [34/360], Batch [30/196], Loss: 2.0307\n",
      "Epoch [34/360], Batch [35/196], Loss: 1.2799\n",
      "Epoch [34/360], Batch [40/196], Loss: 1.7466\n",
      "Epoch [34/360], Batch [45/196], Loss: 4.2186\n",
      "Epoch [34/360], Batch [50/196], Loss: 0.8386\n",
      "Epoch [34/360], Batch [55/196], Loss: 0.8160\n",
      "Epoch [34/360], Batch [60/196], Loss: 0.6106\n",
      "Epoch [34/360], Batch [65/196], Loss: 0.4748\n",
      "Epoch [34/360], Batch [70/196], Loss: 1.7102\n",
      "Epoch [34/360], Batch [75/196], Loss: 0.6589\n",
      "Epoch [34/360], Batch [80/196], Loss: 0.7571\n",
      "Epoch [34/360], Batch [85/196], Loss: 0.5917\n",
      "Epoch [34/360], Batch [90/196], Loss: 0.7050\n",
      "Epoch [34/360], Batch [95/196], Loss: 0.7927\n",
      "Epoch [34/360], Batch [100/196], Loss: 0.7518\n",
      "Epoch [34/360], Batch [105/196], Loss: 0.8007\n",
      "Epoch [34/360], Batch [110/196], Loss: 0.4798\n",
      "Epoch [34/360], Batch [115/196], Loss: 0.5107\n",
      "Epoch [34/360], Batch [120/196], Loss: 0.4214\n",
      "Epoch [34/360], Batch [125/196], Loss: 0.9195\n",
      "Epoch [34/360], Batch [130/196], Loss: 1.1083\n",
      "Epoch [34/360], Batch [135/196], Loss: 1.1572\n",
      "Epoch [34/360], Batch [140/196], Loss: 0.9655\n",
      "Epoch [34/360], Batch [145/196], Loss: 1.4726\n",
      "Epoch [34/360], Batch [150/196], Loss: 1.6053\n",
      "Epoch [34/360], Batch [155/196], Loss: 1.3338\n",
      "Epoch [34/360], Batch [160/196], Loss: 0.8391\n",
      "Epoch [34/360], Batch [165/196], Loss: 0.4932\n",
      "Epoch [34/360], Batch [170/196], Loss: 0.6726\n",
      "Epoch [34/360], Batch [175/196], Loss: 0.5575\n",
      "Epoch [34/360], Batch [180/196], Loss: 0.8556\n",
      "Epoch [34/360], Batch [185/196], Loss: 0.4807\n",
      "Epoch [34/360], Batch [190/196], Loss: 0.5831\n",
      "Epoch [34/360], Batch [195/196], Loss: 0.4494\n",
      "Epoch [35/360], Batch [5/196], Loss: 0.5116\n",
      "Epoch [35/360], Batch [10/196], Loss: 1.0219\n",
      "Epoch [35/360], Batch [15/196], Loss: 0.7426\n",
      "Epoch [35/360], Batch [20/196], Loss: 1.3814\n",
      "Epoch [35/360], Batch [25/196], Loss: 0.6824\n",
      "Epoch [35/360], Batch [30/196], Loss: 0.6772\n",
      "Epoch [35/360], Batch [35/196], Loss: 1.0072\n",
      "Epoch [35/360], Batch [40/196], Loss: 0.6298\n",
      "Epoch [35/360], Batch [45/196], Loss: 0.5002\n",
      "Epoch [35/360], Batch [50/196], Loss: 0.6343\n",
      "Epoch [35/360], Batch [55/196], Loss: 0.5746\n",
      "Epoch [35/360], Batch [60/196], Loss: 0.7899\n",
      "Epoch [35/360], Batch [65/196], Loss: 1.5510\n",
      "Epoch [35/360], Batch [70/196], Loss: 0.8795\n",
      "Epoch [35/360], Batch [75/196], Loss: 1.4916\n",
      "Epoch [35/360], Batch [80/196], Loss: 0.3970\n",
      "Epoch [35/360], Batch [85/196], Loss: 1.0810\n",
      "Epoch [35/360], Batch [90/196], Loss: 0.6068\n",
      "Epoch [35/360], Batch [95/196], Loss: 0.4304\n",
      "Epoch [35/360], Batch [100/196], Loss: 0.5355\n",
      "Epoch [35/360], Batch [105/196], Loss: 1.1723\n",
      "Epoch [35/360], Batch [110/196], Loss: 0.4165\n",
      "Epoch [35/360], Batch [115/196], Loss: 0.5862\n",
      "Epoch [35/360], Batch [120/196], Loss: 0.5608\n",
      "Epoch [35/360], Batch [125/196], Loss: 0.5232\n",
      "Epoch [35/360], Batch [130/196], Loss: 0.9270\n",
      "Epoch [35/360], Batch [135/196], Loss: 1.3869\n",
      "Epoch [35/360], Batch [140/196], Loss: 0.8393\n",
      "Epoch [35/360], Batch [145/196], Loss: 1.5063\n",
      "Epoch [35/360], Batch [150/196], Loss: 0.4908\n",
      "Epoch [35/360], Batch [155/196], Loss: 0.7759\n",
      "Epoch [35/360], Batch [160/196], Loss: 0.3431\n",
      "Epoch [35/360], Batch [165/196], Loss: 0.3855\n",
      "Epoch [35/360], Batch [170/196], Loss: 0.8548\n",
      "Epoch [35/360], Batch [175/196], Loss: 0.8051\n",
      "Epoch [35/360], Batch [180/196], Loss: 0.7450\n",
      "Epoch [35/360], Batch [185/196], Loss: 1.1743\n",
      "Epoch [35/360], Batch [190/196], Loss: 1.0161\n",
      "Epoch [35/360], Batch [195/196], Loss: 0.5704\n",
      "Epoch [36/360], Batch [5/196], Loss: 1.1518\n",
      "Epoch [36/360], Batch [10/196], Loss: 1.7119\n",
      "Epoch [36/360], Batch [15/196], Loss: 0.5313\n",
      "Epoch [36/360], Batch [20/196], Loss: 0.8833\n",
      "Epoch [36/360], Batch [25/196], Loss: 1.0121\n",
      "Epoch [36/360], Batch [30/196], Loss: 0.6510\n",
      "Epoch [36/360], Batch [35/196], Loss: 1.2695\n",
      "Epoch [36/360], Batch [40/196], Loss: 0.8148\n",
      "Epoch [36/360], Batch [45/196], Loss: 1.0511\n",
      "Epoch [36/360], Batch [50/196], Loss: 0.8602\n",
      "Epoch [36/360], Batch [55/196], Loss: 0.6751\n",
      "Epoch [36/360], Batch [60/196], Loss: 1.5284\n",
      "Epoch [36/360], Batch [65/196], Loss: 0.4567\n",
      "Epoch [36/360], Batch [70/196], Loss: 0.6397\n",
      "Epoch [36/360], Batch [75/196], Loss: 1.1495\n",
      "Epoch [36/360], Batch [80/196], Loss: 0.6625\n",
      "Epoch [36/360], Batch [85/196], Loss: 0.9710\n",
      "Epoch [36/360], Batch [90/196], Loss: 0.8756\n",
      "Epoch [36/360], Batch [95/196], Loss: 1.0929\n",
      "Epoch [36/360], Batch [100/196], Loss: 2.1577\n",
      "Epoch [36/360], Batch [105/196], Loss: 1.4480\n",
      "Epoch [36/360], Batch [110/196], Loss: 0.5951\n",
      "Epoch [36/360], Batch [115/196], Loss: 1.7627\n",
      "Epoch [36/360], Batch [120/196], Loss: 0.9360\n",
      "Epoch [36/360], Batch [125/196], Loss: 0.8212\n",
      "Epoch [36/360], Batch [130/196], Loss: 0.6810\n",
      "Epoch [36/360], Batch [135/196], Loss: 2.3145\n",
      "Epoch [36/360], Batch [140/196], Loss: 0.6062\n",
      "Epoch [36/360], Batch [145/196], Loss: 1.1463\n",
      "Epoch [36/360], Batch [150/196], Loss: 0.5314\n",
      "Epoch [36/360], Batch [155/196], Loss: 1.0312\n",
      "Epoch [36/360], Batch [160/196], Loss: 0.8307\n",
      "Epoch [36/360], Batch [165/196], Loss: 0.7958\n",
      "Epoch [36/360], Batch [170/196], Loss: 0.7285\n",
      "Epoch [36/360], Batch [175/196], Loss: 0.5413\n",
      "Epoch [36/360], Batch [180/196], Loss: 0.5710\n",
      "Epoch [36/360], Batch [185/196], Loss: 0.6574\n",
      "Epoch [36/360], Batch [190/196], Loss: 0.8084\n",
      "Epoch [36/360], Batch [195/196], Loss: 0.8452\n",
      "Epoch [37/360], Batch [5/196], Loss: 0.9634\n",
      "Epoch [37/360], Batch [10/196], Loss: 0.5489\n",
      "Epoch [37/360], Batch [15/196], Loss: 0.2917\n",
      "Epoch [37/360], Batch [20/196], Loss: 0.7621\n",
      "Epoch [37/360], Batch [25/196], Loss: 0.3437\n",
      "Epoch [37/360], Batch [30/196], Loss: 1.0386\n",
      "Epoch [37/360], Batch [35/196], Loss: 0.7398\n",
      "Epoch [37/360], Batch [40/196], Loss: 0.4368\n",
      "Epoch [37/360], Batch [45/196], Loss: 0.7051\n",
      "Epoch [37/360], Batch [50/196], Loss: 0.3707\n",
      "Epoch [37/360], Batch [55/196], Loss: 1.0928\n",
      "Epoch [37/360], Batch [60/196], Loss: 0.9367\n",
      "Epoch [37/360], Batch [65/196], Loss: 2.3203\n",
      "Epoch [37/360], Batch [70/196], Loss: 0.8927\n",
      "Epoch [37/360], Batch [75/196], Loss: 0.7016\n",
      "Epoch [37/360], Batch [80/196], Loss: 0.5965\n",
      "Epoch [37/360], Batch [85/196], Loss: 0.6265\n",
      "Epoch [37/360], Batch [90/196], Loss: 1.0347\n",
      "Epoch [37/360], Batch [95/196], Loss: 1.6666\n",
      "Epoch [37/360], Batch [100/196], Loss: 0.8724\n",
      "Epoch [37/360], Batch [105/196], Loss: 0.8516\n",
      "Epoch [37/360], Batch [110/196], Loss: 0.6049\n",
      "Epoch [37/360], Batch [115/196], Loss: 1.2783\n",
      "Epoch [37/360], Batch [120/196], Loss: 1.0037\n",
      "Epoch [37/360], Batch [125/196], Loss: 1.2779\n",
      "Epoch [37/360], Batch [130/196], Loss: 0.9216\n",
      "Epoch [37/360], Batch [135/196], Loss: 1.0116\n",
      "Epoch [37/360], Batch [140/196], Loss: 0.8604\n",
      "Epoch [37/360], Batch [145/196], Loss: 0.8307\n",
      "Epoch [37/360], Batch [150/196], Loss: 0.9968\n",
      "Epoch [37/360], Batch [155/196], Loss: 0.7278\n",
      "Epoch [37/360], Batch [160/196], Loss: 1.0401\n",
      "Epoch [37/360], Batch [165/196], Loss: 0.8012\n",
      "Epoch [37/360], Batch [170/196], Loss: 0.6175\n",
      "Epoch [37/360], Batch [175/196], Loss: 0.6812\n",
      "Epoch [37/360], Batch [180/196], Loss: 1.2185\n",
      "Epoch [37/360], Batch [185/196], Loss: 0.5560\n",
      "Epoch [37/360], Batch [190/196], Loss: 0.7989\n",
      "Epoch [37/360], Batch [195/196], Loss: 1.1983\n",
      "Epoch [38/360], Batch [5/196], Loss: 0.8932\n",
      "Epoch [38/360], Batch [10/196], Loss: 0.9558\n",
      "Epoch [38/360], Batch [15/196], Loss: 0.3657\n",
      "Epoch [38/360], Batch [20/196], Loss: 0.9397\n",
      "Epoch [38/360], Batch [25/196], Loss: 0.9313\n",
      "Epoch [38/360], Batch [30/196], Loss: 0.3401\n",
      "Epoch [38/360], Batch [35/196], Loss: 0.7718\n",
      "Epoch [38/360], Batch [40/196], Loss: 0.5187\n",
      "Epoch [38/360], Batch [45/196], Loss: 0.6010\n",
      "Epoch [38/360], Batch [50/196], Loss: 0.7527\n",
      "Epoch [38/360], Batch [55/196], Loss: 0.6644\n",
      "Epoch [38/360], Batch [60/196], Loss: 0.6822\n",
      "Epoch [38/360], Batch [65/196], Loss: 1.0612\n",
      "Epoch [38/360], Batch [70/196], Loss: 1.7549\n",
      "Epoch [38/360], Batch [75/196], Loss: 0.6905\n",
      "Epoch [38/360], Batch [80/196], Loss: 0.9587\n",
      "Epoch [38/360], Batch [85/196], Loss: 0.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/360], Batch [90/196], Loss: 1.2126\n",
      "Epoch [38/360], Batch [95/196], Loss: 0.4012\n",
      "Epoch [38/360], Batch [100/196], Loss: 0.4608\n",
      "Epoch [38/360], Batch [105/196], Loss: 0.5994\n",
      "Epoch [38/360], Batch [110/196], Loss: 1.2171\n",
      "Epoch [38/360], Batch [115/196], Loss: 1.5642\n",
      "Epoch [38/360], Batch [120/196], Loss: 0.6976\n",
      "Epoch [38/360], Batch [125/196], Loss: 0.6705\n",
      "Epoch [38/360], Batch [130/196], Loss: 0.4957\n",
      "Epoch [38/360], Batch [135/196], Loss: 0.9043\n",
      "Epoch [38/360], Batch [140/196], Loss: 0.8267\n",
      "Epoch [38/360], Batch [145/196], Loss: 0.7579\n",
      "Epoch [38/360], Batch [150/196], Loss: 0.5390\n",
      "Epoch [38/360], Batch [155/196], Loss: 1.0304\n",
      "Epoch [38/360], Batch [160/196], Loss: 0.8876\n",
      "Epoch [38/360], Batch [165/196], Loss: 1.9899\n",
      "Epoch [38/360], Batch [170/196], Loss: 0.4448\n",
      "Epoch [38/360], Batch [175/196], Loss: 1.0168\n",
      "Epoch [38/360], Batch [180/196], Loss: 0.5924\n",
      "Epoch [38/360], Batch [185/196], Loss: 0.5005\n",
      "Epoch [38/360], Batch [190/196], Loss: 0.6537\n",
      "Epoch [38/360], Batch [195/196], Loss: 1.0460\n",
      "Epoch [39/360], Batch [5/196], Loss: 1.0395\n",
      "Epoch [39/360], Batch [10/196], Loss: 0.6499\n",
      "Epoch [39/360], Batch [15/196], Loss: 0.5244\n",
      "Epoch [39/360], Batch [20/196], Loss: 0.5937\n",
      "Epoch [39/360], Batch [25/196], Loss: 0.3800\n",
      "Epoch [39/360], Batch [30/196], Loss: 1.2042\n",
      "Epoch [39/360], Batch [35/196], Loss: 2.2119\n",
      "Epoch [39/360], Batch [40/196], Loss: 0.4496\n",
      "Epoch [39/360], Batch [45/196], Loss: 0.9292\n",
      "Epoch [39/360], Batch [50/196], Loss: 1.5718\n",
      "Epoch [39/360], Batch [55/196], Loss: 0.2907\n",
      "Epoch [39/360], Batch [60/196], Loss: 0.5478\n",
      "Epoch [39/360], Batch [65/196], Loss: 0.6972\n",
      "Epoch [39/360], Batch [70/196], Loss: 0.9831\n",
      "Epoch [39/360], Batch [75/196], Loss: 0.3566\n",
      "Epoch [39/360], Batch [80/196], Loss: 0.7196\n",
      "Epoch [39/360], Batch [85/196], Loss: 0.5020\n",
      "Epoch [39/360], Batch [90/196], Loss: 0.4814\n",
      "Epoch [39/360], Batch [95/196], Loss: 0.9001\n",
      "Epoch [39/360], Batch [100/196], Loss: 0.6825\n",
      "Epoch [39/360], Batch [105/196], Loss: 3.1627\n",
      "Epoch [39/360], Batch [110/196], Loss: 1.3593\n",
      "Epoch [39/360], Batch [115/196], Loss: 0.9588\n",
      "Epoch [39/360], Batch [120/196], Loss: 1.1325\n",
      "Epoch [39/360], Batch [125/196], Loss: 0.5566\n",
      "Epoch [39/360], Batch [130/196], Loss: 1.4377\n",
      "Epoch [39/360], Batch [135/196], Loss: 0.7555\n",
      "Epoch [39/360], Batch [140/196], Loss: 1.9577\n",
      "Epoch [39/360], Batch [145/196], Loss: 0.6903\n",
      "Epoch [39/360], Batch [150/196], Loss: 0.4527\n",
      "Epoch [39/360], Batch [155/196], Loss: 1.6091\n",
      "Epoch [39/360], Batch [160/196], Loss: 0.8606\n",
      "Epoch [39/360], Batch [165/196], Loss: 0.6791\n",
      "Epoch [39/360], Batch [170/196], Loss: 0.4183\n",
      "Epoch [39/360], Batch [175/196], Loss: 0.7001\n",
      "Epoch [39/360], Batch [180/196], Loss: 1.0039\n",
      "Epoch [39/360], Batch [185/196], Loss: 0.8191\n",
      "Epoch [39/360], Batch [190/196], Loss: 0.5953\n",
      "Epoch [39/360], Batch [195/196], Loss: 1.2550\n",
      "Epoch [40/360], Batch [5/196], Loss: 1.9697\n",
      "Epoch [40/360], Batch [10/196], Loss: 0.8136\n",
      "Epoch [40/360], Batch [15/196], Loss: 0.6298\n",
      "Epoch [40/360], Batch [20/196], Loss: 0.8264\n",
      "Epoch [40/360], Batch [25/196], Loss: 0.5601\n",
      "Epoch [40/360], Batch [30/196], Loss: 0.7099\n",
      "Epoch [40/360], Batch [35/196], Loss: 0.5660\n",
      "Epoch [40/360], Batch [40/196], Loss: 0.7579\n",
      "Epoch [40/360], Batch [45/196], Loss: 0.6531\n",
      "Epoch [40/360], Batch [50/196], Loss: 1.0113\n",
      "Epoch [40/360], Batch [55/196], Loss: 0.4780\n",
      "Epoch [40/360], Batch [60/196], Loss: 0.7271\n",
      "Epoch [40/360], Batch [65/196], Loss: 0.9837\n",
      "Epoch [40/360], Batch [70/196], Loss: 0.7511\n",
      "Epoch [40/360], Batch [75/196], Loss: 0.5660\n",
      "Epoch [40/360], Batch [80/196], Loss: 0.6798\n",
      "Epoch [40/360], Batch [85/196], Loss: 2.4384\n",
      "Epoch [40/360], Batch [90/196], Loss: 6.9872\n",
      "Epoch [40/360], Batch [95/196], Loss: 0.4793\n",
      "Epoch [40/360], Batch [100/196], Loss: 1.0646\n",
      "Epoch [40/360], Batch [105/196], Loss: 0.6313\n",
      "Epoch [40/360], Batch [110/196], Loss: 0.7446\n",
      "Epoch [40/360], Batch [115/196], Loss: 0.7241\n",
      "Epoch [40/360], Batch [120/196], Loss: 1.1841\n",
      "Epoch [40/360], Batch [125/196], Loss: 0.9854\n",
      "Epoch [40/360], Batch [130/196], Loss: 0.7167\n",
      "Epoch [40/360], Batch [135/196], Loss: 0.6357\n",
      "Epoch [40/360], Batch [140/196], Loss: 1.0562\n",
      "Epoch [40/360], Batch [145/196], Loss: 0.5257\n",
      "Epoch [40/360], Batch [150/196], Loss: 0.9549\n",
      "Epoch [40/360], Batch [155/196], Loss: 0.6994\n",
      "Epoch [40/360], Batch [160/196], Loss: 1.1090\n",
      "Epoch [40/360], Batch [165/196], Loss: 0.6696\n",
      "Epoch [40/360], Batch [170/196], Loss: 0.5976\n",
      "Epoch [40/360], Batch [175/196], Loss: 1.0711\n",
      "Epoch [40/360], Batch [180/196], Loss: 0.4314\n",
      "Epoch [40/360], Batch [185/196], Loss: 0.8489\n",
      "Epoch [40/360], Batch [190/196], Loss: 0.8005\n",
      "Epoch [40/360], Batch [195/196], Loss: 0.9638\n",
      "Epoch [41/360], Batch [5/196], Loss: 0.7895\n",
      "Epoch [41/360], Batch [10/196], Loss: 1.4442\n",
      "Epoch [41/360], Batch [15/196], Loss: 0.3031\n",
      "Epoch [41/360], Batch [20/196], Loss: 0.6216\n",
      "Epoch [41/360], Batch [25/196], Loss: 0.6087\n",
      "Epoch [41/360], Batch [30/196], Loss: 0.6631\n",
      "Epoch [41/360], Batch [35/196], Loss: 0.7313\n",
      "Epoch [41/360], Batch [40/196], Loss: 1.1031\n",
      "Epoch [41/360], Batch [45/196], Loss: 1.6941\n",
      "Epoch [41/360], Batch [50/196], Loss: 0.5186\n",
      "Epoch [41/360], Batch [55/196], Loss: 0.7128\n",
      "Epoch [41/360], Batch [60/196], Loss: 0.6199\n",
      "Epoch [41/360], Batch [65/196], Loss: 0.8792\n",
      "Epoch [41/360], Batch [70/196], Loss: 1.8922\n",
      "Epoch [41/360], Batch [75/196], Loss: 0.9896\n",
      "Epoch [41/360], Batch [80/196], Loss: 0.3689\n",
      "Epoch [41/360], Batch [85/196], Loss: 0.5766\n",
      "Epoch [41/360], Batch [90/196], Loss: 0.7016\n",
      "Epoch [41/360], Batch [95/196], Loss: 0.8664\n",
      "Epoch [41/360], Batch [100/196], Loss: 6.4908\n",
      "Epoch [41/360], Batch [105/196], Loss: 0.7546\n",
      "Epoch [41/360], Batch [110/196], Loss: 2.2176\n",
      "Epoch [41/360], Batch [115/196], Loss: 0.9886\n",
      "Epoch [41/360], Batch [120/196], Loss: 2.3670\n",
      "Epoch [41/360], Batch [125/196], Loss: 0.9024\n",
      "Epoch [41/360], Batch [130/196], Loss: 0.7361\n",
      "Epoch [41/360], Batch [135/196], Loss: 1.7917\n",
      "Epoch [41/360], Batch [140/196], Loss: 0.5106\n",
      "Epoch [41/360], Batch [145/196], Loss: 0.8628\n",
      "Epoch [41/360], Batch [150/196], Loss: 0.5620\n",
      "Epoch [41/360], Batch [155/196], Loss: 2.4819\n",
      "Epoch [41/360], Batch [160/196], Loss: 1.2648\n",
      "Epoch [41/360], Batch [165/196], Loss: 0.7332\n",
      "Epoch [41/360], Batch [170/196], Loss: 0.9428\n",
      "Epoch [41/360], Batch [175/196], Loss: 0.3617\n",
      "Epoch [41/360], Batch [180/196], Loss: 0.8047\n",
      "Epoch [41/360], Batch [185/196], Loss: 1.4947\n",
      "Epoch [41/360], Batch [190/196], Loss: 0.5891\n",
      "Epoch [41/360], Batch [195/196], Loss: 0.4957\n",
      "Epoch [42/360], Batch [5/196], Loss: 0.6067\n",
      "Epoch [42/360], Batch [10/196], Loss: 1.5466\n",
      "Epoch [42/360], Batch [15/196], Loss: 0.8769\n",
      "Epoch [42/360], Batch [20/196], Loss: 0.7814\n",
      "Epoch [42/360], Batch [25/196], Loss: 0.8252\n",
      "Epoch [42/360], Batch [30/196], Loss: 0.6176\n",
      "Epoch [42/360], Batch [35/196], Loss: 0.6828\n",
      "Epoch [42/360], Batch [40/196], Loss: 1.6484\n",
      "Epoch [42/360], Batch [45/196], Loss: 0.7994\n",
      "Epoch [42/360], Batch [50/196], Loss: 0.5512\n",
      "Epoch [42/360], Batch [55/196], Loss: 0.6104\n",
      "Epoch [42/360], Batch [60/196], Loss: 0.7504\n",
      "Epoch [42/360], Batch [65/196], Loss: 1.0316\n",
      "Epoch [42/360], Batch [70/196], Loss: 0.9053\n",
      "Epoch [42/360], Batch [75/196], Loss: 0.4326\n",
      "Epoch [42/360], Batch [80/196], Loss: 0.8923\n",
      "Epoch [42/360], Batch [85/196], Loss: 0.9110\n",
      "Epoch [42/360], Batch [90/196], Loss: 0.5074\n",
      "Epoch [42/360], Batch [95/196], Loss: 0.8586\n",
      "Epoch [42/360], Batch [100/196], Loss: 0.5752\n",
      "Epoch [42/360], Batch [105/196], Loss: 0.4869\n",
      "Epoch [42/360], Batch [110/196], Loss: 0.5113\n",
      "Epoch [42/360], Batch [115/196], Loss: 0.3404\n",
      "Epoch [42/360], Batch [120/196], Loss: 0.5446\n",
      "Epoch [42/360], Batch [125/196], Loss: 0.6062\n",
      "Epoch [42/360], Batch [130/196], Loss: 1.4970\n",
      "Epoch [42/360], Batch [135/196], Loss: 1.2185\n",
      "Epoch [42/360], Batch [140/196], Loss: 1.2157\n",
      "Epoch [42/360], Batch [145/196], Loss: 0.4011\n",
      "Epoch [42/360], Batch [150/196], Loss: 0.6430\n",
      "Epoch [42/360], Batch [155/196], Loss: 1.2923\n",
      "Epoch [42/360], Batch [160/196], Loss: 0.4736\n",
      "Epoch [42/360], Batch [165/196], Loss: 0.3441\n",
      "Epoch [42/360], Batch [170/196], Loss: 0.7862\n",
      "Epoch [42/360], Batch [175/196], Loss: 0.8123\n",
      "Epoch [42/360], Batch [180/196], Loss: 0.4468\n",
      "Epoch [42/360], Batch [185/196], Loss: 1.3207\n",
      "Epoch [42/360], Batch [190/196], Loss: 1.1509\n",
      "Epoch [42/360], Batch [195/196], Loss: 0.7954\n",
      "Epoch [43/360], Batch [5/196], Loss: 1.2974\n",
      "Epoch [43/360], Batch [10/196], Loss: 0.5616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/360], Batch [15/196], Loss: 0.9256\n",
      "Epoch [43/360], Batch [20/196], Loss: 0.7421\n",
      "Epoch [43/360], Batch [25/196], Loss: 0.7177\n",
      "Epoch [43/360], Batch [30/196], Loss: 0.7465\n",
      "Epoch [43/360], Batch [35/196], Loss: 1.2163\n",
      "Epoch [43/360], Batch [40/196], Loss: 0.7336\n",
      "Epoch [43/360], Batch [45/196], Loss: 0.6581\n",
      "Epoch [43/360], Batch [50/196], Loss: 0.7997\n",
      "Epoch [43/360], Batch [55/196], Loss: 0.5063\n",
      "Epoch [43/360], Batch [60/196], Loss: 0.5448\n",
      "Epoch [43/360], Batch [65/196], Loss: 0.8203\n",
      "Epoch [43/360], Batch [70/196], Loss: 0.4691\n",
      "Epoch [43/360], Batch [75/196], Loss: 1.4482\n",
      "Epoch [43/360], Batch [80/196], Loss: 0.7809\n",
      "Epoch [43/360], Batch [85/196], Loss: 1.3216\n",
      "Epoch [43/360], Batch [90/196], Loss: 0.3981\n",
      "Epoch [43/360], Batch [95/196], Loss: 0.9484\n",
      "Epoch [43/360], Batch [100/196], Loss: 0.3388\n",
      "Epoch [43/360], Batch [105/196], Loss: 1.2872\n",
      "Epoch [43/360], Batch [110/196], Loss: 0.7716\n",
      "Epoch [43/360], Batch [115/196], Loss: 0.7214\n",
      "Epoch [43/360], Batch [120/196], Loss: 1.2160\n",
      "Epoch [43/360], Batch [125/196], Loss: 0.3901\n",
      "Epoch [43/360], Batch [130/196], Loss: 0.8547\n",
      "Epoch [43/360], Batch [135/196], Loss: 1.0255\n",
      "Epoch [43/360], Batch [140/196], Loss: 0.8124\n",
      "Epoch [43/360], Batch [145/196], Loss: 1.1099\n",
      "Epoch [43/360], Batch [150/196], Loss: 1.5544\n",
      "Epoch [43/360], Batch [155/196], Loss: 0.5176\n",
      "Epoch [43/360], Batch [160/196], Loss: 0.6376\n",
      "Epoch [43/360], Batch [165/196], Loss: 0.9247\n",
      "Epoch [43/360], Batch [170/196], Loss: 0.5180\n",
      "Epoch [43/360], Batch [175/196], Loss: 1.1464\n",
      "Epoch [43/360], Batch [180/196], Loss: 1.0090\n",
      "Epoch [43/360], Batch [185/196], Loss: 0.6411\n",
      "Epoch [43/360], Batch [190/196], Loss: 0.7734\n",
      "Epoch [43/360], Batch [195/196], Loss: 1.1013\n",
      "Epoch [44/360], Batch [5/196], Loss: 0.6192\n",
      "Epoch [44/360], Batch [10/196], Loss: 0.3281\n",
      "Epoch [44/360], Batch [15/196], Loss: 1.3543\n",
      "Epoch [44/360], Batch [20/196], Loss: 0.7732\n",
      "Epoch [44/360], Batch [25/196], Loss: 0.5985\n",
      "Epoch [44/360], Batch [30/196], Loss: 0.3549\n",
      "Epoch [44/360], Batch [35/196], Loss: 0.4390\n",
      "Epoch [44/360], Batch [40/196], Loss: 0.8946\n",
      "Epoch [44/360], Batch [45/196], Loss: 0.7858\n",
      "Epoch [44/360], Batch [50/196], Loss: 0.7542\n",
      "Epoch [44/360], Batch [55/196], Loss: 0.7400\n",
      "Epoch [44/360], Batch [60/196], Loss: 0.7194\n",
      "Epoch [44/360], Batch [65/196], Loss: 2.3380\n",
      "Epoch [44/360], Batch [70/196], Loss: 0.5810\n",
      "Epoch [44/360], Batch [75/196], Loss: 0.9625\n",
      "Epoch [44/360], Batch [80/196], Loss: 1.2896\n",
      "Epoch [44/360], Batch [85/196], Loss: 0.6770\n",
      "Epoch [44/360], Batch [90/196], Loss: 0.7381\n",
      "Epoch [44/360], Batch [95/196], Loss: 0.6202\n",
      "Epoch [44/360], Batch [100/196], Loss: 0.4522\n",
      "Epoch [44/360], Batch [105/196], Loss: 1.0080\n",
      "Epoch [44/360], Batch [110/196], Loss: 0.3971\n",
      "Epoch [44/360], Batch [115/196], Loss: 0.7142\n",
      "Epoch [44/360], Batch [120/196], Loss: 0.6207\n",
      "Epoch [44/360], Batch [125/196], Loss: 0.8135\n",
      "Epoch [44/360], Batch [130/196], Loss: 0.4990\n",
      "Epoch [44/360], Batch [135/196], Loss: 0.4880\n",
      "Epoch [44/360], Batch [140/196], Loss: 1.0075\n",
      "Epoch [44/360], Batch [145/196], Loss: 0.6792\n",
      "Epoch [44/360], Batch [150/196], Loss: 1.4737\n",
      "Epoch [44/360], Batch [155/196], Loss: 1.5457\n",
      "Epoch [44/360], Batch [160/196], Loss: 0.9497\n",
      "Epoch [44/360], Batch [165/196], Loss: 0.5398\n",
      "Epoch [44/360], Batch [170/196], Loss: 0.5593\n",
      "Epoch [44/360], Batch [175/196], Loss: 0.8316\n",
      "Epoch [44/360], Batch [180/196], Loss: 0.6103\n",
      "Epoch [44/360], Batch [185/196], Loss: 0.5350\n",
      "Epoch [44/360], Batch [190/196], Loss: 0.7891\n",
      "Epoch [44/360], Batch [195/196], Loss: 0.7044\n",
      "Epoch [45/360], Batch [5/196], Loss: 0.7886\n",
      "Epoch [45/360], Batch [10/196], Loss: 0.4276\n",
      "Epoch [45/360], Batch [15/196], Loss: 0.8001\n",
      "Epoch [45/360], Batch [20/196], Loss: 0.9800\n",
      "Epoch [45/360], Batch [25/196], Loss: 0.5849\n",
      "Epoch [45/360], Batch [30/196], Loss: 0.6013\n",
      "Epoch [45/360], Batch [35/196], Loss: 4.0619\n",
      "Epoch [45/360], Batch [40/196], Loss: 0.3730\n",
      "Epoch [45/360], Batch [45/196], Loss: 0.3981\n",
      "Epoch [45/360], Batch [50/196], Loss: 1.9190\n",
      "Epoch [45/360], Batch [55/196], Loss: 1.5386\n",
      "Epoch [45/360], Batch [60/196], Loss: 1.0458\n",
      "Epoch [45/360], Batch [65/196], Loss: 0.5780\n",
      "Epoch [45/360], Batch [70/196], Loss: 0.7501\n",
      "Epoch [45/360], Batch [75/196], Loss: 0.7352\n",
      "Epoch [45/360], Batch [80/196], Loss: 1.8081\n",
      "Epoch [45/360], Batch [85/196], Loss: 0.7259\n",
      "Epoch [45/360], Batch [90/196], Loss: 0.8261\n",
      "Epoch [45/360], Batch [95/196], Loss: 1.2343\n",
      "Epoch [45/360], Batch [100/196], Loss: 0.7730\n",
      "Epoch [45/360], Batch [105/196], Loss: 0.6892\n",
      "Epoch [45/360], Batch [110/196], Loss: 0.3964\n",
      "Epoch [45/360], Batch [115/196], Loss: 0.6415\n",
      "Epoch [45/360], Batch [120/196], Loss: 0.4118\n",
      "Epoch [45/360], Batch [125/196], Loss: 0.5185\n",
      "Epoch [45/360], Batch [130/196], Loss: 0.5949\n",
      "Epoch [45/360], Batch [135/196], Loss: 1.7903\n",
      "Epoch [45/360], Batch [140/196], Loss: 0.5551\n",
      "Epoch [45/360], Batch [145/196], Loss: 0.8247\n",
      "Epoch [45/360], Batch [150/196], Loss: 0.7354\n",
      "Epoch [45/360], Batch [155/196], Loss: 0.6985\n",
      "Epoch [45/360], Batch [160/196], Loss: 0.8386\n",
      "Epoch [45/360], Batch [165/196], Loss: 0.3565\n",
      "Epoch [45/360], Batch [170/196], Loss: 0.5782\n",
      "Epoch [45/360], Batch [175/196], Loss: 1.5033\n",
      "Epoch [45/360], Batch [180/196], Loss: 1.0786\n",
      "Epoch [45/360], Batch [185/196], Loss: 0.6731\n",
      "Epoch [45/360], Batch [190/196], Loss: 0.3046\n",
      "Epoch [45/360], Batch [195/196], Loss: 0.7047\n",
      "Epoch [46/360], Batch [5/196], Loss: 0.8272\n",
      "Epoch [46/360], Batch [10/196], Loss: 0.9568\n",
      "Epoch [46/360], Batch [15/196], Loss: 0.6092\n",
      "Epoch [46/360], Batch [20/196], Loss: 0.6529\n",
      "Epoch [46/360], Batch [25/196], Loss: 0.5567\n",
      "Epoch [46/360], Batch [30/196], Loss: 1.1419\n",
      "Epoch [46/360], Batch [35/196], Loss: 1.3699\n",
      "Epoch [46/360], Batch [40/196], Loss: 0.7989\n",
      "Epoch [46/360], Batch [45/196], Loss: 0.5800\n",
      "Epoch [46/360], Batch [50/196], Loss: 0.9972\n",
      "Epoch [46/360], Batch [55/196], Loss: 0.4994\n",
      "Epoch [46/360], Batch [60/196], Loss: 0.5090\n",
      "Epoch [46/360], Batch [65/196], Loss: 0.6411\n",
      "Epoch [46/360], Batch [70/196], Loss: 0.9498\n",
      "Epoch [46/360], Batch [75/196], Loss: 0.2777\n",
      "Epoch [46/360], Batch [80/196], Loss: 0.6374\n",
      "Epoch [46/360], Batch [85/196], Loss: 0.7689\n",
      "Epoch [46/360], Batch [90/196], Loss: 1.1397\n",
      "Epoch [46/360], Batch [95/196], Loss: 0.5456\n",
      "Epoch [46/360], Batch [100/196], Loss: 1.0717\n",
      "Epoch [46/360], Batch [105/196], Loss: 0.7684\n",
      "Epoch [46/360], Batch [110/196], Loss: 0.7197\n",
      "Epoch [46/360], Batch [115/196], Loss: 1.1735\n",
      "Epoch [46/360], Batch [120/196], Loss: 1.0642\n",
      "Epoch [46/360], Batch [125/196], Loss: 0.4705\n",
      "Epoch [46/360], Batch [130/196], Loss: 0.8671\n",
      "Epoch [46/360], Batch [135/196], Loss: 0.5436\n",
      "Epoch [46/360], Batch [140/196], Loss: 1.1879\n",
      "Epoch [46/360], Batch [145/196], Loss: 0.5980\n",
      "Epoch [46/360], Batch [150/196], Loss: 0.5030\n",
      "Epoch [46/360], Batch [155/196], Loss: 0.5659\n",
      "Epoch [46/360], Batch [160/196], Loss: 0.4867\n",
      "Epoch [46/360], Batch [165/196], Loss: 1.3605\n",
      "Epoch [46/360], Batch [170/196], Loss: 0.6613\n",
      "Epoch [46/360], Batch [175/196], Loss: 0.6185\n",
      "Epoch [46/360], Batch [180/196], Loss: 0.7195\n",
      "Epoch [46/360], Batch [185/196], Loss: 0.6964\n",
      "Epoch [46/360], Batch [190/196], Loss: 0.7053\n",
      "Epoch [46/360], Batch [195/196], Loss: 0.8666\n",
      "Epoch [47/360], Batch [5/196], Loss: 0.8241\n",
      "Epoch [47/360], Batch [10/196], Loss: 1.5371\n",
      "Epoch [47/360], Batch [15/196], Loss: 0.7387\n",
      "Epoch [47/360], Batch [20/196], Loss: 0.7165\n",
      "Epoch [47/360], Batch [25/196], Loss: 1.7753\n",
      "Epoch [47/360], Batch [30/196], Loss: 0.3939\n",
      "Epoch [47/360], Batch [35/196], Loss: 0.7954\n",
      "Epoch [47/360], Batch [40/196], Loss: 1.9282\n",
      "Epoch [47/360], Batch [45/196], Loss: 1.5245\n",
      "Epoch [47/360], Batch [50/196], Loss: 0.5827\n",
      "Epoch [47/360], Batch [55/196], Loss: 0.6755\n",
      "Epoch [47/360], Batch [60/196], Loss: 0.5012\n",
      "Epoch [47/360], Batch [65/196], Loss: 1.0065\n",
      "Epoch [47/360], Batch [70/196], Loss: 0.5983\n",
      "Epoch [47/360], Batch [75/196], Loss: 0.4096\n",
      "Epoch [47/360], Batch [80/196], Loss: 0.4622\n",
      "Epoch [47/360], Batch [85/196], Loss: 0.2935\n",
      "Epoch [47/360], Batch [90/196], Loss: 1.0417\n",
      "Epoch [47/360], Batch [95/196], Loss: 0.9770\n",
      "Epoch [47/360], Batch [100/196], Loss: 0.8240\n",
      "Epoch [47/360], Batch [105/196], Loss: 0.6661\n",
      "Epoch [47/360], Batch [110/196], Loss: 1.2217\n",
      "Epoch [47/360], Batch [115/196], Loss: 0.7117\n",
      "Epoch [47/360], Batch [120/196], Loss: 0.8685\n",
      "Epoch [47/360], Batch [125/196], Loss: 0.3877\n",
      "Epoch [47/360], Batch [130/196], Loss: 0.5276\n",
      "Epoch [47/360], Batch [135/196], Loss: 0.6961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/360], Batch [140/196], Loss: 0.4092\n",
      "Epoch [47/360], Batch [145/196], Loss: 1.0784\n",
      "Epoch [47/360], Batch [150/196], Loss: 0.5974\n",
      "Epoch [47/360], Batch [155/196], Loss: 0.6611\n",
      "Epoch [47/360], Batch [160/196], Loss: 0.6742\n",
      "Epoch [47/360], Batch [165/196], Loss: 0.4017\n",
      "Epoch [47/360], Batch [170/196], Loss: 1.0219\n",
      "Epoch [47/360], Batch [175/196], Loss: 0.5132\n",
      "Epoch [47/360], Batch [180/196], Loss: 0.5242\n",
      "Epoch [47/360], Batch [185/196], Loss: 0.3161\n",
      "Epoch [47/360], Batch [190/196], Loss: 0.9211\n",
      "Epoch [47/360], Batch [195/196], Loss: 1.0724\n",
      "Epoch [48/360], Batch [5/196], Loss: 0.4372\n",
      "Epoch [48/360], Batch [10/196], Loss: 0.4645\n",
      "Epoch [48/360], Batch [15/196], Loss: 0.7594\n",
      "Epoch [48/360], Batch [20/196], Loss: 0.9954\n",
      "Epoch [48/360], Batch [25/196], Loss: 1.0969\n",
      "Epoch [48/360], Batch [30/196], Loss: 0.5478\n",
      "Epoch [48/360], Batch [35/196], Loss: 0.4898\n",
      "Epoch [48/360], Batch [40/196], Loss: 1.7065\n",
      "Epoch [48/360], Batch [45/196], Loss: 0.4504\n",
      "Epoch [48/360], Batch [50/196], Loss: 0.7300\n",
      "Epoch [48/360], Batch [55/196], Loss: 0.7967\n",
      "Epoch [48/360], Batch [60/196], Loss: 1.1058\n",
      "Epoch [48/360], Batch [65/196], Loss: 0.7680\n",
      "Epoch [48/360], Batch [70/196], Loss: 0.8264\n",
      "Epoch [48/360], Batch [75/196], Loss: 0.5246\n",
      "Epoch [48/360], Batch [80/196], Loss: 0.6352\n",
      "Epoch [48/360], Batch [85/196], Loss: 0.5234\n",
      "Epoch [48/360], Batch [90/196], Loss: 0.3738\n",
      "Epoch [48/360], Batch [95/196], Loss: 0.8504\n",
      "Epoch [48/360], Batch [100/196], Loss: 0.6023\n",
      "Epoch [48/360], Batch [105/196], Loss: 1.1357\n",
      "Epoch [48/360], Batch [110/196], Loss: 0.6086\n",
      "Epoch [48/360], Batch [115/196], Loss: 0.8406\n",
      "Epoch [48/360], Batch [120/196], Loss: 0.5036\n",
      "Epoch [48/360], Batch [125/196], Loss: 1.0983\n",
      "Epoch [48/360], Batch [130/196], Loss: 0.8562\n",
      "Epoch [48/360], Batch [135/196], Loss: 0.5994\n",
      "Epoch [48/360], Batch [140/196], Loss: 0.3785\n",
      "Epoch [48/360], Batch [145/196], Loss: 1.5207\n",
      "Epoch [48/360], Batch [150/196], Loss: 0.9800\n",
      "Epoch [48/360], Batch [155/196], Loss: 0.5299\n",
      "Epoch [48/360], Batch [160/196], Loss: 0.3779\n",
      "Epoch [48/360], Batch [165/196], Loss: 0.6717\n",
      "Epoch [48/360], Batch [170/196], Loss: 1.0228\n",
      "Epoch [48/360], Batch [175/196], Loss: 0.2398\n",
      "Epoch [48/360], Batch [180/196], Loss: 0.7285\n",
      "Epoch [48/360], Batch [185/196], Loss: 1.8771\n",
      "Epoch [48/360], Batch [190/196], Loss: 0.8627\n",
      "Epoch [48/360], Batch [195/196], Loss: 1.1529\n",
      "Epoch [49/360], Batch [5/196], Loss: 0.6152\n",
      "Epoch [49/360], Batch [10/196], Loss: 0.6826\n",
      "Epoch [49/360], Batch [15/196], Loss: 0.3979\n",
      "Epoch [49/360], Batch [20/196], Loss: 0.7863\n",
      "Epoch [49/360], Batch [25/196], Loss: 0.4515\n",
      "Epoch [49/360], Batch [30/196], Loss: 0.7558\n",
      "Epoch [49/360], Batch [35/196], Loss: 0.4919\n",
      "Epoch [49/360], Batch [40/196], Loss: 0.8065\n",
      "Epoch [49/360], Batch [45/196], Loss: 0.6484\n",
      "Epoch [49/360], Batch [50/196], Loss: 0.2675\n",
      "Epoch [49/360], Batch [55/196], Loss: 1.1197\n",
      "Epoch [49/360], Batch [60/196], Loss: 0.5611\n",
      "Epoch [49/360], Batch [65/196], Loss: 0.5500\n",
      "Epoch [49/360], Batch [70/196], Loss: 0.7256\n",
      "Epoch [49/360], Batch [75/196], Loss: 3.7340\n",
      "Epoch [49/360], Batch [80/196], Loss: 0.5221\n",
      "Epoch [49/360], Batch [85/196], Loss: 0.9540\n",
      "Epoch [49/360], Batch [90/196], Loss: 0.7733\n",
      "Epoch [49/360], Batch [95/196], Loss: 0.6539\n",
      "Epoch [49/360], Batch [100/196], Loss: 0.3141\n",
      "Epoch [49/360], Batch [105/196], Loss: 0.9174\n",
      "Epoch [49/360], Batch [110/196], Loss: 0.6947\n",
      "Epoch [49/360], Batch [115/196], Loss: 0.5955\n",
      "Epoch [49/360], Batch [120/196], Loss: 0.9621\n",
      "Epoch [49/360], Batch [125/196], Loss: 0.4394\n",
      "Epoch [49/360], Batch [130/196], Loss: 0.8206\n",
      "Epoch [49/360], Batch [135/196], Loss: 0.6275\n",
      "Epoch [49/360], Batch [140/196], Loss: 0.5833\n",
      "Epoch [49/360], Batch [145/196], Loss: 0.2555\n",
      "Epoch [49/360], Batch [150/196], Loss: 0.9699\n",
      "Epoch [49/360], Batch [155/196], Loss: 0.6093\n",
      "Epoch [49/360], Batch [160/196], Loss: 0.6419\n",
      "Epoch [49/360], Batch [165/196], Loss: 0.4454\n",
      "Epoch [49/360], Batch [170/196], Loss: 0.6353\n",
      "Epoch [49/360], Batch [175/196], Loss: 1.8090\n",
      "Epoch [49/360], Batch [180/196], Loss: 0.6543\n",
      "Epoch [49/360], Batch [185/196], Loss: 0.5875\n",
      "Epoch [49/360], Batch [190/196], Loss: 2.9375\n",
      "Epoch [49/360], Batch [195/196], Loss: 0.9088\n",
      "Epoch [50/360], Batch [5/196], Loss: 0.7887\n",
      "Epoch [50/360], Batch [10/196], Loss: 0.5236\n",
      "Epoch [50/360], Batch [15/196], Loss: 0.5408\n",
      "Epoch [50/360], Batch [20/196], Loss: 0.6784\n",
      "Epoch [50/360], Batch [25/196], Loss: 1.4719\n",
      "Epoch [50/360], Batch [30/196], Loss: 0.7736\n",
      "Epoch [50/360], Batch [35/196], Loss: 0.6210\n",
      "Epoch [50/360], Batch [40/196], Loss: 0.7618\n",
      "Epoch [50/360], Batch [45/196], Loss: 3.9991\n",
      "Epoch [50/360], Batch [50/196], Loss: 1.2765\n",
      "Epoch [50/360], Batch [55/196], Loss: 0.9754\n",
      "Epoch [50/360], Batch [60/196], Loss: 0.4568\n",
      "Epoch [50/360], Batch [65/196], Loss: 1.1928\n",
      "Epoch [50/360], Batch [70/196], Loss: 0.5302\n",
      "Epoch [50/360], Batch [75/196], Loss: 0.3775\n",
      "Epoch [50/360], Batch [80/196], Loss: 1.5417\n",
      "Epoch [50/360], Batch [85/196], Loss: 1.0079\n",
      "Epoch [50/360], Batch [90/196], Loss: 1.0665\n",
      "Epoch [50/360], Batch [95/196], Loss: 0.2733\n",
      "Epoch [50/360], Batch [100/196], Loss: 0.3901\n",
      "Epoch [50/360], Batch [105/196], Loss: 0.5512\n",
      "Epoch [50/360], Batch [110/196], Loss: 0.7829\n",
      "Epoch [50/360], Batch [115/196], Loss: 0.5379\n",
      "Epoch [50/360], Batch [120/196], Loss: 0.3207\n",
      "Epoch [50/360], Batch [125/196], Loss: 0.9156\n",
      "Epoch [50/360], Batch [130/196], Loss: 0.4963\n",
      "Epoch [50/360], Batch [135/196], Loss: 1.3571\n",
      "Epoch [50/360], Batch [140/196], Loss: 0.6967\n",
      "Epoch [50/360], Batch [145/196], Loss: 0.5994\n",
      "Epoch [50/360], Batch [150/196], Loss: 1.1875\n",
      "Epoch [50/360], Batch [155/196], Loss: 0.3120\n",
      "Epoch [50/360], Batch [160/196], Loss: 0.4188\n",
      "Epoch [50/360], Batch [165/196], Loss: 0.5252\n",
      "Epoch [50/360], Batch [170/196], Loss: 0.4692\n",
      "Epoch [50/360], Batch [175/196], Loss: 0.5536\n",
      "Epoch [50/360], Batch [180/196], Loss: 0.4581\n",
      "Epoch [50/360], Batch [185/196], Loss: 0.6397\n",
      "Epoch [50/360], Batch [190/196], Loss: 0.6899\n",
      "Epoch [50/360], Batch [195/196], Loss: 1.1389\n",
      "Epoch [51/360], Batch [5/196], Loss: 4.5370\n",
      "Epoch [51/360], Batch [10/196], Loss: 0.8260\n",
      "Epoch [51/360], Batch [15/196], Loss: 0.4241\n",
      "Epoch [51/360], Batch [20/196], Loss: 0.4979\n",
      "Epoch [51/360], Batch [25/196], Loss: 0.3318\n",
      "Epoch [51/360], Batch [30/196], Loss: 0.7498\n",
      "Epoch [51/360], Batch [35/196], Loss: 0.6975\n",
      "Epoch [51/360], Batch [40/196], Loss: 0.3483\n",
      "Epoch [51/360], Batch [45/196], Loss: 0.3486\n",
      "Epoch [51/360], Batch [50/196], Loss: 1.7876\n",
      "Epoch [51/360], Batch [55/196], Loss: 0.3116\n",
      "Epoch [51/360], Batch [60/196], Loss: 0.4953\n",
      "Epoch [51/360], Batch [65/196], Loss: 0.4467\n",
      "Epoch [51/360], Batch [70/196], Loss: 1.2814\n",
      "Epoch [51/360], Batch [75/196], Loss: 0.4105\n",
      "Epoch [51/360], Batch [80/196], Loss: 0.4501\n",
      "Epoch [51/360], Batch [85/196], Loss: 0.3087\n",
      "Epoch [51/360], Batch [90/196], Loss: 0.5568\n",
      "Epoch [51/360], Batch [95/196], Loss: 0.5577\n",
      "Epoch [51/360], Batch [100/196], Loss: 0.5939\n",
      "Epoch [51/360], Batch [105/196], Loss: 0.6581\n",
      "Epoch [51/360], Batch [110/196], Loss: 0.7668\n",
      "Epoch [51/360], Batch [115/196], Loss: 0.7698\n",
      "Epoch [51/360], Batch [120/196], Loss: 0.8975\n",
      "Epoch [51/360], Batch [125/196], Loss: 0.5824\n",
      "Epoch [51/360], Batch [130/196], Loss: 0.4630\n",
      "Epoch [51/360], Batch [135/196], Loss: 0.5972\n",
      "Epoch [51/360], Batch [140/196], Loss: 0.6000\n",
      "Epoch [51/360], Batch [145/196], Loss: 0.3981\n",
      "Epoch [51/360], Batch [150/196], Loss: 1.0912\n",
      "Epoch [51/360], Batch [155/196], Loss: 0.7115\n",
      "Epoch [51/360], Batch [160/196], Loss: 0.6575\n",
      "Epoch [51/360], Batch [165/196], Loss: 0.6289\n",
      "Epoch [51/360], Batch [170/196], Loss: 0.4933\n",
      "Epoch [51/360], Batch [175/196], Loss: 1.0827\n",
      "Epoch [51/360], Batch [180/196], Loss: 0.3254\n",
      "Epoch [51/360], Batch [185/196], Loss: 0.3496\n",
      "Epoch [51/360], Batch [190/196], Loss: 0.5828\n",
      "Epoch [51/360], Batch [195/196], Loss: 1.2625\n",
      "Epoch [52/360], Batch [5/196], Loss: 0.5227\n",
      "Epoch [52/360], Batch [10/196], Loss: 0.5860\n",
      "Epoch [52/360], Batch [15/196], Loss: 0.6869\n",
      "Epoch [52/360], Batch [20/196], Loss: 1.1727\n",
      "Epoch [52/360], Batch [25/196], Loss: 0.5473\n",
      "Epoch [52/360], Batch [30/196], Loss: 1.2163\n",
      "Epoch [52/360], Batch [35/196], Loss: 0.7117\n",
      "Epoch [52/360], Batch [40/196], Loss: 0.8266\n",
      "Epoch [52/360], Batch [45/196], Loss: 1.3979\n",
      "Epoch [52/360], Batch [50/196], Loss: 0.3159\n",
      "Epoch [52/360], Batch [55/196], Loss: 0.6031\n",
      "Epoch [52/360], Batch [60/196], Loss: 1.7689\n",
      "Epoch [52/360], Batch [65/196], Loss: 1.2490\n",
      "Epoch [52/360], Batch [70/196], Loss: 6.1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/360], Batch [75/196], Loss: 1.2761\n",
      "Epoch [52/360], Batch [80/196], Loss: 0.4612\n",
      "Epoch [52/360], Batch [85/196], Loss: 0.6219\n",
      "Epoch [52/360], Batch [90/196], Loss: 0.4168\n",
      "Epoch [52/360], Batch [95/196], Loss: 0.7738\n",
      "Epoch [52/360], Batch [100/196], Loss: 0.6267\n",
      "Epoch [52/360], Batch [105/196], Loss: 0.5289\n",
      "Epoch [52/360], Batch [110/196], Loss: 0.5074\n",
      "Epoch [52/360], Batch [115/196], Loss: 0.6120\n",
      "Epoch [52/360], Batch [120/196], Loss: 0.6915\n",
      "Epoch [52/360], Batch [125/196], Loss: 0.9441\n",
      "Epoch [52/360], Batch [130/196], Loss: 0.6406\n",
      "Epoch [52/360], Batch [135/196], Loss: 0.3210\n",
      "Epoch [52/360], Batch [140/196], Loss: 0.3519\n",
      "Epoch [52/360], Batch [145/196], Loss: 0.3798\n",
      "Epoch [52/360], Batch [150/196], Loss: 0.7002\n",
      "Epoch [52/360], Batch [155/196], Loss: 0.4534\n",
      "Epoch [52/360], Batch [160/196], Loss: 0.4950\n",
      "Epoch [52/360], Batch [165/196], Loss: 0.4278\n",
      "Epoch [52/360], Batch [170/196], Loss: 0.5394\n",
      "Epoch [52/360], Batch [175/196], Loss: 0.5139\n",
      "Epoch [52/360], Batch [180/196], Loss: 1.6019\n",
      "Epoch [52/360], Batch [185/196], Loss: 0.5002\n",
      "Epoch [52/360], Batch [190/196], Loss: 0.8442\n",
      "Epoch [52/360], Batch [195/196], Loss: 0.8556\n",
      "Epoch [53/360], Batch [5/196], Loss: 1.0275\n",
      "Epoch [53/360], Batch [10/196], Loss: 0.2130\n",
      "Epoch [53/360], Batch [15/196], Loss: 0.5513\n",
      "Epoch [53/360], Batch [20/196], Loss: 0.3809\n",
      "Epoch [53/360], Batch [25/196], Loss: 0.4087\n",
      "Epoch [53/360], Batch [30/196], Loss: 0.9933\n",
      "Epoch [53/360], Batch [35/196], Loss: 0.5122\n",
      "Epoch [53/360], Batch [40/196], Loss: 5.7239\n",
      "Epoch [53/360], Batch [45/196], Loss: 0.4308\n",
      "Epoch [53/360], Batch [50/196], Loss: 0.8770\n",
      "Epoch [53/360], Batch [55/196], Loss: 0.4418\n",
      "Epoch [53/360], Batch [60/196], Loss: 0.5518\n",
      "Epoch [53/360], Batch [65/196], Loss: 0.5873\n",
      "Epoch [53/360], Batch [70/196], Loss: 0.7439\n",
      "Epoch [53/360], Batch [75/196], Loss: 0.4295\n",
      "Epoch [53/360], Batch [80/196], Loss: 0.9086\n",
      "Epoch [53/360], Batch [85/196], Loss: 0.6977\n",
      "Epoch [53/360], Batch [90/196], Loss: 1.2418\n",
      "Epoch [53/360], Batch [95/196], Loss: 0.5705\n",
      "Epoch [53/360], Batch [100/196], Loss: 0.7238\n",
      "Epoch [53/360], Batch [105/196], Loss: 1.0291\n",
      "Epoch [53/360], Batch [110/196], Loss: 0.6880\n",
      "Epoch [53/360], Batch [115/196], Loss: 0.5228\n",
      "Epoch [53/360], Batch [120/196], Loss: 0.6216\n",
      "Epoch [53/360], Batch [125/196], Loss: 0.6635\n",
      "Epoch [53/360], Batch [130/196], Loss: 0.5695\n",
      "Epoch [53/360], Batch [135/196], Loss: 0.8693\n",
      "Epoch [53/360], Batch [140/196], Loss: 0.3240\n",
      "Epoch [53/360], Batch [145/196], Loss: 0.4503\n",
      "Epoch [53/360], Batch [150/196], Loss: 0.4878\n",
      "Epoch [53/360], Batch [155/196], Loss: 0.6446\n",
      "Epoch [53/360], Batch [160/196], Loss: 0.3353\n",
      "Epoch [53/360], Batch [165/196], Loss: 0.5966\n",
      "Epoch [53/360], Batch [170/196], Loss: 0.6492\n",
      "Epoch [53/360], Batch [175/196], Loss: 0.6075\n",
      "Epoch [53/360], Batch [180/196], Loss: 0.3125\n",
      "Epoch [53/360], Batch [185/196], Loss: 0.6630\n",
      "Epoch [53/360], Batch [190/196], Loss: 1.9080\n",
      "Epoch [53/360], Batch [195/196], Loss: 0.5449\n",
      "Epoch [54/360], Batch [5/196], Loss: 0.7995\n",
      "Epoch [54/360], Batch [10/196], Loss: 0.7871\n",
      "Epoch [54/360], Batch [15/196], Loss: 0.4386\n",
      "Epoch [54/360], Batch [20/196], Loss: 0.4599\n",
      "Epoch [54/360], Batch [25/196], Loss: 0.4897\n",
      "Epoch [54/360], Batch [30/196], Loss: 0.9207\n",
      "Epoch [54/360], Batch [35/196], Loss: 0.8809\n",
      "Epoch [54/360], Batch [40/196], Loss: 0.6809\n",
      "Epoch [54/360], Batch [45/196], Loss: 0.4250\n",
      "Epoch [54/360], Batch [50/196], Loss: 0.7661\n",
      "Epoch [54/360], Batch [55/196], Loss: 0.6308\n",
      "Epoch [54/360], Batch [60/196], Loss: 0.3522\n",
      "Epoch [54/360], Batch [65/196], Loss: 0.5046\n",
      "Epoch [54/360], Batch [70/196], Loss: 0.3727\n",
      "Epoch [54/360], Batch [75/196], Loss: 1.4384\n",
      "Epoch [54/360], Batch [80/196], Loss: 1.1577\n",
      "Epoch [54/360], Batch [85/196], Loss: 0.5128\n",
      "Epoch [54/360], Batch [90/196], Loss: 0.6306\n",
      "Epoch [54/360], Batch [95/196], Loss: 1.4303\n",
      "Epoch [54/360], Batch [100/196], Loss: 1.0807\n",
      "Epoch [54/360], Batch [105/196], Loss: 0.4280\n",
      "Epoch [54/360], Batch [110/196], Loss: 0.4641\n",
      "Epoch [54/360], Batch [115/196], Loss: 0.5240\n",
      "Epoch [54/360], Batch [120/196], Loss: 0.8697\n",
      "Epoch [54/360], Batch [125/196], Loss: 1.2387\n",
      "Epoch [54/360], Batch [130/196], Loss: 0.8799\n",
      "Epoch [54/360], Batch [135/196], Loss: 0.6595\n",
      "Epoch [54/360], Batch [140/196], Loss: 0.7407\n",
      "Epoch [54/360], Batch [145/196], Loss: 0.6228\n",
      "Epoch [54/360], Batch [150/196], Loss: 0.2799\n",
      "Epoch [54/360], Batch [155/196], Loss: 0.4922\n",
      "Epoch [54/360], Batch [160/196], Loss: 0.5428\n",
      "Epoch [54/360], Batch [165/196], Loss: 0.9906\n",
      "Epoch [54/360], Batch [170/196], Loss: 0.7622\n",
      "Epoch [54/360], Batch [175/196], Loss: 0.6151\n",
      "Epoch [54/360], Batch [180/196], Loss: 1.0813\n",
      "Epoch [54/360], Batch [185/196], Loss: 0.6642\n",
      "Epoch [54/360], Batch [190/196], Loss: 1.4942\n",
      "Epoch [54/360], Batch [195/196], Loss: 0.5405\n",
      "Epoch [55/360], Batch [5/196], Loss: 0.8727\n",
      "Epoch [55/360], Batch [10/196], Loss: 1.2036\n",
      "Epoch [55/360], Batch [15/196], Loss: 0.5235\n",
      "Epoch [55/360], Batch [20/196], Loss: 0.9225\n",
      "Epoch [55/360], Batch [25/196], Loss: 1.3536\n",
      "Epoch [55/360], Batch [30/196], Loss: 0.6865\n",
      "Epoch [55/360], Batch [35/196], Loss: 0.7270\n",
      "Epoch [55/360], Batch [40/196], Loss: 0.9380\n",
      "Epoch [55/360], Batch [45/196], Loss: 0.4173\n",
      "Epoch [55/360], Batch [50/196], Loss: 0.4164\n",
      "Epoch [55/360], Batch [55/196], Loss: 0.3750\n",
      "Epoch [55/360], Batch [60/196], Loss: 0.7957\n",
      "Epoch [55/360], Batch [65/196], Loss: 0.3055\n",
      "Epoch [55/360], Batch [70/196], Loss: 0.4866\n",
      "Epoch [55/360], Batch [75/196], Loss: 1.5804\n",
      "Epoch [55/360], Batch [80/196], Loss: 0.5793\n",
      "Epoch [55/360], Batch [85/196], Loss: 1.4397\n",
      "Epoch [55/360], Batch [90/196], Loss: 0.6722\n",
      "Epoch [55/360], Batch [95/196], Loss: 0.4773\n",
      "Epoch [55/360], Batch [100/196], Loss: 0.5530\n",
      "Epoch [55/360], Batch [105/196], Loss: 0.3341\n",
      "Epoch [55/360], Batch [110/196], Loss: 0.3292\n",
      "Epoch [55/360], Batch [115/196], Loss: 0.9507\n",
      "Epoch [55/360], Batch [120/196], Loss: 0.8554\n",
      "Epoch [55/360], Batch [125/196], Loss: 0.8151\n",
      "Epoch [55/360], Batch [130/196], Loss: 0.9998\n",
      "Epoch [55/360], Batch [135/196], Loss: 1.1603\n",
      "Epoch [55/360], Batch [140/196], Loss: 0.4718\n",
      "Epoch [55/360], Batch [145/196], Loss: 0.7883\n",
      "Epoch [55/360], Batch [150/196], Loss: 0.9371\n",
      "Epoch [55/360], Batch [155/196], Loss: 0.3816\n",
      "Epoch [55/360], Batch [160/196], Loss: 1.3749\n",
      "Epoch [55/360], Batch [165/196], Loss: 0.4047\n",
      "Epoch [55/360], Batch [170/196], Loss: 0.6421\n",
      "Epoch [55/360], Batch [175/196], Loss: 0.4862\n",
      "Epoch [55/360], Batch [180/196], Loss: 0.3971\n",
      "Epoch [55/360], Batch [185/196], Loss: 0.5182\n",
      "Epoch [55/360], Batch [190/196], Loss: 0.6643\n",
      "Epoch [55/360], Batch [195/196], Loss: 0.4180\n",
      "Epoch [56/360], Batch [5/196], Loss: 0.4194\n",
      "Epoch [56/360], Batch [10/196], Loss: 0.6251\n",
      "Epoch [56/360], Batch [15/196], Loss: 3.5668\n",
      "Epoch [56/360], Batch [20/196], Loss: 0.7183\n",
      "Epoch [56/360], Batch [25/196], Loss: 0.4413\n",
      "Epoch [56/360], Batch [30/196], Loss: 0.5914\n",
      "Epoch [56/360], Batch [35/196], Loss: 0.5054\n",
      "Epoch [56/360], Batch [40/196], Loss: 1.4290\n",
      "Epoch [56/360], Batch [45/196], Loss: 0.7943\n",
      "Epoch [56/360], Batch [50/196], Loss: 0.5561\n",
      "Epoch [56/360], Batch [55/196], Loss: 1.7245\n",
      "Epoch [56/360], Batch [60/196], Loss: 0.2400\n",
      "Epoch [56/360], Batch [65/196], Loss: 0.8506\n",
      "Epoch [56/360], Batch [70/196], Loss: 0.2483\n",
      "Epoch [56/360], Batch [75/196], Loss: 1.1463\n",
      "Epoch [56/360], Batch [80/196], Loss: 0.4153\n",
      "Epoch [56/360], Batch [85/196], Loss: 0.7156\n",
      "Epoch [56/360], Batch [90/196], Loss: 0.7890\n",
      "Epoch [56/360], Batch [95/196], Loss: 0.8148\n",
      "Epoch [56/360], Batch [100/196], Loss: 0.5003\n",
      "Epoch [56/360], Batch [105/196], Loss: 0.7324\n",
      "Epoch [56/360], Batch [110/196], Loss: 0.8226\n",
      "Epoch [56/360], Batch [115/196], Loss: 0.4414\n",
      "Epoch [56/360], Batch [120/196], Loss: 0.4274\n",
      "Epoch [56/360], Batch [125/196], Loss: 1.1741\n",
      "Epoch [56/360], Batch [130/196], Loss: 0.8497\n",
      "Epoch [56/360], Batch [135/196], Loss: 0.5629\n",
      "Epoch [56/360], Batch [140/196], Loss: 0.7445\n",
      "Epoch [56/360], Batch [145/196], Loss: 0.8230\n",
      "Epoch [56/360], Batch [150/196], Loss: 1.0899\n",
      "Epoch [56/360], Batch [155/196], Loss: 0.8312\n",
      "Epoch [56/360], Batch [160/196], Loss: 0.3760\n",
      "Epoch [56/360], Batch [165/196], Loss: 0.5689\n",
      "Epoch [56/360], Batch [170/196], Loss: 0.4563\n",
      "Epoch [56/360], Batch [175/196], Loss: 0.5609\n",
      "Epoch [56/360], Batch [180/196], Loss: 0.5445\n",
      "Epoch [56/360], Batch [185/196], Loss: 0.4676\n",
      "Epoch [56/360], Batch [190/196], Loss: 0.3258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/360], Batch [195/196], Loss: 0.5847\n",
      "Epoch [57/360], Batch [5/196], Loss: 0.4668\n",
      "Epoch [57/360], Batch [10/196], Loss: 0.5427\n",
      "Epoch [57/360], Batch [15/196], Loss: 0.3848\n",
      "Epoch [57/360], Batch [20/196], Loss: 0.6279\n",
      "Epoch [57/360], Batch [25/196], Loss: 0.6803\n",
      "Epoch [57/360], Batch [30/196], Loss: 0.5560\n",
      "Epoch [57/360], Batch [35/196], Loss: 0.4248\n",
      "Epoch [57/360], Batch [40/196], Loss: 0.6394\n",
      "Epoch [57/360], Batch [45/196], Loss: 0.7603\n",
      "Epoch [57/360], Batch [50/196], Loss: 0.6324\n",
      "Epoch [57/360], Batch [55/196], Loss: 0.8709\n",
      "Epoch [57/360], Batch [60/196], Loss: 0.2946\n",
      "Epoch [57/360], Batch [65/196], Loss: 0.7294\n",
      "Epoch [57/360], Batch [70/196], Loss: 1.6457\n",
      "Epoch [57/360], Batch [75/196], Loss: 0.4807\n",
      "Epoch [57/360], Batch [80/196], Loss: 0.2959\n",
      "Epoch [57/360], Batch [85/196], Loss: 0.5293\n",
      "Epoch [57/360], Batch [90/196], Loss: 0.3897\n",
      "Epoch [57/360], Batch [95/196], Loss: 0.5711\n",
      "Epoch [57/360], Batch [100/196], Loss: 0.5023\n",
      "Epoch [57/360], Batch [105/196], Loss: 0.4723\n",
      "Epoch [57/360], Batch [110/196], Loss: 0.5495\n",
      "Epoch [57/360], Batch [115/196], Loss: 0.6766\n",
      "Epoch [57/360], Batch [120/196], Loss: 0.5273\n",
      "Epoch [57/360], Batch [125/196], Loss: 1.0954\n",
      "Epoch [57/360], Batch [130/196], Loss: 1.1641\n",
      "Epoch [57/360], Batch [135/196], Loss: 0.4512\n",
      "Epoch [57/360], Batch [140/196], Loss: 0.9509\n",
      "Epoch [57/360], Batch [145/196], Loss: 0.5888\n",
      "Epoch [57/360], Batch [150/196], Loss: 1.4707\n",
      "Epoch [57/360], Batch [155/196], Loss: 0.5173\n",
      "Epoch [57/360], Batch [160/196], Loss: 0.3262\n",
      "Epoch [57/360], Batch [165/196], Loss: 0.3668\n",
      "Epoch [57/360], Batch [170/196], Loss: 0.5303\n",
      "Epoch [57/360], Batch [175/196], Loss: 0.7861\n",
      "Epoch [57/360], Batch [180/196], Loss: 0.3497\n",
      "Epoch [57/360], Batch [185/196], Loss: 0.8545\n",
      "Epoch [57/360], Batch [190/196], Loss: 0.4013\n",
      "Epoch [57/360], Batch [195/196], Loss: 1.1008\n",
      "Epoch [58/360], Batch [5/196], Loss: 0.5759\n",
      "Epoch [58/360], Batch [10/196], Loss: 0.3673\n",
      "Epoch [58/360], Batch [15/196], Loss: 0.2791\n",
      "Epoch [58/360], Batch [20/196], Loss: 0.5183\n",
      "Epoch [58/360], Batch [25/196], Loss: 0.4785\n",
      "Epoch [58/360], Batch [30/196], Loss: 0.8635\n",
      "Epoch [58/360], Batch [35/196], Loss: 0.9670\n",
      "Epoch [58/360], Batch [40/196], Loss: 0.6527\n",
      "Epoch [58/360], Batch [45/196], Loss: 0.4313\n",
      "Epoch [58/360], Batch [50/196], Loss: 0.5374\n",
      "Epoch [58/360], Batch [55/196], Loss: 0.5974\n",
      "Epoch [58/360], Batch [60/196], Loss: 0.5699\n",
      "Epoch [58/360], Batch [65/196], Loss: 0.6310\n",
      "Epoch [58/360], Batch [70/196], Loss: 1.0615\n",
      "Epoch [58/360], Batch [75/196], Loss: 0.5640\n",
      "Epoch [58/360], Batch [80/196], Loss: 0.4106\n",
      "Epoch [58/360], Batch [85/196], Loss: 0.7096\n",
      "Epoch [58/360], Batch [90/196], Loss: 0.5923\n",
      "Epoch [58/360], Batch [95/196], Loss: 0.5945\n",
      "Epoch [58/360], Batch [100/196], Loss: 0.7074\n",
      "Epoch [58/360], Batch [105/196], Loss: 0.8422\n",
      "Epoch [58/360], Batch [110/196], Loss: 0.6197\n",
      "Epoch [58/360], Batch [115/196], Loss: 0.3788\n",
      "Epoch [58/360], Batch [120/196], Loss: 0.5369\n",
      "Epoch [58/360], Batch [125/196], Loss: 0.9759\n",
      "Epoch [58/360], Batch [130/196], Loss: 0.3558\n",
      "Epoch [58/360], Batch [135/196], Loss: 0.5060\n",
      "Epoch [58/360], Batch [140/196], Loss: 1.6674\n",
      "Epoch [58/360], Batch [145/196], Loss: 0.3939\n",
      "Epoch [58/360], Batch [150/196], Loss: 0.3152\n",
      "Epoch [58/360], Batch [155/196], Loss: 0.4739\n",
      "Epoch [58/360], Batch [160/196], Loss: 0.8368\n",
      "Epoch [58/360], Batch [165/196], Loss: 0.4463\n",
      "Epoch [58/360], Batch [170/196], Loss: 0.7898\n",
      "Epoch [58/360], Batch [175/196], Loss: 0.6925\n",
      "Epoch [58/360], Batch [180/196], Loss: 1.9007\n",
      "Epoch [58/360], Batch [185/196], Loss: 0.6408\n",
      "Epoch [58/360], Batch [190/196], Loss: 0.6970\n",
      "Epoch [58/360], Batch [195/196], Loss: 0.4658\n",
      "Epoch [59/360], Batch [5/196], Loss: 0.5334\n",
      "Epoch [59/360], Batch [10/196], Loss: 1.8424\n",
      "Epoch [59/360], Batch [15/196], Loss: 0.7271\n",
      "Epoch [59/360], Batch [20/196], Loss: 0.3999\n",
      "Epoch [59/360], Batch [25/196], Loss: 0.3011\n",
      "Epoch [59/360], Batch [30/196], Loss: 0.6899\n",
      "Epoch [59/360], Batch [35/196], Loss: 0.9516\n",
      "Epoch [59/360], Batch [40/196], Loss: 0.7303\n",
      "Epoch [59/360], Batch [45/196], Loss: 0.3601\n",
      "Epoch [59/360], Batch [50/196], Loss: 0.6647\n",
      "Epoch [59/360], Batch [55/196], Loss: 0.6526\n",
      "Epoch [59/360], Batch [60/196], Loss: 0.6913\n",
      "Epoch [59/360], Batch [65/196], Loss: 0.5565\n",
      "Epoch [59/360], Batch [70/196], Loss: 0.9326\n",
      "Epoch [59/360], Batch [75/196], Loss: 0.8693\n",
      "Epoch [59/360], Batch [80/196], Loss: 1.0921\n",
      "Epoch [59/360], Batch [85/196], Loss: 1.0633\n",
      "Epoch [59/360], Batch [90/196], Loss: 0.3245\n",
      "Epoch [59/360], Batch [95/196], Loss: 0.7694\n",
      "Epoch [59/360], Batch [100/196], Loss: 0.6346\n",
      "Epoch [59/360], Batch [105/196], Loss: 1.2640\n",
      "Epoch [59/360], Batch [110/196], Loss: 0.5491\n",
      "Epoch [59/360], Batch [115/196], Loss: 1.2645\n",
      "Epoch [59/360], Batch [120/196], Loss: 0.5131\n",
      "Epoch [59/360], Batch [125/196], Loss: 1.2671\n",
      "Epoch [59/360], Batch [130/196], Loss: 0.7146\n",
      "Epoch [59/360], Batch [135/196], Loss: 1.0178\n",
      "Epoch [59/360], Batch [140/196], Loss: 0.4227\n",
      "Epoch [59/360], Batch [145/196], Loss: 1.0326\n",
      "Epoch [59/360], Batch [150/196], Loss: 0.8368\n",
      "Epoch [59/360], Batch [155/196], Loss: 0.5194\n",
      "Epoch [59/360], Batch [160/196], Loss: 0.4748\n",
      "Epoch [59/360], Batch [165/196], Loss: 0.8051\n",
      "Epoch [59/360], Batch [170/196], Loss: 0.5258\n",
      "Epoch [59/360], Batch [175/196], Loss: 1.4645\n",
      "Epoch [59/360], Batch [180/196], Loss: 0.4808\n",
      "Epoch [59/360], Batch [185/196], Loss: 0.8168\n",
      "Epoch [59/360], Batch [190/196], Loss: 0.7633\n",
      "Epoch [59/360], Batch [195/196], Loss: 0.6089\n",
      "Epoch [60/360], Batch [5/196], Loss: 0.8577\n",
      "Epoch [60/360], Batch [10/196], Loss: 0.5661\n",
      "Epoch [60/360], Batch [15/196], Loss: 0.2719\n",
      "Epoch [60/360], Batch [20/196], Loss: 0.5357\n",
      "Epoch [60/360], Batch [25/196], Loss: 0.5637\n",
      "Epoch [60/360], Batch [30/196], Loss: 0.7335\n",
      "Epoch [60/360], Batch [35/196], Loss: 0.4894\n",
      "Epoch [60/360], Batch [40/196], Loss: 0.5761\n",
      "Epoch [60/360], Batch [45/196], Loss: 0.4901\n",
      "Epoch [60/360], Batch [50/196], Loss: 0.5271\n",
      "Epoch [60/360], Batch [55/196], Loss: 0.3573\n",
      "Epoch [60/360], Batch [60/196], Loss: 0.4602\n",
      "Epoch [60/360], Batch [65/196], Loss: 0.5964\n",
      "Epoch [60/360], Batch [70/196], Loss: 1.3850\n",
      "Epoch [60/360], Batch [75/196], Loss: 0.6052\n",
      "Epoch [60/360], Batch [80/196], Loss: 0.3170\n",
      "Epoch [60/360], Batch [85/196], Loss: 0.4293\n",
      "Epoch [60/360], Batch [90/196], Loss: 1.6446\n",
      "Epoch [60/360], Batch [95/196], Loss: 0.3807\n",
      "Epoch [60/360], Batch [100/196], Loss: 0.8475\n",
      "Epoch [60/360], Batch [105/196], Loss: 0.7328\n",
      "Epoch [60/360], Batch [110/196], Loss: 0.4110\n",
      "Epoch [60/360], Batch [115/196], Loss: 0.7357\n",
      "Epoch [60/360], Batch [120/196], Loss: 0.7015\n",
      "Epoch [60/360], Batch [125/196], Loss: 0.8739\n",
      "Epoch [60/360], Batch [130/196], Loss: 0.4160\n",
      "Epoch [60/360], Batch [135/196], Loss: 0.6560\n",
      "Epoch [60/360], Batch [140/196], Loss: 0.6806\n",
      "Epoch [60/360], Batch [145/196], Loss: 0.7394\n",
      "Epoch [60/360], Batch [150/196], Loss: 0.6819\n",
      "Epoch [60/360], Batch [155/196], Loss: 0.8914\n",
      "Epoch [60/360], Batch [160/196], Loss: 0.5377\n",
      "Epoch [60/360], Batch [165/196], Loss: 0.8503\n",
      "Epoch [60/360], Batch [170/196], Loss: 1.0328\n",
      "Epoch [60/360], Batch [175/196], Loss: 0.4364\n",
      "Epoch [60/360], Batch [180/196], Loss: 0.7096\n",
      "Epoch [60/360], Batch [185/196], Loss: 0.6637\n",
      "Epoch [60/360], Batch [190/196], Loss: 0.7423\n",
      "Epoch [60/360], Batch [195/196], Loss: 0.6900\n",
      "Epoch [61/360], Batch [5/196], Loss: 0.7432\n",
      "Epoch [61/360], Batch [10/196], Loss: 0.4236\n",
      "Epoch [61/360], Batch [15/196], Loss: 0.5175\n",
      "Epoch [61/360], Batch [20/196], Loss: 0.5106\n",
      "Epoch [61/360], Batch [25/196], Loss: 0.2703\n",
      "Epoch [61/360], Batch [30/196], Loss: 1.0825\n",
      "Epoch [61/360], Batch [35/196], Loss: 0.4783\n",
      "Epoch [61/360], Batch [40/196], Loss: 0.3934\n",
      "Epoch [61/360], Batch [45/196], Loss: 0.5917\n",
      "Epoch [61/360], Batch [50/196], Loss: 0.2693\n",
      "Epoch [61/360], Batch [55/196], Loss: 0.4083\n",
      "Epoch [61/360], Batch [60/196], Loss: 0.4076\n",
      "Epoch [61/360], Batch [65/196], Loss: 0.8165\n",
      "Epoch [61/360], Batch [70/196], Loss: 0.7761\n",
      "Epoch [61/360], Batch [75/196], Loss: 0.7503\n",
      "Epoch [61/360], Batch [80/196], Loss: 0.7293\n",
      "Epoch [61/360], Batch [85/196], Loss: 0.2313\n",
      "Epoch [61/360], Batch [90/196], Loss: 1.1786\n",
      "Epoch [61/360], Batch [95/196], Loss: 0.6100\n",
      "Epoch [61/360], Batch [100/196], Loss: 0.9650\n",
      "Epoch [61/360], Batch [105/196], Loss: 0.4253\n",
      "Epoch [61/360], Batch [110/196], Loss: 1.1854\n",
      "Epoch [61/360], Batch [115/196], Loss: 0.4448\n",
      "Epoch [61/360], Batch [120/196], Loss: 1.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/360], Batch [125/196], Loss: 0.4103\n",
      "Epoch [61/360], Batch [130/196], Loss: 0.6940\n",
      "Epoch [61/360], Batch [135/196], Loss: 0.6092\n",
      "Epoch [61/360], Batch [140/196], Loss: 0.8024\n",
      "Epoch [61/360], Batch [145/196], Loss: 0.5394\n",
      "Epoch [61/360], Batch [150/196], Loss: 0.4499\n",
      "Epoch [61/360], Batch [155/196], Loss: 0.5120\n",
      "Epoch [61/360], Batch [160/196], Loss: 0.7831\n",
      "Epoch [61/360], Batch [165/196], Loss: 1.1697\n",
      "Epoch [61/360], Batch [170/196], Loss: 0.8510\n",
      "Epoch [61/360], Batch [175/196], Loss: 0.6507\n",
      "Epoch [61/360], Batch [180/196], Loss: 0.3399\n",
      "Epoch [61/360], Batch [185/196], Loss: 0.7938\n",
      "Epoch [61/360], Batch [190/196], Loss: 0.6008\n",
      "Epoch [61/360], Batch [195/196], Loss: 0.4786\n",
      "Epoch [62/360], Batch [5/196], Loss: 0.3911\n",
      "Epoch [62/360], Batch [10/196], Loss: 0.3518\n",
      "Epoch [62/360], Batch [15/196], Loss: 0.7578\n",
      "Epoch [62/360], Batch [20/196], Loss: 0.5628\n",
      "Epoch [62/360], Batch [25/196], Loss: 0.5400\n",
      "Epoch [62/360], Batch [30/196], Loss: 0.5116\n",
      "Epoch [62/360], Batch [35/196], Loss: 0.4663\n",
      "Epoch [62/360], Batch [40/196], Loss: 0.4418\n",
      "Epoch [62/360], Batch [45/196], Loss: 0.6334\n",
      "Epoch [62/360], Batch [50/196], Loss: 0.5066\n",
      "Epoch [62/360], Batch [55/196], Loss: 0.8020\n",
      "Epoch [62/360], Batch [60/196], Loss: 0.4202\n",
      "Epoch [62/360], Batch [65/196], Loss: 0.5063\n",
      "Epoch [62/360], Batch [70/196], Loss: 0.6935\n",
      "Epoch [62/360], Batch [75/196], Loss: 0.5538\n",
      "Epoch [62/360], Batch [80/196], Loss: 0.3691\n",
      "Epoch [62/360], Batch [85/196], Loss: 4.8330\n",
      "Epoch [62/360], Batch [90/196], Loss: 0.7885\n",
      "Epoch [62/360], Batch [95/196], Loss: 0.5242\n",
      "Epoch [62/360], Batch [100/196], Loss: 0.5155\n",
      "Epoch [62/360], Batch [105/196], Loss: 0.5613\n",
      "Epoch [62/360], Batch [110/196], Loss: 0.5698\n",
      "Epoch [62/360], Batch [115/196], Loss: 0.8757\n",
      "Epoch [62/360], Batch [120/196], Loss: 0.5023\n",
      "Epoch [62/360], Batch [125/196], Loss: 0.6305\n",
      "Epoch [62/360], Batch [130/196], Loss: 0.4984\n",
      "Epoch [62/360], Batch [135/196], Loss: 1.3218\n",
      "Epoch [62/360], Batch [140/196], Loss: 0.5279\n",
      "Epoch [62/360], Batch [145/196], Loss: 0.5807\n",
      "Epoch [62/360], Batch [150/196], Loss: 0.5624\n",
      "Epoch [62/360], Batch [155/196], Loss: 0.5404\n",
      "Epoch [62/360], Batch [160/196], Loss: 0.6424\n",
      "Epoch [62/360], Batch [165/196], Loss: 1.0813\n",
      "Epoch [62/360], Batch [170/196], Loss: 0.5800\n",
      "Epoch [62/360], Batch [175/196], Loss: 0.8277\n",
      "Epoch [62/360], Batch [180/196], Loss: 0.8323\n",
      "Epoch [62/360], Batch [185/196], Loss: 0.7200\n",
      "Epoch [62/360], Batch [190/196], Loss: 0.2463\n",
      "Epoch [62/360], Batch [195/196], Loss: 0.5292\n",
      "Epoch [63/360], Batch [5/196], Loss: 0.6282\n",
      "Epoch [63/360], Batch [10/196], Loss: 0.6519\n",
      "Epoch [63/360], Batch [15/196], Loss: 0.5359\n",
      "Epoch [63/360], Batch [20/196], Loss: 0.6098\n",
      "Epoch [63/360], Batch [25/196], Loss: 0.3576\n",
      "Epoch [63/360], Batch [30/196], Loss: 0.3350\n",
      "Epoch [63/360], Batch [35/196], Loss: 0.3914\n",
      "Epoch [63/360], Batch [40/196], Loss: 0.4579\n",
      "Epoch [63/360], Batch [45/196], Loss: 0.8691\n",
      "Epoch [63/360], Batch [50/196], Loss: 1.3093\n",
      "Epoch [63/360], Batch [55/196], Loss: 0.4959\n",
      "Epoch [63/360], Batch [60/196], Loss: 0.6337\n",
      "Epoch [63/360], Batch [65/196], Loss: 0.3635\n",
      "Epoch [63/360], Batch [70/196], Loss: 0.6646\n",
      "Epoch [63/360], Batch [75/196], Loss: 0.5661\n",
      "Epoch [63/360], Batch [80/196], Loss: 0.5790\n",
      "Epoch [63/360], Batch [85/196], Loss: 1.5601\n",
      "Epoch [63/360], Batch [90/196], Loss: 0.5829\n",
      "Epoch [63/360], Batch [95/196], Loss: 1.0801\n",
      "Epoch [63/360], Batch [100/196], Loss: 0.4591\n",
      "Epoch [63/360], Batch [105/196], Loss: 0.3569\n",
      "Epoch [63/360], Batch [110/196], Loss: 0.7252\n",
      "Epoch [63/360], Batch [115/196], Loss: 0.7430\n",
      "Epoch [63/360], Batch [120/196], Loss: 1.2802\n",
      "Epoch [63/360], Batch [125/196], Loss: 0.4654\n",
      "Epoch [63/360], Batch [130/196], Loss: 0.6050\n",
      "Epoch [63/360], Batch [135/196], Loss: 0.7762\n",
      "Epoch [63/360], Batch [140/196], Loss: 0.6546\n",
      "Epoch [63/360], Batch [145/196], Loss: 0.5055\n",
      "Epoch [63/360], Batch [150/196], Loss: 0.7944\n",
      "Epoch [63/360], Batch [155/196], Loss: 0.6307\n",
      "Epoch [63/360], Batch [160/196], Loss: 0.3147\n",
      "Epoch [63/360], Batch [165/196], Loss: 0.3883\n",
      "Epoch [63/360], Batch [170/196], Loss: 0.5132\n",
      "Epoch [63/360], Batch [175/196], Loss: 0.5514\n",
      "Epoch [63/360], Batch [180/196], Loss: 0.3713\n",
      "Epoch [63/360], Batch [185/196], Loss: 0.5783\n",
      "Epoch [63/360], Batch [190/196], Loss: 0.6069\n",
      "Epoch [63/360], Batch [195/196], Loss: 0.8696\n",
      "Epoch [64/360], Batch [5/196], Loss: 0.8924\n",
      "Epoch [64/360], Batch [10/196], Loss: 0.3964\n",
      "Epoch [64/360], Batch [15/196], Loss: 0.5689\n",
      "Epoch [64/360], Batch [20/196], Loss: 1.0998\n",
      "Epoch [64/360], Batch [25/196], Loss: 0.3897\n",
      "Epoch [64/360], Batch [30/196], Loss: 0.9796\n",
      "Epoch [64/360], Batch [35/196], Loss: 0.4565\n",
      "Epoch [64/360], Batch [40/196], Loss: 0.6564\n",
      "Epoch [64/360], Batch [45/196], Loss: 0.4353\n",
      "Epoch [64/360], Batch [50/196], Loss: 0.3834\n",
      "Epoch [64/360], Batch [55/196], Loss: 0.8300\n",
      "Epoch [64/360], Batch [60/196], Loss: 0.3499\n",
      "Epoch [64/360], Batch [65/196], Loss: 0.5382\n",
      "Epoch [64/360], Batch [70/196], Loss: 1.6104\n",
      "Epoch [64/360], Batch [75/196], Loss: 0.7444\n",
      "Epoch [64/360], Batch [80/196], Loss: 0.3719\n",
      "Epoch [64/360], Batch [85/196], Loss: 0.5260\n",
      "Epoch [64/360], Batch [90/196], Loss: 0.6742\n",
      "Epoch [64/360], Batch [95/196], Loss: 0.5885\n",
      "Epoch [64/360], Batch [100/196], Loss: 0.6224\n",
      "Epoch [64/360], Batch [105/196], Loss: 0.3849\n",
      "Epoch [64/360], Batch [110/196], Loss: 0.5516\n",
      "Epoch [64/360], Batch [115/196], Loss: 0.3905\n",
      "Epoch [64/360], Batch [120/196], Loss: 0.5237\n",
      "Epoch [64/360], Batch [125/196], Loss: 0.6732\n",
      "Epoch [64/360], Batch [130/196], Loss: 0.4898\n",
      "Epoch [64/360], Batch [135/196], Loss: 0.5224\n",
      "Epoch [64/360], Batch [140/196], Loss: 0.3574\n",
      "Epoch [64/360], Batch [145/196], Loss: 0.1907\n",
      "Epoch [64/360], Batch [150/196], Loss: 0.3615\n",
      "Epoch [64/360], Batch [155/196], Loss: 1.2016\n",
      "Epoch [64/360], Batch [160/196], Loss: 0.4494\n",
      "Epoch [64/360], Batch [165/196], Loss: 0.5662\n",
      "Epoch [64/360], Batch [170/196], Loss: 0.5627\n",
      "Epoch [64/360], Batch [175/196], Loss: 0.4114\n",
      "Epoch [64/360], Batch [180/196], Loss: 0.4319\n",
      "Epoch [64/360], Batch [185/196], Loss: 1.2731\n",
      "Epoch [64/360], Batch [190/196], Loss: 0.6083\n",
      "Epoch [64/360], Batch [195/196], Loss: 0.4546\n",
      "Epoch [65/360], Batch [5/196], Loss: 0.5253\n",
      "Epoch [65/360], Batch [10/196], Loss: 1.1439\n",
      "Epoch [65/360], Batch [15/196], Loss: 0.2809\n",
      "Epoch [65/360], Batch [20/196], Loss: 0.5787\n",
      "Epoch [65/360], Batch [25/196], Loss: 0.4844\n",
      "Epoch [65/360], Batch [30/196], Loss: 0.4453\n",
      "Epoch [65/360], Batch [35/196], Loss: 0.6592\n",
      "Epoch [65/360], Batch [40/196], Loss: 1.6117\n",
      "Epoch [65/360], Batch [45/196], Loss: 0.5084\n",
      "Epoch [65/360], Batch [50/196], Loss: 0.5904\n",
      "Epoch [65/360], Batch [55/196], Loss: 0.3900\n",
      "Epoch [65/360], Batch [60/196], Loss: 0.4020\n",
      "Epoch [65/360], Batch [65/196], Loss: 0.7422\n",
      "Epoch [65/360], Batch [70/196], Loss: 1.2134\n",
      "Epoch [65/360], Batch [75/196], Loss: 0.3364\n",
      "Epoch [65/360], Batch [80/196], Loss: 0.4111\n",
      "Epoch [65/360], Batch [85/196], Loss: 0.4755\n",
      "Epoch [65/360], Batch [90/196], Loss: 0.6784\n",
      "Epoch [65/360], Batch [95/196], Loss: 0.5155\n",
      "Epoch [65/360], Batch [100/196], Loss: 0.9396\n",
      "Epoch [65/360], Batch [105/196], Loss: 0.6047\n",
      "Epoch [65/360], Batch [110/196], Loss: 0.3049\n",
      "Epoch [65/360], Batch [115/196], Loss: 0.5551\n",
      "Epoch [65/360], Batch [120/196], Loss: 0.5423\n",
      "Epoch [65/360], Batch [125/196], Loss: 0.4649\n",
      "Epoch [65/360], Batch [130/196], Loss: 0.3687\n",
      "Epoch [65/360], Batch [135/196], Loss: 0.3363\n",
      "Epoch [65/360], Batch [140/196], Loss: 0.4108\n",
      "Epoch [65/360], Batch [145/196], Loss: 0.5707\n",
      "Epoch [65/360], Batch [150/196], Loss: 0.8830\n",
      "Epoch [65/360], Batch [155/196], Loss: 0.6092\n",
      "Epoch [65/360], Batch [160/196], Loss: 0.5021\n",
      "Epoch [65/360], Batch [165/196], Loss: 0.4742\n",
      "Epoch [65/360], Batch [170/196], Loss: 0.6697\n",
      "Epoch [65/360], Batch [175/196], Loss: 0.7412\n",
      "Epoch [65/360], Batch [180/196], Loss: 0.2822\n",
      "Epoch [65/360], Batch [185/196], Loss: 0.3681\n",
      "Epoch [65/360], Batch [190/196], Loss: 0.4348\n",
      "Epoch [65/360], Batch [195/196], Loss: 0.3184\n",
      "Epoch [66/360], Batch [5/196], Loss: 0.4032\n",
      "Epoch [66/360], Batch [10/196], Loss: 0.6049\n",
      "Epoch [66/360], Batch [15/196], Loss: 0.4368\n",
      "Epoch [66/360], Batch [20/196], Loss: 0.4165\n",
      "Epoch [66/360], Batch [25/196], Loss: 0.4444\n",
      "Epoch [66/360], Batch [30/196], Loss: 0.4938\n",
      "Epoch [66/360], Batch [35/196], Loss: 0.8006\n",
      "Epoch [66/360], Batch [40/196], Loss: 0.3370\n",
      "Epoch [66/360], Batch [45/196], Loss: 0.5096\n",
      "Epoch [66/360], Batch [50/196], Loss: 0.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/360], Batch [55/196], Loss: 0.3921\n",
      "Epoch [66/360], Batch [60/196], Loss: 0.5079\n",
      "Epoch [66/360], Batch [65/196], Loss: 0.7170\n",
      "Epoch [66/360], Batch [70/196], Loss: 0.3637\n",
      "Epoch [66/360], Batch [75/196], Loss: 0.7565\n",
      "Epoch [66/360], Batch [80/196], Loss: 0.4570\n",
      "Epoch [66/360], Batch [85/196], Loss: 1.0158\n",
      "Epoch [66/360], Batch [90/196], Loss: 0.4365\n",
      "Epoch [66/360], Batch [95/196], Loss: 0.2175\n",
      "Epoch [66/360], Batch [100/196], Loss: 0.4037\n",
      "Epoch [66/360], Batch [105/196], Loss: 0.5537\n",
      "Epoch [66/360], Batch [110/196], Loss: 0.4173\n",
      "Epoch [66/360], Batch [115/196], Loss: 0.4793\n",
      "Epoch [66/360], Batch [120/196], Loss: 0.3366\n",
      "Epoch [66/360], Batch [125/196], Loss: 0.7371\n",
      "Epoch [66/360], Batch [130/196], Loss: 0.7543\n",
      "Epoch [66/360], Batch [135/196], Loss: 3.3902\n",
      "Epoch [66/360], Batch [140/196], Loss: 0.4014\n",
      "Epoch [66/360], Batch [145/196], Loss: 0.7619\n",
      "Epoch [66/360], Batch [150/196], Loss: 0.3430\n",
      "Epoch [66/360], Batch [155/196], Loss: 0.5370\n",
      "Epoch [66/360], Batch [160/196], Loss: 0.5047\n",
      "Epoch [66/360], Batch [165/196], Loss: 0.3716\n",
      "Epoch [66/360], Batch [170/196], Loss: 0.3356\n",
      "Epoch [66/360], Batch [175/196], Loss: 0.4284\n",
      "Epoch [66/360], Batch [180/196], Loss: 0.6288\n",
      "Epoch [66/360], Batch [185/196], Loss: 0.2446\n",
      "Epoch [66/360], Batch [190/196], Loss: 1.4850\n",
      "Epoch [66/360], Batch [195/196], Loss: 0.7777\n",
      "Epoch [67/360], Batch [5/196], Loss: 1.1229\n",
      "Epoch [67/360], Batch [10/196], Loss: 0.6966\n",
      "Epoch [67/360], Batch [15/196], Loss: 0.5824\n",
      "Epoch [67/360], Batch [20/196], Loss: 0.4150\n",
      "Epoch [67/360], Batch [25/196], Loss: 0.4700\n",
      "Epoch [67/360], Batch [30/196], Loss: 0.6356\n",
      "Epoch [67/360], Batch [35/196], Loss: 0.3291\n",
      "Epoch [67/360], Batch [40/196], Loss: 0.6060\n",
      "Epoch [67/360], Batch [45/196], Loss: 0.1746\n",
      "Epoch [67/360], Batch [50/196], Loss: 0.6014\n",
      "Epoch [67/360], Batch [55/196], Loss: 0.3721\n",
      "Epoch [67/360], Batch [60/196], Loss: 0.5429\n",
      "Epoch [67/360], Batch [65/196], Loss: 0.5345\n",
      "Epoch [67/360], Batch [70/196], Loss: 0.5407\n",
      "Epoch [67/360], Batch [75/196], Loss: 0.4366\n",
      "Epoch [67/360], Batch [80/196], Loss: 0.7247\n",
      "Epoch [67/360], Batch [85/196], Loss: 0.7957\n",
      "Epoch [67/360], Batch [90/196], Loss: 0.3922\n",
      "Epoch [67/360], Batch [95/196], Loss: 0.4164\n",
      "Epoch [67/360], Batch [100/196], Loss: 0.5018\n",
      "Epoch [67/360], Batch [105/196], Loss: 0.6370\n",
      "Epoch [67/360], Batch [110/196], Loss: 0.4787\n",
      "Epoch [67/360], Batch [115/196], Loss: 0.5650\n",
      "Epoch [67/360], Batch [120/196], Loss: 0.7596\n",
      "Epoch [67/360], Batch [125/196], Loss: 0.4113\n",
      "Epoch [67/360], Batch [130/196], Loss: 0.5640\n",
      "Epoch [67/360], Batch [135/196], Loss: 0.4055\n",
      "Epoch [67/360], Batch [140/196], Loss: 0.3664\n",
      "Epoch [67/360], Batch [145/196], Loss: 0.4166\n",
      "Epoch [67/360], Batch [150/196], Loss: 0.3151\n",
      "Epoch [67/360], Batch [155/196], Loss: 0.7229\n",
      "Epoch [67/360], Batch [160/196], Loss: 0.5837\n",
      "Epoch [67/360], Batch [165/196], Loss: 0.4426\n",
      "Epoch [67/360], Batch [170/196], Loss: 0.6426\n",
      "Epoch [67/360], Batch [175/196], Loss: 0.6900\n",
      "Epoch [67/360], Batch [180/196], Loss: 0.4686\n",
      "Epoch [67/360], Batch [185/196], Loss: 0.5926\n",
      "Epoch [67/360], Batch [190/196], Loss: 0.6243\n",
      "Epoch [67/360], Batch [195/196], Loss: 0.8626\n",
      "Epoch [68/360], Batch [5/196], Loss: 0.6948\n",
      "Epoch [68/360], Batch [10/196], Loss: 0.8213\n",
      "Epoch [68/360], Batch [15/196], Loss: 0.4021\n",
      "Epoch [68/360], Batch [20/196], Loss: 0.2350\n",
      "Epoch [68/360], Batch [25/196], Loss: 0.3449\n",
      "Epoch [68/360], Batch [30/196], Loss: 0.3650\n",
      "Epoch [68/360], Batch [35/196], Loss: 1.7699\n",
      "Epoch [68/360], Batch [40/196], Loss: 0.5833\n",
      "Epoch [68/360], Batch [45/196], Loss: 0.8853\n",
      "Epoch [68/360], Batch [50/196], Loss: 0.4793\n",
      "Epoch [68/360], Batch [55/196], Loss: 0.7782\n",
      "Epoch [68/360], Batch [60/196], Loss: 0.7406\n",
      "Epoch [68/360], Batch [65/196], Loss: 0.5709\n",
      "Epoch [68/360], Batch [70/196], Loss: 0.3917\n",
      "Epoch [68/360], Batch [75/196], Loss: 0.5150\n",
      "Epoch [68/360], Batch [80/196], Loss: 0.8791\n",
      "Epoch [68/360], Batch [85/196], Loss: 0.4690\n",
      "Epoch [68/360], Batch [90/196], Loss: 0.5121\n",
      "Epoch [68/360], Batch [95/196], Loss: 0.7065\n",
      "Epoch [68/360], Batch [100/196], Loss: 0.3963\n",
      "Epoch [68/360], Batch [105/196], Loss: 0.8711\n",
      "Epoch [68/360], Batch [110/196], Loss: 0.4272\n",
      "Epoch [68/360], Batch [115/196], Loss: 0.4949\n",
      "Epoch [68/360], Batch [120/196], Loss: 0.5300\n",
      "Epoch [68/360], Batch [125/196], Loss: 0.4310\n",
      "Epoch [68/360], Batch [130/196], Loss: 0.4961\n",
      "Epoch [68/360], Batch [135/196], Loss: 0.7940\n",
      "Epoch [68/360], Batch [140/196], Loss: 1.5500\n",
      "Epoch [68/360], Batch [145/196], Loss: 0.3303\n",
      "Epoch [68/360], Batch [150/196], Loss: 0.5803\n",
      "Epoch [68/360], Batch [155/196], Loss: 0.7497\n",
      "Epoch [68/360], Batch [160/196], Loss: 0.8494\n",
      "Epoch [68/360], Batch [165/196], Loss: 0.4261\n",
      "Epoch [68/360], Batch [170/196], Loss: 0.5180\n",
      "Epoch [68/360], Batch [175/196], Loss: 1.0093\n",
      "Epoch [68/360], Batch [180/196], Loss: 0.5384\n",
      "Epoch [68/360], Batch [185/196], Loss: 0.3795\n",
      "Epoch [68/360], Batch [190/196], Loss: 0.5041\n",
      "Epoch [68/360], Batch [195/196], Loss: 0.5421\n",
      "Epoch [69/360], Batch [5/196], Loss: 0.3795\n",
      "Epoch [69/360], Batch [10/196], Loss: 0.5905\n",
      "Epoch [69/360], Batch [15/196], Loss: 0.5924\n",
      "Epoch [69/360], Batch [20/196], Loss: 0.4395\n",
      "Epoch [69/360], Batch [25/196], Loss: 0.4618\n",
      "Epoch [69/360], Batch [30/196], Loss: 0.3945\n",
      "Epoch [69/360], Batch [35/196], Loss: 0.3718\n",
      "Epoch [69/360], Batch [40/196], Loss: 0.4580\n",
      "Epoch [69/360], Batch [45/196], Loss: 3.6325\n",
      "Epoch [69/360], Batch [50/196], Loss: 0.6382\n",
      "Epoch [69/360], Batch [55/196], Loss: 0.2612\n",
      "Epoch [69/360], Batch [60/196], Loss: 0.5893\n",
      "Epoch [69/360], Batch [65/196], Loss: 0.6580\n",
      "Epoch [69/360], Batch [70/196], Loss: 0.6112\n",
      "Epoch [69/360], Batch [75/196], Loss: 0.8618\n",
      "Epoch [69/360], Batch [80/196], Loss: 0.5362\n",
      "Epoch [69/360], Batch [85/196], Loss: 0.5120\n",
      "Epoch [69/360], Batch [90/196], Loss: 1.7925\n",
      "Epoch [69/360], Batch [95/196], Loss: 0.3394\n",
      "Epoch [69/360], Batch [100/196], Loss: 0.4563\n",
      "Epoch [69/360], Batch [105/196], Loss: 0.6567\n",
      "Epoch [69/360], Batch [110/196], Loss: 0.4581\n",
      "Epoch [69/360], Batch [115/196], Loss: 0.7329\n",
      "Epoch [69/360], Batch [120/196], Loss: 0.4748\n",
      "Epoch [69/360], Batch [125/196], Loss: 0.5674\n",
      "Epoch [69/360], Batch [130/196], Loss: 0.3909\n",
      "Epoch [69/360], Batch [135/196], Loss: 0.6196\n",
      "Epoch [69/360], Batch [140/196], Loss: 0.5272\n",
      "Epoch [69/360], Batch [145/196], Loss: 0.4472\n",
      "Epoch [69/360], Batch [150/196], Loss: 0.2717\n",
      "Epoch [69/360], Batch [155/196], Loss: 1.0833\n",
      "Epoch [69/360], Batch [160/196], Loss: 1.0636\n",
      "Epoch [69/360], Batch [165/196], Loss: 0.8643\n",
      "Epoch [69/360], Batch [170/196], Loss: 0.5413\n",
      "Epoch [69/360], Batch [175/196], Loss: 0.4338\n",
      "Epoch [69/360], Batch [180/196], Loss: 0.5053\n",
      "Epoch [69/360], Batch [185/196], Loss: 0.3713\n",
      "Epoch [69/360], Batch [190/196], Loss: 0.4289\n",
      "Epoch [69/360], Batch [195/196], Loss: 0.3600\n",
      "Epoch [70/360], Batch [5/196], Loss: 0.4266\n",
      "Epoch [70/360], Batch [10/196], Loss: 0.4189\n",
      "Epoch [70/360], Batch [15/196], Loss: 0.4724\n",
      "Epoch [70/360], Batch [20/196], Loss: 0.5405\n",
      "Epoch [70/360], Batch [25/196], Loss: 0.3882\n",
      "Epoch [70/360], Batch [30/196], Loss: 0.7300\n",
      "Epoch [70/360], Batch [35/196], Loss: 0.8366\n",
      "Epoch [70/360], Batch [40/196], Loss: 0.3814\n",
      "Epoch [70/360], Batch [45/196], Loss: 0.9016\n",
      "Epoch [70/360], Batch [50/196], Loss: 0.2680\n",
      "Epoch [70/360], Batch [55/196], Loss: 0.4836\n",
      "Epoch [70/360], Batch [60/196], Loss: 0.4058\n",
      "Epoch [70/360], Batch [65/196], Loss: 0.4025\n",
      "Epoch [70/360], Batch [70/196], Loss: 0.6753\n",
      "Epoch [70/360], Batch [75/196], Loss: 0.6508\n",
      "Epoch [70/360], Batch [80/196], Loss: 0.6593\n",
      "Epoch [70/360], Batch [85/196], Loss: 1.0659\n",
      "Epoch [70/360], Batch [90/196], Loss: 3.9928\n",
      "Epoch [70/360], Batch [95/196], Loss: 0.2993\n",
      "Epoch [70/360], Batch [100/196], Loss: 0.3520\n",
      "Epoch [70/360], Batch [105/196], Loss: 0.5613\n",
      "Epoch [70/360], Batch [110/196], Loss: 0.8114\n",
      "Epoch [70/360], Batch [115/196], Loss: 2.7181\n",
      "Epoch [70/360], Batch [120/196], Loss: 0.4529\n",
      "Epoch [70/360], Batch [125/196], Loss: 0.4271\n",
      "Epoch [70/360], Batch [130/196], Loss: 0.7647\n",
      "Epoch [70/360], Batch [135/196], Loss: 0.3209\n",
      "Epoch [70/360], Batch [140/196], Loss: 0.5054\n",
      "Epoch [70/360], Batch [145/196], Loss: 0.4020\n",
      "Epoch [70/360], Batch [150/196], Loss: 0.4070\n",
      "Epoch [70/360], Batch [155/196], Loss: 1.0830\n",
      "Epoch [70/360], Batch [160/196], Loss: 0.4650\n",
      "Epoch [70/360], Batch [165/196], Loss: 0.4779\n",
      "Epoch [70/360], Batch [170/196], Loss: 0.6097\n",
      "Epoch [70/360], Batch [175/196], Loss: 0.6014\n",
      "Epoch [70/360], Batch [180/196], Loss: 0.7847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/360], Batch [185/196], Loss: 0.5452\n",
      "Epoch [70/360], Batch [190/196], Loss: 0.6425\n",
      "Epoch [70/360], Batch [195/196], Loss: 0.4134\n",
      "Epoch [71/360], Batch [5/196], Loss: 0.3750\n",
      "Epoch [71/360], Batch [10/196], Loss: 0.5435\n",
      "Epoch [71/360], Batch [15/196], Loss: 0.4550\n",
      "Epoch [71/360], Batch [20/196], Loss: 0.6513\n",
      "Epoch [71/360], Batch [25/196], Loss: 0.3948\n",
      "Epoch [71/360], Batch [30/196], Loss: 0.3280\n",
      "Epoch [71/360], Batch [35/196], Loss: 0.4112\n",
      "Epoch [71/360], Batch [40/196], Loss: 0.4186\n",
      "Epoch [71/360], Batch [45/196], Loss: 0.5725\n",
      "Epoch [71/360], Batch [50/196], Loss: 0.3374\n",
      "Epoch [71/360], Batch [55/196], Loss: 0.4341\n",
      "Epoch [71/360], Batch [60/196], Loss: 0.3640\n",
      "Epoch [71/360], Batch [65/196], Loss: 0.5724\n",
      "Epoch [71/360], Batch [70/196], Loss: 0.4176\n",
      "Epoch [71/360], Batch [75/196], Loss: 0.7585\n",
      "Epoch [71/360], Batch [80/196], Loss: 0.5513\n",
      "Epoch [71/360], Batch [85/196], Loss: 0.6266\n",
      "Epoch [71/360], Batch [90/196], Loss: 0.4342\n",
      "Epoch [71/360], Batch [95/196], Loss: 0.5672\n",
      "Epoch [71/360], Batch [100/196], Loss: 0.4158\n",
      "Epoch [71/360], Batch [105/196], Loss: 0.4203\n",
      "Epoch [71/360], Batch [110/196], Loss: 0.5772\n",
      "Epoch [71/360], Batch [115/196], Loss: 0.4271\n",
      "Epoch [71/360], Batch [120/196], Loss: 0.4867\n",
      "Epoch [71/360], Batch [125/196], Loss: 0.6804\n",
      "Epoch [71/360], Batch [130/196], Loss: 0.6557\n",
      "Epoch [71/360], Batch [135/196], Loss: 0.6524\n",
      "Epoch [71/360], Batch [140/196], Loss: 0.6349\n",
      "Epoch [71/360], Batch [145/196], Loss: 0.5567\n",
      "Epoch [71/360], Batch [150/196], Loss: 1.3144\n",
      "Epoch [71/360], Batch [155/196], Loss: 0.7219\n",
      "Epoch [71/360], Batch [160/196], Loss: 0.4609\n",
      "Epoch [71/360], Batch [165/196], Loss: 0.6389\n",
      "Epoch [71/360], Batch [170/196], Loss: 0.3867\n",
      "Epoch [71/360], Batch [175/196], Loss: 0.3335\n",
      "Epoch [71/360], Batch [180/196], Loss: 0.6538\n",
      "Epoch [71/360], Batch [185/196], Loss: 0.4025\n",
      "Epoch [71/360], Batch [190/196], Loss: 0.3426\n",
      "Epoch [71/360], Batch [195/196], Loss: 0.5250\n",
      "Epoch [72/360], Batch [5/196], Loss: 0.4120\n",
      "Epoch [72/360], Batch [10/196], Loss: 0.4406\n",
      "Epoch [72/360], Batch [15/196], Loss: 0.4612\n",
      "Epoch [72/360], Batch [20/196], Loss: 0.3606\n",
      "Epoch [72/360], Batch [25/196], Loss: 0.7525\n",
      "Epoch [72/360], Batch [30/196], Loss: 0.7043\n",
      "Epoch [72/360], Batch [35/196], Loss: 0.4113\n",
      "Epoch [72/360], Batch [40/196], Loss: 0.3087\n",
      "Epoch [72/360], Batch [45/196], Loss: 1.1315\n",
      "Epoch [72/360], Batch [50/196], Loss: 0.1670\n",
      "Epoch [72/360], Batch [55/196], Loss: 0.5043\n",
      "Epoch [72/360], Batch [60/196], Loss: 0.2698\n",
      "Epoch [72/360], Batch [65/196], Loss: 0.3244\n",
      "Epoch [72/360], Batch [70/196], Loss: 2.2601\n",
      "Epoch [72/360], Batch [75/196], Loss: 0.2848\n",
      "Epoch [72/360], Batch [80/196], Loss: 0.3561\n",
      "Epoch [72/360], Batch [85/196], Loss: 0.5159\n",
      "Epoch [72/360], Batch [90/196], Loss: 0.7743\n",
      "Epoch [72/360], Batch [95/196], Loss: 0.5888\n",
      "Epoch [72/360], Batch [100/196], Loss: 0.4370\n",
      "Epoch [72/360], Batch [105/196], Loss: 0.3618\n",
      "Epoch [72/360], Batch [110/196], Loss: 0.7396\n",
      "Epoch [72/360], Batch [115/196], Loss: 0.2945\n",
      "Epoch [72/360], Batch [120/196], Loss: 0.4765\n",
      "Epoch [72/360], Batch [125/196], Loss: 0.3397\n",
      "Epoch [72/360], Batch [130/196], Loss: 0.5001\n",
      "Epoch [72/360], Batch [135/196], Loss: 0.4310\n",
      "Epoch [72/360], Batch [140/196], Loss: 0.6227\n",
      "Epoch [72/360], Batch [145/196], Loss: 0.4141\n",
      "Epoch [72/360], Batch [150/196], Loss: 0.3781\n",
      "Epoch [72/360], Batch [155/196], Loss: 0.6291\n",
      "Epoch [72/360], Batch [160/196], Loss: 0.5431\n",
      "Epoch [72/360], Batch [165/196], Loss: 0.7324\n",
      "Epoch [72/360], Batch [170/196], Loss: 0.4534\n",
      "Epoch [72/360], Batch [175/196], Loss: 0.5063\n",
      "Epoch [72/360], Batch [180/196], Loss: 0.5000\n",
      "Epoch [72/360], Batch [185/196], Loss: 0.3993\n",
      "Epoch [72/360], Batch [190/196], Loss: 0.5339\n",
      "Epoch [72/360], Batch [195/196], Loss: 0.5509\n",
      "Epoch [73/360], Batch [5/196], Loss: 0.3517\n",
      "Epoch [73/360], Batch [10/196], Loss: 0.3372\n",
      "Epoch [73/360], Batch [15/196], Loss: 0.6264\n",
      "Epoch [73/360], Batch [20/196], Loss: 0.6076\n",
      "Epoch [73/360], Batch [25/196], Loss: 0.5625\n",
      "Epoch [73/360], Batch [30/196], Loss: 0.5970\n",
      "Epoch [73/360], Batch [35/196], Loss: 0.4903\n",
      "Epoch [73/360], Batch [40/196], Loss: 0.4007\n",
      "Epoch [73/360], Batch [45/196], Loss: 0.4560\n",
      "Epoch [73/360], Batch [50/196], Loss: 0.7799\n",
      "Epoch [73/360], Batch [55/196], Loss: 1.0697\n",
      "Epoch [73/360], Batch [60/196], Loss: 1.5179\n",
      "Epoch [73/360], Batch [65/196], Loss: 0.6802\n",
      "Epoch [73/360], Batch [70/196], Loss: 0.2693\n",
      "Epoch [73/360], Batch [75/196], Loss: 0.3369\n",
      "Epoch [73/360], Batch [80/196], Loss: 0.5997\n",
      "Epoch [73/360], Batch [85/196], Loss: 0.5910\n",
      "Epoch [73/360], Batch [90/196], Loss: 0.5200\n",
      "Epoch [73/360], Batch [95/196], Loss: 0.3702\n",
      "Epoch [73/360], Batch [100/196], Loss: 0.5771\n",
      "Epoch [73/360], Batch [105/196], Loss: 0.3812\n",
      "Epoch [73/360], Batch [110/196], Loss: 0.3669\n",
      "Epoch [73/360], Batch [115/196], Loss: 0.5550\n",
      "Epoch [73/360], Batch [120/196], Loss: 0.8964\n",
      "Epoch [73/360], Batch [125/196], Loss: 0.5527\n",
      "Epoch [73/360], Batch [130/196], Loss: 0.5708\n",
      "Epoch [73/360], Batch [135/196], Loss: 0.5953\n",
      "Epoch [73/360], Batch [140/196], Loss: 0.6373\n",
      "Epoch [73/360], Batch [145/196], Loss: 0.5946\n",
      "Epoch [73/360], Batch [150/196], Loss: 0.5524\n",
      "Epoch [73/360], Batch [155/196], Loss: 0.7978\n",
      "Epoch [73/360], Batch [160/196], Loss: 0.4571\n",
      "Epoch [73/360], Batch [165/196], Loss: 0.5281\n",
      "Epoch [73/360], Batch [170/196], Loss: 0.3842\n",
      "Epoch [73/360], Batch [175/196], Loss: 0.5228\n",
      "Epoch [73/360], Batch [180/196], Loss: 0.9703\n",
      "Epoch [73/360], Batch [185/196], Loss: 0.2597\n",
      "Epoch [73/360], Batch [190/196], Loss: 0.2544\n",
      "Epoch [73/360], Batch [195/196], Loss: 0.6529\n",
      "Epoch [74/360], Batch [5/196], Loss: 0.3811\n",
      "Epoch [74/360], Batch [10/196], Loss: 0.3603\n",
      "Epoch [74/360], Batch [15/196], Loss: 0.4524\n",
      "Epoch [74/360], Batch [20/196], Loss: 0.4460\n",
      "Epoch [74/360], Batch [25/196], Loss: 0.7627\n",
      "Epoch [74/360], Batch [30/196], Loss: 0.4623\n",
      "Epoch [74/360], Batch [35/196], Loss: 0.3817\n",
      "Epoch [74/360], Batch [40/196], Loss: 0.6858\n",
      "Epoch [74/360], Batch [45/196], Loss: 0.5685\n",
      "Epoch [74/360], Batch [50/196], Loss: 0.3912\n",
      "Epoch [74/360], Batch [55/196], Loss: 1.7863\n",
      "Epoch [74/360], Batch [60/196], Loss: 0.3743\n",
      "Epoch [74/360], Batch [65/196], Loss: 0.4655\n",
      "Epoch [74/360], Batch [70/196], Loss: 0.3291\n",
      "Epoch [74/360], Batch [75/196], Loss: 0.2949\n",
      "Epoch [74/360], Batch [80/196], Loss: 0.2973\n",
      "Epoch [74/360], Batch [85/196], Loss: 0.4000\n",
      "Epoch [74/360], Batch [90/196], Loss: 0.5692\n",
      "Epoch [74/360], Batch [95/196], Loss: 1.0329\n",
      "Epoch [74/360], Batch [100/196], Loss: 0.6100\n",
      "Epoch [74/360], Batch [105/196], Loss: 0.5526\n",
      "Epoch [74/360], Batch [110/196], Loss: 0.3411\n",
      "Epoch [74/360], Batch [115/196], Loss: 0.4387\n",
      "Epoch [74/360], Batch [120/196], Loss: 0.4214\n",
      "Epoch [74/360], Batch [125/196], Loss: 0.5522\n",
      "Epoch [74/360], Batch [130/196], Loss: 0.3689\n",
      "Epoch [74/360], Batch [135/196], Loss: 0.6734\n",
      "Epoch [74/360], Batch [140/196], Loss: 0.5785\n",
      "Epoch [74/360], Batch [145/196], Loss: 0.5126\n",
      "Epoch [74/360], Batch [150/196], Loss: 1.3743\n",
      "Epoch [74/360], Batch [155/196], Loss: 1.2623\n",
      "Epoch [74/360], Batch [160/196], Loss: 0.6332\n",
      "Epoch [74/360], Batch [165/196], Loss: 0.3017\n",
      "Epoch [74/360], Batch [170/196], Loss: 0.5383\n",
      "Epoch [74/360], Batch [175/196], Loss: 0.3606\n",
      "Epoch [74/360], Batch [180/196], Loss: 0.7454\n",
      "Epoch [74/360], Batch [185/196], Loss: 0.4363\n",
      "Epoch [74/360], Batch [190/196], Loss: 0.3440\n",
      "Epoch [74/360], Batch [195/196], Loss: 0.3777\n",
      "Epoch [75/360], Batch [5/196], Loss: 0.5900\n",
      "Epoch [75/360], Batch [10/196], Loss: 0.9366\n",
      "Epoch [75/360], Batch [15/196], Loss: 3.6342\n",
      "Epoch [75/360], Batch [20/196], Loss: 0.6393\n",
      "Epoch [75/360], Batch [25/196], Loss: 0.4474\n",
      "Epoch [75/360], Batch [30/196], Loss: 0.2633\n",
      "Epoch [75/360], Batch [35/196], Loss: 0.4062\n",
      "Epoch [75/360], Batch [40/196], Loss: 0.6317\n",
      "Epoch [75/360], Batch [45/196], Loss: 0.5183\n",
      "Epoch [75/360], Batch [50/196], Loss: 0.2792\n",
      "Epoch [75/360], Batch [55/196], Loss: 0.3858\n",
      "Epoch [75/360], Batch [60/196], Loss: 0.3262\n",
      "Epoch [75/360], Batch [65/196], Loss: 0.4006\n",
      "Epoch [75/360], Batch [70/196], Loss: 0.4220\n",
      "Epoch [75/360], Batch [75/196], Loss: 0.7214\n",
      "Epoch [75/360], Batch [80/196], Loss: 0.4069\n",
      "Epoch [75/360], Batch [85/196], Loss: 0.9348\n",
      "Epoch [75/360], Batch [90/196], Loss: 0.4540\n",
      "Epoch [75/360], Batch [95/196], Loss: 0.4341\n",
      "Epoch [75/360], Batch [100/196], Loss: 0.4093\n",
      "Epoch [75/360], Batch [105/196], Loss: 0.3881\n",
      "Epoch [75/360], Batch [110/196], Loss: 0.6728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/360], Batch [115/196], Loss: 0.5460\n",
      "Epoch [75/360], Batch [120/196], Loss: 0.3914\n",
      "Epoch [75/360], Batch [125/196], Loss: 0.6071\n",
      "Epoch [75/360], Batch [130/196], Loss: 0.2643\n",
      "Epoch [75/360], Batch [135/196], Loss: 0.5329\n",
      "Epoch [75/360], Batch [140/196], Loss: 0.4917\n",
      "Epoch [75/360], Batch [145/196], Loss: 0.6203\n",
      "Epoch [75/360], Batch [150/196], Loss: 1.4550\n",
      "Epoch [75/360], Batch [155/196], Loss: 0.4684\n",
      "Epoch [75/360], Batch [160/196], Loss: 0.5040\n",
      "Epoch [75/360], Batch [165/196], Loss: 0.3955\n",
      "Epoch [75/360], Batch [170/196], Loss: 0.8174\n",
      "Epoch [75/360], Batch [175/196], Loss: 0.3633\n",
      "Epoch [75/360], Batch [180/196], Loss: 0.7801\n",
      "Epoch [75/360], Batch [185/196], Loss: 0.5934\n",
      "Epoch [75/360], Batch [190/196], Loss: 0.5336\n",
      "Epoch [75/360], Batch [195/196], Loss: 0.4559\n",
      "Epoch [76/360], Batch [5/196], Loss: 0.3787\n",
      "Epoch [76/360], Batch [10/196], Loss: 0.3014\n",
      "Epoch [76/360], Batch [15/196], Loss: 0.7707\n",
      "Epoch [76/360], Batch [20/196], Loss: 0.2663\n",
      "Epoch [76/360], Batch [25/196], Loss: 0.3586\n",
      "Epoch [76/360], Batch [30/196], Loss: 0.2421\n",
      "Epoch [76/360], Batch [35/196], Loss: 0.3756\n",
      "Epoch [76/360], Batch [40/196], Loss: 0.4006\n",
      "Epoch [76/360], Batch [45/196], Loss: 0.6204\n",
      "Epoch [76/360], Batch [50/196], Loss: 0.5009\n",
      "Epoch [76/360], Batch [55/196], Loss: 0.2643\n",
      "Epoch [76/360], Batch [60/196], Loss: 0.4444\n",
      "Epoch [76/360], Batch [65/196], Loss: 0.3316\n",
      "Epoch [76/360], Batch [70/196], Loss: 1.1042\n",
      "Epoch [76/360], Batch [75/196], Loss: 0.5011\n",
      "Epoch [76/360], Batch [80/196], Loss: 0.4734\n",
      "Epoch [76/360], Batch [85/196], Loss: 0.5752\n",
      "Epoch [76/360], Batch [90/196], Loss: 0.4576\n",
      "Epoch [76/360], Batch [95/196], Loss: 0.1715\n",
      "Epoch [76/360], Batch [100/196], Loss: 0.6641\n",
      "Epoch [76/360], Batch [105/196], Loss: 0.5684\n",
      "Epoch [76/360], Batch [110/196], Loss: 0.5331\n",
      "Epoch [76/360], Batch [115/196], Loss: 0.5389\n",
      "Epoch [76/360], Batch [120/196], Loss: 0.3602\n",
      "Epoch [76/360], Batch [125/196], Loss: 0.4875\n",
      "Epoch [76/360], Batch [130/196], Loss: 0.2838\n",
      "Epoch [76/360], Batch [135/196], Loss: 0.4870\n",
      "Epoch [76/360], Batch [140/196], Loss: 0.6657\n",
      "Epoch [76/360], Batch [145/196], Loss: 0.2704\n",
      "Epoch [76/360], Batch [150/196], Loss: 0.3435\n",
      "Epoch [76/360], Batch [155/196], Loss: 0.7549\n",
      "Epoch [76/360], Batch [160/196], Loss: 0.6235\n",
      "Epoch [76/360], Batch [165/196], Loss: 0.3722\n",
      "Epoch [76/360], Batch [170/196], Loss: 0.5181\n",
      "Epoch [76/360], Batch [175/196], Loss: 0.1843\n",
      "Epoch [76/360], Batch [180/196], Loss: 0.9374\n",
      "Epoch [76/360], Batch [185/196], Loss: 0.3730\n",
      "Epoch [76/360], Batch [190/196], Loss: 0.6186\n",
      "Epoch [76/360], Batch [195/196], Loss: 0.5632\n",
      "Epoch [77/360], Batch [5/196], Loss: 0.4363\n",
      "Epoch [77/360], Batch [10/196], Loss: 0.5292\n",
      "Epoch [77/360], Batch [15/196], Loss: 0.8008\n",
      "Epoch [77/360], Batch [20/196], Loss: 0.3632\n",
      "Epoch [77/360], Batch [25/196], Loss: 0.8708\n",
      "Epoch [77/360], Batch [30/196], Loss: 0.3860\n",
      "Epoch [77/360], Batch [35/196], Loss: 0.2613\n",
      "Epoch [77/360], Batch [40/196], Loss: 0.3977\n",
      "Epoch [77/360], Batch [45/196], Loss: 0.3492\n",
      "Epoch [77/360], Batch [50/196], Loss: 0.4314\n",
      "Epoch [77/360], Batch [55/196], Loss: 0.3346\n",
      "Epoch [77/360], Batch [60/196], Loss: 0.3785\n",
      "Epoch [77/360], Batch [65/196], Loss: 0.2900\n",
      "Epoch [77/360], Batch [70/196], Loss: 0.5334\n",
      "Epoch [77/360], Batch [75/196], Loss: 0.3671\n",
      "Epoch [77/360], Batch [80/196], Loss: 0.4486\n",
      "Epoch [77/360], Batch [85/196], Loss: 0.3692\n",
      "Epoch [77/360], Batch [90/196], Loss: 0.4348\n",
      "Epoch [77/360], Batch [95/196], Loss: 0.5114\n",
      "Epoch [77/360], Batch [100/196], Loss: 0.4522\n",
      "Epoch [77/360], Batch [105/196], Loss: 0.7635\n",
      "Epoch [77/360], Batch [110/196], Loss: 0.7711\n",
      "Epoch [77/360], Batch [115/196], Loss: 0.2640\n",
      "Epoch [77/360], Batch [120/196], Loss: 0.3137\n",
      "Epoch [77/360], Batch [125/196], Loss: 0.3703\n",
      "Epoch [77/360], Batch [130/196], Loss: 0.3775\n",
      "Epoch [77/360], Batch [135/196], Loss: 0.3633\n",
      "Epoch [77/360], Batch [140/196], Loss: 0.5816\n",
      "Epoch [77/360], Batch [145/196], Loss: 0.3224\n",
      "Epoch [77/360], Batch [150/196], Loss: 0.8352\n",
      "Epoch [77/360], Batch [155/196], Loss: 0.7595\n",
      "Epoch [77/360], Batch [160/196], Loss: 0.5232\n",
      "Epoch [77/360], Batch [165/196], Loss: 0.3690\n",
      "Epoch [77/360], Batch [170/196], Loss: 0.5187\n",
      "Epoch [77/360], Batch [175/196], Loss: 0.3034\n",
      "Epoch [77/360], Batch [180/196], Loss: 0.3537\n",
      "Epoch [77/360], Batch [185/196], Loss: 0.3875\n",
      "Epoch [77/360], Batch [190/196], Loss: 0.5414\n",
      "Epoch [77/360], Batch [195/196], Loss: 0.3171\n",
      "Epoch [78/360], Batch [5/196], Loss: 0.3996\n",
      "Epoch [78/360], Batch [10/196], Loss: 0.3906\n",
      "Epoch [78/360], Batch [15/196], Loss: 0.3135\n",
      "Epoch [78/360], Batch [20/196], Loss: 0.2072\n",
      "Epoch [78/360], Batch [25/196], Loss: 0.6160\n",
      "Epoch [78/360], Batch [30/196], Loss: 0.4042\n",
      "Epoch [78/360], Batch [35/196], Loss: 0.4361\n",
      "Epoch [78/360], Batch [40/196], Loss: 0.6032\n",
      "Epoch [78/360], Batch [45/196], Loss: 0.3027\n",
      "Epoch [78/360], Batch [50/196], Loss: 0.4434\n",
      "Epoch [78/360], Batch [55/196], Loss: 0.6325\n",
      "Epoch [78/360], Batch [60/196], Loss: 0.7811\n",
      "Epoch [78/360], Batch [65/196], Loss: 0.5466\n",
      "Epoch [78/360], Batch [70/196], Loss: 0.1928\n",
      "Epoch [78/360], Batch [75/196], Loss: 0.4878\n",
      "Epoch [78/360], Batch [80/196], Loss: 0.3823\n",
      "Epoch [78/360], Batch [85/196], Loss: 0.5463\n",
      "Epoch [78/360], Batch [90/196], Loss: 0.3632\n",
      "Epoch [78/360], Batch [95/196], Loss: 0.5623\n",
      "Epoch [78/360], Batch [100/196], Loss: 0.2031\n",
      "Epoch [78/360], Batch [105/196], Loss: 0.3322\n",
      "Epoch [78/360], Batch [110/196], Loss: 0.6437\n",
      "Epoch [78/360], Batch [115/196], Loss: 0.3232\n",
      "Epoch [78/360], Batch [120/196], Loss: 0.5371\n",
      "Epoch [78/360], Batch [125/196], Loss: 0.5248\n",
      "Epoch [78/360], Batch [130/196], Loss: 0.3652\n",
      "Epoch [78/360], Batch [135/196], Loss: 0.4523\n",
      "Epoch [78/360], Batch [140/196], Loss: 3.7842\n",
      "Epoch [78/360], Batch [145/196], Loss: 1.0373\n",
      "Epoch [78/360], Batch [150/196], Loss: 0.3602\n",
      "Epoch [78/360], Batch [155/196], Loss: 0.6124\n",
      "Epoch [78/360], Batch [160/196], Loss: 0.3154\n",
      "Epoch [78/360], Batch [165/196], Loss: 0.4206\n",
      "Epoch [78/360], Batch [170/196], Loss: 0.4357\n",
      "Epoch [78/360], Batch [175/196], Loss: 0.4290\n",
      "Epoch [78/360], Batch [180/196], Loss: 0.2029\n",
      "Epoch [78/360], Batch [185/196], Loss: 0.5553\n",
      "Epoch [78/360], Batch [190/196], Loss: 0.8136\n",
      "Epoch [78/360], Batch [195/196], Loss: 0.5421\n",
      "Epoch [79/360], Batch [5/196], Loss: 0.4412\n",
      "Epoch [79/360], Batch [10/196], Loss: 0.3068\n",
      "Epoch [79/360], Batch [15/196], Loss: 0.6269\n",
      "Epoch [79/360], Batch [20/196], Loss: 0.3031\n",
      "Epoch [79/360], Batch [25/196], Loss: 0.3027\n",
      "Epoch [79/360], Batch [30/196], Loss: 0.2672\n",
      "Epoch [79/360], Batch [35/196], Loss: 0.4143\n",
      "Epoch [79/360], Batch [40/196], Loss: 0.3840\n",
      "Epoch [79/360], Batch [45/196], Loss: 0.4027\n",
      "Epoch [79/360], Batch [50/196], Loss: 0.4194\n",
      "Epoch [79/360], Batch [55/196], Loss: 0.2674\n",
      "Epoch [79/360], Batch [60/196], Loss: 0.4822\n",
      "Epoch [79/360], Batch [65/196], Loss: 0.4662\n",
      "Epoch [79/360], Batch [70/196], Loss: 0.3633\n",
      "Epoch [79/360], Batch [75/196], Loss: 0.6489\n",
      "Epoch [79/360], Batch [80/196], Loss: 0.2987\n",
      "Epoch [79/360], Batch [85/196], Loss: 0.3218\n",
      "Epoch [79/360], Batch [90/196], Loss: 0.4196\n",
      "Epoch [79/360], Batch [95/196], Loss: 0.3120\n",
      "Epoch [79/360], Batch [100/196], Loss: 0.2302\n",
      "Epoch [79/360], Batch [105/196], Loss: 0.4428\n",
      "Epoch [79/360], Batch [110/196], Loss: 0.5421\n",
      "Epoch [79/360], Batch [115/196], Loss: 0.6730\n",
      "Epoch [79/360], Batch [120/196], Loss: 1.5114\n",
      "Epoch [79/360], Batch [125/196], Loss: 0.5506\n",
      "Epoch [79/360], Batch [130/196], Loss: 1.8579\n",
      "Epoch [79/360], Batch [135/196], Loss: 0.5249\n",
      "Epoch [79/360], Batch [140/196], Loss: 0.2394\n",
      "Epoch [79/360], Batch [145/196], Loss: 0.3422\n",
      "Epoch [79/360], Batch [150/196], Loss: 0.3415\n",
      "Epoch [79/360], Batch [155/196], Loss: 0.4967\n",
      "Epoch [79/360], Batch [160/196], Loss: 0.6770\n",
      "Epoch [79/360], Batch [165/196], Loss: 0.5120\n",
      "Epoch [79/360], Batch [170/196], Loss: 0.6998\n",
      "Epoch [79/360], Batch [175/196], Loss: 0.6900\n",
      "Epoch [79/360], Batch [180/196], Loss: 0.3051\n",
      "Epoch [79/360], Batch [185/196], Loss: 0.2918\n",
      "Epoch [79/360], Batch [190/196], Loss: 0.4043\n",
      "Epoch [79/360], Batch [195/196], Loss: 0.3974\n",
      "Epoch [80/360], Batch [5/196], Loss: 0.4011\n",
      "Epoch [80/360], Batch [10/196], Loss: 0.4715\n",
      "Epoch [80/360], Batch [15/196], Loss: 0.4883\n",
      "Epoch [80/360], Batch [20/196], Loss: 0.2067\n",
      "Epoch [80/360], Batch [25/196], Loss: 0.5132\n",
      "Epoch [80/360], Batch [30/196], Loss: 0.2470\n",
      "Epoch [80/360], Batch [35/196], Loss: 0.6106\n",
      "Epoch [80/360], Batch [40/196], Loss: 0.2632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/360], Batch [45/196], Loss: 0.5303\n",
      "Epoch [80/360], Batch [50/196], Loss: 0.6127\n",
      "Epoch [80/360], Batch [55/196], Loss: 0.2966\n",
      "Epoch [80/360], Batch [60/196], Loss: 0.2753\n",
      "Epoch [80/360], Batch [65/196], Loss: 0.2872\n",
      "Epoch [80/360], Batch [70/196], Loss: 0.3970\n",
      "Epoch [80/360], Batch [75/196], Loss: 0.4484\n",
      "Epoch [80/360], Batch [80/196], Loss: 0.4395\n",
      "Epoch [80/360], Batch [85/196], Loss: 1.0218\n",
      "Epoch [80/360], Batch [90/196], Loss: 0.2493\n",
      "Epoch [80/360], Batch [95/196], Loss: 0.3586\n",
      "Epoch [80/360], Batch [100/196], Loss: 0.5322\n",
      "Epoch [80/360], Batch [105/196], Loss: 0.3086\n",
      "Epoch [80/360], Batch [110/196], Loss: 0.9857\n",
      "Epoch [80/360], Batch [115/196], Loss: 0.4514\n",
      "Epoch [80/360], Batch [120/196], Loss: 0.3841\n",
      "Epoch [80/360], Batch [125/196], Loss: 0.6319\n",
      "Epoch [80/360], Batch [130/196], Loss: 0.8080\n",
      "Epoch [80/360], Batch [135/196], Loss: 0.6400\n",
      "Epoch [80/360], Batch [140/196], Loss: 2.2724\n",
      "Epoch [80/360], Batch [145/196], Loss: 0.2954\n",
      "Epoch [80/360], Batch [150/196], Loss: 0.2979\n",
      "Epoch [80/360], Batch [155/196], Loss: 0.4464\n",
      "Epoch [80/360], Batch [160/196], Loss: 0.2890\n",
      "Epoch [80/360], Batch [165/196], Loss: 0.5096\n",
      "Epoch [80/360], Batch [170/196], Loss: 0.5430\n",
      "Epoch [80/360], Batch [175/196], Loss: 0.4551\n",
      "Epoch [80/360], Batch [180/196], Loss: 0.4059\n",
      "Epoch [80/360], Batch [185/196], Loss: 0.4180\n",
      "Epoch [80/360], Batch [190/196], Loss: 0.5272\n",
      "Epoch [80/360], Batch [195/196], Loss: 0.4491\n",
      "Epoch [81/360], Batch [5/196], Loss: 0.3386\n",
      "Epoch [81/360], Batch [10/196], Loss: 0.3842\n",
      "Epoch [81/360], Batch [15/196], Loss: 0.4975\n",
      "Epoch [81/360], Batch [20/196], Loss: 0.3145\n",
      "Epoch [81/360], Batch [25/196], Loss: 0.5510\n",
      "Epoch [81/360], Batch [30/196], Loss: 0.1923\n",
      "Epoch [81/360], Batch [35/196], Loss: 0.2609\n",
      "Epoch [81/360], Batch [40/196], Loss: 0.4197\n",
      "Epoch [81/360], Batch [45/196], Loss: 2.0365\n",
      "Epoch [81/360], Batch [50/196], Loss: 0.3908\n",
      "Epoch [81/360], Batch [55/196], Loss: 0.3623\n",
      "Epoch [81/360], Batch [60/196], Loss: 0.3595\n",
      "Epoch [81/360], Batch [65/196], Loss: 0.7033\n",
      "Epoch [81/360], Batch [70/196], Loss: 0.3039\n",
      "Epoch [81/360], Batch [75/196], Loss: 0.3379\n",
      "Epoch [81/360], Batch [80/196], Loss: 0.4032\n",
      "Epoch [81/360], Batch [85/196], Loss: 0.6002\n",
      "Epoch [81/360], Batch [90/196], Loss: 0.6253\n",
      "Epoch [81/360], Batch [95/196], Loss: 0.4095\n",
      "Epoch [81/360], Batch [100/196], Loss: 0.3367\n",
      "Epoch [81/360], Batch [105/196], Loss: 0.4465\n",
      "Epoch [81/360], Batch [110/196], Loss: 0.2342\n",
      "Epoch [81/360], Batch [115/196], Loss: 0.3713\n",
      "Epoch [81/360], Batch [120/196], Loss: 0.2651\n",
      "Epoch [81/360], Batch [125/196], Loss: 0.3629\n",
      "Epoch [81/360], Batch [130/196], Loss: 0.3050\n",
      "Epoch [81/360], Batch [135/196], Loss: 0.5670\n",
      "Epoch [81/360], Batch [140/196], Loss: 0.3902\n",
      "Epoch [81/360], Batch [145/196], Loss: 0.5711\n",
      "Epoch [81/360], Batch [150/196], Loss: 0.5998\n",
      "Epoch [81/360], Batch [155/196], Loss: 0.4078\n",
      "Epoch [81/360], Batch [160/196], Loss: 0.5085\n",
      "Epoch [81/360], Batch [165/196], Loss: 1.2616\n",
      "Epoch [81/360], Batch [170/196], Loss: 0.2947\n",
      "Epoch [81/360], Batch [175/196], Loss: 0.2153\n",
      "Epoch [81/360], Batch [180/196], Loss: 0.2578\n",
      "Epoch [81/360], Batch [185/196], Loss: 0.3646\n",
      "Epoch [81/360], Batch [190/196], Loss: 0.3019\n",
      "Epoch [81/360], Batch [195/196], Loss: 0.4443\n",
      "Epoch [82/360], Batch [5/196], Loss: 0.5277\n",
      "Epoch [82/360], Batch [10/196], Loss: 0.2237\n",
      "Epoch [82/360], Batch [15/196], Loss: 0.3461\n",
      "Epoch [82/360], Batch [20/196], Loss: 0.3059\n",
      "Epoch [82/360], Batch [25/196], Loss: 0.2619\n",
      "Epoch [82/360], Batch [30/196], Loss: 0.2833\n",
      "Epoch [82/360], Batch [35/196], Loss: 0.4282\n",
      "Epoch [82/360], Batch [40/196], Loss: 0.2224\n",
      "Epoch [82/360], Batch [45/196], Loss: 0.5568\n",
      "Epoch [82/360], Batch [50/196], Loss: 0.3899\n",
      "Epoch [82/360], Batch [55/196], Loss: 0.2258\n",
      "Epoch [82/360], Batch [60/196], Loss: 0.2468\n",
      "Epoch [82/360], Batch [65/196], Loss: 0.5112\n",
      "Epoch [82/360], Batch [70/196], Loss: 0.2887\n",
      "Epoch [82/360], Batch [75/196], Loss: 0.4860\n",
      "Epoch [82/360], Batch [80/196], Loss: 0.4004\n",
      "Epoch [82/360], Batch [85/196], Loss: 0.5146\n",
      "Epoch [82/360], Batch [90/196], Loss: 0.4553\n",
      "Epoch [82/360], Batch [95/196], Loss: 0.4220\n",
      "Epoch [82/360], Batch [100/196], Loss: 0.4162\n",
      "Epoch [82/360], Batch [105/196], Loss: 0.3441\n",
      "Epoch [82/360], Batch [110/196], Loss: 0.4460\n",
      "Epoch [82/360], Batch [115/196], Loss: 0.7481\n",
      "Epoch [82/360], Batch [120/196], Loss: 0.3306\n",
      "Epoch [82/360], Batch [125/196], Loss: 0.3800\n",
      "Epoch [82/360], Batch [130/196], Loss: 0.5976\n",
      "Epoch [82/360], Batch [135/196], Loss: 0.4205\n",
      "Epoch [82/360], Batch [140/196], Loss: 0.3500\n",
      "Epoch [82/360], Batch [145/196], Loss: 0.2912\n",
      "Epoch [82/360], Batch [150/196], Loss: 0.6433\n",
      "Epoch [82/360], Batch [155/196], Loss: 0.6156\n",
      "Epoch [82/360], Batch [160/196], Loss: 0.7111\n",
      "Epoch [82/360], Batch [165/196], Loss: 0.5452\n",
      "Epoch [82/360], Batch [170/196], Loss: 0.5336\n",
      "Epoch [82/360], Batch [175/196], Loss: 0.3896\n",
      "Epoch [82/360], Batch [180/196], Loss: 0.3833\n",
      "Epoch [82/360], Batch [185/196], Loss: 0.3502\n",
      "Epoch [82/360], Batch [190/196], Loss: 0.4605\n",
      "Epoch [82/360], Batch [195/196], Loss: 0.4276\n",
      "Epoch [83/360], Batch [5/196], Loss: 0.4543\n",
      "Epoch [83/360], Batch [10/196], Loss: 0.2673\n",
      "Epoch [83/360], Batch [15/196], Loss: 0.6841\n",
      "Epoch [83/360], Batch [20/196], Loss: 0.4450\n",
      "Epoch [83/360], Batch [25/196], Loss: 0.2994\n",
      "Epoch [83/360], Batch [30/196], Loss: 0.3142\n",
      "Epoch [83/360], Batch [35/196], Loss: 0.5220\n",
      "Epoch [83/360], Batch [40/196], Loss: 0.2609\n",
      "Epoch [83/360], Batch [45/196], Loss: 0.3370\n",
      "Epoch [83/360], Batch [50/196], Loss: 0.2390\n",
      "Epoch [83/360], Batch [55/196], Loss: 0.2650\n",
      "Epoch [83/360], Batch [60/196], Loss: 0.6345\n",
      "Epoch [83/360], Batch [65/196], Loss: 0.5283\n",
      "Epoch [83/360], Batch [70/196], Loss: 0.5408\n",
      "Epoch [83/360], Batch [75/196], Loss: 0.3590\n",
      "Epoch [83/360], Batch [80/196], Loss: 0.2797\n",
      "Epoch [83/360], Batch [85/196], Loss: 0.4773\n",
      "Epoch [83/360], Batch [90/196], Loss: 0.7819\n",
      "Epoch [83/360], Batch [95/196], Loss: 0.4489\n",
      "Epoch [83/360], Batch [100/196], Loss: 0.2803\n",
      "Epoch [83/360], Batch [105/196], Loss: 0.3267\n",
      "Epoch [83/360], Batch [110/196], Loss: 0.3263\n",
      "Epoch [83/360], Batch [115/196], Loss: 0.4308\n",
      "Epoch [83/360], Batch [120/196], Loss: 0.2594\n",
      "Epoch [83/360], Batch [125/196], Loss: 0.5274\n",
      "Epoch [83/360], Batch [130/196], Loss: 0.4033\n",
      "Epoch [83/360], Batch [135/196], Loss: 0.3909\n",
      "Epoch [83/360], Batch [140/196], Loss: 0.4323\n",
      "Epoch [83/360], Batch [145/196], Loss: 0.2946\n",
      "Epoch [83/360], Batch [150/196], Loss: 0.4095\n",
      "Epoch [83/360], Batch [155/196], Loss: 0.4487\n",
      "Epoch [83/360], Batch [160/196], Loss: 0.3795\n",
      "Epoch [83/360], Batch [165/196], Loss: 0.7355\n",
      "Epoch [83/360], Batch [170/196], Loss: 0.4563\n",
      "Epoch [83/360], Batch [175/196], Loss: 0.8630\n",
      "Epoch [83/360], Batch [180/196], Loss: 0.9060\n",
      "Epoch [83/360], Batch [185/196], Loss: 0.4012\n",
      "Epoch [83/360], Batch [190/196], Loss: 0.5813\n",
      "Epoch [83/360], Batch [195/196], Loss: 0.3979\n",
      "Epoch [84/360], Batch [5/196], Loss: 0.2374\n",
      "Epoch [84/360], Batch [10/196], Loss: 0.5273\n",
      "Epoch [84/360], Batch [15/196], Loss: 0.1949\n",
      "Epoch [84/360], Batch [20/196], Loss: 0.5157\n",
      "Epoch [84/360], Batch [25/196], Loss: 0.6652\n",
      "Epoch [84/360], Batch [30/196], Loss: 0.4198\n",
      "Epoch [84/360], Batch [35/196], Loss: 0.4563\n",
      "Epoch [84/360], Batch [40/196], Loss: 0.9412\n",
      "Epoch [84/360], Batch [45/196], Loss: 0.6467\n",
      "Epoch [84/360], Batch [50/196], Loss: 0.4507\n",
      "Epoch [84/360], Batch [55/196], Loss: 0.3425\n",
      "Epoch [84/360], Batch [60/196], Loss: 0.3863\n",
      "Epoch [84/360], Batch [65/196], Loss: 0.5458\n",
      "Epoch [84/360], Batch [70/196], Loss: 0.7340\n",
      "Epoch [84/360], Batch [75/196], Loss: 0.4402\n",
      "Epoch [84/360], Batch [80/196], Loss: 0.5261\n",
      "Epoch [84/360], Batch [85/196], Loss: 0.4207\n",
      "Epoch [84/360], Batch [90/196], Loss: 0.7763\n",
      "Epoch [84/360], Batch [95/196], Loss: 0.4530\n",
      "Epoch [84/360], Batch [100/196], Loss: 0.4799\n",
      "Epoch [84/360], Batch [105/196], Loss: 0.3451\n",
      "Epoch [84/360], Batch [110/196], Loss: 0.4029\n",
      "Epoch [84/360], Batch [115/196], Loss: 0.4357\n",
      "Epoch [84/360], Batch [120/196], Loss: 0.3289\n",
      "Epoch [84/360], Batch [125/196], Loss: 0.3628\n",
      "Epoch [84/360], Batch [130/196], Loss: 0.3745\n",
      "Epoch [84/360], Batch [135/196], Loss: 0.6178\n",
      "Epoch [84/360], Batch [140/196], Loss: 0.4666\n",
      "Epoch [84/360], Batch [145/196], Loss: 0.4024\n",
      "Epoch [84/360], Batch [150/196], Loss: 0.4646\n",
      "Epoch [84/360], Batch [155/196], Loss: 1.0231\n",
      "Epoch [84/360], Batch [160/196], Loss: 0.4031\n",
      "Epoch [84/360], Batch [165/196], Loss: 0.4867\n",
      "Epoch [84/360], Batch [170/196], Loss: 0.7041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/360], Batch [175/196], Loss: 0.5362\n",
      "Epoch [84/360], Batch [180/196], Loss: 0.3322\n",
      "Epoch [84/360], Batch [185/196], Loss: 0.2995\n",
      "Epoch [84/360], Batch [190/196], Loss: 0.6426\n",
      "Epoch [84/360], Batch [195/196], Loss: 0.3938\n",
      "Epoch [85/360], Batch [5/196], Loss: 0.5064\n",
      "Epoch [85/360], Batch [10/196], Loss: 0.2560\n",
      "Epoch [85/360], Batch [15/196], Loss: 0.4551\n",
      "Epoch [85/360], Batch [20/196], Loss: 0.4121\n",
      "Epoch [85/360], Batch [25/196], Loss: 0.5320\n",
      "Epoch [85/360], Batch [30/196], Loss: 0.3029\n",
      "Epoch [85/360], Batch [35/196], Loss: 0.3086\n",
      "Epoch [85/360], Batch [40/196], Loss: 0.3322\n",
      "Epoch [85/360], Batch [45/196], Loss: 0.3146\n",
      "Epoch [85/360], Batch [50/196], Loss: 0.4332\n",
      "Epoch [85/360], Batch [55/196], Loss: 0.4654\n",
      "Epoch [85/360], Batch [60/196], Loss: 0.4968\n",
      "Epoch [85/360], Batch [65/196], Loss: 0.3676\n",
      "Epoch [85/360], Batch [70/196], Loss: 0.4755\n",
      "Epoch [85/360], Batch [75/196], Loss: 0.3981\n",
      "Epoch [85/360], Batch [80/196], Loss: 0.4111\n",
      "Epoch [85/360], Batch [85/196], Loss: 0.4588\n",
      "Epoch [85/360], Batch [90/196], Loss: 0.4053\n",
      "Epoch [85/360], Batch [95/196], Loss: 0.2585\n",
      "Epoch [85/360], Batch [100/196], Loss: 0.5249\n",
      "Epoch [85/360], Batch [105/196], Loss: 0.3283\n",
      "Epoch [85/360], Batch [110/196], Loss: 0.3658\n",
      "Epoch [85/360], Batch [115/196], Loss: 0.3646\n",
      "Epoch [85/360], Batch [120/196], Loss: 0.3674\n",
      "Epoch [85/360], Batch [125/196], Loss: 0.4885\n",
      "Epoch [85/360], Batch [130/196], Loss: 0.5105\n",
      "Epoch [85/360], Batch [135/196], Loss: 0.3110\n",
      "Epoch [85/360], Batch [140/196], Loss: 0.2564\n",
      "Epoch [85/360], Batch [145/196], Loss: 0.3803\n",
      "Epoch [85/360], Batch [150/196], Loss: 0.3676\n",
      "Epoch [85/360], Batch [155/196], Loss: 0.3331\n",
      "Epoch [85/360], Batch [160/196], Loss: 0.5771\n",
      "Epoch [85/360], Batch [165/196], Loss: 0.5234\n",
      "Epoch [85/360], Batch [170/196], Loss: 0.3119\n",
      "Epoch [85/360], Batch [175/196], Loss: 0.2930\n",
      "Epoch [85/360], Batch [180/196], Loss: 0.7788\n",
      "Epoch [85/360], Batch [185/196], Loss: 0.4941\n",
      "Epoch [85/360], Batch [190/196], Loss: 0.3603\n",
      "Epoch [85/360], Batch [195/196], Loss: 0.6000\n",
      "Epoch [86/360], Batch [5/196], Loss: 0.4285\n",
      "Epoch [86/360], Batch [10/196], Loss: 0.4233\n",
      "Epoch [86/360], Batch [15/196], Loss: 0.3290\n",
      "Epoch [86/360], Batch [20/196], Loss: 0.4840\n",
      "Epoch [86/360], Batch [25/196], Loss: 0.4210\n",
      "Epoch [86/360], Batch [30/196], Loss: 0.2852\n",
      "Epoch [86/360], Batch [35/196], Loss: 0.3657\n",
      "Epoch [86/360], Batch [40/196], Loss: 0.3635\n",
      "Epoch [86/360], Batch [45/196], Loss: 0.3705\n",
      "Epoch [86/360], Batch [50/196], Loss: 0.4463\n",
      "Epoch [86/360], Batch [55/196], Loss: 0.3168\n",
      "Epoch [86/360], Batch [60/196], Loss: 0.2617\n",
      "Epoch [86/360], Batch [65/196], Loss: 0.2474\n",
      "Epoch [86/360], Batch [70/196], Loss: 0.3567\n",
      "Epoch [86/360], Batch [75/196], Loss: 0.5317\n",
      "Epoch [86/360], Batch [80/196], Loss: 0.3029\n",
      "Epoch [86/360], Batch [85/196], Loss: 0.4064\n",
      "Epoch [86/360], Batch [90/196], Loss: 0.4863\n",
      "Epoch [86/360], Batch [95/196], Loss: 0.2483\n",
      "Epoch [86/360], Batch [100/196], Loss: 0.3819\n",
      "Epoch [86/360], Batch [105/196], Loss: 0.4689\n",
      "Epoch [86/360], Batch [110/196], Loss: 0.5795\n",
      "Epoch [86/360], Batch [115/196], Loss: 0.2583\n",
      "Epoch [86/360], Batch [120/196], Loss: 0.3129\n",
      "Epoch [86/360], Batch [125/196], Loss: 0.4411\n",
      "Epoch [86/360], Batch [130/196], Loss: 0.5260\n",
      "Epoch [86/360], Batch [135/196], Loss: 0.5295\n",
      "Epoch [86/360], Batch [140/196], Loss: 0.2587\n",
      "Epoch [86/360], Batch [145/196], Loss: 0.5297\n",
      "Epoch [86/360], Batch [150/196], Loss: 0.2492\n",
      "Epoch [86/360], Batch [155/196], Loss: 0.4499\n",
      "Epoch [86/360], Batch [160/196], Loss: 0.3615\n",
      "Epoch [86/360], Batch [165/196], Loss: 0.3169\n",
      "Epoch [86/360], Batch [170/196], Loss: 0.3250\n",
      "Epoch [86/360], Batch [175/196], Loss: 0.2189\n",
      "Epoch [86/360], Batch [180/196], Loss: 0.3577\n",
      "Epoch [86/360], Batch [185/196], Loss: 0.2778\n",
      "Epoch [86/360], Batch [190/196], Loss: 1.5391\n",
      "Epoch [86/360], Batch [195/196], Loss: 0.3006\n",
      "Epoch [87/360], Batch [5/196], Loss: 0.3603\n",
      "Epoch [87/360], Batch [10/196], Loss: 0.2721\n",
      "Epoch [87/360], Batch [15/196], Loss: 0.3329\n",
      "Epoch [87/360], Batch [20/196], Loss: 0.2456\n",
      "Epoch [87/360], Batch [25/196], Loss: 0.8267\n",
      "Epoch [87/360], Batch [30/196], Loss: 0.2811\n",
      "Epoch [87/360], Batch [35/196], Loss: 0.3072\n",
      "Epoch [87/360], Batch [40/196], Loss: 0.3335\n",
      "Epoch [87/360], Batch [45/196], Loss: 0.3540\n",
      "Epoch [87/360], Batch [50/196], Loss: 0.3628\n",
      "Epoch [87/360], Batch [55/196], Loss: 0.5916\n",
      "Epoch [87/360], Batch [60/196], Loss: 0.1745\n",
      "Epoch [87/360], Batch [65/196], Loss: 0.2791\n",
      "Epoch [87/360], Batch [70/196], Loss: 0.4497\n",
      "Epoch [87/360], Batch [75/196], Loss: 0.2505\n",
      "Epoch [87/360], Batch [80/196], Loss: 0.2761\n",
      "Epoch [87/360], Batch [85/196], Loss: 0.3032\n",
      "Epoch [87/360], Batch [90/196], Loss: 0.4385\n",
      "Epoch [87/360], Batch [95/196], Loss: 0.2642\n",
      "Epoch [87/360], Batch [100/196], Loss: 0.5214\n",
      "Epoch [87/360], Batch [105/196], Loss: 0.3937\n",
      "Epoch [87/360], Batch [110/196], Loss: 1.5061\n",
      "Epoch [87/360], Batch [115/196], Loss: 0.3244\n",
      "Epoch [87/360], Batch [120/196], Loss: 0.2590\n",
      "Epoch [87/360], Batch [125/196], Loss: 0.3698\n",
      "Epoch [87/360], Batch [130/196], Loss: 0.2327\n",
      "Epoch [87/360], Batch [135/196], Loss: 0.2658\n",
      "Epoch [87/360], Batch [140/196], Loss: 0.4792\n",
      "Epoch [87/360], Batch [145/196], Loss: 0.2123\n",
      "Epoch [87/360], Batch [150/196], Loss: 0.3799\n",
      "Epoch [87/360], Batch [155/196], Loss: 0.5250\n",
      "Epoch [87/360], Batch [160/196], Loss: 0.2853\n",
      "Epoch [87/360], Batch [165/196], Loss: 0.6154\n",
      "Epoch [87/360], Batch [170/196], Loss: 0.4374\n",
      "Epoch [87/360], Batch [175/196], Loss: 0.3932\n",
      "Epoch [87/360], Batch [180/196], Loss: 0.2710\n",
      "Epoch [87/360], Batch [185/196], Loss: 0.5636\n",
      "Epoch [87/360], Batch [190/196], Loss: 0.5275\n",
      "Epoch [87/360], Batch [195/196], Loss: 0.3811\n",
      "Epoch [88/360], Batch [5/196], Loss: 0.3275\n",
      "Epoch [88/360], Batch [10/196], Loss: 0.4400\n",
      "Epoch [88/360], Batch [15/196], Loss: 0.4424\n",
      "Epoch [88/360], Batch [20/196], Loss: 0.5188\n",
      "Epoch [88/360], Batch [25/196], Loss: 0.6509\n",
      "Epoch [88/360], Batch [30/196], Loss: 0.2185\n",
      "Epoch [88/360], Batch [35/196], Loss: 0.3928\n",
      "Epoch [88/360], Batch [40/196], Loss: 0.3172\n",
      "Epoch [88/360], Batch [45/196], Loss: 0.4074\n",
      "Epoch [88/360], Batch [50/196], Loss: 0.2363\n",
      "Epoch [88/360], Batch [55/196], Loss: 0.2790\n",
      "Epoch [88/360], Batch [60/196], Loss: 0.1751\n",
      "Epoch [88/360], Batch [65/196], Loss: 0.2981\n",
      "Epoch [88/360], Batch [70/196], Loss: 0.4289\n",
      "Epoch [88/360], Batch [75/196], Loss: 0.3402\n",
      "Epoch [88/360], Batch [80/196], Loss: 0.3909\n",
      "Epoch [88/360], Batch [85/196], Loss: 0.2841\n",
      "Epoch [88/360], Batch [90/196], Loss: 0.5002\n",
      "Epoch [88/360], Batch [95/196], Loss: 0.3622\n",
      "Epoch [88/360], Batch [100/196], Loss: 0.3820\n",
      "Epoch [88/360], Batch [105/196], Loss: 0.2297\n",
      "Epoch [88/360], Batch [110/196], Loss: 0.2085\n",
      "Epoch [88/360], Batch [115/196], Loss: 0.4052\n",
      "Epoch [88/360], Batch [120/196], Loss: 0.4403\n",
      "Epoch [88/360], Batch [125/196], Loss: 0.5489\n",
      "Epoch [88/360], Batch [130/196], Loss: 0.2533\n",
      "Epoch [88/360], Batch [135/196], Loss: 1.8897\n",
      "Epoch [88/360], Batch [140/196], Loss: 0.2899\n",
      "Epoch [88/360], Batch [145/196], Loss: 0.3617\n",
      "Epoch [88/360], Batch [150/196], Loss: 0.4251\n",
      "Epoch [88/360], Batch [155/196], Loss: 0.7813\n",
      "Epoch [88/360], Batch [160/196], Loss: 0.3562\n",
      "Epoch [88/360], Batch [165/196], Loss: 0.3443\n",
      "Epoch [88/360], Batch [170/196], Loss: 0.2460\n",
      "Epoch [88/360], Batch [175/196], Loss: 0.2850\n",
      "Epoch [88/360], Batch [180/196], Loss: 0.2819\n",
      "Epoch [88/360], Batch [185/196], Loss: 0.4887\n",
      "Epoch [88/360], Batch [190/196], Loss: 0.5903\n",
      "Epoch [88/360], Batch [195/196], Loss: 0.2826\n",
      "Epoch [89/360], Batch [5/196], Loss: 0.3106\n",
      "Epoch [89/360], Batch [10/196], Loss: 0.2609\n",
      "Epoch [89/360], Batch [15/196], Loss: 0.2931\n",
      "Epoch [89/360], Batch [20/196], Loss: 0.3048\n",
      "Epoch [89/360], Batch [25/196], Loss: 0.2402\n",
      "Epoch [89/360], Batch [30/196], Loss: 0.2632\n",
      "Epoch [89/360], Batch [35/196], Loss: 0.3894\n",
      "Epoch [89/360], Batch [40/196], Loss: 0.2571\n",
      "Epoch [89/360], Batch [45/196], Loss: 0.2488\n",
      "Epoch [89/360], Batch [50/196], Loss: 0.5630\n",
      "Epoch [89/360], Batch [55/196], Loss: 0.1653\n",
      "Epoch [89/360], Batch [60/196], Loss: 0.5504\n",
      "Epoch [89/360], Batch [65/196], Loss: 0.2983\n",
      "Epoch [89/360], Batch [70/196], Loss: 0.3323\n",
      "Epoch [89/360], Batch [75/196], Loss: 0.2744\n",
      "Epoch [89/360], Batch [80/196], Loss: 0.3488\n",
      "Epoch [89/360], Batch [85/196], Loss: 0.4691\n",
      "Epoch [89/360], Batch [90/196], Loss: 0.2553\n",
      "Epoch [89/360], Batch [95/196], Loss: 0.4210\n",
      "Epoch [89/360], Batch [100/196], Loss: 0.3470\n",
      "Epoch [89/360], Batch [105/196], Loss: 0.3825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/360], Batch [110/196], Loss: 0.4157\n",
      "Epoch [89/360], Batch [115/196], Loss: 0.3806\n",
      "Epoch [89/360], Batch [120/196], Loss: 0.3737\n",
      "Epoch [89/360], Batch [125/196], Loss: 0.4356\n",
      "Epoch [89/360], Batch [130/196], Loss: 0.6343\n",
      "Epoch [89/360], Batch [135/196], Loss: 0.2872\n",
      "Epoch [89/360], Batch [140/196], Loss: 0.2259\n",
      "Epoch [89/360], Batch [145/196], Loss: 0.3347\n",
      "Epoch [89/360], Batch [150/196], Loss: 0.5480\n",
      "Epoch [89/360], Batch [155/196], Loss: 0.3194\n",
      "Epoch [89/360], Batch [160/196], Loss: 0.3241\n",
      "Epoch [89/360], Batch [165/196], Loss: 0.4446\n",
      "Epoch [89/360], Batch [170/196], Loss: 0.2666\n",
      "Epoch [89/360], Batch [175/196], Loss: 0.3652\n",
      "Epoch [89/360], Batch [180/196], Loss: 0.2666\n",
      "Epoch [89/360], Batch [185/196], Loss: 1.6877\n",
      "Epoch [89/360], Batch [190/196], Loss: 0.2422\n",
      "Epoch [89/360], Batch [195/196], Loss: 0.4060\n",
      "Epoch [90/360], Batch [5/196], Loss: 0.2962\n",
      "Epoch [90/360], Batch [10/196], Loss: 0.4086\n",
      "Epoch [90/360], Batch [15/196], Loss: 0.3486\n",
      "Epoch [90/360], Batch [20/196], Loss: 0.3179\n",
      "Epoch [90/360], Batch [25/196], Loss: 0.2173\n",
      "Epoch [90/360], Batch [30/196], Loss: 0.2574\n",
      "Epoch [90/360], Batch [35/196], Loss: 0.3278\n",
      "Epoch [90/360], Batch [40/196], Loss: 0.2296\n",
      "Epoch [90/360], Batch [45/196], Loss: 0.2155\n",
      "Epoch [90/360], Batch [50/196], Loss: 0.4728\n",
      "Epoch [90/360], Batch [55/196], Loss: 0.4985\n",
      "Epoch [90/360], Batch [60/196], Loss: 0.1895\n",
      "Epoch [90/360], Batch [65/196], Loss: 0.2947\n",
      "Epoch [90/360], Batch [70/196], Loss: 0.2559\n",
      "Epoch [90/360], Batch [75/196], Loss: 0.4142\n",
      "Epoch [90/360], Batch [80/196], Loss: 0.4988\n",
      "Epoch [90/360], Batch [85/196], Loss: 0.2438\n",
      "Epoch [90/360], Batch [90/196], Loss: 0.2753\n",
      "Epoch [90/360], Batch [95/196], Loss: 0.2317\n",
      "Epoch [90/360], Batch [100/196], Loss: 0.3787\n",
      "Epoch [90/360], Batch [105/196], Loss: 0.1300\n",
      "Epoch [90/360], Batch [110/196], Loss: 0.3479\n",
      "Epoch [90/360], Batch [115/196], Loss: 0.4193\n",
      "Epoch [90/360], Batch [120/196], Loss: 0.3007\n",
      "Epoch [90/360], Batch [125/196], Loss: 0.3023\n",
      "Epoch [90/360], Batch [130/196], Loss: 0.2715\n",
      "Epoch [90/360], Batch [135/196], Loss: 0.3429\n",
      "Epoch [90/360], Batch [140/196], Loss: 0.2196\n",
      "Epoch [90/360], Batch [145/196], Loss: 0.1928\n",
      "Epoch [90/360], Batch [150/196], Loss: 0.3583\n",
      "Epoch [90/360], Batch [155/196], Loss: 0.1747\n",
      "Epoch [90/360], Batch [160/196], Loss: 0.4307\n",
      "Epoch [90/360], Batch [165/196], Loss: 0.3627\n",
      "Epoch [90/360], Batch [170/196], Loss: 0.2225\n",
      "Epoch [90/360], Batch [175/196], Loss: 0.3165\n",
      "Epoch [90/360], Batch [180/196], Loss: 0.3033\n",
      "Epoch [90/360], Batch [185/196], Loss: 0.1672\n",
      "Epoch [90/360], Batch [190/196], Loss: 0.4215\n",
      "Epoch [90/360], Batch [195/196], Loss: 0.2488\n",
      "Epoch [91/360], Batch [5/196], Loss: 1.3933\n",
      "Epoch [91/360], Batch [10/196], Loss: 0.3159\n",
      "Epoch [91/360], Batch [15/196], Loss: 0.3285\n",
      "Epoch [91/360], Batch [20/196], Loss: 0.3148\n",
      "Epoch [91/360], Batch [25/196], Loss: 0.3643\n",
      "Epoch [91/360], Batch [30/196], Loss: 0.3109\n",
      "Epoch [91/360], Batch [35/196], Loss: 0.3534\n",
      "Epoch [91/360], Batch [40/196], Loss: 0.3261\n",
      "Epoch [91/360], Batch [45/196], Loss: 0.3665\n",
      "Epoch [91/360], Batch [50/196], Loss: 0.3220\n",
      "Epoch [91/360], Batch [55/196], Loss: 0.4425\n",
      "Epoch [91/360], Batch [60/196], Loss: 0.3435\n",
      "Epoch [91/360], Batch [65/196], Loss: 0.3564\n",
      "Epoch [91/360], Batch [70/196], Loss: 0.3649\n",
      "Epoch [91/360], Batch [75/196], Loss: 0.3090\n",
      "Epoch [91/360], Batch [80/196], Loss: 0.3434\n",
      "Epoch [91/360], Batch [85/196], Loss: 0.2695\n",
      "Epoch [91/360], Batch [90/196], Loss: 0.3982\n",
      "Epoch [91/360], Batch [95/196], Loss: 0.3995\n",
      "Epoch [91/360], Batch [100/196], Loss: 0.3910\n",
      "Epoch [91/360], Batch [105/196], Loss: 0.1831\n",
      "Epoch [91/360], Batch [110/196], Loss: 0.3229\n",
      "Epoch [91/360], Batch [115/196], Loss: 0.2077\n",
      "Epoch [91/360], Batch [120/196], Loss: 0.2227\n",
      "Epoch [91/360], Batch [125/196], Loss: 0.4947\n",
      "Epoch [91/360], Batch [130/196], Loss: 0.2565\n",
      "Epoch [91/360], Batch [135/196], Loss: 0.3773\n",
      "Epoch [91/360], Batch [140/196], Loss: 0.4082\n",
      "Epoch [91/360], Batch [145/196], Loss: 0.6716\n",
      "Epoch [91/360], Batch [150/196], Loss: 0.2658\n",
      "Epoch [91/360], Batch [155/196], Loss: 0.4375\n",
      "Epoch [91/360], Batch [160/196], Loss: 0.2891\n",
      "Epoch [91/360], Batch [165/196], Loss: 0.4350\n",
      "Epoch [91/360], Batch [170/196], Loss: 0.5495\n",
      "Epoch [91/360], Batch [175/196], Loss: 0.2198\n",
      "Epoch [91/360], Batch [180/196], Loss: 0.2630\n",
      "Epoch [91/360], Batch [185/196], Loss: 0.2002\n",
      "Epoch [91/360], Batch [190/196], Loss: 0.3301\n",
      "Epoch [91/360], Batch [195/196], Loss: 0.2260\n",
      "Epoch [92/360], Batch [5/196], Loss: 0.7442\n",
      "Epoch [92/360], Batch [10/196], Loss: 0.2799\n",
      "Epoch [92/360], Batch [15/196], Loss: 0.1911\n",
      "Epoch [92/360], Batch [20/196], Loss: 0.2145\n",
      "Epoch [92/360], Batch [25/196], Loss: 0.2842\n",
      "Epoch [92/360], Batch [30/196], Loss: 0.2042\n",
      "Epoch [92/360], Batch [35/196], Loss: 0.3819\n",
      "Epoch [92/360], Batch [40/196], Loss: 0.3120\n",
      "Epoch [92/360], Batch [45/196], Loss: 0.2303\n",
      "Epoch [92/360], Batch [50/196], Loss: 0.2277\n",
      "Epoch [92/360], Batch [55/196], Loss: 0.2414\n",
      "Epoch [92/360], Batch [60/196], Loss: 0.2497\n",
      "Epoch [92/360], Batch [65/196], Loss: 0.2367\n",
      "Epoch [92/360], Batch [70/196], Loss: 0.3905\n",
      "Epoch [92/360], Batch [75/196], Loss: 0.3182\n",
      "Epoch [92/360], Batch [80/196], Loss: 0.2490\n",
      "Epoch [92/360], Batch [85/196], Loss: 0.2231\n",
      "Epoch [92/360], Batch [90/196], Loss: 0.5216\n",
      "Epoch [92/360], Batch [95/196], Loss: 0.3089\n",
      "Epoch [92/360], Batch [100/196], Loss: 0.2856\n",
      "Epoch [92/360], Batch [105/196], Loss: 0.1253\n",
      "Epoch [92/360], Batch [110/196], Loss: 0.4040\n",
      "Epoch [92/360], Batch [115/196], Loss: 0.2167\n",
      "Epoch [92/360], Batch [120/196], Loss: 0.5586\n",
      "Epoch [92/360], Batch [125/196], Loss: 1.3765\n",
      "Epoch [92/360], Batch [130/196], Loss: 0.2233\n",
      "Epoch [92/360], Batch [135/196], Loss: 0.3537\n",
      "Epoch [92/360], Batch [140/196], Loss: 0.2579\n",
      "Epoch [92/360], Batch [145/196], Loss: 0.3213\n",
      "Epoch [92/360], Batch [150/196], Loss: 0.3119\n",
      "Epoch [92/360], Batch [155/196], Loss: 0.2243\n",
      "Epoch [92/360], Batch [160/196], Loss: 0.3794\n",
      "Epoch [92/360], Batch [165/196], Loss: 0.2400\n",
      "Epoch [92/360], Batch [170/196], Loss: 0.2258\n",
      "Epoch [92/360], Batch [175/196], Loss: 0.3627\n",
      "Epoch [92/360], Batch [180/196], Loss: 0.2498\n",
      "Epoch [92/360], Batch [185/196], Loss: 0.3929\n",
      "Epoch [92/360], Batch [190/196], Loss: 0.2813\n",
      "Epoch [92/360], Batch [195/196], Loss: 0.4264\n",
      "Epoch [93/360], Batch [5/196], Loss: 0.3404\n",
      "Epoch [93/360], Batch [10/196], Loss: 0.3612\n",
      "Epoch [93/360], Batch [15/196], Loss: 0.3160\n",
      "Epoch [93/360], Batch [20/196], Loss: 0.4244\n",
      "Epoch [93/360], Batch [25/196], Loss: 0.2560\n",
      "Epoch [93/360], Batch [30/196], Loss: 0.2777\n",
      "Epoch [93/360], Batch [35/196], Loss: 0.2326\n",
      "Epoch [93/360], Batch [40/196], Loss: 0.2993\n",
      "Epoch [93/360], Batch [45/196], Loss: 0.4019\n",
      "Epoch [93/360], Batch [50/196], Loss: 0.2878\n",
      "Epoch [93/360], Batch [55/196], Loss: 0.1947\n",
      "Epoch [93/360], Batch [60/196], Loss: 0.3753\n",
      "Epoch [93/360], Batch [65/196], Loss: 0.3442\n",
      "Epoch [93/360], Batch [70/196], Loss: 0.3475\n",
      "Epoch [93/360], Batch [75/196], Loss: 0.3580\n",
      "Epoch [93/360], Batch [80/196], Loss: 0.1989\n",
      "Epoch [93/360], Batch [85/196], Loss: 0.2701\n",
      "Epoch [93/360], Batch [90/196], Loss: 0.1722\n",
      "Epoch [93/360], Batch [95/196], Loss: 0.1557\n",
      "Epoch [93/360], Batch [100/196], Loss: 0.3103\n",
      "Epoch [93/360], Batch [105/196], Loss: 0.2411\n",
      "Epoch [93/360], Batch [110/196], Loss: 0.3597\n",
      "Epoch [93/360], Batch [115/196], Loss: 0.3311\n",
      "Epoch [93/360], Batch [120/196], Loss: 0.2802\n",
      "Epoch [93/360], Batch [125/196], Loss: 0.1943\n",
      "Epoch [93/360], Batch [130/196], Loss: 0.3033\n",
      "Epoch [93/360], Batch [135/196], Loss: 0.4025\n",
      "Epoch [93/360], Batch [140/196], Loss: 0.3633\n",
      "Epoch [93/360], Batch [145/196], Loss: 0.4329\n",
      "Epoch [93/360], Batch [150/196], Loss: 0.3124\n",
      "Epoch [93/360], Batch [155/196], Loss: 0.1496\n",
      "Epoch [93/360], Batch [160/196], Loss: 0.2497\n",
      "Epoch [93/360], Batch [165/196], Loss: 0.2116\n",
      "Epoch [93/360], Batch [170/196], Loss: 0.3719\n",
      "Epoch [93/360], Batch [175/196], Loss: 0.2083\n",
      "Epoch [93/360], Batch [180/196], Loss: 0.2247\n",
      "Epoch [93/360], Batch [185/196], Loss: 0.2656\n",
      "Epoch [93/360], Batch [190/196], Loss: 0.3347\n",
      "Epoch [93/360], Batch [195/196], Loss: 0.1998\n",
      "Epoch [94/360], Batch [5/196], Loss: 0.3425\n",
      "Epoch [94/360], Batch [10/196], Loss: 0.6373\n",
      "Epoch [94/360], Batch [15/196], Loss: 0.3349\n",
      "Epoch [94/360], Batch [20/196], Loss: 0.5165\n",
      "Epoch [94/360], Batch [25/196], Loss: 0.2566\n",
      "Epoch [94/360], Batch [30/196], Loss: 0.2526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/360], Batch [35/196], Loss: 0.3727\n",
      "Epoch [94/360], Batch [40/196], Loss: 0.2588\n",
      "Epoch [94/360], Batch [45/196], Loss: 0.3066\n",
      "Epoch [94/360], Batch [50/196], Loss: 0.1918\n",
      "Epoch [94/360], Batch [55/196], Loss: 0.3381\n",
      "Epoch [94/360], Batch [60/196], Loss: 0.3361\n",
      "Epoch [94/360], Batch [65/196], Loss: 0.1988\n",
      "Epoch [94/360], Batch [70/196], Loss: 0.2943\n",
      "Epoch [94/360], Batch [75/196], Loss: 0.2556\n",
      "Epoch [94/360], Batch [80/196], Loss: 0.3898\n",
      "Epoch [94/360], Batch [85/196], Loss: 0.3861\n",
      "Epoch [94/360], Batch [90/196], Loss: 0.3752\n",
      "Epoch [94/360], Batch [95/196], Loss: 0.3643\n",
      "Epoch [94/360], Batch [100/196], Loss: 0.4621\n",
      "Epoch [94/360], Batch [105/196], Loss: 0.2908\n",
      "Epoch [94/360], Batch [110/196], Loss: 0.1985\n",
      "Epoch [94/360], Batch [115/196], Loss: 0.2920\n",
      "Epoch [94/360], Batch [120/196], Loss: 0.2796\n",
      "Epoch [94/360], Batch [125/196], Loss: 0.4065\n",
      "Epoch [94/360], Batch [130/196], Loss: 0.4522\n",
      "Epoch [94/360], Batch [135/196], Loss: 0.3291\n",
      "Epoch [94/360], Batch [140/196], Loss: 0.3912\n",
      "Epoch [94/360], Batch [145/196], Loss: 0.4630\n",
      "Epoch [94/360], Batch [150/196], Loss: 0.4741\n",
      "Epoch [94/360], Batch [155/196], Loss: 0.4011\n",
      "Epoch [94/360], Batch [160/196], Loss: 0.3571\n",
      "Epoch [94/360], Batch [165/196], Loss: 0.3982\n",
      "Epoch [94/360], Batch [170/196], Loss: 0.2668\n",
      "Epoch [94/360], Batch [175/196], Loss: 0.4137\n",
      "Epoch [94/360], Batch [180/196], Loss: 0.3902\n",
      "Epoch [94/360], Batch [185/196], Loss: 0.2947\n",
      "Epoch [94/360], Batch [190/196], Loss: 0.3388\n",
      "Epoch [94/360], Batch [195/196], Loss: 0.3432\n",
      "Epoch [95/360], Batch [5/196], Loss: 0.3815\n",
      "Epoch [95/360], Batch [10/196], Loss: 0.3632\n",
      "Epoch [95/360], Batch [15/196], Loss: 0.3009\n",
      "Epoch [95/360], Batch [20/196], Loss: 0.2456\n",
      "Epoch [95/360], Batch [25/196], Loss: 0.3071\n",
      "Epoch [95/360], Batch [30/196], Loss: 0.2175\n",
      "Epoch [95/360], Batch [35/196], Loss: 0.2420\n",
      "Epoch [95/360], Batch [40/196], Loss: 0.2446\n",
      "Epoch [95/360], Batch [45/196], Loss: 0.3062\n",
      "Epoch [95/360], Batch [50/196], Loss: 0.1883\n",
      "Epoch [95/360], Batch [55/196], Loss: 0.2466\n",
      "Epoch [95/360], Batch [60/196], Loss: 0.3367\n",
      "Epoch [95/360], Batch [65/196], Loss: 0.2816\n",
      "Epoch [95/360], Batch [70/196], Loss: 0.1454\n",
      "Epoch [95/360], Batch [75/196], Loss: 0.1960\n",
      "Epoch [95/360], Batch [80/196], Loss: 0.3218\n",
      "Epoch [95/360], Batch [85/196], Loss: 0.4181\n",
      "Epoch [95/360], Batch [90/196], Loss: 0.3103\n",
      "Epoch [95/360], Batch [95/196], Loss: 0.2620\n",
      "Epoch [95/360], Batch [100/196], Loss: 0.3443\n",
      "Epoch [95/360], Batch [105/196], Loss: 0.2914\n",
      "Epoch [95/360], Batch [110/196], Loss: 0.2407\n",
      "Epoch [95/360], Batch [115/196], Loss: 1.2387\n",
      "Epoch [95/360], Batch [120/196], Loss: 0.2763\n",
      "Epoch [95/360], Batch [125/196], Loss: 0.3010\n",
      "Epoch [95/360], Batch [130/196], Loss: 0.3956\n",
      "Epoch [95/360], Batch [135/196], Loss: 0.2895\n",
      "Epoch [95/360], Batch [140/196], Loss: 0.2252\n",
      "Epoch [95/360], Batch [145/196], Loss: 0.3256\n",
      "Epoch [95/360], Batch [150/196], Loss: 0.3381\n",
      "Epoch [95/360], Batch [155/196], Loss: 0.2974\n",
      "Epoch [95/360], Batch [160/196], Loss: 0.3947\n",
      "Epoch [95/360], Batch [165/196], Loss: 0.3175\n",
      "Epoch [95/360], Batch [170/196], Loss: 0.3407\n",
      "Epoch [95/360], Batch [175/196], Loss: 0.2176\n",
      "Epoch [95/360], Batch [180/196], Loss: 0.2469\n",
      "Epoch [95/360], Batch [185/196], Loss: 0.1701\n",
      "Epoch [95/360], Batch [190/196], Loss: 0.2457\n",
      "Epoch [95/360], Batch [195/196], Loss: 0.3649\n",
      "Epoch [96/360], Batch [5/196], Loss: 0.3769\n",
      "Epoch [96/360], Batch [10/196], Loss: 0.2335\n",
      "Epoch [96/360], Batch [15/196], Loss: 0.3393\n",
      "Epoch [96/360], Batch [20/196], Loss: 0.1759\n",
      "Epoch [96/360], Batch [25/196], Loss: 0.2186\n",
      "Epoch [96/360], Batch [30/196], Loss: 0.2250\n",
      "Epoch [96/360], Batch [35/196], Loss: 0.1362\n",
      "Epoch [96/360], Batch [40/196], Loss: 0.2494\n",
      "Epoch [96/360], Batch [45/196], Loss: 0.2114\n",
      "Epoch [96/360], Batch [50/196], Loss: 0.2357\n",
      "Epoch [96/360], Batch [55/196], Loss: 0.2059\n",
      "Epoch [96/360], Batch [60/196], Loss: 0.1984\n",
      "Epoch [96/360], Batch [65/196], Loss: 0.3761\n",
      "Epoch [96/360], Batch [70/196], Loss: 0.1820\n",
      "Epoch [96/360], Batch [75/196], Loss: 0.2471\n",
      "Epoch [96/360], Batch [80/196], Loss: 0.1784\n",
      "Epoch [96/360], Batch [85/196], Loss: 0.3843\n",
      "Epoch [96/360], Batch [90/196], Loss: 0.2472\n",
      "Epoch [96/360], Batch [95/196], Loss: 0.2102\n",
      "Epoch [96/360], Batch [100/196], Loss: 0.1719\n",
      "Epoch [96/360], Batch [105/196], Loss: 0.3586\n",
      "Epoch [96/360], Batch [110/196], Loss: 0.4056\n",
      "Epoch [96/360], Batch [115/196], Loss: 0.2311\n",
      "Epoch [96/360], Batch [120/196], Loss: 0.2193\n",
      "Epoch [96/360], Batch [125/196], Loss: 0.3152\n",
      "Epoch [96/360], Batch [130/196], Loss: 0.5279\n",
      "Epoch [96/360], Batch [135/196], Loss: 0.3438\n",
      "Epoch [96/360], Batch [140/196], Loss: 0.2577\n",
      "Epoch [96/360], Batch [145/196], Loss: 0.1996\n",
      "Epoch [96/360], Batch [150/196], Loss: 0.2878\n",
      "Epoch [96/360], Batch [155/196], Loss: 0.2931\n",
      "Epoch [96/360], Batch [160/196], Loss: 0.4106\n",
      "Epoch [96/360], Batch [165/196], Loss: 0.3343\n",
      "Epoch [96/360], Batch [170/196], Loss: 0.1588\n",
      "Epoch [96/360], Batch [175/196], Loss: 0.4372\n",
      "Epoch [96/360], Batch [180/196], Loss: 0.2771\n",
      "Epoch [96/360], Batch [185/196], Loss: 0.2637\n",
      "Epoch [96/360], Batch [190/196], Loss: 0.2961\n",
      "Epoch [96/360], Batch [195/196], Loss: 0.2828\n",
      "Epoch [97/360], Batch [5/196], Loss: 0.1496\n",
      "Epoch [97/360], Batch [10/196], Loss: 0.1547\n",
      "Epoch [97/360], Batch [15/196], Loss: 0.3084\n",
      "Epoch [97/360], Batch [20/196], Loss: 0.2616\n",
      "Epoch [97/360], Batch [25/196], Loss: 0.3032\n",
      "Epoch [97/360], Batch [30/196], Loss: 0.4866\n",
      "Epoch [97/360], Batch [35/196], Loss: 0.2018\n",
      "Epoch [97/360], Batch [40/196], Loss: 0.3142\n",
      "Epoch [97/360], Batch [45/196], Loss: 0.1475\n",
      "Epoch [97/360], Batch [50/196], Loss: 0.1967\n",
      "Epoch [97/360], Batch [55/196], Loss: 0.2541\n",
      "Epoch [97/360], Batch [60/196], Loss: 0.1331\n",
      "Epoch [97/360], Batch [65/196], Loss: 0.3696\n",
      "Epoch [97/360], Batch [70/196], Loss: 0.3628\n",
      "Epoch [97/360], Batch [75/196], Loss: 0.3197\n",
      "Epoch [97/360], Batch [80/196], Loss: 0.2646\n",
      "Epoch [97/360], Batch [85/196], Loss: 0.4209\n",
      "Epoch [97/360], Batch [90/196], Loss: 0.2740\n",
      "Epoch [97/360], Batch [95/196], Loss: 0.1694\n",
      "Epoch [97/360], Batch [100/196], Loss: 0.3161\n",
      "Epoch [97/360], Batch [105/196], Loss: 0.7349\n",
      "Epoch [97/360], Batch [110/196], Loss: 0.3158\n",
      "Epoch [97/360], Batch [115/196], Loss: 0.2899\n",
      "Epoch [97/360], Batch [120/196], Loss: 0.4810\n",
      "Epoch [97/360], Batch [125/196], Loss: 0.4776\n",
      "Epoch [97/360], Batch [130/196], Loss: 0.2701\n",
      "Epoch [97/360], Batch [135/196], Loss: 0.3785\n",
      "Epoch [97/360], Batch [140/196], Loss: 0.3129\n",
      "Epoch [97/360], Batch [145/196], Loss: 0.1569\n",
      "Epoch [97/360], Batch [150/196], Loss: 0.3155\n",
      "Epoch [97/360], Batch [155/196], Loss: 0.2946\n",
      "Epoch [97/360], Batch [160/196], Loss: 0.3895\n",
      "Epoch [97/360], Batch [165/196], Loss: 0.3555\n",
      "Epoch [97/360], Batch [170/196], Loss: 0.2489\n",
      "Epoch [97/360], Batch [175/196], Loss: 0.2593\n",
      "Epoch [97/360], Batch [180/196], Loss: 0.3086\n",
      "Epoch [97/360], Batch [185/196], Loss: 0.1723\n",
      "Epoch [97/360], Batch [190/196], Loss: 0.2473\n",
      "Epoch [97/360], Batch [195/196], Loss: 0.2627\n",
      "Epoch [98/360], Batch [5/196], Loss: 0.2029\n",
      "Epoch [98/360], Batch [10/196], Loss: 0.1601\n",
      "Epoch [98/360], Batch [15/196], Loss: 0.2778\n",
      "Epoch [98/360], Batch [20/196], Loss: 0.2414\n",
      "Epoch [98/360], Batch [25/196], Loss: 0.1394\n",
      "Epoch [98/360], Batch [30/196], Loss: 0.2127\n",
      "Epoch [98/360], Batch [35/196], Loss: 0.2271\n",
      "Epoch [98/360], Batch [40/196], Loss: 0.2452\n",
      "Epoch [98/360], Batch [45/196], Loss: 0.3688\n",
      "Epoch [98/360], Batch [50/196], Loss: 0.1739\n",
      "Epoch [98/360], Batch [55/196], Loss: 0.3157\n",
      "Epoch [98/360], Batch [60/196], Loss: 0.2909\n",
      "Epoch [98/360], Batch [65/196], Loss: 0.2922\n",
      "Epoch [98/360], Batch [70/196], Loss: 0.2789\n",
      "Epoch [98/360], Batch [75/196], Loss: 0.2828\n",
      "Epoch [98/360], Batch [80/196], Loss: 0.2547\n",
      "Epoch [98/360], Batch [85/196], Loss: 0.3048\n",
      "Epoch [98/360], Batch [90/196], Loss: 0.3691\n",
      "Epoch [98/360], Batch [95/196], Loss: 0.2945\n",
      "Epoch [98/360], Batch [100/196], Loss: 0.3031\n",
      "Epoch [98/360], Batch [105/196], Loss: 0.2673\n",
      "Epoch [98/360], Batch [110/196], Loss: 0.1984\n",
      "Epoch [98/360], Batch [115/196], Loss: 0.2439\n",
      "Epoch [98/360], Batch [120/196], Loss: 0.2398\n",
      "Epoch [98/360], Batch [125/196], Loss: 0.3301\n",
      "Epoch [98/360], Batch [130/196], Loss: 0.2232\n",
      "Epoch [98/360], Batch [135/196], Loss: 0.2118\n",
      "Epoch [98/360], Batch [140/196], Loss: 0.4528\n",
      "Epoch [98/360], Batch [145/196], Loss: 0.3902\n",
      "Epoch [98/360], Batch [150/196], Loss: 0.1955\n",
      "Epoch [98/360], Batch [155/196], Loss: 0.4481\n",
      "Epoch [98/360], Batch [160/196], Loss: 0.3439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/360], Batch [165/196], Loss: 0.3728\n",
      "Epoch [98/360], Batch [170/196], Loss: 0.3619\n",
      "Epoch [98/360], Batch [175/196], Loss: 0.2243\n",
      "Epoch [98/360], Batch [180/196], Loss: 0.6387\n",
      "Epoch [98/360], Batch [185/196], Loss: 0.2378\n",
      "Epoch [98/360], Batch [190/196], Loss: 0.3050\n",
      "Epoch [98/360], Batch [195/196], Loss: 0.4985\n",
      "Epoch [99/360], Batch [5/196], Loss: 0.1887\n",
      "Epoch [99/360], Batch [10/196], Loss: 0.1965\n",
      "Epoch [99/360], Batch [15/196], Loss: 0.1763\n",
      "Epoch [99/360], Batch [20/196], Loss: 0.3488\n",
      "Epoch [99/360], Batch [25/196], Loss: 0.3573\n",
      "Epoch [99/360], Batch [30/196], Loss: 0.2020\n",
      "Epoch [99/360], Batch [35/196], Loss: 0.2071\n",
      "Epoch [99/360], Batch [40/196], Loss: 0.2839\n",
      "Epoch [99/360], Batch [45/196], Loss: 0.2535\n",
      "Epoch [99/360], Batch [50/196], Loss: 0.1847\n",
      "Epoch [99/360], Batch [55/196], Loss: 0.2260\n",
      "Epoch [99/360], Batch [60/196], Loss: 0.2067\n",
      "Epoch [99/360], Batch [65/196], Loss: 0.4627\n",
      "Epoch [99/360], Batch [70/196], Loss: 0.2784\n",
      "Epoch [99/360], Batch [75/196], Loss: 0.1680\n",
      "Epoch [99/360], Batch [80/196], Loss: 0.3071\n",
      "Epoch [99/360], Batch [85/196], Loss: 0.3242\n",
      "Epoch [99/360], Batch [90/196], Loss: 0.2385\n",
      "Epoch [99/360], Batch [95/196], Loss: 0.2222\n",
      "Epoch [99/360], Batch [100/196], Loss: 0.2445\n",
      "Epoch [99/360], Batch [105/196], Loss: 0.3169\n",
      "Epoch [99/360], Batch [110/196], Loss: 0.3031\n",
      "Epoch [99/360], Batch [115/196], Loss: 0.1902\n",
      "Epoch [99/360], Batch [120/196], Loss: 0.2364\n",
      "Epoch [99/360], Batch [125/196], Loss: 0.1818\n",
      "Epoch [99/360], Batch [130/196], Loss: 0.2299\n",
      "Epoch [99/360], Batch [135/196], Loss: 0.2226\n",
      "Epoch [99/360], Batch [140/196], Loss: 0.2663\n",
      "Epoch [99/360], Batch [145/196], Loss: 0.2774\n",
      "Epoch [99/360], Batch [150/196], Loss: 0.2937\n",
      "Epoch [99/360], Batch [155/196], Loss: 0.1900\n",
      "Epoch [99/360], Batch [160/196], Loss: 0.1818\n",
      "Epoch [99/360], Batch [165/196], Loss: 0.2486\n",
      "Epoch [99/360], Batch [170/196], Loss: 0.2903\n",
      "Epoch [99/360], Batch [175/196], Loss: 0.3358\n",
      "Epoch [99/360], Batch [180/196], Loss: 0.3006\n",
      "Epoch [99/360], Batch [185/196], Loss: 0.2299\n",
      "Epoch [99/360], Batch [190/196], Loss: 0.2014\n",
      "Epoch [99/360], Batch [195/196], Loss: 0.3846\n",
      "Epoch [100/360], Batch [5/196], Loss: 0.1130\n",
      "Epoch [100/360], Batch [10/196], Loss: 0.1980\n",
      "Epoch [100/360], Batch [15/196], Loss: 0.1884\n",
      "Epoch [100/360], Batch [20/196], Loss: 0.2259\n",
      "Epoch [100/360], Batch [25/196], Loss: 0.1589\n",
      "Epoch [100/360], Batch [30/196], Loss: 0.1752\n",
      "Epoch [100/360], Batch [35/196], Loss: 0.1834\n",
      "Epoch [100/360], Batch [40/196], Loss: 0.1511\n",
      "Epoch [100/360], Batch [45/196], Loss: 0.2507\n",
      "Epoch [100/360], Batch [50/196], Loss: 0.1826\n",
      "Epoch [100/360], Batch [55/196], Loss: 0.1632\n",
      "Epoch [100/360], Batch [60/196], Loss: 0.2305\n",
      "Epoch [100/360], Batch [65/196], Loss: 0.2092\n",
      "Epoch [100/360], Batch [70/196], Loss: 0.2152\n",
      "Epoch [100/360], Batch [75/196], Loss: 0.2311\n",
      "Epoch [100/360], Batch [80/196], Loss: 0.2084\n",
      "Epoch [100/360], Batch [85/196], Loss: 0.1984\n",
      "Epoch [100/360], Batch [90/196], Loss: 0.1383\n",
      "Epoch [100/360], Batch [95/196], Loss: 0.2540\n",
      "Epoch [100/360], Batch [100/196], Loss: 0.3188\n",
      "Epoch [100/360], Batch [105/196], Loss: 0.3107\n",
      "Epoch [100/360], Batch [110/196], Loss: 0.2009\n",
      "Epoch [100/360], Batch [115/196], Loss: 0.3144\n",
      "Epoch [100/360], Batch [120/196], Loss: 0.1991\n",
      "Epoch [100/360], Batch [125/196], Loss: 0.3850\n",
      "Epoch [100/360], Batch [130/196], Loss: 0.2828\n",
      "Epoch [100/360], Batch [135/196], Loss: 0.2327\n",
      "Epoch [100/360], Batch [140/196], Loss: 0.2222\n",
      "Epoch [100/360], Batch [145/196], Loss: 0.4033\n",
      "Epoch [100/360], Batch [150/196], Loss: 0.1827\n",
      "Epoch [100/360], Batch [155/196], Loss: 0.2517\n",
      "Epoch [100/360], Batch [160/196], Loss: 0.2167\n",
      "Epoch [100/360], Batch [165/196], Loss: 0.1817\n",
      "Epoch [100/360], Batch [170/196], Loss: 0.2264\n",
      "Epoch [100/360], Batch [175/196], Loss: 0.2966\n",
      "Epoch [100/360], Batch [180/196], Loss: 0.3357\n",
      "Epoch [100/360], Batch [185/196], Loss: 0.2667\n",
      "Epoch [100/360], Batch [190/196], Loss: 0.3018\n",
      "Epoch [100/360], Batch [195/196], Loss: 0.2628\n",
      "Epoch [101/360], Batch [5/196], Loss: 0.2359\n",
      "Epoch [101/360], Batch [10/196], Loss: 0.2494\n",
      "Epoch [101/360], Batch [15/196], Loss: 0.2984\n",
      "Epoch [101/360], Batch [20/196], Loss: 0.2161\n",
      "Epoch [101/360], Batch [25/196], Loss: 0.1363\n",
      "Epoch [101/360], Batch [30/196], Loss: 0.1611\n",
      "Epoch [101/360], Batch [35/196], Loss: 0.2973\n",
      "Epoch [101/360], Batch [40/196], Loss: 0.2813\n",
      "Epoch [101/360], Batch [45/196], Loss: 0.2670\n",
      "Epoch [101/360], Batch [50/196], Loss: 0.1476\n",
      "Epoch [101/360], Batch [55/196], Loss: 0.2559\n",
      "Epoch [101/360], Batch [60/196], Loss: 0.2327\n",
      "Epoch [101/360], Batch [65/196], Loss: 0.2549\n",
      "Epoch [101/360], Batch [70/196], Loss: 0.2340\n",
      "Epoch [101/360], Batch [75/196], Loss: 0.3063\n",
      "Epoch [101/360], Batch [80/196], Loss: 0.2290\n",
      "Epoch [101/360], Batch [85/196], Loss: 0.1441\n",
      "Epoch [101/360], Batch [90/196], Loss: 0.2213\n",
      "Epoch [101/360], Batch [95/196], Loss: 0.2252\n",
      "Epoch [101/360], Batch [100/196], Loss: 0.1400\n",
      "Epoch [101/360], Batch [105/196], Loss: 0.1787\n",
      "Epoch [101/360], Batch [110/196], Loss: 0.2097\n",
      "Epoch [101/360], Batch [115/196], Loss: 0.2287\n",
      "Epoch [101/360], Batch [120/196], Loss: 0.1804\n",
      "Epoch [101/360], Batch [125/196], Loss: 0.2482\n",
      "Epoch [101/360], Batch [130/196], Loss: 0.2966\n",
      "Epoch [101/360], Batch [135/196], Loss: 0.1975\n",
      "Epoch [101/360], Batch [140/196], Loss: 0.1648\n",
      "Epoch [101/360], Batch [145/196], Loss: 0.2456\n",
      "Epoch [101/360], Batch [150/196], Loss: 0.1920\n",
      "Epoch [101/360], Batch [155/196], Loss: 0.1368\n",
      "Epoch [101/360], Batch [160/196], Loss: 0.2303\n",
      "Epoch [101/360], Batch [165/196], Loss: 0.5237\n",
      "Epoch [101/360], Batch [170/196], Loss: 0.1970\n",
      "Epoch [101/360], Batch [175/196], Loss: 0.2935\n",
      "Epoch [101/360], Batch [180/196], Loss: 0.3183\n",
      "Epoch [101/360], Batch [185/196], Loss: 0.1966\n",
      "Epoch [101/360], Batch [190/196], Loss: 0.2221\n",
      "Epoch [101/360], Batch [195/196], Loss: 0.2607\n",
      "Epoch [102/360], Batch [5/196], Loss: 0.1410\n",
      "Epoch [102/360], Batch [10/196], Loss: 0.1996\n",
      "Epoch [102/360], Batch [15/196], Loss: 0.1755\n",
      "Epoch [102/360], Batch [20/196], Loss: 0.1632\n",
      "Epoch [102/360], Batch [25/196], Loss: 0.1324\n",
      "Epoch [102/360], Batch [30/196], Loss: 0.2012\n",
      "Epoch [102/360], Batch [35/196], Loss: 0.1507\n",
      "Epoch [102/360], Batch [40/196], Loss: 0.1610\n",
      "Epoch [102/360], Batch [45/196], Loss: 0.2333\n",
      "Epoch [102/360], Batch [50/196], Loss: 0.1297\n",
      "Epoch [102/360], Batch [55/196], Loss: 0.1946\n",
      "Epoch [102/360], Batch [60/196], Loss: 0.2140\n",
      "Epoch [102/360], Batch [65/196], Loss: 0.2206\n",
      "Epoch [102/360], Batch [70/196], Loss: 0.2156\n",
      "Epoch [102/360], Batch [75/196], Loss: 0.1698\n",
      "Epoch [102/360], Batch [80/196], Loss: 0.1653\n",
      "Epoch [102/360], Batch [85/196], Loss: 0.1819\n",
      "Epoch [102/360], Batch [90/196], Loss: 0.1889\n",
      "Epoch [102/360], Batch [95/196], Loss: 0.1584\n",
      "Epoch [102/360], Batch [100/196], Loss: 0.1258\n",
      "Epoch [102/360], Batch [105/196], Loss: 0.2167\n",
      "Epoch [102/360], Batch [110/196], Loss: 0.1571\n",
      "Epoch [102/360], Batch [115/196], Loss: 0.2700\n",
      "Epoch [102/360], Batch [120/196], Loss: 0.2047\n",
      "Epoch [102/360], Batch [125/196], Loss: 0.2799\n",
      "Epoch [102/360], Batch [130/196], Loss: 0.1455\n",
      "Epoch [102/360], Batch [135/196], Loss: 0.1723\n",
      "Epoch [102/360], Batch [140/196], Loss: 0.1650\n",
      "Epoch [102/360], Batch [145/196], Loss: 0.2417\n",
      "Epoch [102/360], Batch [150/196], Loss: 0.1944\n",
      "Epoch [102/360], Batch [155/196], Loss: 0.2524\n",
      "Epoch [102/360], Batch [160/196], Loss: 0.2995\n",
      "Epoch [102/360], Batch [165/196], Loss: 0.1486\n",
      "Epoch [102/360], Batch [170/196], Loss: 0.2682\n",
      "Epoch [102/360], Batch [175/196], Loss: 0.1995\n",
      "Epoch [102/360], Batch [180/196], Loss: 0.1181\n",
      "Epoch [102/360], Batch [185/196], Loss: 0.2116\n",
      "Epoch [102/360], Batch [190/196], Loss: 0.2929\n",
      "Epoch [102/360], Batch [195/196], Loss: 0.2001\n",
      "Epoch [103/360], Batch [5/196], Loss: 0.1734\n",
      "Epoch [103/360], Batch [10/196], Loss: 0.1721\n",
      "Epoch [103/360], Batch [15/196], Loss: 0.1926\n",
      "Epoch [103/360], Batch [20/196], Loss: 0.2648\n",
      "Epoch [103/360], Batch [25/196], Loss: 0.1935\n",
      "Epoch [103/360], Batch [30/196], Loss: 0.1857\n",
      "Epoch [103/360], Batch [35/196], Loss: 0.1644\n",
      "Epoch [103/360], Batch [40/196], Loss: 0.2319\n",
      "Epoch [103/360], Batch [45/196], Loss: 0.1768\n",
      "Epoch [103/360], Batch [50/196], Loss: 0.1847\n",
      "Epoch [103/360], Batch [55/196], Loss: 0.2403\n",
      "Epoch [103/360], Batch [60/196], Loss: 0.1522\n",
      "Epoch [103/360], Batch [65/196], Loss: 0.1469\n",
      "Epoch [103/360], Batch [70/196], Loss: 0.1556\n",
      "Epoch [103/360], Batch [75/196], Loss: 0.2637\n",
      "Epoch [103/360], Batch [80/196], Loss: 0.1556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [103/360], Batch [85/196], Loss: 0.2141\n",
      "Epoch [103/360], Batch [90/196], Loss: 0.2380\n",
      "Epoch [103/360], Batch [95/196], Loss: 0.1995\n",
      "Epoch [103/360], Batch [100/196], Loss: 0.2802\n",
      "Epoch [103/360], Batch [105/196], Loss: 0.3174\n",
      "Epoch [103/360], Batch [110/196], Loss: 0.1849\n",
      "Epoch [103/360], Batch [115/196], Loss: 0.1731\n",
      "Epoch [103/360], Batch [120/196], Loss: 0.2349\n",
      "Epoch [103/360], Batch [125/196], Loss: 0.3628\n",
      "Epoch [103/360], Batch [130/196], Loss: 0.1761\n",
      "Epoch [103/360], Batch [135/196], Loss: 0.2258\n",
      "Epoch [103/360], Batch [140/196], Loss: 0.4521\n",
      "Epoch [103/360], Batch [145/196], Loss: 0.1640\n",
      "Epoch [103/360], Batch [150/196], Loss: 0.1915\n",
      "Epoch [103/360], Batch [155/196], Loss: 0.2656\n",
      "Epoch [103/360], Batch [160/196], Loss: 0.1282\n",
      "Epoch [103/360], Batch [165/196], Loss: 0.1837\n",
      "Epoch [103/360], Batch [170/196], Loss: 0.1919\n",
      "Epoch [103/360], Batch [175/196], Loss: 0.1944\n",
      "Epoch [103/360], Batch [180/196], Loss: 0.3060\n",
      "Epoch [103/360], Batch [185/196], Loss: 0.2739\n",
      "Epoch [103/360], Batch [190/196], Loss: 0.2544\n",
      "Epoch [103/360], Batch [195/196], Loss: 0.1706\n",
      "Epoch [104/360], Batch [5/196], Loss: 0.1326\n",
      "Epoch [104/360], Batch [10/196], Loss: 0.2601\n",
      "Epoch [104/360], Batch [15/196], Loss: 0.2008\n",
      "Epoch [104/360], Batch [20/196], Loss: 0.1120\n",
      "Epoch [104/360], Batch [25/196], Loss: 0.2953\n",
      "Epoch [104/360], Batch [30/196], Loss: 0.2344\n",
      "Epoch [104/360], Batch [35/196], Loss: 0.3234\n",
      "Epoch [104/360], Batch [40/196], Loss: 0.2771\n",
      "Epoch [104/360], Batch [45/196], Loss: 0.2626\n",
      "Epoch [104/360], Batch [50/196], Loss: 0.3043\n",
      "Epoch [104/360], Batch [55/196], Loss: 0.2562\n",
      "Epoch [104/360], Batch [60/196], Loss: 0.2154\n",
      "Epoch [104/360], Batch [65/196], Loss: 0.3202\n",
      "Epoch [104/360], Batch [70/196], Loss: 0.2968\n",
      "Epoch [104/360], Batch [75/196], Loss: 0.2011\n",
      "Epoch [104/360], Batch [80/196], Loss: 0.2402\n",
      "Epoch [104/360], Batch [85/196], Loss: 0.3747\n",
      "Epoch [104/360], Batch [90/196], Loss: 0.2050\n",
      "Epoch [104/360], Batch [95/196], Loss: 0.2007\n",
      "Epoch [104/360], Batch [100/196], Loss: 0.2836\n",
      "Epoch [104/360], Batch [105/196], Loss: 0.1884\n",
      "Epoch [104/360], Batch [110/196], Loss: 0.3575\n",
      "Epoch [104/360], Batch [115/196], Loss: 0.1613\n",
      "Epoch [104/360], Batch [120/196], Loss: 0.3447\n",
      "Epoch [104/360], Batch [125/196], Loss: 0.3379\n",
      "Epoch [104/360], Batch [130/196], Loss: 0.5759\n",
      "Epoch [104/360], Batch [135/196], Loss: 0.7092\n",
      "Epoch [104/360], Batch [140/196], Loss: 0.5130\n",
      "Epoch [104/360], Batch [145/196], Loss: 0.7076\n",
      "Epoch [104/360], Batch [150/196], Loss: 0.6011\n",
      "Epoch [104/360], Batch [155/196], Loss: 0.7142\n",
      "Epoch [104/360], Batch [160/196], Loss: 0.9833\n",
      "Epoch [104/360], Batch [165/196], Loss: 0.4359\n",
      "Epoch [104/360], Batch [170/196], Loss: 0.5483\n",
      "Epoch [104/360], Batch [175/196], Loss: 0.8404\n",
      "Epoch [104/360], Batch [180/196], Loss: 1.1294\n",
      "Epoch [104/360], Batch [185/196], Loss: 0.4262\n",
      "Epoch [104/360], Batch [190/196], Loss: 0.4748\n",
      "Epoch [104/360], Batch [195/196], Loss: 0.4744\n",
      "Epoch [105/360], Batch [5/196], Loss: 0.5970\n",
      "Epoch [105/360], Batch [10/196], Loss: 0.5678\n",
      "Epoch [105/360], Batch [15/196], Loss: 0.4062\n",
      "Epoch [105/360], Batch [20/196], Loss: 0.3679\n",
      "Epoch [105/360], Batch [25/196], Loss: 0.4255\n",
      "Epoch [105/360], Batch [30/196], Loss: 0.6951\n",
      "Epoch [105/360], Batch [35/196], Loss: 0.6615\n",
      "Epoch [105/360], Batch [40/196], Loss: 0.3268\n",
      "Epoch [105/360], Batch [45/196], Loss: 0.2982\n",
      "Epoch [105/360], Batch [50/196], Loss: 0.5504\n",
      "Epoch [105/360], Batch [55/196], Loss: 0.3891\n",
      "Epoch [105/360], Batch [60/196], Loss: 0.3413\n",
      "Epoch [105/360], Batch [65/196], Loss: 0.3402\n",
      "Epoch [105/360], Batch [70/196], Loss: 0.5245\n",
      "Epoch [105/360], Batch [75/196], Loss: 0.4088\n",
      "Epoch [105/360], Batch [80/196], Loss: 0.3436\n",
      "Epoch [105/360], Batch [85/196], Loss: 0.3386\n",
      "Epoch [105/360], Batch [90/196], Loss: 0.7355\n",
      "Epoch [105/360], Batch [95/196], Loss: 0.4209\n",
      "Epoch [105/360], Batch [100/196], Loss: 0.4387\n",
      "Epoch [105/360], Batch [105/196], Loss: 0.4164\n",
      "Epoch [105/360], Batch [110/196], Loss: 0.6312\n",
      "Epoch [105/360], Batch [115/196], Loss: 0.3545\n",
      "Epoch [105/360], Batch [120/196], Loss: 0.3647\n",
      "Epoch [105/360], Batch [125/196], Loss: 0.5090\n",
      "Epoch [105/360], Batch [130/196], Loss: 1.0308\n",
      "Epoch [105/360], Batch [135/196], Loss: 0.4391\n",
      "Epoch [105/360], Batch [140/196], Loss: 0.4076\n",
      "Epoch [105/360], Batch [145/196], Loss: 0.8477\n",
      "Epoch [105/360], Batch [150/196], Loss: 0.3850\n",
      "Epoch [105/360], Batch [155/196], Loss: 0.3886\n",
      "Epoch [105/360], Batch [160/196], Loss: 1.2921\n",
      "Epoch [105/360], Batch [165/196], Loss: 0.3452\n",
      "Epoch [105/360], Batch [170/196], Loss: 0.4542\n",
      "Epoch [105/360], Batch [175/196], Loss: 0.2392\n",
      "Epoch [105/360], Batch [180/196], Loss: 0.4562\n",
      "Epoch [105/360], Batch [185/196], Loss: 0.4724\n",
      "Epoch [105/360], Batch [190/196], Loss: 0.4841\n",
      "Epoch [105/360], Batch [195/196], Loss: 0.5577\n",
      "Epoch [106/360], Batch [5/196], Loss: 0.3667\n",
      "Epoch [106/360], Batch [10/196], Loss: 0.7580\n",
      "Epoch [106/360], Batch [15/196], Loss: 0.3403\n",
      "Epoch [106/360], Batch [20/196], Loss: 0.3519\n",
      "Epoch [106/360], Batch [25/196], Loss: 0.2973\n",
      "Epoch [106/360], Batch [30/196], Loss: 0.3775\n",
      "Epoch [106/360], Batch [35/196], Loss: 0.2960\n",
      "Epoch [106/360], Batch [40/196], Loss: 0.3190\n",
      "Epoch [106/360], Batch [45/196], Loss: 0.3435\n",
      "Epoch [106/360], Batch [50/196], Loss: 0.5267\n",
      "Epoch [106/360], Batch [55/196], Loss: 0.2842\n",
      "Epoch [106/360], Batch [60/196], Loss: 0.3555\n",
      "Epoch [106/360], Batch [65/196], Loss: 0.2703\n",
      "Epoch [106/360], Batch [70/196], Loss: 0.2607\n",
      "Epoch [106/360], Batch [75/196], Loss: 0.2131\n",
      "Epoch [106/360], Batch [80/196], Loss: 0.3568\n",
      "Epoch [106/360], Batch [85/196], Loss: 0.2435\n",
      "Epoch [106/360], Batch [90/196], Loss: 0.4220\n",
      "Epoch [106/360], Batch [95/196], Loss: 0.3848\n",
      "Epoch [106/360], Batch [100/196], Loss: 0.3578\n",
      "Epoch [106/360], Batch [105/196], Loss: 0.2770\n",
      "Epoch [106/360], Batch [110/196], Loss: 0.1924\n",
      "Epoch [106/360], Batch [115/196], Loss: 0.2838\n",
      "Epoch [106/360], Batch [120/196], Loss: 0.4822\n",
      "Epoch [106/360], Batch [125/196], Loss: 0.2272\n",
      "Epoch [106/360], Batch [130/196], Loss: 0.1875\n",
      "Epoch [106/360], Batch [135/196], Loss: 0.3962\n",
      "Epoch [106/360], Batch [140/196], Loss: 0.4728\n",
      "Epoch [106/360], Batch [145/196], Loss: 0.4243\n",
      "Epoch [106/360], Batch [150/196], Loss: 0.3100\n",
      "Epoch [106/360], Batch [155/196], Loss: 0.3098\n",
      "Epoch [106/360], Batch [160/196], Loss: 0.3067\n",
      "Epoch [106/360], Batch [165/196], Loss: 0.1655\n",
      "Epoch [106/360], Batch [170/196], Loss: 0.2820\n",
      "Epoch [106/360], Batch [175/196], Loss: 0.4561\n",
      "Epoch [106/360], Batch [180/196], Loss: 0.1675\n",
      "Epoch [106/360], Batch [185/196], Loss: 0.6800\n",
      "Epoch [106/360], Batch [190/196], Loss: 0.2641\n",
      "Epoch [106/360], Batch [195/196], Loss: 0.2506\n",
      "Epoch [107/360], Batch [5/196], Loss: 0.2068\n",
      "Epoch [107/360], Batch [10/196], Loss: 0.1791\n",
      "Epoch [107/360], Batch [15/196], Loss: 0.2622\n",
      "Epoch [107/360], Batch [20/196], Loss: 0.3493\n",
      "Epoch [107/360], Batch [25/196], Loss: 0.2514\n",
      "Epoch [107/360], Batch [30/196], Loss: 0.3200\n",
      "Epoch [107/360], Batch [35/196], Loss: 0.2875\n",
      "Epoch [107/360], Batch [40/196], Loss: 0.3257\n",
      "Epoch [107/360], Batch [45/196], Loss: 0.2825\n",
      "Epoch [107/360], Batch [50/196], Loss: 0.2204\n",
      "Epoch [107/360], Batch [55/196], Loss: 0.3472\n",
      "Epoch [107/360], Batch [60/196], Loss: 0.1878\n",
      "Epoch [107/360], Batch [65/196], Loss: 0.1506\n",
      "Epoch [107/360], Batch [70/196], Loss: 0.2622\n",
      "Epoch [107/360], Batch [75/196], Loss: 0.3008\n",
      "Epoch [107/360], Batch [80/196], Loss: 0.2458\n",
      "Epoch [107/360], Batch [85/196], Loss: 0.2112\n",
      "Epoch [107/360], Batch [90/196], Loss: 0.1946\n",
      "Epoch [107/360], Batch [95/196], Loss: 0.2137\n",
      "Epoch [107/360], Batch [100/196], Loss: 0.2042\n",
      "Epoch [107/360], Batch [105/196], Loss: 0.2175\n",
      "Epoch [107/360], Batch [110/196], Loss: 0.2409\n",
      "Epoch [107/360], Batch [115/196], Loss: 0.3343\n",
      "Epoch [107/360], Batch [120/196], Loss: 0.2811\n",
      "Epoch [107/360], Batch [125/196], Loss: 0.5369\n",
      "Epoch [107/360], Batch [130/196], Loss: 0.2420\n",
      "Epoch [107/360], Batch [135/196], Loss: 0.2082\n",
      "Epoch [107/360], Batch [140/196], Loss: 0.2178\n",
      "Epoch [107/360], Batch [145/196], Loss: 0.2319\n",
      "Epoch [107/360], Batch [150/196], Loss: 0.3517\n",
      "Epoch [107/360], Batch [155/196], Loss: 0.1984\n",
      "Epoch [107/360], Batch [160/196], Loss: 0.2945\n",
      "Epoch [107/360], Batch [165/196], Loss: 0.3210\n",
      "Epoch [107/360], Batch [170/196], Loss: 0.2458\n",
      "Epoch [107/360], Batch [175/196], Loss: 0.4907\n",
      "Epoch [107/360], Batch [180/196], Loss: 0.2559\n",
      "Epoch [107/360], Batch [185/196], Loss: 0.4117\n",
      "Epoch [107/360], Batch [190/196], Loss: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/360], Batch [195/196], Loss: 0.3790\n",
      "Epoch [108/360], Batch [5/196], Loss: 0.3267\n",
      "Epoch [108/360], Batch [10/196], Loss: 0.1681\n",
      "Epoch [108/360], Batch [15/196], Loss: 0.2314\n",
      "Epoch [108/360], Batch [20/196], Loss: 0.2920\n",
      "Epoch [108/360], Batch [25/196], Loss: 0.4997\n",
      "Epoch [108/360], Batch [30/196], Loss: 0.5046\n",
      "Epoch [108/360], Batch [35/196], Loss: 0.3158\n",
      "Epoch [108/360], Batch [40/196], Loss: 0.6109\n",
      "Epoch [108/360], Batch [45/196], Loss: 0.2997\n",
      "Epoch [108/360], Batch [50/196], Loss: 0.4340\n",
      "Epoch [108/360], Batch [55/196], Loss: 0.5726\n",
      "Epoch [108/360], Batch [60/196], Loss: 0.2825\n",
      "Epoch [108/360], Batch [65/196], Loss: 0.4184\n",
      "Epoch [108/360], Batch [70/196], Loss: 0.3854\n",
      "Epoch [108/360], Batch [75/196], Loss: 0.5187\n",
      "Epoch [108/360], Batch [80/196], Loss: 0.2663\n",
      "Epoch [108/360], Batch [85/196], Loss: 0.6085\n",
      "Epoch [108/360], Batch [90/196], Loss: 0.3704\n",
      "Epoch [108/360], Batch [95/196], Loss: 0.4732\n",
      "Epoch [108/360], Batch [100/196], Loss: 0.5573\n",
      "Epoch [108/360], Batch [105/196], Loss: 0.2977\n",
      "Epoch [108/360], Batch [110/196], Loss: 0.2548\n",
      "Epoch [108/360], Batch [115/196], Loss: 0.2237\n",
      "Epoch [108/360], Batch [120/196], Loss: 0.2883\n",
      "Epoch [108/360], Batch [125/196], Loss: 0.3392\n",
      "Epoch [108/360], Batch [130/196], Loss: 0.3546\n",
      "Epoch [108/360], Batch [135/196], Loss: 0.7563\n",
      "Epoch [108/360], Batch [140/196], Loss: 0.2877\n",
      "Epoch [108/360], Batch [145/196], Loss: 0.3088\n",
      "Epoch [108/360], Batch [150/196], Loss: 0.8932\n",
      "Epoch [108/360], Batch [155/196], Loss: 0.3355\n",
      "Epoch [108/360], Batch [160/196], Loss: 0.4182\n",
      "Epoch [108/360], Batch [165/196], Loss: 0.2455\n",
      "Epoch [108/360], Batch [170/196], Loss: 0.3896\n",
      "Epoch [108/360], Batch [175/196], Loss: 0.6198\n",
      "Epoch [108/360], Batch [180/196], Loss: 0.3126\n",
      "Epoch [108/360], Batch [185/196], Loss: 0.5972\n",
      "Epoch [108/360], Batch [190/196], Loss: 0.2761\n",
      "Epoch [108/360], Batch [195/196], Loss: 0.3920\n",
      "Epoch [109/360], Batch [5/196], Loss: 0.1775\n",
      "Epoch [109/360], Batch [10/196], Loss: 0.2966\n",
      "Epoch [109/360], Batch [15/196], Loss: 0.3192\n",
      "Epoch [109/360], Batch [20/196], Loss: 0.2140\n",
      "Epoch [109/360], Batch [25/196], Loss: 0.3626\n",
      "Epoch [109/360], Batch [30/196], Loss: 0.3189\n",
      "Epoch [109/360], Batch [35/196], Loss: 0.2438\n",
      "Epoch [109/360], Batch [40/196], Loss: 0.3327\n",
      "Epoch [109/360], Batch [45/196], Loss: 0.3805\n",
      "Epoch [109/360], Batch [50/196], Loss: 0.2906\n",
      "Epoch [109/360], Batch [55/196], Loss: 0.2628\n",
      "Epoch [109/360], Batch [60/196], Loss: 0.1644\n",
      "Epoch [109/360], Batch [65/196], Loss: 0.2259\n",
      "Epoch [109/360], Batch [70/196], Loss: 0.2739\n",
      "Epoch [109/360], Batch [75/196], Loss: 0.2868\n",
      "Epoch [109/360], Batch [80/196], Loss: 0.2321\n",
      "Epoch [109/360], Batch [85/196], Loss: 0.2865\n",
      "Epoch [109/360], Batch [90/196], Loss: 0.2578\n",
      "Epoch [109/360], Batch [95/196], Loss: 0.2565\n",
      "Epoch [109/360], Batch [100/196], Loss: 0.4947\n",
      "Epoch [109/360], Batch [105/196], Loss: 0.2121\n",
      "Epoch [109/360], Batch [110/196], Loss: 0.3296\n",
      "Epoch [109/360], Batch [115/196], Loss: 0.3399\n",
      "Epoch [109/360], Batch [120/196], Loss: 0.2310\n",
      "Epoch [109/360], Batch [125/196], Loss: 0.1914\n",
      "Epoch [109/360], Batch [130/196], Loss: 0.2755\n",
      "Epoch [109/360], Batch [135/196], Loss: 0.2831\n",
      "Epoch [109/360], Batch [140/196], Loss: 0.4068\n",
      "Epoch [109/360], Batch [145/196], Loss: 0.3002\n",
      "Epoch [109/360], Batch [150/196], Loss: 0.3359\n",
      "Epoch [109/360], Batch [155/196], Loss: 0.3533\n",
      "Epoch [109/360], Batch [160/196], Loss: 0.3267\n",
      "Epoch [109/360], Batch [165/196], Loss: 0.1993\n",
      "Epoch [109/360], Batch [170/196], Loss: 0.3378\n",
      "Epoch [109/360], Batch [175/196], Loss: 0.4510\n",
      "Epoch [109/360], Batch [180/196], Loss: 0.2971\n",
      "Epoch [109/360], Batch [185/196], Loss: 0.2603\n",
      "Epoch [109/360], Batch [190/196], Loss: 0.1916\n",
      "Epoch [109/360], Batch [195/196], Loss: 0.2904\n",
      "Epoch [110/360], Batch [5/196], Loss: 0.2542\n",
      "Epoch [110/360], Batch [10/196], Loss: 0.1570\n",
      "Epoch [110/360], Batch [15/196], Loss: 0.3894\n",
      "Epoch [110/360], Batch [20/196], Loss: 0.2306\n",
      "Epoch [110/360], Batch [25/196], Loss: 0.2639\n",
      "Epoch [110/360], Batch [30/196], Loss: 0.3047\n",
      "Epoch [110/360], Batch [35/196], Loss: 0.1156\n",
      "Epoch [110/360], Batch [40/196], Loss: 0.1876\n",
      "Epoch [110/360], Batch [45/196], Loss: 0.2445\n",
      "Epoch [110/360], Batch [50/196], Loss: 1.0251\n",
      "Epoch [110/360], Batch [55/196], Loss: 0.3950\n",
      "Epoch [110/360], Batch [60/196], Loss: 0.1571\n",
      "Epoch [110/360], Batch [65/196], Loss: 0.2900\n",
      "Epoch [110/360], Batch [70/196], Loss: 0.2826\n",
      "Epoch [110/360], Batch [75/196], Loss: 0.1300\n",
      "Epoch [110/360], Batch [80/196], Loss: 0.2818\n",
      "Epoch [110/360], Batch [85/196], Loss: 0.5874\n",
      "Epoch [110/360], Batch [90/196], Loss: 0.7259\n",
      "Epoch [110/360], Batch [95/196], Loss: 0.3626\n",
      "Epoch [110/360], Batch [100/196], Loss: 0.4622\n",
      "Epoch [110/360], Batch [105/196], Loss: 0.2937\n",
      "Epoch [110/360], Batch [110/196], Loss: 0.5061\n",
      "Epoch [110/360], Batch [115/196], Loss: 0.5004\n",
      "Epoch [110/360], Batch [120/196], Loss: 0.3244\n",
      "Epoch [110/360], Batch [125/196], Loss: 0.3422\n",
      "Epoch [110/360], Batch [130/196], Loss: 0.3768\n",
      "Epoch [110/360], Batch [135/196], Loss: 0.3416\n",
      "Epoch [110/360], Batch [140/196], Loss: 0.3370\n",
      "Epoch [110/360], Batch [145/196], Loss: 0.1907\n",
      "Epoch [110/360], Batch [150/196], Loss: 0.2619\n",
      "Epoch [110/360], Batch [155/196], Loss: 0.2217\n",
      "Epoch [110/360], Batch [160/196], Loss: 0.3334\n",
      "Epoch [110/360], Batch [165/196], Loss: 0.1775\n",
      "Epoch [110/360], Batch [170/196], Loss: 0.2104\n",
      "Epoch [110/360], Batch [175/196], Loss: 0.2759\n",
      "Epoch [110/360], Batch [180/196], Loss: 0.3178\n",
      "Epoch [110/360], Batch [185/196], Loss: 0.2351\n",
      "Epoch [110/360], Batch [190/196], Loss: 0.3401\n",
      "Epoch [110/360], Batch [195/196], Loss: 0.2444\n",
      "Epoch [111/360], Batch [5/196], Loss: 0.3194\n",
      "Epoch [111/360], Batch [10/196], Loss: 0.1496\n",
      "Epoch [111/360], Batch [15/196], Loss: 0.2258\n",
      "Epoch [111/360], Batch [20/196], Loss: 0.2317\n",
      "Epoch [111/360], Batch [25/196], Loss: 0.2490\n",
      "Epoch [111/360], Batch [30/196], Loss: 0.1710\n",
      "Epoch [111/360], Batch [35/196], Loss: 0.2650\n",
      "Epoch [111/360], Batch [40/196], Loss: 0.2431\n",
      "Epoch [111/360], Batch [45/196], Loss: 0.1777\n",
      "Epoch [111/360], Batch [50/196], Loss: 0.1355\n",
      "Epoch [111/360], Batch [55/196], Loss: 0.4141\n",
      "Epoch [111/360], Batch [60/196], Loss: 0.1763\n",
      "Epoch [111/360], Batch [65/196], Loss: 0.1639\n",
      "Epoch [111/360], Batch [70/196], Loss: 0.1898\n",
      "Epoch [111/360], Batch [75/196], Loss: 0.2723\n",
      "Epoch [111/360], Batch [80/196], Loss: 0.1898\n",
      "Epoch [111/360], Batch [85/196], Loss: 0.2782\n",
      "Epoch [111/360], Batch [90/196], Loss: 0.3100\n",
      "Epoch [111/360], Batch [95/196], Loss: 0.1473\n",
      "Epoch [111/360], Batch [100/196], Loss: 0.2754\n",
      "Epoch [111/360], Batch [105/196], Loss: 0.2560\n",
      "Epoch [111/360], Batch [110/196], Loss: 0.2130\n",
      "Epoch [111/360], Batch [115/196], Loss: 0.3289\n",
      "Epoch [111/360], Batch [120/196], Loss: 0.1646\n",
      "Epoch [111/360], Batch [125/196], Loss: 0.2515\n",
      "Epoch [111/360], Batch [130/196], Loss: 0.2201\n",
      "Epoch [111/360], Batch [135/196], Loss: 0.2472\n",
      "Epoch [111/360], Batch [140/196], Loss: 0.2492\n",
      "Epoch [111/360], Batch [145/196], Loss: 0.1632\n",
      "Epoch [111/360], Batch [150/196], Loss: 0.3872\n",
      "Epoch [111/360], Batch [155/196], Loss: 0.3180\n",
      "Epoch [111/360], Batch [160/196], Loss: 0.1445\n",
      "Epoch [111/360], Batch [165/196], Loss: 0.1610\n",
      "Epoch [111/360], Batch [170/196], Loss: 0.1327\n",
      "Epoch [111/360], Batch [175/196], Loss: 0.1596\n",
      "Epoch [111/360], Batch [180/196], Loss: 0.2187\n",
      "Epoch [111/360], Batch [185/196], Loss: 0.2406\n",
      "Epoch [111/360], Batch [190/196], Loss: 0.4086\n",
      "Epoch [111/360], Batch [195/196], Loss: 0.1906\n",
      "Epoch [112/360], Batch [5/196], Loss: 0.2339\n",
      "Epoch [112/360], Batch [10/196], Loss: 0.2374\n",
      "Epoch [112/360], Batch [15/196], Loss: 0.1931\n",
      "Epoch [112/360], Batch [20/196], Loss: 0.1642\n",
      "Epoch [112/360], Batch [25/196], Loss: 0.1825\n",
      "Epoch [112/360], Batch [30/196], Loss: 0.1258\n",
      "Epoch [112/360], Batch [35/196], Loss: 0.1534\n",
      "Epoch [112/360], Batch [40/196], Loss: 0.2117\n",
      "Epoch [112/360], Batch [45/196], Loss: 0.4923\n",
      "Epoch [112/360], Batch [50/196], Loss: 0.2762\n",
      "Epoch [112/360], Batch [55/196], Loss: 0.2966\n",
      "Epoch [112/360], Batch [60/196], Loss: 0.2073\n",
      "Epoch [112/360], Batch [65/196], Loss: 0.0872\n",
      "Epoch [112/360], Batch [70/196], Loss: 0.2869\n",
      "Epoch [112/360], Batch [75/196], Loss: 0.1731\n",
      "Epoch [112/360], Batch [80/196], Loss: 0.1905\n",
      "Epoch [112/360], Batch [85/196], Loss: 0.2681\n",
      "Epoch [112/360], Batch [90/196], Loss: 0.3527\n",
      "Epoch [112/360], Batch [95/196], Loss: 0.1887\n",
      "Epoch [112/360], Batch [100/196], Loss: 0.2499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/360], Batch [105/196], Loss: 0.1682\n",
      "Epoch [112/360], Batch [110/196], Loss: 0.2201\n",
      "Epoch [112/360], Batch [115/196], Loss: 0.1474\n",
      "Epoch [112/360], Batch [120/196], Loss: 0.2310\n",
      "Epoch [112/360], Batch [125/196], Loss: 0.2660\n",
      "Epoch [112/360], Batch [130/196], Loss: 0.1945\n",
      "Epoch [112/360], Batch [135/196], Loss: 0.2106\n",
      "Epoch [112/360], Batch [140/196], Loss: 0.1639\n",
      "Epoch [112/360], Batch [145/196], Loss: 0.1808\n",
      "Epoch [112/360], Batch [150/196], Loss: 0.2085\n",
      "Epoch [112/360], Batch [155/196], Loss: 0.3120\n",
      "Epoch [112/360], Batch [160/196], Loss: 0.2785\n",
      "Epoch [112/360], Batch [165/196], Loss: 0.1895\n",
      "Epoch [112/360], Batch [170/196], Loss: 0.1748\n",
      "Epoch [112/360], Batch [175/196], Loss: 0.1790\n",
      "Epoch [112/360], Batch [180/196], Loss: 0.3241\n",
      "Epoch [112/360], Batch [185/196], Loss: 0.1756\n",
      "Epoch [112/360], Batch [190/196], Loss: 0.2164\n",
      "Epoch [112/360], Batch [195/196], Loss: 0.3183\n",
      "Epoch [113/360], Batch [5/196], Loss: 0.0822\n",
      "Epoch [113/360], Batch [10/196], Loss: 0.1016\n",
      "Epoch [113/360], Batch [15/196], Loss: 0.2127\n",
      "Epoch [113/360], Batch [20/196], Loss: 0.1691\n",
      "Epoch [113/360], Batch [25/196], Loss: 0.2038\n",
      "Epoch [113/360], Batch [30/196], Loss: 0.2489\n",
      "Epoch [113/360], Batch [35/196], Loss: 0.1674\n",
      "Epoch [113/360], Batch [40/196], Loss: 0.1433\n",
      "Epoch [113/360], Batch [45/196], Loss: 0.1264\n",
      "Epoch [113/360], Batch [50/196], Loss: 0.2632\n",
      "Epoch [113/360], Batch [55/196], Loss: 0.1541\n",
      "Epoch [113/360], Batch [60/196], Loss: 0.1429\n",
      "Epoch [113/360], Batch [65/196], Loss: 0.1123\n",
      "Epoch [113/360], Batch [70/196], Loss: 0.3991\n",
      "Epoch [113/360], Batch [75/196], Loss: 0.1219\n",
      "Epoch [113/360], Batch [80/196], Loss: 0.1696\n",
      "Epoch [113/360], Batch [85/196], Loss: 0.1260\n",
      "Epoch [113/360], Batch [90/196], Loss: 0.2453\n",
      "Epoch [113/360], Batch [95/196], Loss: 0.1530\n",
      "Epoch [113/360], Batch [100/196], Loss: 0.2961\n",
      "Epoch [113/360], Batch [105/196], Loss: 0.1754\n",
      "Epoch [113/360], Batch [110/196], Loss: 0.2550\n",
      "Epoch [113/360], Batch [115/196], Loss: 0.2468\n",
      "Epoch [113/360], Batch [120/196], Loss: 0.3400\n",
      "Epoch [113/360], Batch [125/196], Loss: 0.1880\n",
      "Epoch [113/360], Batch [130/196], Loss: 0.1287\n",
      "Epoch [113/360], Batch [135/196], Loss: 0.2343\n",
      "Epoch [113/360], Batch [140/196], Loss: 0.2279\n",
      "Epoch [113/360], Batch [145/196], Loss: 0.1643\n",
      "Epoch [113/360], Batch [150/196], Loss: 0.1554\n",
      "Epoch [113/360], Batch [155/196], Loss: 0.2760\n",
      "Epoch [113/360], Batch [160/196], Loss: 0.1967\n",
      "Epoch [113/360], Batch [165/196], Loss: 0.1771\n",
      "Epoch [113/360], Batch [170/196], Loss: 0.1254\n",
      "Epoch [113/360], Batch [175/196], Loss: 0.1130\n",
      "Epoch [113/360], Batch [180/196], Loss: 0.2422\n",
      "Epoch [113/360], Batch [185/196], Loss: 0.2347\n",
      "Epoch [113/360], Batch [190/196], Loss: 0.2816\n",
      "Epoch [113/360], Batch [195/196], Loss: 0.3103\n",
      "Epoch [114/360], Batch [5/196], Loss: 0.1265\n",
      "Epoch [114/360], Batch [10/196], Loss: 0.2838\n",
      "Epoch [114/360], Batch [15/196], Loss: 0.1107\n",
      "Epoch [114/360], Batch [20/196], Loss: 0.1196\n",
      "Epoch [114/360], Batch [25/196], Loss: 0.1715\n",
      "Epoch [114/360], Batch [30/196], Loss: 0.1692\n",
      "Epoch [114/360], Batch [35/196], Loss: 0.1526\n",
      "Epoch [114/360], Batch [40/196], Loss: 0.1249\n",
      "Epoch [114/360], Batch [45/196], Loss: 0.1417\n",
      "Epoch [114/360], Batch [50/196], Loss: 0.1022\n",
      "Epoch [114/360], Batch [55/196], Loss: 0.1672\n",
      "Epoch [114/360], Batch [60/196], Loss: 0.1505\n",
      "Epoch [114/360], Batch [65/196], Loss: 0.1537\n",
      "Epoch [114/360], Batch [70/196], Loss: 0.1636\n",
      "Epoch [114/360], Batch [75/196], Loss: 0.0968\n",
      "Epoch [114/360], Batch [80/196], Loss: 0.1665\n",
      "Epoch [114/360], Batch [85/196], Loss: 0.1720\n",
      "Epoch [114/360], Batch [90/196], Loss: 0.1830\n",
      "Epoch [114/360], Batch [95/196], Loss: 0.2354\n",
      "Epoch [114/360], Batch [100/196], Loss: 0.1813\n",
      "Epoch [114/360], Batch [105/196], Loss: 0.1189\n",
      "Epoch [114/360], Batch [110/196], Loss: 0.2534\n",
      "Epoch [114/360], Batch [115/196], Loss: 0.1710\n",
      "Epoch [114/360], Batch [120/196], Loss: 0.1820\n",
      "Epoch [114/360], Batch [125/196], Loss: 0.1012\n",
      "Epoch [114/360], Batch [130/196], Loss: 0.1753\n",
      "Epoch [114/360], Batch [135/196], Loss: 0.1062\n",
      "Epoch [114/360], Batch [140/196], Loss: 0.1340\n",
      "Epoch [114/360], Batch [145/196], Loss: 0.1732\n",
      "Epoch [114/360], Batch [150/196], Loss: 0.1356\n",
      "Epoch [114/360], Batch [155/196], Loss: 0.1806\n",
      "Epoch [114/360], Batch [160/196], Loss: 0.1642\n",
      "Epoch [114/360], Batch [165/196], Loss: 0.1134\n",
      "Epoch [114/360], Batch [170/196], Loss: 0.1492\n",
      "Epoch [114/360], Batch [175/196], Loss: 0.2847\n",
      "Epoch [114/360], Batch [180/196], Loss: 0.1321\n",
      "Epoch [114/360], Batch [185/196], Loss: 0.2521\n",
      "Epoch [114/360], Batch [190/196], Loss: 0.1699\n",
      "Epoch [114/360], Batch [195/196], Loss: 0.1670\n",
      "Epoch [115/360], Batch [5/196], Loss: 0.1444\n",
      "Epoch [115/360], Batch [10/196], Loss: 0.2224\n",
      "Epoch [115/360], Batch [15/196], Loss: 0.4263\n",
      "Epoch [115/360], Batch [20/196], Loss: 0.1016\n",
      "Epoch [115/360], Batch [25/196], Loss: 0.2088\n",
      "Epoch [115/360], Batch [30/196], Loss: 0.1051\n",
      "Epoch [115/360], Batch [35/196], Loss: 0.1356\n",
      "Epoch [115/360], Batch [40/196], Loss: 0.1245\n",
      "Epoch [115/360], Batch [45/196], Loss: 0.1215\n",
      "Epoch [115/360], Batch [50/196], Loss: 0.1805\n",
      "Epoch [115/360], Batch [55/196], Loss: 0.1147\n",
      "Epoch [115/360], Batch [60/196], Loss: 0.1272\n",
      "Epoch [115/360], Batch [65/196], Loss: 0.1960\n",
      "Epoch [115/360], Batch [70/196], Loss: 0.1307\n",
      "Epoch [115/360], Batch [75/196], Loss: 0.1107\n",
      "Epoch [115/360], Batch [80/196], Loss: 0.1726\n",
      "Epoch [115/360], Batch [85/196], Loss: 0.1232\n",
      "Epoch [115/360], Batch [90/196], Loss: 0.1582\n",
      "Epoch [115/360], Batch [95/196], Loss: 0.2069\n",
      "Epoch [115/360], Batch [100/196], Loss: 0.1610\n",
      "Epoch [115/360], Batch [105/196], Loss: 0.3450\n",
      "Epoch [115/360], Batch [110/196], Loss: 0.1349\n",
      "Epoch [115/360], Batch [115/196], Loss: 0.1352\n",
      "Epoch [115/360], Batch [120/196], Loss: 0.1218\n",
      "Epoch [115/360], Batch [125/196], Loss: 0.1694\n",
      "Epoch [115/360], Batch [130/196], Loss: 0.2049\n",
      "Epoch [115/360], Batch [135/196], Loss: 0.1171\n",
      "Epoch [115/360], Batch [140/196], Loss: 0.1489\n",
      "Epoch [115/360], Batch [145/196], Loss: 0.1231\n",
      "Epoch [115/360], Batch [150/196], Loss: 0.1284\n",
      "Epoch [115/360], Batch [155/196], Loss: 0.1224\n",
      "Epoch [115/360], Batch [160/196], Loss: 0.1906\n",
      "Epoch [115/360], Batch [165/196], Loss: 0.2007\n",
      "Epoch [115/360], Batch [170/196], Loss: 0.1140\n",
      "Epoch [115/360], Batch [175/196], Loss: 0.1303\n",
      "Epoch [115/360], Batch [180/196], Loss: 0.1930\n",
      "Epoch [115/360], Batch [185/196], Loss: 0.1889\n",
      "Epoch [115/360], Batch [190/196], Loss: 0.0828\n",
      "Epoch [115/360], Batch [195/196], Loss: 0.0740\n",
      "Epoch [116/360], Batch [5/196], Loss: 0.1399\n",
      "Epoch [116/360], Batch [10/196], Loss: 0.1380\n",
      "Epoch [116/360], Batch [15/196], Loss: 0.1739\n",
      "Epoch [116/360], Batch [20/196], Loss: 0.0981\n",
      "Epoch [116/360], Batch [25/196], Loss: 0.1207\n",
      "Epoch [116/360], Batch [30/196], Loss: 0.0934\n",
      "Epoch [116/360], Batch [35/196], Loss: 0.1817\n",
      "Epoch [116/360], Batch [40/196], Loss: 0.2046\n",
      "Epoch [116/360], Batch [45/196], Loss: 0.1513\n",
      "Epoch [116/360], Batch [50/196], Loss: 0.1556\n",
      "Epoch [116/360], Batch [55/196], Loss: 0.1276\n",
      "Epoch [116/360], Batch [60/196], Loss: 0.2569\n",
      "Epoch [116/360], Batch [65/196], Loss: 0.1429\n",
      "Epoch [116/360], Batch [70/196], Loss: 0.1561\n",
      "Epoch [116/360], Batch [75/196], Loss: 0.1282\n",
      "Epoch [116/360], Batch [80/196], Loss: 0.0951\n",
      "Epoch [116/360], Batch [85/196], Loss: 0.1298\n",
      "Epoch [116/360], Batch [90/196], Loss: 0.1439\n",
      "Epoch [116/360], Batch [95/196], Loss: 0.1587\n",
      "Epoch [116/360], Batch [100/196], Loss: 0.1432\n",
      "Epoch [116/360], Batch [105/196], Loss: 0.1199\n",
      "Epoch [116/360], Batch [110/196], Loss: 0.0859\n",
      "Epoch [116/360], Batch [115/196], Loss: 0.0946\n",
      "Epoch [116/360], Batch [120/196], Loss: 0.1761\n",
      "Epoch [116/360], Batch [125/196], Loss: 0.1223\n",
      "Epoch [116/360], Batch [130/196], Loss: 0.2270\n",
      "Epoch [116/360], Batch [135/196], Loss: 0.1686\n",
      "Epoch [116/360], Batch [140/196], Loss: 0.1189\n",
      "Epoch [116/360], Batch [145/196], Loss: 0.1302\n",
      "Epoch [116/360], Batch [150/196], Loss: 0.1868\n",
      "Epoch [116/360], Batch [155/196], Loss: 0.1024\n",
      "Epoch [116/360], Batch [160/196], Loss: 0.1659\n",
      "Epoch [116/360], Batch [165/196], Loss: 0.1461\n",
      "Epoch [116/360], Batch [170/196], Loss: 0.1122\n",
      "Epoch [116/360], Batch [175/196], Loss: 0.1946\n",
      "Epoch [116/360], Batch [180/196], Loss: 0.1254\n",
      "Epoch [116/360], Batch [185/196], Loss: 0.1308\n",
      "Epoch [116/360], Batch [190/196], Loss: 0.1370\n",
      "Epoch [116/360], Batch [195/196], Loss: 0.1653\n",
      "Epoch [117/360], Batch [5/196], Loss: 0.1474\n",
      "Epoch [117/360], Batch [10/196], Loss: 0.1293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [117/360], Batch [15/196], Loss: 0.1071\n",
      "Epoch [117/360], Batch [20/196], Loss: 0.1253\n",
      "Epoch [117/360], Batch [25/196], Loss: 0.2441\n",
      "Epoch [117/360], Batch [30/196], Loss: 0.2019\n",
      "Epoch [117/360], Batch [35/196], Loss: 0.1363\n",
      "Epoch [117/360], Batch [40/196], Loss: 0.1168\n",
      "Epoch [117/360], Batch [45/196], Loss: 0.1143\n",
      "Epoch [117/360], Batch [50/196], Loss: 0.2249\n",
      "Epoch [117/360], Batch [55/196], Loss: 0.1390\n",
      "Epoch [117/360], Batch [60/196], Loss: 0.2123\n",
      "Epoch [117/360], Batch [65/196], Loss: 0.0890\n",
      "Epoch [117/360], Batch [70/196], Loss: 0.1352\n",
      "Epoch [117/360], Batch [75/196], Loss: 0.1154\n",
      "Epoch [117/360], Batch [80/196], Loss: 0.2326\n",
      "Epoch [117/360], Batch [85/196], Loss: 0.1130\n",
      "Epoch [117/360], Batch [90/196], Loss: 0.0978\n",
      "Epoch [117/360], Batch [95/196], Loss: 0.0894\n",
      "Epoch [117/360], Batch [100/196], Loss: 0.1757\n",
      "Epoch [117/360], Batch [105/196], Loss: 0.1378\n",
      "Epoch [117/360], Batch [110/196], Loss: 0.1734\n",
      "Epoch [117/360], Batch [115/196], Loss: 0.1642\n",
      "Epoch [117/360], Batch [120/196], Loss: 0.1530\n",
      "Epoch [117/360], Batch [125/196], Loss: 0.0900\n",
      "Epoch [117/360], Batch [130/196], Loss: 0.1438\n",
      "Epoch [117/360], Batch [135/196], Loss: 0.1260\n",
      "Epoch [117/360], Batch [140/196], Loss: 0.0978\n",
      "Epoch [117/360], Batch [145/196], Loss: 0.0985\n",
      "Epoch [117/360], Batch [150/196], Loss: 0.1541\n",
      "Epoch [117/360], Batch [155/196], Loss: 0.1514\n",
      "Epoch [117/360], Batch [160/196], Loss: 0.1834\n",
      "Epoch [117/360], Batch [165/196], Loss: 0.1801\n",
      "Epoch [117/360], Batch [170/196], Loss: 0.1336\n",
      "Epoch [117/360], Batch [175/196], Loss: 0.1566\n",
      "Epoch [117/360], Batch [180/196], Loss: 0.1072\n",
      "Epoch [117/360], Batch [185/196], Loss: 0.2125\n",
      "Epoch [117/360], Batch [190/196], Loss: 0.1146\n",
      "Epoch [117/360], Batch [195/196], Loss: 0.1858\n",
      "Epoch [118/360], Batch [5/196], Loss: 0.1391\n",
      "Epoch [118/360], Batch [10/196], Loss: 0.1246\n",
      "Epoch [118/360], Batch [15/196], Loss: 0.1255\n",
      "Epoch [118/360], Batch [20/196], Loss: 0.2078\n",
      "Epoch [118/360], Batch [25/196], Loss: 0.1026\n",
      "Epoch [118/360], Batch [30/196], Loss: 0.2292\n",
      "Epoch [118/360], Batch [35/196], Loss: 0.0927\n",
      "Epoch [118/360], Batch [40/196], Loss: 0.1295\n",
      "Epoch [118/360], Batch [45/196], Loss: 0.1458\n",
      "Epoch [118/360], Batch [50/196], Loss: 0.1218\n",
      "Epoch [118/360], Batch [55/196], Loss: 0.1207\n",
      "Epoch [118/360], Batch [60/196], Loss: 0.1709\n",
      "Epoch [118/360], Batch [65/196], Loss: 0.1676\n",
      "Epoch [118/360], Batch [70/196], Loss: 0.1174\n",
      "Epoch [118/360], Batch [75/196], Loss: 0.0993\n",
      "Epoch [118/360], Batch [80/196], Loss: 0.1998\n",
      "Epoch [118/360], Batch [85/196], Loss: 0.1358\n",
      "Epoch [118/360], Batch [90/196], Loss: 0.1379\n",
      "Epoch [118/360], Batch [95/196], Loss: 0.1084\n",
      "Epoch [118/360], Batch [100/196], Loss: 0.0700\n",
      "Epoch [118/360], Batch [105/196], Loss: 0.1062\n",
      "Epoch [118/360], Batch [110/196], Loss: 0.0672\n",
      "Epoch [118/360], Batch [115/196], Loss: 0.1773\n",
      "Epoch [118/360], Batch [120/196], Loss: 0.0844\n",
      "Epoch [118/360], Batch [125/196], Loss: 0.1420\n",
      "Epoch [118/360], Batch [130/196], Loss: 0.1633\n",
      "Epoch [118/360], Batch [135/196], Loss: 0.0882\n",
      "Epoch [118/360], Batch [140/196], Loss: 0.1693\n",
      "Epoch [118/360], Batch [145/196], Loss: 0.1028\n",
      "Epoch [118/360], Batch [150/196], Loss: 0.1458\n",
      "Epoch [118/360], Batch [155/196], Loss: 0.1172\n",
      "Epoch [118/360], Batch [160/196], Loss: 0.1014\n",
      "Epoch [118/360], Batch [165/196], Loss: 0.2377\n",
      "Epoch [118/360], Batch [170/196], Loss: 0.1855\n",
      "Epoch [118/360], Batch [175/196], Loss: 0.1657\n",
      "Epoch [118/360], Batch [180/196], Loss: 0.2674\n",
      "Epoch [118/360], Batch [185/196], Loss: 0.7950\n",
      "Epoch [118/360], Batch [190/196], Loss: 0.2200\n",
      "Epoch [118/360], Batch [195/196], Loss: 0.1588\n",
      "Epoch [119/360], Batch [5/196], Loss: 0.1414\n",
      "Epoch [119/360], Batch [10/196], Loss: 0.1133\n",
      "Epoch [119/360], Batch [15/196], Loss: 0.1264\n",
      "Epoch [119/360], Batch [20/196], Loss: 0.1161\n",
      "Epoch [119/360], Batch [25/196], Loss: 0.1288\n",
      "Epoch [119/360], Batch [30/196], Loss: 0.1213\n",
      "Epoch [119/360], Batch [35/196], Loss: 0.1156\n",
      "Epoch [119/360], Batch [40/196], Loss: 0.1670\n",
      "Epoch [119/360], Batch [45/196], Loss: 0.1122\n",
      "Epoch [119/360], Batch [50/196], Loss: 0.1223\n",
      "Epoch [119/360], Batch [55/196], Loss: 0.1794\n",
      "Epoch [119/360], Batch [60/196], Loss: 0.1196\n",
      "Epoch [119/360], Batch [65/196], Loss: 0.1019\n",
      "Epoch [119/360], Batch [70/196], Loss: 0.1861\n",
      "Epoch [119/360], Batch [75/196], Loss: 0.1461\n",
      "Epoch [119/360], Batch [80/196], Loss: 0.1443\n",
      "Epoch [119/360], Batch [85/196], Loss: 0.2558\n",
      "Epoch [119/360], Batch [90/196], Loss: 0.1599\n",
      "Epoch [119/360], Batch [95/196], Loss: 0.1528\n",
      "Epoch [119/360], Batch [100/196], Loss: 0.2035\n",
      "Epoch [119/360], Batch [105/196], Loss: 0.1032\n",
      "Epoch [119/360], Batch [110/196], Loss: 0.1738\n",
      "Epoch [119/360], Batch [115/196], Loss: 0.1036\n",
      "Epoch [119/360], Batch [120/196], Loss: 0.1012\n",
      "Epoch [119/360], Batch [125/196], Loss: 0.1030\n",
      "Epoch [119/360], Batch [130/196], Loss: 0.1093\n",
      "Epoch [119/360], Batch [135/196], Loss: 0.1499\n",
      "Epoch [119/360], Batch [140/196], Loss: 0.1565\n",
      "Epoch [119/360], Batch [145/196], Loss: 0.1582\n",
      "Epoch [119/360], Batch [150/196], Loss: 0.1194\n",
      "Epoch [119/360], Batch [155/196], Loss: 0.1653\n",
      "Epoch [119/360], Batch [160/196], Loss: 0.2528\n",
      "Epoch [119/360], Batch [165/196], Loss: 0.1320\n",
      "Epoch [119/360], Batch [170/196], Loss: 0.1320\n",
      "Epoch [119/360], Batch [175/196], Loss: 0.3022\n",
      "Epoch [119/360], Batch [180/196], Loss: 0.1695\n",
      "Epoch [119/360], Batch [185/196], Loss: 0.0863\n",
      "Epoch [119/360], Batch [190/196], Loss: 0.1405\n",
      "Epoch [119/360], Batch [195/196], Loss: 0.1741\n",
      "Epoch [120/360], Batch [5/196], Loss: 0.0646\n",
      "Epoch [120/360], Batch [10/196], Loss: 0.1069\n",
      "Epoch [120/360], Batch [15/196], Loss: 0.1304\n",
      "Epoch [120/360], Batch [20/196], Loss: 0.1597\n",
      "Epoch [120/360], Batch [25/196], Loss: 0.1366\n",
      "Epoch [120/360], Batch [30/196], Loss: 0.1779\n",
      "Epoch [120/360], Batch [35/196], Loss: 0.1098\n",
      "Epoch [120/360], Batch [40/196], Loss: 0.1151\n",
      "Epoch [120/360], Batch [45/196], Loss: 0.1316\n",
      "Epoch [120/360], Batch [50/196], Loss: 0.1330\n",
      "Epoch [120/360], Batch [55/196], Loss: 0.1004\n",
      "Epoch [120/360], Batch [60/196], Loss: 0.0880\n",
      "Epoch [120/360], Batch [65/196], Loss: 0.1570\n",
      "Epoch [120/360], Batch [70/196], Loss: 0.1955\n",
      "Epoch [120/360], Batch [75/196], Loss: 0.0996\n",
      "Epoch [120/360], Batch [80/196], Loss: 0.1530\n",
      "Epoch [120/360], Batch [85/196], Loss: 0.1195\n",
      "Epoch [120/360], Batch [90/196], Loss: 0.1506\n",
      "Epoch [120/360], Batch [95/196], Loss: 0.3335\n",
      "Epoch [120/360], Batch [100/196], Loss: 0.2478\n",
      "Epoch [120/360], Batch [105/196], Loss: 0.1950\n",
      "Epoch [120/360], Batch [110/196], Loss: 0.3409\n",
      "Epoch [120/360], Batch [115/196], Loss: 0.0960\n",
      "Epoch [120/360], Batch [120/196], Loss: 0.2748\n",
      "Epoch [120/360], Batch [125/196], Loss: 0.2246\n",
      "Epoch [120/360], Batch [130/196], Loss: 0.1638\n",
      "Epoch [120/360], Batch [135/196], Loss: 0.1676\n",
      "Epoch [120/360], Batch [140/196], Loss: 0.1475\n",
      "Epoch [120/360], Batch [145/196], Loss: 0.1510\n",
      "Epoch [120/360], Batch [150/196], Loss: 0.2435\n",
      "Epoch [120/360], Batch [155/196], Loss: 0.1794\n",
      "Epoch [120/360], Batch [160/196], Loss: 0.1549\n",
      "Epoch [120/360], Batch [165/196], Loss: 0.2299\n",
      "Epoch [120/360], Batch [170/196], Loss: 0.2134\n",
      "Epoch [120/360], Batch [175/196], Loss: 0.1658\n",
      "Epoch [120/360], Batch [180/196], Loss: 0.1946\n",
      "Epoch [120/360], Batch [185/196], Loss: 0.2440\n",
      "Epoch [120/360], Batch [190/196], Loss: 0.1614\n",
      "Epoch [120/360], Batch [195/196], Loss: 0.3113\n",
      "Epoch [121/360], Batch [5/196], Loss: 0.1730\n",
      "Epoch [121/360], Batch [10/196], Loss: 0.0785\n",
      "Epoch [121/360], Batch [15/196], Loss: 0.1154\n",
      "Epoch [121/360], Batch [20/196], Loss: 0.1803\n",
      "Epoch [121/360], Batch [25/196], Loss: 0.2763\n",
      "Epoch [121/360], Batch [30/196], Loss: 0.1620\n",
      "Epoch [121/360], Batch [35/196], Loss: 0.1463\n",
      "Epoch [121/360], Batch [40/196], Loss: 0.1666\n",
      "Epoch [121/360], Batch [45/196], Loss: 0.1783\n",
      "Epoch [121/360], Batch [50/196], Loss: 0.1739\n",
      "Epoch [121/360], Batch [55/196], Loss: 0.1377\n",
      "Epoch [121/360], Batch [60/196], Loss: 0.1311\n",
      "Epoch [121/360], Batch [65/196], Loss: 0.1173\n",
      "Epoch [121/360], Batch [70/196], Loss: 0.2061\n",
      "Epoch [121/360], Batch [75/196], Loss: 0.0999\n",
      "Epoch [121/360], Batch [80/196], Loss: 0.1967\n",
      "Epoch [121/360], Batch [85/196], Loss: 0.1491\n",
      "Epoch [121/360], Batch [90/196], Loss: 0.1430\n",
      "Epoch [121/360], Batch [95/196], Loss: 0.2288\n",
      "Epoch [121/360], Batch [100/196], Loss: 0.1603\n",
      "Epoch [121/360], Batch [105/196], Loss: 0.2092\n",
      "Epoch [121/360], Batch [110/196], Loss: 0.1599\n",
      "Epoch [121/360], Batch [115/196], Loss: 0.2025\n",
      "Epoch [121/360], Batch [120/196], Loss: 0.1320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [121/360], Batch [125/196], Loss: 0.1439\n",
      "Epoch [121/360], Batch [130/196], Loss: 0.1637\n",
      "Epoch [121/360], Batch [135/196], Loss: 0.1869\n",
      "Epoch [121/360], Batch [140/196], Loss: 0.1441\n",
      "Epoch [121/360], Batch [145/196], Loss: 0.1656\n",
      "Epoch [121/360], Batch [150/196], Loss: 0.1539\n",
      "Epoch [121/360], Batch [155/196], Loss: 0.1888\n",
      "Epoch [121/360], Batch [160/196], Loss: 0.1485\n",
      "Epoch [121/360], Batch [165/196], Loss: 0.2236\n",
      "Epoch [121/360], Batch [170/196], Loss: 0.1386\n",
      "Epoch [121/360], Batch [175/196], Loss: 0.0924\n",
      "Epoch [121/360], Batch [180/196], Loss: 0.1883\n",
      "Epoch [121/360], Batch [185/196], Loss: 0.1032\n",
      "Epoch [121/360], Batch [190/196], Loss: 0.2145\n",
      "Epoch [121/360], Batch [195/196], Loss: 0.1945\n",
      "Epoch [122/360], Batch [5/196], Loss: 0.1446\n",
      "Epoch [122/360], Batch [10/196], Loss: 0.0931\n",
      "Epoch [122/360], Batch [15/196], Loss: 0.1022\n",
      "Epoch [122/360], Batch [20/196], Loss: 0.0970\n",
      "Epoch [122/360], Batch [25/196], Loss: 0.1145\n",
      "Epoch [122/360], Batch [30/196], Loss: 0.2031\n",
      "Epoch [122/360], Batch [35/196], Loss: 0.1337\n",
      "Epoch [122/360], Batch [40/196], Loss: 0.1095\n",
      "Epoch [122/360], Batch [45/196], Loss: 0.1561\n",
      "Epoch [122/360], Batch [50/196], Loss: 0.1680\n",
      "Epoch [122/360], Batch [55/196], Loss: 0.1439\n",
      "Epoch [122/360], Batch [60/196], Loss: 0.1452\n",
      "Epoch [122/360], Batch [65/196], Loss: 0.1565\n",
      "Epoch [122/360], Batch [70/196], Loss: 0.1184\n",
      "Epoch [122/360], Batch [75/196], Loss: 0.1024\n",
      "Epoch [122/360], Batch [80/196], Loss: 0.0964\n",
      "Epoch [122/360], Batch [85/196], Loss: 0.1176\n",
      "Epoch [122/360], Batch [90/196], Loss: 0.1052\n",
      "Epoch [122/360], Batch [95/196], Loss: 0.1751\n",
      "Epoch [122/360], Batch [100/196], Loss: 0.1048\n",
      "Epoch [122/360], Batch [105/196], Loss: 0.0904\n",
      "Epoch [122/360], Batch [110/196], Loss: 0.1144\n",
      "Epoch [122/360], Batch [115/196], Loss: 0.1412\n",
      "Epoch [122/360], Batch [120/196], Loss: 0.1553\n",
      "Epoch [122/360], Batch [125/196], Loss: 0.1715\n",
      "Epoch [122/360], Batch [130/196], Loss: 0.1064\n",
      "Epoch [122/360], Batch [135/196], Loss: 0.1286\n",
      "Epoch [122/360], Batch [140/196], Loss: 0.1522\n",
      "Epoch [122/360], Batch [145/196], Loss: 0.0826\n",
      "Epoch [122/360], Batch [150/196], Loss: 0.1296\n",
      "Epoch [122/360], Batch [155/196], Loss: 0.1066\n",
      "Epoch [122/360], Batch [160/196], Loss: 0.1562\n",
      "Epoch [122/360], Batch [165/196], Loss: 0.1744\n",
      "Epoch [122/360], Batch [170/196], Loss: 0.1042\n",
      "Epoch [122/360], Batch [175/196], Loss: 0.1642\n",
      "Epoch [122/360], Batch [180/196], Loss: 0.1092\n",
      "Epoch [122/360], Batch [185/196], Loss: 0.1092\n",
      "Epoch [122/360], Batch [190/196], Loss: 0.1807\n",
      "Epoch [122/360], Batch [195/196], Loss: 0.1283\n",
      "Epoch [123/360], Batch [5/196], Loss: 0.1693\n",
      "Epoch [123/360], Batch [10/196], Loss: 0.0935\n",
      "Epoch [123/360], Batch [15/196], Loss: 0.0888\n",
      "Epoch [123/360], Batch [20/196], Loss: 0.1114\n",
      "Epoch [123/360], Batch [25/196], Loss: 0.1193\n",
      "Epoch [123/360], Batch [30/196], Loss: 0.0699\n",
      "Epoch [123/360], Batch [35/196], Loss: 0.1258\n",
      "Epoch [123/360], Batch [40/196], Loss: 0.1089\n",
      "Epoch [123/360], Batch [45/196], Loss: 0.1061\n",
      "Epoch [123/360], Batch [50/196], Loss: 0.1496\n",
      "Epoch [123/360], Batch [55/196], Loss: 0.1450\n",
      "Epoch [123/360], Batch [60/196], Loss: 0.1101\n",
      "Epoch [123/360], Batch [65/196], Loss: 0.2023\n",
      "Epoch [123/360], Batch [70/196], Loss: 0.1336\n",
      "Epoch [123/360], Batch [75/196], Loss: 0.1682\n",
      "Epoch [123/360], Batch [80/196], Loss: 0.1729\n",
      "Epoch [123/360], Batch [85/196], Loss: 0.1729\n",
      "Epoch [123/360], Batch [90/196], Loss: 0.1177\n",
      "Epoch [123/360], Batch [95/196], Loss: 0.1851\n",
      "Epoch [123/360], Batch [100/196], Loss: 0.1351\n",
      "Epoch [123/360], Batch [105/196], Loss: 0.1078\n",
      "Epoch [123/360], Batch [110/196], Loss: 0.2536\n",
      "Epoch [123/360], Batch [115/196], Loss: 0.2048\n",
      "Epoch [123/360], Batch [120/196], Loss: 0.1128\n",
      "Epoch [123/360], Batch [125/196], Loss: 0.1441\n",
      "Epoch [123/360], Batch [130/196], Loss: 0.1255\n",
      "Epoch [123/360], Batch [135/196], Loss: 0.1571\n",
      "Epoch [123/360], Batch [140/196], Loss: 0.1010\n",
      "Epoch [123/360], Batch [145/196], Loss: 0.1448\n",
      "Epoch [123/360], Batch [150/196], Loss: 0.0706\n",
      "Epoch [123/360], Batch [155/196], Loss: 0.1962\n",
      "Epoch [123/360], Batch [160/196], Loss: 0.0800\n",
      "Epoch [123/360], Batch [165/196], Loss: 0.1120\n",
      "Epoch [123/360], Batch [170/196], Loss: 0.1256\n",
      "Epoch [123/360], Batch [175/196], Loss: 0.1156\n",
      "Epoch [123/360], Batch [180/196], Loss: 0.1679\n",
      "Epoch [123/360], Batch [185/196], Loss: 0.0984\n",
      "Epoch [123/360], Batch [190/196], Loss: 0.0936\n",
      "Epoch [123/360], Batch [195/196], Loss: 0.1163\n",
      "Epoch [124/360], Batch [5/196], Loss: 0.1801\n",
      "Epoch [124/360], Batch [10/196], Loss: 0.0775\n",
      "Epoch [124/360], Batch [15/196], Loss: 0.1526\n",
      "Epoch [124/360], Batch [20/196], Loss: 0.1242\n",
      "Epoch [124/360], Batch [25/196], Loss: 0.1278\n",
      "Epoch [124/360], Batch [30/196], Loss: 0.1452\n",
      "Epoch [124/360], Batch [35/196], Loss: 0.1237\n",
      "Epoch [124/360], Batch [40/196], Loss: 0.1302\n",
      "Epoch [124/360], Batch [45/196], Loss: 0.1238\n",
      "Epoch [124/360], Batch [50/196], Loss: 0.1243\n",
      "Epoch [124/360], Batch [55/196], Loss: 0.1000\n",
      "Epoch [124/360], Batch [60/196], Loss: 0.1293\n",
      "Epoch [124/360], Batch [65/196], Loss: 0.1168\n",
      "Epoch [124/360], Batch [70/196], Loss: 0.1197\n",
      "Epoch [124/360], Batch [75/196], Loss: 0.1164\n",
      "Epoch [124/360], Batch [80/196], Loss: 0.1200\n",
      "Epoch [124/360], Batch [85/196], Loss: 0.1133\n",
      "Epoch [124/360], Batch [90/196], Loss: 0.1099\n",
      "Epoch [124/360], Batch [95/196], Loss: 0.0756\n",
      "Epoch [124/360], Batch [100/196], Loss: 0.1827\n",
      "Epoch [124/360], Batch [105/196], Loss: 0.1191\n",
      "Epoch [124/360], Batch [110/196], Loss: 0.1187\n",
      "Epoch [124/360], Batch [115/196], Loss: 0.1262\n",
      "Epoch [124/360], Batch [120/196], Loss: 0.1187\n",
      "Epoch [124/360], Batch [125/196], Loss: 0.1114\n",
      "Epoch [124/360], Batch [130/196], Loss: 0.1007\n",
      "Epoch [124/360], Batch [135/196], Loss: 0.1074\n",
      "Epoch [124/360], Batch [140/196], Loss: 0.1452\n",
      "Epoch [124/360], Batch [145/196], Loss: 0.1571\n",
      "Epoch [124/360], Batch [150/196], Loss: 0.1223\n",
      "Epoch [124/360], Batch [155/196], Loss: 0.1174\n",
      "Epoch [124/360], Batch [160/196], Loss: 0.1609\n",
      "Epoch [124/360], Batch [165/196], Loss: 0.1068\n",
      "Epoch [124/360], Batch [170/196], Loss: 0.0920\n",
      "Epoch [124/360], Batch [175/196], Loss: 0.1631\n",
      "Epoch [124/360], Batch [180/196], Loss: 0.1570\n",
      "Epoch [124/360], Batch [185/196], Loss: 0.1667\n",
      "Epoch [124/360], Batch [190/196], Loss: 0.1384\n",
      "Epoch [124/360], Batch [195/196], Loss: 0.1420\n",
      "Epoch [125/360], Batch [5/196], Loss: 0.1126\n",
      "Epoch [125/360], Batch [10/196], Loss: 0.0827\n",
      "Epoch [125/360], Batch [15/196], Loss: 0.1201\n",
      "Epoch [125/360], Batch [20/196], Loss: 0.0804\n",
      "Epoch [125/360], Batch [25/196], Loss: 0.1180\n",
      "Epoch [125/360], Batch [30/196], Loss: 0.0654\n",
      "Epoch [125/360], Batch [35/196], Loss: 0.1495\n",
      "Epoch [125/360], Batch [40/196], Loss: 0.0761\n",
      "Epoch [125/360], Batch [45/196], Loss: 0.0816\n",
      "Epoch [125/360], Batch [50/196], Loss: 0.0698\n",
      "Epoch [125/360], Batch [55/196], Loss: 0.0910\n",
      "Epoch [125/360], Batch [60/196], Loss: 0.1307\n",
      "Epoch [125/360], Batch [65/196], Loss: 0.0785\n",
      "Epoch [125/360], Batch [70/196], Loss: 0.0925\n",
      "Epoch [125/360], Batch [75/196], Loss: 0.0742\n",
      "Epoch [125/360], Batch [80/196], Loss: 0.1205\n",
      "Epoch [125/360], Batch [85/196], Loss: 0.0656\n",
      "Epoch [125/360], Batch [90/196], Loss: 0.0962\n",
      "Epoch [125/360], Batch [95/196], Loss: 0.1019\n",
      "Epoch [125/360], Batch [100/196], Loss: 0.1466\n",
      "Epoch [125/360], Batch [105/196], Loss: 0.1268\n",
      "Epoch [125/360], Batch [110/196], Loss: 0.1413\n",
      "Epoch [125/360], Batch [115/196], Loss: 0.0987\n",
      "Epoch [125/360], Batch [120/196], Loss: 0.1150\n",
      "Epoch [125/360], Batch [125/196], Loss: 0.0841\n",
      "Epoch [125/360], Batch [130/196], Loss: 0.0874\n",
      "Epoch [125/360], Batch [135/196], Loss: 0.2611\n",
      "Epoch [125/360], Batch [140/196], Loss: 0.2116\n",
      "Epoch [125/360], Batch [145/196], Loss: 0.2110\n",
      "Epoch [125/360], Batch [150/196], Loss: 0.1963\n",
      "Epoch [125/360], Batch [155/196], Loss: 0.1065\n",
      "Epoch [125/360], Batch [160/196], Loss: 0.1237\n",
      "Epoch [125/360], Batch [165/196], Loss: 0.0927\n",
      "Epoch [125/360], Batch [170/196], Loss: 0.1267\n",
      "Epoch [125/360], Batch [175/196], Loss: 0.1601\n",
      "Epoch [125/360], Batch [180/196], Loss: 0.1141\n",
      "Epoch [125/360], Batch [185/196], Loss: 0.1405\n",
      "Epoch [125/360], Batch [190/196], Loss: 0.1100\n",
      "Epoch [125/360], Batch [195/196], Loss: 0.1534\n",
      "Epoch [126/360], Batch [5/196], Loss: 0.0739\n",
      "Epoch [126/360], Batch [10/196], Loss: 0.0789\n",
      "Epoch [126/360], Batch [15/196], Loss: 0.0555\n",
      "Epoch [126/360], Batch [20/196], Loss: 0.0657\n",
      "Epoch [126/360], Batch [25/196], Loss: 0.1133\n",
      "Epoch [126/360], Batch [30/196], Loss: 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [126/360], Batch [35/196], Loss: 0.1332\n",
      "Epoch [126/360], Batch [40/196], Loss: 0.1025\n",
      "Epoch [126/360], Batch [45/196], Loss: 0.1195\n",
      "Epoch [126/360], Batch [50/196], Loss: 0.1356\n",
      "Epoch [126/360], Batch [55/196], Loss: 0.0948\n",
      "Epoch [126/360], Batch [60/196], Loss: 0.0751\n",
      "Epoch [126/360], Batch [65/196], Loss: 0.0848\n",
      "Epoch [126/360], Batch [70/196], Loss: 0.0886\n",
      "Epoch [126/360], Batch [75/196], Loss: 0.0877\n",
      "Epoch [126/360], Batch [80/196], Loss: 0.1515\n",
      "Epoch [126/360], Batch [85/196], Loss: 0.0820\n",
      "Epoch [126/360], Batch [90/196], Loss: 0.0732\n",
      "Epoch [126/360], Batch [95/196], Loss: 0.0747\n",
      "Epoch [126/360], Batch [100/196], Loss: 0.1080\n",
      "Epoch [126/360], Batch [105/196], Loss: 0.1780\n",
      "Epoch [126/360], Batch [110/196], Loss: 0.1380\n",
      "Epoch [126/360], Batch [115/196], Loss: 0.1212\n",
      "Epoch [126/360], Batch [120/196], Loss: 0.1467\n",
      "Epoch [126/360], Batch [125/196], Loss: 0.1441\n",
      "Epoch [126/360], Batch [130/196], Loss: 0.1383\n",
      "Epoch [126/360], Batch [135/196], Loss: 0.1012\n",
      "Epoch [126/360], Batch [140/196], Loss: 0.0998\n",
      "Epoch [126/360], Batch [145/196], Loss: 0.1693\n",
      "Epoch [126/360], Batch [150/196], Loss: 0.1216\n",
      "Epoch [126/360], Batch [155/196], Loss: 0.1078\n",
      "Epoch [126/360], Batch [160/196], Loss: 0.0981\n",
      "Epoch [126/360], Batch [165/196], Loss: 0.0982\n",
      "Epoch [126/360], Batch [170/196], Loss: 0.1272\n",
      "Epoch [126/360], Batch [175/196], Loss: 0.0815\n",
      "Epoch [126/360], Batch [180/196], Loss: 0.1086\n",
      "Epoch [126/360], Batch [185/196], Loss: 0.1398\n",
      "Epoch [126/360], Batch [190/196], Loss: 0.1102\n",
      "Epoch [126/360], Batch [195/196], Loss: 0.1058\n",
      "Epoch [127/360], Batch [5/196], Loss: 0.1400\n",
      "Epoch [127/360], Batch [10/196], Loss: 0.0850\n",
      "Epoch [127/360], Batch [15/196], Loss: 0.0913\n",
      "Epoch [127/360], Batch [20/196], Loss: 0.0991\n",
      "Epoch [127/360], Batch [25/196], Loss: 0.1115\n",
      "Epoch [127/360], Batch [30/196], Loss: 0.0999\n",
      "Epoch [127/360], Batch [35/196], Loss: 0.0729\n",
      "Epoch [127/360], Batch [40/196], Loss: 0.1350\n",
      "Epoch [127/360], Batch [45/196], Loss: 0.1602\n",
      "Epoch [127/360], Batch [50/196], Loss: 0.1372\n",
      "Epoch [127/360], Batch [55/196], Loss: 0.1578\n",
      "Epoch [127/360], Batch [60/196], Loss: 0.0840\n",
      "Epoch [127/360], Batch [65/196], Loss: 0.1221\n",
      "Epoch [127/360], Batch [70/196], Loss: 0.2171\n",
      "Epoch [127/360], Batch [75/196], Loss: 0.1873\n",
      "Epoch [127/360], Batch [80/196], Loss: 0.1594\n",
      "Epoch [127/360], Batch [85/196], Loss: 0.1676\n",
      "Epoch [127/360], Batch [90/196], Loss: 0.1602\n",
      "Epoch [127/360], Batch [95/196], Loss: 0.1556\n",
      "Epoch [127/360], Batch [100/196], Loss: 0.1721\n",
      "Epoch [127/360], Batch [105/196], Loss: 0.1620\n",
      "Epoch [127/360], Batch [110/196], Loss: 0.1120\n",
      "Epoch [127/360], Batch [115/196], Loss: 0.1453\n",
      "Epoch [127/360], Batch [120/196], Loss: 0.1930\n",
      "Epoch [127/360], Batch [125/196], Loss: 0.1334\n",
      "Epoch [127/360], Batch [130/196], Loss: 0.1720\n",
      "Epoch [127/360], Batch [135/196], Loss: 0.7096\n",
      "Epoch [127/360], Batch [140/196], Loss: 0.2344\n",
      "Epoch [127/360], Batch [145/196], Loss: 0.1563\n",
      "Epoch [127/360], Batch [150/196], Loss: 0.1313\n",
      "Epoch [127/360], Batch [155/196], Loss: 0.1396\n",
      "Epoch [127/360], Batch [160/196], Loss: 0.1553\n",
      "Epoch [127/360], Batch [165/196], Loss: 0.2020\n",
      "Epoch [127/360], Batch [170/196], Loss: 0.1863\n",
      "Epoch [127/360], Batch [175/196], Loss: 0.1532\n",
      "Epoch [127/360], Batch [180/196], Loss: 0.1198\n",
      "Epoch [127/360], Batch [185/196], Loss: 0.1211\n",
      "Epoch [127/360], Batch [190/196], Loss: 0.2211\n",
      "Epoch [127/360], Batch [195/196], Loss: 0.1273\n",
      "Epoch [128/360], Batch [5/196], Loss: 0.1083\n",
      "Epoch [128/360], Batch [10/196], Loss: 0.0980\n",
      "Epoch [128/360], Batch [15/196], Loss: 0.1410\n",
      "Epoch [128/360], Batch [20/196], Loss: 0.1326\n",
      "Epoch [128/360], Batch [25/196], Loss: 0.0750\n",
      "Epoch [128/360], Batch [30/196], Loss: 0.1468\n",
      "Epoch [128/360], Batch [35/196], Loss: 0.1069\n",
      "Epoch [128/360], Batch [40/196], Loss: 0.1437\n",
      "Epoch [128/360], Batch [45/196], Loss: 0.1537\n",
      "Epoch [128/360], Batch [50/196], Loss: 0.0944\n",
      "Epoch [128/360], Batch [55/196], Loss: 0.1275\n",
      "Epoch [128/360], Batch [60/196], Loss: 0.1934\n",
      "Epoch [128/360], Batch [65/196], Loss: 0.1542\n",
      "Epoch [128/360], Batch [70/196], Loss: 0.1323\n",
      "Epoch [128/360], Batch [75/196], Loss: 0.1178\n",
      "Epoch [128/360], Batch [80/196], Loss: 0.1388\n",
      "Epoch [128/360], Batch [85/196], Loss: 0.1457\n",
      "Epoch [128/360], Batch [90/196], Loss: 0.0773\n",
      "Epoch [128/360], Batch [95/196], Loss: 0.1385\n",
      "Epoch [128/360], Batch [100/196], Loss: 0.1514\n",
      "Epoch [128/360], Batch [105/196], Loss: 0.1252\n",
      "Epoch [128/360], Batch [110/196], Loss: 0.0885\n",
      "Epoch [128/360], Batch [115/196], Loss: 0.1385\n",
      "Epoch [128/360], Batch [120/196], Loss: 0.0909\n",
      "Epoch [128/360], Batch [125/196], Loss: 0.1783\n",
      "Epoch [128/360], Batch [130/196], Loss: 0.1453\n",
      "Epoch [128/360], Batch [135/196], Loss: 0.1314\n",
      "Epoch [128/360], Batch [140/196], Loss: 0.1157\n",
      "Epoch [128/360], Batch [145/196], Loss: 0.1472\n",
      "Epoch [128/360], Batch [150/196], Loss: 0.1012\n",
      "Epoch [128/360], Batch [155/196], Loss: 0.1025\n",
      "Epoch [128/360], Batch [160/196], Loss: 0.1064\n",
      "Epoch [128/360], Batch [165/196], Loss: 0.1097\n",
      "Epoch [128/360], Batch [170/196], Loss: 0.1002\n",
      "Epoch [128/360], Batch [175/196], Loss: 0.1327\n",
      "Epoch [128/360], Batch [180/196], Loss: 0.1334\n",
      "Epoch [128/360], Batch [185/196], Loss: 0.1489\n",
      "Epoch [128/360], Batch [190/196], Loss: 0.1758\n",
      "Epoch [128/360], Batch [195/196], Loss: 0.1373\n",
      "Epoch [129/360], Batch [5/196], Loss: 0.1118\n",
      "Epoch [129/360], Batch [10/196], Loss: 0.0984\n",
      "Epoch [129/360], Batch [15/196], Loss: 0.1166\n",
      "Epoch [129/360], Batch [20/196], Loss: 0.1089\n",
      "Epoch [129/360], Batch [25/196], Loss: 0.0763\n",
      "Epoch [129/360], Batch [30/196], Loss: 0.1008\n",
      "Epoch [129/360], Batch [35/196], Loss: 0.0705\n",
      "Epoch [129/360], Batch [40/196], Loss: 0.0956\n",
      "Epoch [129/360], Batch [45/196], Loss: 0.0957\n",
      "Epoch [129/360], Batch [50/196], Loss: 0.0954\n",
      "Epoch [129/360], Batch [55/196], Loss: 0.0844\n",
      "Epoch [129/360], Batch [60/196], Loss: 0.1082\n",
      "Epoch [129/360], Batch [65/196], Loss: 0.0978\n",
      "Epoch [129/360], Batch [70/196], Loss: 0.1250\n",
      "Epoch [129/360], Batch [75/196], Loss: 0.1288\n",
      "Epoch [129/360], Batch [80/196], Loss: 0.0853\n",
      "Epoch [129/360], Batch [85/196], Loss: 0.1119\n",
      "Epoch [129/360], Batch [90/196], Loss: 0.1370\n",
      "Epoch [129/360], Batch [95/196], Loss: 0.1122\n",
      "Epoch [129/360], Batch [100/196], Loss: 0.0903\n",
      "Epoch [129/360], Batch [105/196], Loss: 0.0974\n",
      "Epoch [129/360], Batch [110/196], Loss: 0.0733\n",
      "Epoch [129/360], Batch [115/196], Loss: 0.0986\n",
      "Epoch [129/360], Batch [120/196], Loss: 0.1121\n",
      "Epoch [129/360], Batch [125/196], Loss: 0.0805\n",
      "Epoch [129/360], Batch [130/196], Loss: 0.0906\n",
      "Epoch [129/360], Batch [135/196], Loss: 0.0962\n",
      "Epoch [129/360], Batch [140/196], Loss: 0.1132\n",
      "Epoch [129/360], Batch [145/196], Loss: 0.1096\n",
      "Epoch [129/360], Batch [150/196], Loss: 0.1048\n",
      "Epoch [129/360], Batch [155/196], Loss: 0.0822\n",
      "Epoch [129/360], Batch [160/196], Loss: 0.0991\n",
      "Epoch [129/360], Batch [165/196], Loss: 0.1325\n",
      "Epoch [129/360], Batch [170/196], Loss: 0.0925\n",
      "Epoch [129/360], Batch [175/196], Loss: 0.0612\n",
      "Epoch [129/360], Batch [180/196], Loss: 0.1055\n",
      "Epoch [129/360], Batch [185/196], Loss: 0.0796\n",
      "Epoch [129/360], Batch [190/196], Loss: 0.1146\n",
      "Epoch [129/360], Batch [195/196], Loss: 0.0943\n",
      "Epoch [130/360], Batch [5/196], Loss: 0.0677\n",
      "Epoch [130/360], Batch [10/196], Loss: 0.1234\n",
      "Epoch [130/360], Batch [15/196], Loss: 0.0794\n",
      "Epoch [130/360], Batch [20/196], Loss: 0.1304\n",
      "Epoch [130/360], Batch [25/196], Loss: 0.1087\n",
      "Epoch [130/360], Batch [30/196], Loss: 0.0973\n",
      "Epoch [130/360], Batch [35/196], Loss: 0.1071\n",
      "Epoch [130/360], Batch [40/196], Loss: 0.0935\n",
      "Epoch [130/360], Batch [45/196], Loss: 0.0933\n",
      "Epoch [130/360], Batch [50/196], Loss: 0.0990\n",
      "Epoch [130/360], Batch [55/196], Loss: 0.0996\n",
      "Epoch [130/360], Batch [60/196], Loss: 0.1051\n",
      "Epoch [130/360], Batch [65/196], Loss: 0.1323\n",
      "Epoch [130/360], Batch [70/196], Loss: 0.0656\n",
      "Epoch [130/360], Batch [75/196], Loss: 0.1106\n",
      "Epoch [130/360], Batch [80/196], Loss: 0.0781\n",
      "Epoch [130/360], Batch [85/196], Loss: 0.0675\n",
      "Epoch [130/360], Batch [90/196], Loss: 0.0679\n",
      "Epoch [130/360], Batch [95/196], Loss: 0.0987\n",
      "Epoch [130/360], Batch [100/196], Loss: 0.1351\n",
      "Epoch [130/360], Batch [105/196], Loss: 0.1055\n",
      "Epoch [130/360], Batch [110/196], Loss: 0.1151\n",
      "Epoch [130/360], Batch [115/196], Loss: 0.1108\n",
      "Epoch [130/360], Batch [120/196], Loss: 0.0979\n",
      "Epoch [130/360], Batch [125/196], Loss: 0.0906\n",
      "Epoch [130/360], Batch [130/196], Loss: 0.1298\n",
      "Epoch [130/360], Batch [135/196], Loss: 0.0893\n",
      "Epoch [130/360], Batch [140/196], Loss: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [130/360], Batch [145/196], Loss: 0.1215\n",
      "Epoch [130/360], Batch [150/196], Loss: 0.1052\n",
      "Epoch [130/360], Batch [155/196], Loss: 0.1083\n",
      "Epoch [130/360], Batch [160/196], Loss: 0.0941\n",
      "Epoch [130/360], Batch [165/196], Loss: 0.0978\n",
      "Epoch [130/360], Batch [170/196], Loss: 0.1182\n",
      "Epoch [130/360], Batch [175/196], Loss: 0.1426\n",
      "Epoch [130/360], Batch [180/196], Loss: 0.1194\n",
      "Epoch [130/360], Batch [185/196], Loss: 0.0917\n",
      "Epoch [130/360], Batch [190/196], Loss: 0.0843\n",
      "Epoch [130/360], Batch [195/196], Loss: 0.0875\n",
      "Epoch [131/360], Batch [5/196], Loss: 0.1015\n",
      "Epoch [131/360], Batch [10/196], Loss: 0.0860\n",
      "Epoch [131/360], Batch [15/196], Loss: 0.0818\n",
      "Epoch [131/360], Batch [20/196], Loss: 0.0683\n",
      "Epoch [131/360], Batch [25/196], Loss: 0.0620\n",
      "Epoch [131/360], Batch [30/196], Loss: 0.0945\n",
      "Epoch [131/360], Batch [35/196], Loss: 0.1143\n",
      "Epoch [131/360], Batch [40/196], Loss: 0.0799\n",
      "Epoch [131/360], Batch [45/196], Loss: 0.1093\n",
      "Epoch [131/360], Batch [50/196], Loss: 0.0782\n",
      "Epoch [131/360], Batch [55/196], Loss: 0.1024\n",
      "Epoch [131/360], Batch [60/196], Loss: 0.0889\n",
      "Epoch [131/360], Batch [65/196], Loss: 0.1280\n",
      "Epoch [131/360], Batch [70/196], Loss: 0.0648\n",
      "Epoch [131/360], Batch [75/196], Loss: 0.0689\n",
      "Epoch [131/360], Batch [80/196], Loss: 0.0880\n",
      "Epoch [131/360], Batch [85/196], Loss: 0.0710\n",
      "Epoch [131/360], Batch [90/196], Loss: 0.0674\n",
      "Epoch [131/360], Batch [95/196], Loss: 0.0839\n",
      "Epoch [131/360], Batch [100/196], Loss: 0.1473\n",
      "Epoch [131/360], Batch [105/196], Loss: 0.1116\n",
      "Epoch [131/360], Batch [110/196], Loss: 0.1072\n",
      "Epoch [131/360], Batch [115/196], Loss: 0.1040\n",
      "Epoch [131/360], Batch [120/196], Loss: 0.1053\n",
      "Epoch [131/360], Batch [125/196], Loss: 0.1161\n",
      "Epoch [131/360], Batch [130/196], Loss: 0.1048\n",
      "Epoch [131/360], Batch [135/196], Loss: 0.0844\n",
      "Epoch [131/360], Batch [140/196], Loss: 0.1095\n",
      "Epoch [131/360], Batch [145/196], Loss: 0.1007\n",
      "Epoch [131/360], Batch [150/196], Loss: 0.0964\n",
      "Epoch [131/360], Batch [155/196], Loss: 0.1034\n",
      "Epoch [131/360], Batch [160/196], Loss: 0.0987\n",
      "Epoch [131/360], Batch [165/196], Loss: 0.0811\n",
      "Epoch [131/360], Batch [170/196], Loss: 0.0995\n",
      "Epoch [131/360], Batch [175/196], Loss: 0.0870\n",
      "Epoch [131/360], Batch [180/196], Loss: 0.0755\n",
      "Epoch [131/360], Batch [185/196], Loss: 0.1198\n",
      "Epoch [131/360], Batch [190/196], Loss: 0.0732\n",
      "Epoch [131/360], Batch [195/196], Loss: 0.0758\n",
      "Epoch [132/360], Batch [5/196], Loss: 0.0800\n",
      "Epoch [132/360], Batch [10/196], Loss: 0.0612\n",
      "Epoch [132/360], Batch [15/196], Loss: 0.0572\n",
      "Epoch [132/360], Batch [20/196], Loss: 0.0957\n",
      "Epoch [132/360], Batch [25/196], Loss: 0.0852\n",
      "Epoch [132/360], Batch [30/196], Loss: 0.1306\n",
      "Epoch [132/360], Batch [35/196], Loss: 0.0665\n",
      "Epoch [132/360], Batch [40/196], Loss: 0.0713\n",
      "Epoch [132/360], Batch [45/196], Loss: 0.0954\n",
      "Epoch [132/360], Batch [50/196], Loss: 0.0621\n",
      "Epoch [132/360], Batch [55/196], Loss: 0.0751\n",
      "Epoch [132/360], Batch [60/196], Loss: 0.1008\n",
      "Epoch [132/360], Batch [65/196], Loss: 0.0855\n",
      "Epoch [132/360], Batch [70/196], Loss: 0.0636\n",
      "Epoch [132/360], Batch [75/196], Loss: 0.0652\n",
      "Epoch [132/360], Batch [80/196], Loss: 0.0876\n",
      "Epoch [132/360], Batch [85/196], Loss: 0.0812\n",
      "Epoch [132/360], Batch [90/196], Loss: 0.0930\n",
      "Epoch [132/360], Batch [95/196], Loss: 0.1200\n",
      "Epoch [132/360], Batch [100/196], Loss: 0.0715\n",
      "Epoch [132/360], Batch [105/196], Loss: 0.0510\n",
      "Epoch [132/360], Batch [110/196], Loss: 0.1203\n",
      "Epoch [132/360], Batch [115/196], Loss: 0.0842\n",
      "Epoch [132/360], Batch [120/196], Loss: 0.0880\n",
      "Epoch [132/360], Batch [125/196], Loss: 0.0807\n",
      "Epoch [132/360], Batch [130/196], Loss: 0.0873\n",
      "Epoch [132/360], Batch [135/196], Loss: 0.1011\n",
      "Epoch [132/360], Batch [140/196], Loss: 0.0920\n",
      "Epoch [132/360], Batch [145/196], Loss: 0.0697\n",
      "Epoch [132/360], Batch [150/196], Loss: 0.1344\n",
      "Epoch [132/360], Batch [155/196], Loss: 0.0762\n",
      "Epoch [132/360], Batch [160/196], Loss: 0.0936\n",
      "Epoch [132/360], Batch [165/196], Loss: 0.0837\n",
      "Epoch [132/360], Batch [170/196], Loss: 0.1021\n",
      "Epoch [132/360], Batch [175/196], Loss: 0.0558\n",
      "Epoch [132/360], Batch [180/196], Loss: 0.0878\n",
      "Epoch [132/360], Batch [185/196], Loss: 0.0778\n",
      "Epoch [132/360], Batch [190/196], Loss: 0.0764\n",
      "Epoch [132/360], Batch [195/196], Loss: 0.0834\n",
      "Epoch [133/360], Batch [5/196], Loss: 0.0572\n",
      "Epoch [133/360], Batch [10/196], Loss: 0.0549\n",
      "Epoch [133/360], Batch [15/196], Loss: 0.1203\n",
      "Epoch [133/360], Batch [20/196], Loss: 0.0759\n",
      "Epoch [133/360], Batch [25/196], Loss: 0.0573\n",
      "Epoch [133/360], Batch [30/196], Loss: 0.0953\n",
      "Epoch [133/360], Batch [35/196], Loss: 0.0937\n",
      "Epoch [133/360], Batch [40/196], Loss: 0.0766\n",
      "Epoch [133/360], Batch [45/196], Loss: 0.0587\n",
      "Epoch [133/360], Batch [50/196], Loss: 0.1169\n",
      "Epoch [133/360], Batch [55/196], Loss: 0.0600\n",
      "Epoch [133/360], Batch [60/196], Loss: 0.0606\n",
      "Epoch [133/360], Batch [65/196], Loss: 0.0788\n",
      "Epoch [133/360], Batch [70/196], Loss: 0.0670\n",
      "Epoch [133/360], Batch [75/196], Loss: 0.0566\n",
      "Epoch [133/360], Batch [80/196], Loss: 0.0736\n",
      "Epoch [133/360], Batch [85/196], Loss: 0.0777\n",
      "Epoch [133/360], Batch [90/196], Loss: 0.0914\n",
      "Epoch [133/360], Batch [95/196], Loss: 0.0871\n",
      "Epoch [133/360], Batch [100/196], Loss: 0.0787\n",
      "Epoch [133/360], Batch [105/196], Loss: 0.0661\n",
      "Epoch [133/360], Batch [110/196], Loss: 0.4947\n",
      "Epoch [133/360], Batch [115/196], Loss: 0.0895\n",
      "Epoch [133/360], Batch [120/196], Loss: 0.0793\n",
      "Epoch [133/360], Batch [125/196], Loss: 0.0793\n",
      "Epoch [133/360], Batch [130/196], Loss: 0.0683\n",
      "Epoch [133/360], Batch [135/196], Loss: 0.0900\n",
      "Epoch [133/360], Batch [140/196], Loss: 0.0833\n",
      "Epoch [133/360], Batch [145/196], Loss: 0.0609\n",
      "Epoch [133/360], Batch [150/196], Loss: 0.0827\n",
      "Epoch [133/360], Batch [155/196], Loss: 0.0883\n",
      "Epoch [133/360], Batch [160/196], Loss: 0.0714\n",
      "Epoch [133/360], Batch [165/196], Loss: 0.0926\n",
      "Epoch [133/360], Batch [170/196], Loss: 0.0638\n",
      "Epoch [133/360], Batch [175/196], Loss: 0.0881\n",
      "Epoch [133/360], Batch [180/196], Loss: 0.1042\n",
      "Epoch [133/360], Batch [185/196], Loss: 0.1012\n",
      "Epoch [133/360], Batch [190/196], Loss: 0.0825\n",
      "Epoch [133/360], Batch [195/196], Loss: 0.0733\n",
      "Epoch [134/360], Batch [5/196], Loss: 0.0610\n",
      "Epoch [134/360], Batch [10/196], Loss: 0.0636\n",
      "Epoch [134/360], Batch [15/196], Loss: 0.0665\n",
      "Epoch [134/360], Batch [20/196], Loss: 0.0554\n",
      "Epoch [134/360], Batch [25/196], Loss: 0.0710\n",
      "Epoch [134/360], Batch [30/196], Loss: 0.0789\n",
      "Epoch [134/360], Batch [35/196], Loss: 0.0572\n",
      "Epoch [134/360], Batch [40/196], Loss: 0.0580\n",
      "Epoch [134/360], Batch [45/196], Loss: 0.0989\n",
      "Epoch [134/360], Batch [50/196], Loss: 0.0690\n",
      "Epoch [134/360], Batch [55/196], Loss: 0.0770\n",
      "Epoch [134/360], Batch [60/196], Loss: 0.0940\n",
      "Epoch [134/360], Batch [65/196], Loss: 0.0861\n",
      "Epoch [134/360], Batch [70/196], Loss: 0.0870\n",
      "Epoch [134/360], Batch [75/196], Loss: 0.0805\n",
      "Epoch [134/360], Batch [80/196], Loss: 0.0741\n",
      "Epoch [134/360], Batch [85/196], Loss: 0.0824\n",
      "Epoch [134/360], Batch [90/196], Loss: 0.0957\n",
      "Epoch [134/360], Batch [95/196], Loss: 0.0713\n",
      "Epoch [134/360], Batch [100/196], Loss: 0.0818\n",
      "Epoch [134/360], Batch [105/196], Loss: 0.0808\n",
      "Epoch [134/360], Batch [110/196], Loss: 0.0854\n",
      "Epoch [134/360], Batch [115/196], Loss: 0.0562\n",
      "Epoch [134/360], Batch [120/196], Loss: 0.0805\n",
      "Epoch [134/360], Batch [125/196], Loss: 0.0773\n",
      "Epoch [134/360], Batch [130/196], Loss: 0.0769\n",
      "Epoch [134/360], Batch [135/196], Loss: 0.0999\n",
      "Epoch [134/360], Batch [140/196], Loss: 0.0735\n",
      "Epoch [134/360], Batch [145/196], Loss: 0.0828\n",
      "Epoch [134/360], Batch [150/196], Loss: 0.0697\n",
      "Epoch [134/360], Batch [155/196], Loss: 0.0796\n",
      "Epoch [134/360], Batch [160/196], Loss: 0.0784\n",
      "Epoch [134/360], Batch [165/196], Loss: 0.1001\n",
      "Epoch [134/360], Batch [170/196], Loss: 0.1056\n",
      "Epoch [134/360], Batch [175/196], Loss: 0.1243\n",
      "Epoch [134/360], Batch [180/196], Loss: 0.1337\n",
      "Epoch [134/360], Batch [185/196], Loss: 0.0654\n",
      "Epoch [134/360], Batch [190/196], Loss: 0.0527\n",
      "Epoch [134/360], Batch [195/196], Loss: 0.0672\n",
      "Epoch [135/360], Batch [5/196], Loss: 0.0693\n",
      "Epoch [135/360], Batch [10/196], Loss: 0.0596\n",
      "Epoch [135/360], Batch [15/196], Loss: 0.0774\n",
      "Epoch [135/360], Batch [20/196], Loss: 0.0545\n",
      "Epoch [135/360], Batch [25/196], Loss: 0.1006\n",
      "Epoch [135/360], Batch [30/196], Loss: 0.0463\n",
      "Epoch [135/360], Batch [35/196], Loss: 0.0541\n",
      "Epoch [135/360], Batch [40/196], Loss: 0.0587\n",
      "Epoch [135/360], Batch [45/196], Loss: 0.0603\n",
      "Epoch [135/360], Batch [50/196], Loss: 0.0890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [135/360], Batch [55/196], Loss: 0.0737\n",
      "Epoch [135/360], Batch [60/196], Loss: 0.1115\n",
      "Epoch [135/360], Batch [65/196], Loss: 0.0627\n",
      "Epoch [135/360], Batch [70/196], Loss: 0.0843\n",
      "Epoch [135/360], Batch [75/196], Loss: 0.0493\n",
      "Epoch [135/360], Batch [80/196], Loss: 0.0813\n",
      "Epoch [135/360], Batch [85/196], Loss: 0.1080\n",
      "Epoch [135/360], Batch [90/196], Loss: 0.1112\n",
      "Epoch [135/360], Batch [95/196], Loss: 0.1099\n",
      "Epoch [135/360], Batch [100/196], Loss: 0.1078\n",
      "Epoch [135/360], Batch [105/196], Loss: 0.1046\n",
      "Epoch [135/360], Batch [110/196], Loss: 0.0938\n",
      "Epoch [135/360], Batch [115/196], Loss: 0.0733\n",
      "Epoch [135/360], Batch [120/196], Loss: 0.0726\n",
      "Epoch [135/360], Batch [125/196], Loss: 0.0910\n",
      "Epoch [135/360], Batch [130/196], Loss: 0.1262\n",
      "Epoch [135/360], Batch [135/196], Loss: 0.0835\n",
      "Epoch [135/360], Batch [140/196], Loss: 0.1039\n",
      "Epoch [135/360], Batch [145/196], Loss: 0.1450\n",
      "Epoch [135/360], Batch [150/196], Loss: 0.1156\n",
      "Epoch [135/360], Batch [155/196], Loss: 0.1017\n",
      "Epoch [135/360], Batch [160/196], Loss: 0.1358\n",
      "Epoch [135/360], Batch [165/196], Loss: 0.1106\n",
      "Epoch [135/360], Batch [170/196], Loss: 0.1645\n",
      "Epoch [135/360], Batch [175/196], Loss: 0.1158\n",
      "Epoch [135/360], Batch [180/196], Loss: 0.1126\n",
      "Epoch [135/360], Batch [185/196], Loss: 0.1343\n",
      "Epoch [135/360], Batch [190/196], Loss: 0.1310\n",
      "Epoch [135/360], Batch [195/196], Loss: 0.0930\n",
      "Epoch [136/360], Batch [5/196], Loss: 0.0858\n",
      "Epoch [136/360], Batch [10/196], Loss: 0.0697\n",
      "Epoch [136/360], Batch [15/196], Loss: 0.1228\n",
      "Epoch [136/360], Batch [20/196], Loss: 0.0872\n",
      "Epoch [136/360], Batch [25/196], Loss: 0.0929\n",
      "Epoch [136/360], Batch [30/196], Loss: 0.1364\n",
      "Epoch [136/360], Batch [35/196], Loss: 0.1190\n",
      "Epoch [136/360], Batch [40/196], Loss: 0.0889\n",
      "Epoch [136/360], Batch [45/196], Loss: 0.0706\n",
      "Epoch [136/360], Batch [50/196], Loss: 0.1139\n",
      "Epoch [136/360], Batch [55/196], Loss: 0.1941\n",
      "Epoch [136/360], Batch [60/196], Loss: 0.1154\n",
      "Epoch [136/360], Batch [65/196], Loss: 0.1207\n",
      "Epoch [136/360], Batch [70/196], Loss: 0.1223\n",
      "Epoch [136/360], Batch [75/196], Loss: 0.1260\n",
      "Epoch [136/360], Batch [80/196], Loss: 0.1261\n",
      "Epoch [136/360], Batch [85/196], Loss: 0.0977\n",
      "Epoch [136/360], Batch [90/196], Loss: 0.1351\n",
      "Epoch [136/360], Batch [95/196], Loss: 0.1445\n",
      "Epoch [136/360], Batch [100/196], Loss: 0.0809\n",
      "Epoch [136/360], Batch [105/196], Loss: 0.1219\n",
      "Epoch [136/360], Batch [110/196], Loss: 0.0918\n",
      "Epoch [136/360], Batch [115/196], Loss: 0.1336\n",
      "Epoch [136/360], Batch [120/196], Loss: 0.0954\n",
      "Epoch [136/360], Batch [125/196], Loss: 0.0692\n",
      "Epoch [136/360], Batch [130/196], Loss: 0.1727\n",
      "Epoch [136/360], Batch [135/196], Loss: 0.0866\n",
      "Epoch [136/360], Batch [140/196], Loss: 0.0592\n",
      "Epoch [136/360], Batch [145/196], Loss: 0.1374\n",
      "Epoch [136/360], Batch [150/196], Loss: 0.1087\n",
      "Epoch [136/360], Batch [155/196], Loss: 0.1060\n",
      "Epoch [136/360], Batch [160/196], Loss: 0.4479\n",
      "Epoch [136/360], Batch [165/196], Loss: 0.3682\n",
      "Epoch [136/360], Batch [170/196], Loss: 0.3063\n",
      "Epoch [136/360], Batch [175/196], Loss: 0.3182\n",
      "Epoch [136/360], Batch [180/196], Loss: 0.1165\n",
      "Epoch [136/360], Batch [185/196], Loss: 0.1374\n",
      "Epoch [136/360], Batch [190/196], Loss: 0.2328\n",
      "Epoch [136/360], Batch [195/196], Loss: 0.1453\n",
      "Epoch [137/360], Batch [5/196], Loss: 0.1187\n",
      "Epoch [137/360], Batch [10/196], Loss: 0.2122\n",
      "Epoch [137/360], Batch [15/196], Loss: 0.2058\n",
      "Epoch [137/360], Batch [20/196], Loss: 0.1396\n",
      "Epoch [137/360], Batch [25/196], Loss: 0.1811\n",
      "Epoch [137/360], Batch [30/196], Loss: 0.0961\n",
      "Epoch [137/360], Batch [35/196], Loss: 0.1549\n",
      "Epoch [137/360], Batch [40/196], Loss: 0.2081\n",
      "Epoch [137/360], Batch [45/196], Loss: 0.1774\n",
      "Epoch [137/360], Batch [50/196], Loss: 0.1120\n",
      "Epoch [137/360], Batch [55/196], Loss: 0.1044\n",
      "Epoch [137/360], Batch [60/196], Loss: 0.1312\n",
      "Epoch [137/360], Batch [65/196], Loss: 0.1121\n",
      "Epoch [137/360], Batch [70/196], Loss: 0.1098\n",
      "Epoch [137/360], Batch [75/196], Loss: 0.1834\n",
      "Epoch [137/360], Batch [80/196], Loss: 0.1068\n",
      "Epoch [137/360], Batch [85/196], Loss: 0.1478\n",
      "Epoch [137/360], Batch [90/196], Loss: 0.0940\n",
      "Epoch [137/360], Batch [95/196], Loss: 0.1233\n",
      "Epoch [137/360], Batch [100/196], Loss: 0.1063\n",
      "Epoch [137/360], Batch [105/196], Loss: 0.1116\n",
      "Epoch [137/360], Batch [110/196], Loss: 0.1194\n",
      "Epoch [137/360], Batch [115/196], Loss: 0.0996\n",
      "Epoch [137/360], Batch [120/196], Loss: 0.1687\n",
      "Epoch [137/360], Batch [125/196], Loss: 0.1528\n",
      "Epoch [137/360], Batch [130/196], Loss: 0.1127\n",
      "Epoch [137/360], Batch [135/196], Loss: 0.1069\n",
      "Epoch [137/360], Batch [140/196], Loss: 0.1416\n",
      "Epoch [137/360], Batch [145/196], Loss: 0.1285\n",
      "Epoch [137/360], Batch [150/196], Loss: 0.0952\n",
      "Epoch [137/360], Batch [155/196], Loss: 0.1373\n",
      "Epoch [137/360], Batch [160/196], Loss: 0.1553\n",
      "Epoch [137/360], Batch [165/196], Loss: 0.2098\n",
      "Epoch [137/360], Batch [170/196], Loss: 0.0835\n",
      "Epoch [137/360], Batch [175/196], Loss: 0.1451\n",
      "Epoch [137/360], Batch [180/196], Loss: 0.1874\n",
      "Epoch [137/360], Batch [185/196], Loss: 0.0938\n",
      "Epoch [137/360], Batch [190/196], Loss: 0.1239\n",
      "Epoch [137/360], Batch [195/196], Loss: 0.1074\n",
      "Epoch [138/360], Batch [5/196], Loss: 0.1030\n",
      "Epoch [138/360], Batch [10/196], Loss: 0.0636\n",
      "Epoch [138/360], Batch [15/196], Loss: 0.0565\n",
      "Epoch [138/360], Batch [20/196], Loss: 0.1094\n",
      "Epoch [138/360], Batch [25/196], Loss: 0.0543\n",
      "Epoch [138/360], Batch [30/196], Loss: 0.0835\n",
      "Epoch [138/360], Batch [35/196], Loss: 0.0992\n",
      "Epoch [138/360], Batch [40/196], Loss: 0.0671\n",
      "Epoch [138/360], Batch [45/196], Loss: 0.0831\n",
      "Epoch [138/360], Batch [50/196], Loss: 0.0993\n",
      "Epoch [138/360], Batch [55/196], Loss: 0.0438\n",
      "Epoch [138/360], Batch [60/196], Loss: 0.0724\n",
      "Epoch [138/360], Batch [65/196], Loss: 0.1576\n",
      "Epoch [138/360], Batch [70/196], Loss: 0.0583\n",
      "Epoch [138/360], Batch [75/196], Loss: 0.0732\n",
      "Epoch [138/360], Batch [80/196], Loss: 0.1108\n",
      "Epoch [138/360], Batch [85/196], Loss: 0.0787\n",
      "Epoch [138/360], Batch [90/196], Loss: 0.0918\n",
      "Epoch [138/360], Batch [95/196], Loss: 0.0567\n",
      "Epoch [138/360], Batch [100/196], Loss: 0.0736\n",
      "Epoch [138/360], Batch [105/196], Loss: 0.0755\n",
      "Epoch [138/360], Batch [110/196], Loss: 0.1106\n",
      "Epoch [138/360], Batch [115/196], Loss: 0.1022\n",
      "Epoch [138/360], Batch [120/196], Loss: 0.1030\n",
      "Epoch [138/360], Batch [125/196], Loss: 0.1082\n",
      "Epoch [138/360], Batch [130/196], Loss: 0.0722\n",
      "Epoch [138/360], Batch [135/196], Loss: 0.0863\n",
      "Epoch [138/360], Batch [140/196], Loss: 0.0724\n",
      "Epoch [138/360], Batch [145/196], Loss: 0.0788\n",
      "Epoch [138/360], Batch [150/196], Loss: 0.0681\n",
      "Epoch [138/360], Batch [155/196], Loss: 0.0761\n",
      "Epoch [138/360], Batch [160/196], Loss: 0.0781\n",
      "Epoch [138/360], Batch [165/196], Loss: 0.0994\n",
      "Epoch [138/360], Batch [170/196], Loss: 0.0800\n",
      "Epoch [138/360], Batch [175/196], Loss: 0.0614\n",
      "Epoch [138/360], Batch [180/196], Loss: 0.1176\n",
      "Epoch [138/360], Batch [185/196], Loss: 0.5268\n",
      "Epoch [138/360], Batch [190/196], Loss: 0.0730\n",
      "Epoch [138/360], Batch [195/196], Loss: 0.0693\n",
      "Epoch [139/360], Batch [5/196], Loss: 0.0667\n",
      "Epoch [139/360], Batch [10/196], Loss: 0.1307\n",
      "Epoch [139/360], Batch [15/196], Loss: 0.0808\n",
      "Epoch [139/360], Batch [20/196], Loss: 0.0726\n",
      "Epoch [139/360], Batch [25/196], Loss: 0.0607\n",
      "Epoch [139/360], Batch [30/196], Loss: 0.0743\n",
      "Epoch [139/360], Batch [35/196], Loss: 0.0561\n",
      "Epoch [139/360], Batch [40/196], Loss: 0.0794\n",
      "Epoch [139/360], Batch [45/196], Loss: 0.0602\n",
      "Epoch [139/360], Batch [50/196], Loss: 0.0423\n",
      "Epoch [139/360], Batch [55/196], Loss: 0.0686\n",
      "Epoch [139/360], Batch [60/196], Loss: 0.0781\n",
      "Epoch [139/360], Batch [65/196], Loss: 0.0982\n",
      "Epoch [139/360], Batch [70/196], Loss: 0.0539\n",
      "Epoch [139/360], Batch [75/196], Loss: 0.0518\n",
      "Epoch [139/360], Batch [80/196], Loss: 0.0513\n",
      "Epoch [139/360], Batch [85/196], Loss: 0.0555\n",
      "Epoch [139/360], Batch [90/196], Loss: 0.0436\n",
      "Epoch [139/360], Batch [95/196], Loss: 0.0889\n",
      "Epoch [139/360], Batch [100/196], Loss: 0.0791\n",
      "Epoch [139/360], Batch [105/196], Loss: 0.0761\n",
      "Epoch [139/360], Batch [110/196], Loss: 0.0808\n",
      "Epoch [139/360], Batch [115/196], Loss: 0.0840\n",
      "Epoch [139/360], Batch [120/196], Loss: 0.0846\n",
      "Epoch [139/360], Batch [125/196], Loss: 0.0571\n",
      "Epoch [139/360], Batch [130/196], Loss: 0.0870\n",
      "Epoch [139/360], Batch [135/196], Loss: 0.0597\n",
      "Epoch [139/360], Batch [140/196], Loss: 0.0569\n",
      "Epoch [139/360], Batch [145/196], Loss: 0.0682\n",
      "Epoch [139/360], Batch [150/196], Loss: 0.0662\n",
      "Epoch [139/360], Batch [155/196], Loss: 0.0630\n",
      "Epoch [139/360], Batch [160/196], Loss: 0.0752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [139/360], Batch [165/196], Loss: 0.0746\n",
      "Epoch [139/360], Batch [170/196], Loss: 0.0603\n",
      "Epoch [139/360], Batch [175/196], Loss: 0.0735\n",
      "Epoch [139/360], Batch [180/196], Loss: 0.0952\n",
      "Epoch [139/360], Batch [185/196], Loss: 0.0625\n",
      "Epoch [139/360], Batch [190/196], Loss: 0.0568\n",
      "Epoch [139/360], Batch [195/196], Loss: 0.0795\n",
      "Epoch [140/360], Batch [5/196], Loss: 0.0556\n",
      "Epoch [140/360], Batch [10/196], Loss: 0.0750\n",
      "Epoch [140/360], Batch [15/196], Loss: 0.0854\n",
      "Epoch [140/360], Batch [20/196], Loss: 0.0618\n",
      "Epoch [140/360], Batch [25/196], Loss: 0.0737\n",
      "Epoch [140/360], Batch [30/196], Loss: 0.0640\n",
      "Epoch [140/360], Batch [35/196], Loss: 0.0621\n",
      "Epoch [140/360], Batch [40/196], Loss: 0.0483\n",
      "Epoch [140/360], Batch [45/196], Loss: 0.0484\n",
      "Epoch [140/360], Batch [50/196], Loss: 0.0493\n",
      "Epoch [140/360], Batch [55/196], Loss: 0.0458\n",
      "Epoch [140/360], Batch [60/196], Loss: 0.0443\n",
      "Epoch [140/360], Batch [65/196], Loss: 0.0616\n",
      "Epoch [140/360], Batch [70/196], Loss: 0.0748\n",
      "Epoch [140/360], Batch [75/196], Loss: 0.0550\n",
      "Epoch [140/360], Batch [80/196], Loss: 0.0652\n",
      "Epoch [140/360], Batch [85/196], Loss: 0.0550\n",
      "Epoch [140/360], Batch [90/196], Loss: 0.0722\n",
      "Epoch [140/360], Batch [95/196], Loss: 0.0541\n",
      "Epoch [140/360], Batch [100/196], Loss: 0.0395\n",
      "Epoch [140/360], Batch [105/196], Loss: 0.0642\n",
      "Epoch [140/360], Batch [110/196], Loss: 0.0586\n",
      "Epoch [140/360], Batch [115/196], Loss: 0.1001\n",
      "Epoch [140/360], Batch [120/196], Loss: 0.0856\n",
      "Epoch [140/360], Batch [125/196], Loss: 0.0996\n",
      "Epoch [140/360], Batch [130/196], Loss: 0.0664\n",
      "Epoch [140/360], Batch [135/196], Loss: 0.0830\n",
      "Epoch [140/360], Batch [140/196], Loss: 0.0677\n",
      "Epoch [140/360], Batch [145/196], Loss: 0.0815\n",
      "Epoch [140/360], Batch [150/196], Loss: 0.0925\n",
      "Epoch [140/360], Batch [155/196], Loss: 0.0451\n",
      "Epoch [140/360], Batch [160/196], Loss: 0.0742\n",
      "Epoch [140/360], Batch [165/196], Loss: 0.0908\n",
      "Epoch [140/360], Batch [170/196], Loss: 0.0652\n",
      "Epoch [140/360], Batch [175/196], Loss: 0.0681\n",
      "Epoch [140/360], Batch [180/196], Loss: 0.0445\n",
      "Epoch [140/360], Batch [185/196], Loss: 0.0724\n",
      "Epoch [140/360], Batch [190/196], Loss: 0.0578\n",
      "Epoch [140/360], Batch [195/196], Loss: 0.0929\n",
      "Epoch [141/360], Batch [5/196], Loss: 0.0942\n",
      "Epoch [141/360], Batch [10/196], Loss: 0.0804\n",
      "Epoch [141/360], Batch [15/196], Loss: 0.0863\n",
      "Epoch [141/360], Batch [20/196], Loss: 0.0966\n",
      "Epoch [141/360], Batch [25/196], Loss: 0.0791\n",
      "Epoch [141/360], Batch [30/196], Loss: 0.0367\n",
      "Epoch [141/360], Batch [35/196], Loss: 0.0936\n",
      "Epoch [141/360], Batch [40/196], Loss: 0.0783\n",
      "Epoch [141/360], Batch [45/196], Loss: 0.0593\n",
      "Epoch [141/360], Batch [50/196], Loss: 0.0466\n",
      "Epoch [141/360], Batch [55/196], Loss: 0.0604\n",
      "Epoch [141/360], Batch [60/196], Loss: 0.0674\n",
      "Epoch [141/360], Batch [65/196], Loss: 0.0459\n",
      "Epoch [141/360], Batch [70/196], Loss: 0.0649\n",
      "Epoch [141/360], Batch [75/196], Loss: 0.0735\n",
      "Epoch [141/360], Batch [80/196], Loss: 0.0407\n",
      "Epoch [141/360], Batch [85/196], Loss: 0.0470\n",
      "Epoch [141/360], Batch [90/196], Loss: 0.0735\n",
      "Epoch [141/360], Batch [95/196], Loss: 0.0424\n",
      "Epoch [141/360], Batch [100/196], Loss: 0.0684\n",
      "Epoch [141/360], Batch [105/196], Loss: 0.0383\n",
      "Epoch [141/360], Batch [110/196], Loss: 0.0981\n",
      "Epoch [141/360], Batch [115/196], Loss: 0.0489\n",
      "Epoch [141/360], Batch [120/196], Loss: 0.0989\n",
      "Epoch [141/360], Batch [125/196], Loss: 0.0727\n",
      "Epoch [141/360], Batch [130/196], Loss: 0.0509\n",
      "Epoch [141/360], Batch [135/196], Loss: 0.0806\n",
      "Epoch [141/360], Batch [140/196], Loss: 0.0526\n",
      "Epoch [141/360], Batch [145/196], Loss: 0.0362\n",
      "Epoch [141/360], Batch [150/196], Loss: 0.1092\n",
      "Epoch [141/360], Batch [155/196], Loss: 0.0587\n",
      "Epoch [141/360], Batch [160/196], Loss: 0.0572\n",
      "Epoch [141/360], Batch [165/196], Loss: 0.0688\n",
      "Epoch [141/360], Batch [170/196], Loss: 0.0835\n",
      "Epoch [141/360], Batch [175/196], Loss: 0.0622\n",
      "Epoch [141/360], Batch [180/196], Loss: 0.0678\n",
      "Epoch [141/360], Batch [185/196], Loss: 0.0624\n",
      "Epoch [141/360], Batch [190/196], Loss: 0.0677\n",
      "Epoch [141/360], Batch [195/196], Loss: 0.1172\n",
      "Epoch [142/360], Batch [5/196], Loss: 0.0878\n",
      "Epoch [142/360], Batch [10/196], Loss: 0.1355\n",
      "Epoch [142/360], Batch [15/196], Loss: 0.1068\n",
      "Epoch [142/360], Batch [20/196], Loss: 0.1051\n",
      "Epoch [142/360], Batch [25/196], Loss: 0.0626\n",
      "Epoch [142/360], Batch [30/196], Loss: 0.1296\n",
      "Epoch [142/360], Batch [35/196], Loss: 0.0804\n",
      "Epoch [142/360], Batch [40/196], Loss: 0.0758\n",
      "Epoch [142/360], Batch [45/196], Loss: 0.0948\n",
      "Epoch [142/360], Batch [50/196], Loss: 0.0777\n",
      "Epoch [142/360], Batch [55/196], Loss: 0.1135\n",
      "Epoch [142/360], Batch [60/196], Loss: 0.0484\n",
      "Epoch [142/360], Batch [65/196], Loss: 0.0612\n",
      "Epoch [142/360], Batch [70/196], Loss: 0.0953\n",
      "Epoch [142/360], Batch [75/196], Loss: 0.0865\n",
      "Epoch [142/360], Batch [80/196], Loss: 0.0581\n",
      "Epoch [142/360], Batch [85/196], Loss: 0.0656\n",
      "Epoch [142/360], Batch [90/196], Loss: 0.0717\n",
      "Epoch [142/360], Batch [95/196], Loss: 0.0710\n",
      "Epoch [142/360], Batch [100/196], Loss: 0.0462\n",
      "Epoch [142/360], Batch [105/196], Loss: 0.1270\n",
      "Epoch [142/360], Batch [110/196], Loss: 0.1114\n",
      "Epoch [142/360], Batch [115/196], Loss: 0.1924\n",
      "Epoch [142/360], Batch [120/196], Loss: 0.2571\n",
      "Epoch [142/360], Batch [125/196], Loss: 0.1160\n",
      "Epoch [142/360], Batch [130/196], Loss: 0.2032\n",
      "Epoch [142/360], Batch [135/196], Loss: 0.1048\n",
      "Epoch [142/360], Batch [140/196], Loss: 0.1327\n",
      "Epoch [142/360], Batch [145/196], Loss: 0.2022\n",
      "Epoch [142/360], Batch [150/196], Loss: 0.1210\n",
      "Epoch [142/360], Batch [155/196], Loss: 0.1430\n",
      "Epoch [142/360], Batch [160/196], Loss: 0.1371\n",
      "Epoch [142/360], Batch [165/196], Loss: 0.1070\n",
      "Epoch [142/360], Batch [170/196], Loss: 0.0977\n",
      "Epoch [142/360], Batch [175/196], Loss: 0.1293\n",
      "Epoch [142/360], Batch [180/196], Loss: 0.1296\n",
      "Epoch [142/360], Batch [185/196], Loss: 0.1362\n",
      "Epoch [142/360], Batch [190/196], Loss: 0.1276\n",
      "Epoch [142/360], Batch [195/196], Loss: 0.0907\n",
      "Epoch [143/360], Batch [5/196], Loss: 0.0882\n",
      "Epoch [143/360], Batch [10/196], Loss: 0.1393\n",
      "Epoch [143/360], Batch [15/196], Loss: 0.0756\n",
      "Epoch [143/360], Batch [20/196], Loss: 0.0701\n",
      "Epoch [143/360], Batch [25/196], Loss: 0.1121\n",
      "Epoch [143/360], Batch [30/196], Loss: 0.1244\n",
      "Epoch [143/360], Batch [35/196], Loss: 0.1018\n",
      "Epoch [143/360], Batch [40/196], Loss: 0.0755\n",
      "Epoch [143/360], Batch [45/196], Loss: 0.0722\n",
      "Epoch [143/360], Batch [50/196], Loss: 0.0572\n",
      "Epoch [143/360], Batch [55/196], Loss: 0.0736\n",
      "Epoch [143/360], Batch [60/196], Loss: 0.0859\n",
      "Epoch [143/360], Batch [65/196], Loss: 0.0726\n",
      "Epoch [143/360], Batch [70/196], Loss: 0.0819\n",
      "Epoch [143/360], Batch [75/196], Loss: 0.0908\n",
      "Epoch [143/360], Batch [80/196], Loss: 0.0729\n",
      "Epoch [143/360], Batch [85/196], Loss: 0.0875\n",
      "Epoch [143/360], Batch [90/196], Loss: 0.0699\n",
      "Epoch [143/360], Batch [95/196], Loss: 0.0633\n",
      "Epoch [143/360], Batch [100/196], Loss: 0.0641\n",
      "Epoch [143/360], Batch [105/196], Loss: 0.0713\n",
      "Epoch [143/360], Batch [110/196], Loss: 0.0609\n",
      "Epoch [143/360], Batch [115/196], Loss: 0.0808\n",
      "Epoch [143/360], Batch [120/196], Loss: 0.0641\n",
      "Epoch [143/360], Batch [125/196], Loss: 0.0960\n",
      "Epoch [143/360], Batch [130/196], Loss: 0.0703\n",
      "Epoch [143/360], Batch [135/196], Loss: 0.0845\n",
      "Epoch [143/360], Batch [140/196], Loss: 0.1028\n",
      "Epoch [143/360], Batch [145/196], Loss: 0.0589\n",
      "Epoch [143/360], Batch [150/196], Loss: 0.0618\n",
      "Epoch [143/360], Batch [155/196], Loss: 0.0632\n",
      "Epoch [143/360], Batch [160/196], Loss: 0.1135\n",
      "Epoch [143/360], Batch [165/196], Loss: 0.1020\n",
      "Epoch [143/360], Batch [170/196], Loss: 0.0762\n",
      "Epoch [143/360], Batch [175/196], Loss: 0.1185\n",
      "Epoch [143/360], Batch [180/196], Loss: 0.0745\n",
      "Epoch [143/360], Batch [185/196], Loss: 0.0600\n",
      "Epoch [143/360], Batch [190/196], Loss: 0.0557\n",
      "Epoch [143/360], Batch [195/196], Loss: 0.0788\n",
      "Epoch [144/360], Batch [5/196], Loss: 0.0572\n",
      "Epoch [144/360], Batch [10/196], Loss: 0.0695\n",
      "Epoch [144/360], Batch [15/196], Loss: 0.0554\n",
      "Epoch [144/360], Batch [20/196], Loss: 0.0838\n",
      "Epoch [144/360], Batch [25/196], Loss: 0.0428\n",
      "Epoch [144/360], Batch [30/196], Loss: 0.0746\n",
      "Epoch [144/360], Batch [35/196], Loss: 0.0693\n",
      "Epoch [144/360], Batch [40/196], Loss: 0.0554\n",
      "Epoch [144/360], Batch [45/196], Loss: 0.0718\n",
      "Epoch [144/360], Batch [50/196], Loss: 0.0597\n",
      "Epoch [144/360], Batch [55/196], Loss: 0.0908\n",
      "Epoch [144/360], Batch [60/196], Loss: 0.0642\n",
      "Epoch [144/360], Batch [65/196], Loss: 0.0644\n",
      "Epoch [144/360], Batch [70/196], Loss: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [144/360], Batch [75/196], Loss: 0.0758\n",
      "Epoch [144/360], Batch [80/196], Loss: 0.0546\n",
      "Epoch [144/360], Batch [85/196], Loss: 0.0982\n",
      "Epoch [144/360], Batch [90/196], Loss: 0.0497\n",
      "Epoch [144/360], Batch [95/196], Loss: 0.0951\n",
      "Epoch [144/360], Batch [100/196], Loss: 0.0654\n",
      "Epoch [144/360], Batch [105/196], Loss: 0.1196\n",
      "Epoch [144/360], Batch [110/196], Loss: 0.0907\n",
      "Epoch [144/360], Batch [115/196], Loss: 0.0778\n",
      "Epoch [144/360], Batch [120/196], Loss: 0.0823\n",
      "Epoch [144/360], Batch [125/196], Loss: 0.0602\n",
      "Epoch [144/360], Batch [130/196], Loss: 0.0637\n",
      "Epoch [144/360], Batch [135/196], Loss: 0.0773\n",
      "Epoch [144/360], Batch [140/196], Loss: 0.0766\n",
      "Epoch [144/360], Batch [145/196], Loss: 0.0873\n",
      "Epoch [144/360], Batch [150/196], Loss: 0.1336\n",
      "Epoch [144/360], Batch [155/196], Loss: 0.0876\n",
      "Epoch [144/360], Batch [160/196], Loss: 0.0848\n",
      "Epoch [144/360], Batch [165/196], Loss: 0.0864\n",
      "Epoch [144/360], Batch [170/196], Loss: 0.0698\n",
      "Epoch [144/360], Batch [175/196], Loss: 0.0649\n",
      "Epoch [144/360], Batch [180/196], Loss: 0.1077\n",
      "Epoch [144/360], Batch [185/196], Loss: 0.0939\n",
      "Epoch [144/360], Batch [190/196], Loss: 0.0832\n",
      "Epoch [144/360], Batch [195/196], Loss: 0.0645\n",
      "Epoch [145/360], Batch [5/196], Loss: 0.0511\n",
      "Epoch [145/360], Batch [10/196], Loss: 0.0705\n",
      "Epoch [145/360], Batch [15/196], Loss: 0.0434\n",
      "Epoch [145/360], Batch [20/196], Loss: 0.0392\n",
      "Epoch [145/360], Batch [25/196], Loss: 0.0455\n",
      "Epoch [145/360], Batch [30/196], Loss: 0.0448\n",
      "Epoch [145/360], Batch [35/196], Loss: 0.0409\n",
      "Epoch [145/360], Batch [40/196], Loss: 0.0477\n",
      "Epoch [145/360], Batch [45/196], Loss: 0.0668\n",
      "Epoch [145/360], Batch [50/196], Loss: 0.0890\n",
      "Epoch [145/360], Batch [55/196], Loss: 0.0672\n",
      "Epoch [145/360], Batch [60/196], Loss: 0.0600\n",
      "Epoch [145/360], Batch [65/196], Loss: 0.0669\n",
      "Epoch [145/360], Batch [70/196], Loss: 0.0606\n",
      "Epoch [145/360], Batch [75/196], Loss: 0.0524\n",
      "Epoch [145/360], Batch [80/196], Loss: 0.0641\n",
      "Epoch [145/360], Batch [85/196], Loss: 0.0889\n",
      "Epoch [145/360], Batch [90/196], Loss: 0.0818\n",
      "Epoch [145/360], Batch [95/196], Loss: 0.0531\n",
      "Epoch [145/360], Batch [100/196], Loss: 0.0621\n",
      "Epoch [145/360], Batch [105/196], Loss: 0.0687\n",
      "Epoch [145/360], Batch [110/196], Loss: 0.0810\n",
      "Epoch [145/360], Batch [115/196], Loss: 0.0670\n",
      "Epoch [145/360], Batch [120/196], Loss: 0.0683\n",
      "Epoch [145/360], Batch [125/196], Loss: 0.0831\n",
      "Epoch [145/360], Batch [130/196], Loss: 0.0862\n",
      "Epoch [145/360], Batch [135/196], Loss: 0.0599\n",
      "Epoch [145/360], Batch [140/196], Loss: 0.0661\n",
      "Epoch [145/360], Batch [145/196], Loss: 0.0645\n",
      "Epoch [145/360], Batch [150/196], Loss: 0.0701\n",
      "Epoch [145/360], Batch [155/196], Loss: 0.0568\n",
      "Epoch [145/360], Batch [160/196], Loss: 0.0595\n",
      "Epoch [145/360], Batch [165/196], Loss: 0.0652\n",
      "Epoch [145/360], Batch [170/196], Loss: 0.0726\n",
      "Epoch [145/360], Batch [175/196], Loss: 0.0534\n",
      "Epoch [145/360], Batch [180/196], Loss: 0.0731\n",
      "Epoch [145/360], Batch [185/196], Loss: 0.0605\n",
      "Epoch [145/360], Batch [190/196], Loss: 0.0696\n",
      "Epoch [145/360], Batch [195/196], Loss: 0.0847\n",
      "Epoch [146/360], Batch [5/196], Loss: 0.0521\n",
      "Epoch [146/360], Batch [10/196], Loss: 0.0372\n",
      "Epoch [146/360], Batch [15/196], Loss: 0.0615\n",
      "Epoch [146/360], Batch [20/196], Loss: 0.0753\n",
      "Epoch [146/360], Batch [25/196], Loss: 0.0622\n",
      "Epoch [146/360], Batch [30/196], Loss: 0.0432\n",
      "Epoch [146/360], Batch [35/196], Loss: 0.0729\n",
      "Epoch [146/360], Batch [40/196], Loss: 0.0421\n",
      "Epoch [146/360], Batch [45/196], Loss: 0.0529\n",
      "Epoch [146/360], Batch [50/196], Loss: 0.0471\n",
      "Epoch [146/360], Batch [55/196], Loss: 0.0672\n",
      "Epoch [146/360], Batch [60/196], Loss: 0.0319\n",
      "Epoch [146/360], Batch [65/196], Loss: 0.0549\n",
      "Epoch [146/360], Batch [70/196], Loss: 0.0452\n",
      "Epoch [146/360], Batch [75/196], Loss: 0.0471\n",
      "Epoch [146/360], Batch [80/196], Loss: 0.0443\n",
      "Epoch [146/360], Batch [85/196], Loss: 0.0415\n",
      "Epoch [146/360], Batch [90/196], Loss: 0.0548\n",
      "Epoch [146/360], Batch [95/196], Loss: 0.0502\n",
      "Epoch [146/360], Batch [100/196], Loss: 0.0421\n",
      "Epoch [146/360], Batch [105/196], Loss: 0.0472\n",
      "Epoch [146/360], Batch [110/196], Loss: 0.0562\n",
      "Epoch [146/360], Batch [115/196], Loss: 0.3332\n",
      "Epoch [146/360], Batch [120/196], Loss: 0.0496\n",
      "Epoch [146/360], Batch [125/196], Loss: 0.0442\n",
      "Epoch [146/360], Batch [130/196], Loss: 0.0512\n",
      "Epoch [146/360], Batch [135/196], Loss: 0.0603\n",
      "Epoch [146/360], Batch [140/196], Loss: 0.0565\n",
      "Epoch [146/360], Batch [145/196], Loss: 0.0607\n",
      "Epoch [146/360], Batch [150/196], Loss: 0.0611\n",
      "Epoch [146/360], Batch [155/196], Loss: 0.0402\n",
      "Epoch [146/360], Batch [160/196], Loss: 0.0536\n",
      "Epoch [146/360], Batch [165/196], Loss: 0.0362\n",
      "Epoch [146/360], Batch [170/196], Loss: 0.0355\n",
      "Epoch [146/360], Batch [175/196], Loss: 0.0418\n",
      "Epoch [146/360], Batch [180/196], Loss: 0.0808\n",
      "Epoch [146/360], Batch [185/196], Loss: 0.0775\n",
      "Epoch [146/360], Batch [190/196], Loss: 0.0505\n",
      "Epoch [146/360], Batch [195/196], Loss: 0.0488\n",
      "Epoch [147/360], Batch [5/196], Loss: 0.0366\n",
      "Epoch [147/360], Batch [10/196], Loss: 0.0383\n",
      "Epoch [147/360], Batch [15/196], Loss: 0.0482\n",
      "Epoch [147/360], Batch [20/196], Loss: 0.0469\n",
      "Epoch [147/360], Batch [25/196], Loss: 0.0344\n",
      "Epoch [147/360], Batch [30/196], Loss: 0.0479\n",
      "Epoch [147/360], Batch [35/196], Loss: 0.0462\n",
      "Epoch [147/360], Batch [40/196], Loss: 0.0413\n",
      "Epoch [147/360], Batch [45/196], Loss: 0.0631\n",
      "Epoch [147/360], Batch [50/196], Loss: 0.0457\n",
      "Epoch [147/360], Batch [55/196], Loss: 0.0358\n",
      "Epoch [147/360], Batch [60/196], Loss: 0.0447\n",
      "Epoch [147/360], Batch [65/196], Loss: 0.0390\n",
      "Epoch [147/360], Batch [70/196], Loss: 0.0428\n",
      "Epoch [147/360], Batch [75/196], Loss: 0.0522\n",
      "Epoch [147/360], Batch [80/196], Loss: 0.0371\n",
      "Epoch [147/360], Batch [85/196], Loss: 0.0453\n",
      "Epoch [147/360], Batch [90/196], Loss: 0.0529\n",
      "Epoch [147/360], Batch [95/196], Loss: 0.0563\n",
      "Epoch [147/360], Batch [100/196], Loss: 0.0505\n",
      "Epoch [147/360], Batch [105/196], Loss: 0.0620\n",
      "Epoch [147/360], Batch [110/196], Loss: 0.0382\n",
      "Epoch [147/360], Batch [115/196], Loss: 0.0366\n",
      "Epoch [147/360], Batch [120/196], Loss: 0.0211\n",
      "Epoch [147/360], Batch [125/196], Loss: 0.3356\n",
      "Epoch [147/360], Batch [130/196], Loss: 0.0478\n",
      "Epoch [147/360], Batch [135/196], Loss: 0.0718\n",
      "Epoch [147/360], Batch [140/196], Loss: 0.0869\n",
      "Epoch [147/360], Batch [145/196], Loss: 0.0774\n",
      "Epoch [147/360], Batch [150/196], Loss: 0.0674\n",
      "Epoch [147/360], Batch [155/196], Loss: 0.0517\n",
      "Epoch [147/360], Batch [160/196], Loss: 0.0645\n",
      "Epoch [147/360], Batch [165/196], Loss: 0.0460\n",
      "Epoch [147/360], Batch [170/196], Loss: 0.0303\n",
      "Epoch [147/360], Batch [175/196], Loss: 0.0482\n",
      "Epoch [147/360], Batch [180/196], Loss: 0.0379\n",
      "Epoch [147/360], Batch [185/196], Loss: 0.0894\n",
      "Epoch [147/360], Batch [190/196], Loss: 0.0591\n",
      "Epoch [147/360], Batch [195/196], Loss: 0.0676\n",
      "Epoch [148/360], Batch [5/196], Loss: 0.0375\n",
      "Epoch [148/360], Batch [10/196], Loss: 0.0408\n",
      "Epoch [148/360], Batch [15/196], Loss: 0.0294\n",
      "Epoch [148/360], Batch [20/196], Loss: 0.0538\n",
      "Epoch [148/360], Batch [25/196], Loss: 0.0851\n",
      "Epoch [148/360], Batch [30/196], Loss: 0.0841\n",
      "Epoch [148/360], Batch [35/196], Loss: 0.0737\n",
      "Epoch [148/360], Batch [40/196], Loss: 0.1310\n",
      "Epoch [148/360], Batch [45/196], Loss: 0.1079\n",
      "Epoch [148/360], Batch [50/196], Loss: 0.1389\n",
      "Epoch [148/360], Batch [55/196], Loss: 0.1154\n",
      "Epoch [148/360], Batch [60/196], Loss: 0.0679\n",
      "Epoch [148/360], Batch [65/196], Loss: 0.1530\n",
      "Epoch [148/360], Batch [70/196], Loss: 0.0752\n",
      "Epoch [148/360], Batch [75/196], Loss: 0.0892\n",
      "Epoch [148/360], Batch [80/196], Loss: 0.0727\n",
      "Epoch [148/360], Batch [85/196], Loss: 0.0772\n",
      "Epoch [148/360], Batch [90/196], Loss: 0.0844\n",
      "Epoch [148/360], Batch [95/196], Loss: 0.0465\n",
      "Epoch [148/360], Batch [100/196], Loss: 0.0919\n",
      "Epoch [148/360], Batch [105/196], Loss: 0.0688\n",
      "Epoch [148/360], Batch [110/196], Loss: 0.0977\n",
      "Epoch [148/360], Batch [115/196], Loss: 0.0682\n",
      "Epoch [148/360], Batch [120/196], Loss: 0.1026\n",
      "Epoch [148/360], Batch [125/196], Loss: 0.1419\n",
      "Epoch [148/360], Batch [130/196], Loss: 0.0484\n",
      "Epoch [148/360], Batch [135/196], Loss: 0.0740\n",
      "Epoch [148/360], Batch [140/196], Loss: 0.0835\n",
      "Epoch [148/360], Batch [145/196], Loss: 0.0660\n",
      "Epoch [148/360], Batch [150/196], Loss: 0.0572\n",
      "Epoch [148/360], Batch [155/196], Loss: 0.0566\n",
      "Epoch [148/360], Batch [160/196], Loss: 0.0550\n",
      "Epoch [148/360], Batch [165/196], Loss: 0.1019\n",
      "Epoch [148/360], Batch [170/196], Loss: 0.0611\n",
      "Epoch [148/360], Batch [175/196], Loss: 0.0766\n",
      "Epoch [148/360], Batch [180/196], Loss: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/360], Batch [185/196], Loss: 0.0557\n",
      "Epoch [148/360], Batch [190/196], Loss: 0.0599\n",
      "Epoch [148/360], Batch [195/196], Loss: 0.0697\n",
      "Epoch [149/360], Batch [5/196], Loss: 0.0794\n",
      "Epoch [149/360], Batch [10/196], Loss: 0.0662\n",
      "Epoch [149/360], Batch [15/196], Loss: 0.1209\n",
      "Epoch [149/360], Batch [20/196], Loss: 0.0416\n",
      "Epoch [149/360], Batch [25/196], Loss: 0.0628\n",
      "Epoch [149/360], Batch [30/196], Loss: 0.0461\n",
      "Epoch [149/360], Batch [35/196], Loss: 0.0910\n",
      "Epoch [149/360], Batch [40/196], Loss: 0.0823\n",
      "Epoch [149/360], Batch [45/196], Loss: 0.0907\n",
      "Epoch [149/360], Batch [50/196], Loss: 0.0622\n",
      "Epoch [149/360], Batch [55/196], Loss: 0.0464\n",
      "Epoch [149/360], Batch [60/196], Loss: 0.0531\n",
      "Epoch [149/360], Batch [65/196], Loss: 0.0615\n",
      "Epoch [149/360], Batch [70/196], Loss: 0.0819\n",
      "Epoch [149/360], Batch [75/196], Loss: 0.0821\n",
      "Epoch [149/360], Batch [80/196], Loss: 0.0774\n",
      "Epoch [149/360], Batch [85/196], Loss: 0.0687\n",
      "Epoch [149/360], Batch [90/196], Loss: 0.0805\n",
      "Epoch [149/360], Batch [95/196], Loss: 0.1186\n",
      "Epoch [149/360], Batch [100/196], Loss: 0.0404\n",
      "Epoch [149/360], Batch [105/196], Loss: 0.0610\n",
      "Epoch [149/360], Batch [110/196], Loss: 0.1125\n",
      "Epoch [149/360], Batch [115/196], Loss: 0.0630\n",
      "Epoch [149/360], Batch [120/196], Loss: 0.0974\n",
      "Epoch [149/360], Batch [125/196], Loss: 0.0596\n",
      "Epoch [149/360], Batch [130/196], Loss: 0.0516\n",
      "Epoch [149/360], Batch [135/196], Loss: 0.0505\n",
      "Epoch [149/360], Batch [140/196], Loss: 0.0666\n",
      "Epoch [149/360], Batch [145/196], Loss: 0.0673\n",
      "Epoch [149/360], Batch [150/196], Loss: 0.0664\n",
      "Epoch [149/360], Batch [155/196], Loss: 0.0517\n",
      "Epoch [149/360], Batch [160/196], Loss: 0.0702\n",
      "Epoch [149/360], Batch [165/196], Loss: 0.0460\n",
      "Epoch [149/360], Batch [170/196], Loss: 0.0897\n",
      "Epoch [149/360], Batch [175/196], Loss: 0.0807\n",
      "Epoch [149/360], Batch [180/196], Loss: 0.0460\n",
      "Epoch [149/360], Batch [185/196], Loss: 0.0444\n",
      "Epoch [149/360], Batch [190/196], Loss: 0.0716\n",
      "Epoch [149/360], Batch [195/196], Loss: 0.0387\n",
      "Epoch [150/360], Batch [5/196], Loss: 0.0572\n",
      "Epoch [150/360], Batch [10/196], Loss: 0.0446\n",
      "Epoch [150/360], Batch [15/196], Loss: 0.0361\n",
      "Epoch [150/360], Batch [20/196], Loss: 0.0493\n",
      "Epoch [150/360], Batch [25/196], Loss: 0.0587\n",
      "Epoch [150/360], Batch [30/196], Loss: 0.0426\n",
      "Epoch [150/360], Batch [35/196], Loss: 0.0536\n",
      "Epoch [150/360], Batch [40/196], Loss: 0.0353\n",
      "Epoch [150/360], Batch [45/196], Loss: 0.0424\n",
      "Epoch [150/360], Batch [50/196], Loss: 0.0446\n",
      "Epoch [150/360], Batch [55/196], Loss: 0.0556\n",
      "Epoch [150/360], Batch [60/196], Loss: 0.0540\n",
      "Epoch [150/360], Batch [65/196], Loss: 0.0499\n",
      "Epoch [150/360], Batch [70/196], Loss: 0.0794\n",
      "Epoch [150/360], Batch [75/196], Loss: 0.0292\n",
      "Epoch [150/360], Batch [80/196], Loss: 0.0340\n",
      "Epoch [150/360], Batch [85/196], Loss: 0.0632\n",
      "Epoch [150/360], Batch [90/196], Loss: 0.0435\n",
      "Epoch [150/360], Batch [95/196], Loss: 0.0434\n",
      "Epoch [150/360], Batch [100/196], Loss: 0.0558\n",
      "Epoch [150/360], Batch [105/196], Loss: 0.0398\n",
      "Epoch [150/360], Batch [110/196], Loss: 0.0627\n",
      "Epoch [150/360], Batch [115/196], Loss: 0.0421\n",
      "Epoch [150/360], Batch [120/196], Loss: 0.0507\n",
      "Epoch [150/360], Batch [125/196], Loss: 0.0615\n",
      "Epoch [150/360], Batch [130/196], Loss: 0.0591\n",
      "Epoch [150/360], Batch [135/196], Loss: 0.0535\n",
      "Epoch [150/360], Batch [140/196], Loss: 0.0634\n",
      "Epoch [150/360], Batch [145/196], Loss: 0.0669\n",
      "Epoch [150/360], Batch [150/196], Loss: 0.0670\n",
      "Epoch [150/360], Batch [155/196], Loss: 0.0539\n",
      "Epoch [150/360], Batch [160/196], Loss: 0.0669\n",
      "Epoch [150/360], Batch [165/196], Loss: 0.0621\n",
      "Epoch [150/360], Batch [170/196], Loss: 0.0473\n",
      "Epoch [150/360], Batch [175/196], Loss: 0.0556\n",
      "Epoch [150/360], Batch [180/196], Loss: 0.0671\n",
      "Epoch [150/360], Batch [185/196], Loss: 0.0632\n",
      "Epoch [150/360], Batch [190/196], Loss: 0.0441\n",
      "Epoch [150/360], Batch [195/196], Loss: 0.0375\n",
      "Epoch [151/360], Batch [5/196], Loss: 0.0360\n",
      "Epoch [151/360], Batch [10/196], Loss: 0.0397\n",
      "Epoch [151/360], Batch [15/196], Loss: 0.0505\n",
      "Epoch [151/360], Batch [20/196], Loss: 0.0420\n",
      "Epoch [151/360], Batch [25/196], Loss: 0.0425\n",
      "Epoch [151/360], Batch [30/196], Loss: 0.0374\n",
      "Epoch [151/360], Batch [35/196], Loss: 0.0495\n",
      "Epoch [151/360], Batch [40/196], Loss: 0.0330\n",
      "Epoch [151/360], Batch [45/196], Loss: 0.0316\n",
      "Epoch [151/360], Batch [50/196], Loss: 0.0520\n",
      "Epoch [151/360], Batch [55/196], Loss: 0.0362\n",
      "Epoch [151/360], Batch [60/196], Loss: 0.0410\n",
      "Epoch [151/360], Batch [65/196], Loss: 0.0488\n",
      "Epoch [151/360], Batch [70/196], Loss: 0.0428\n",
      "Epoch [151/360], Batch [75/196], Loss: 0.0396\n",
      "Epoch [151/360], Batch [80/196], Loss: 0.0315\n",
      "Epoch [151/360], Batch [85/196], Loss: 0.0380\n",
      "Epoch [151/360], Batch [90/196], Loss: 0.0471\n",
      "Epoch [151/360], Batch [95/196], Loss: 0.0463\n",
      "Epoch [151/360], Batch [100/196], Loss: 0.0628\n",
      "Epoch [151/360], Batch [105/196], Loss: 0.0671\n",
      "Epoch [151/360], Batch [110/196], Loss: 0.0451\n",
      "Epoch [151/360], Batch [115/196], Loss: 0.0304\n",
      "Epoch [151/360], Batch [120/196], Loss: 0.0298\n",
      "Epoch [151/360], Batch [125/196], Loss: 0.0301\n",
      "Epoch [151/360], Batch [130/196], Loss: 0.0426\n",
      "Epoch [151/360], Batch [135/196], Loss: 0.0334\n",
      "Epoch [151/360], Batch [140/196], Loss: 0.0657\n",
      "Epoch [151/360], Batch [145/196], Loss: 0.0332\n",
      "Epoch [151/360], Batch [150/196], Loss: 0.0554\n",
      "Epoch [151/360], Batch [155/196], Loss: 0.0647\n",
      "Epoch [151/360], Batch [160/196], Loss: 0.0687\n",
      "Epoch [151/360], Batch [165/196], Loss: 0.0352\n",
      "Epoch [151/360], Batch [170/196], Loss: 0.0561\n",
      "Epoch [151/360], Batch [175/196], Loss: 0.0346\n",
      "Epoch [151/360], Batch [180/196], Loss: 0.0696\n",
      "Epoch [151/360], Batch [185/196], Loss: 0.0513\n",
      "Epoch [151/360], Batch [190/196], Loss: 0.0602\n",
      "Epoch [151/360], Batch [195/196], Loss: 0.0418\n",
      "Epoch [152/360], Batch [5/196], Loss: 0.0568\n",
      "Epoch [152/360], Batch [10/196], Loss: 0.0530\n",
      "Epoch [152/360], Batch [15/196], Loss: 0.0457\n",
      "Epoch [152/360], Batch [20/196], Loss: 0.1067\n",
      "Epoch [152/360], Batch [25/196], Loss: 0.0292\n",
      "Epoch [152/360], Batch [30/196], Loss: 0.0484\n",
      "Epoch [152/360], Batch [35/196], Loss: 0.0575\n",
      "Epoch [152/360], Batch [40/196], Loss: 0.0318\n",
      "Epoch [152/360], Batch [45/196], Loss: 0.0482\n",
      "Epoch [152/360], Batch [50/196], Loss: 0.0561\n",
      "Epoch [152/360], Batch [55/196], Loss: 0.0662\n",
      "Epoch [152/360], Batch [60/196], Loss: 0.0403\n",
      "Epoch [152/360], Batch [65/196], Loss: 0.0479\n",
      "Epoch [152/360], Batch [70/196], Loss: 0.0365\n",
      "Epoch [152/360], Batch [75/196], Loss: 0.0345\n",
      "Epoch [152/360], Batch [80/196], Loss: 0.0393\n",
      "Epoch [152/360], Batch [85/196], Loss: 0.0544\n",
      "Epoch [152/360], Batch [90/196], Loss: 0.0804\n",
      "Epoch [152/360], Batch [95/196], Loss: 0.0492\n",
      "Epoch [152/360], Batch [100/196], Loss: 0.0346\n",
      "Epoch [152/360], Batch [105/196], Loss: 0.0538\n",
      "Epoch [152/360], Batch [110/196], Loss: 0.0504\n",
      "Epoch [152/360], Batch [115/196], Loss: 0.0651\n",
      "Epoch [152/360], Batch [120/196], Loss: 0.0343\n",
      "Epoch [152/360], Batch [125/196], Loss: 0.0492\n",
      "Epoch [152/360], Batch [130/196], Loss: 0.0446\n",
      "Epoch [152/360], Batch [135/196], Loss: 0.0483\n",
      "Epoch [152/360], Batch [140/196], Loss: 0.0449\n",
      "Epoch [152/360], Batch [145/196], Loss: 0.0434\n",
      "Epoch [152/360], Batch [150/196], Loss: 0.0628\n",
      "Epoch [152/360], Batch [155/196], Loss: 0.0283\n",
      "Epoch [152/360], Batch [160/196], Loss: 0.0519\n",
      "Epoch [152/360], Batch [165/196], Loss: 0.0435\n",
      "Epoch [152/360], Batch [170/196], Loss: 0.0509\n",
      "Epoch [152/360], Batch [175/196], Loss: 0.0380\n",
      "Epoch [152/360], Batch [180/196], Loss: 0.0520\n",
      "Epoch [152/360], Batch [185/196], Loss: 0.0377\n",
      "Epoch [152/360], Batch [190/196], Loss: 0.0435\n",
      "Epoch [152/360], Batch [195/196], Loss: 0.0517\n",
      "Epoch [153/360], Batch [5/196], Loss: 0.0452\n",
      "Epoch [153/360], Batch [10/196], Loss: 0.0619\n",
      "Epoch [153/360], Batch [15/196], Loss: 0.0295\n",
      "Epoch [153/360], Batch [20/196], Loss: 0.0339\n",
      "Epoch [153/360], Batch [25/196], Loss: 0.0284\n",
      "Epoch [153/360], Batch [30/196], Loss: 0.0357\n",
      "Epoch [153/360], Batch [35/196], Loss: 0.0390\n",
      "Epoch [153/360], Batch [40/196], Loss: 0.0513\n",
      "Epoch [153/360], Batch [45/196], Loss: 0.0839\n",
      "Epoch [153/360], Batch [50/196], Loss: 0.0486\n",
      "Epoch [153/360], Batch [55/196], Loss: 0.0707\n",
      "Epoch [153/360], Batch [60/196], Loss: 0.0408\n",
      "Epoch [153/360], Batch [65/196], Loss: 0.0647\n",
      "Epoch [153/360], Batch [70/196], Loss: 0.0505\n",
      "Epoch [153/360], Batch [75/196], Loss: 0.0515\n",
      "Epoch [153/360], Batch [80/196], Loss: 0.0459\n",
      "Epoch [153/360], Batch [85/196], Loss: 0.0341\n",
      "Epoch [153/360], Batch [90/196], Loss: 0.0388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [153/360], Batch [95/196], Loss: 0.0521\n",
      "Epoch [153/360], Batch [100/196], Loss: 0.0448\n",
      "Epoch [153/360], Batch [105/196], Loss: 0.0579\n",
      "Epoch [153/360], Batch [110/196], Loss: 0.0400\n",
      "Epoch [153/360], Batch [115/196], Loss: 0.0490\n",
      "Epoch [153/360], Batch [120/196], Loss: 0.0573\n",
      "Epoch [153/360], Batch [125/196], Loss: 0.0744\n",
      "Epoch [153/360], Batch [130/196], Loss: 0.0535\n",
      "Epoch [153/360], Batch [135/196], Loss: 0.0752\n",
      "Epoch [153/360], Batch [140/196], Loss: 0.0646\n",
      "Epoch [153/360], Batch [145/196], Loss: 0.0447\n",
      "Epoch [153/360], Batch [150/196], Loss: 0.0581\n",
      "Epoch [153/360], Batch [155/196], Loss: 0.0677\n",
      "Epoch [153/360], Batch [160/196], Loss: 0.0685\n",
      "Epoch [153/360], Batch [165/196], Loss: 0.0818\n",
      "Epoch [153/360], Batch [170/196], Loss: 0.0494\n",
      "Epoch [153/360], Batch [175/196], Loss: 0.0710\n",
      "Epoch [153/360], Batch [180/196], Loss: 0.0440\n",
      "Epoch [153/360], Batch [185/196], Loss: 0.0938\n",
      "Epoch [153/360], Batch [190/196], Loss: 0.0380\n",
      "Epoch [153/360], Batch [195/196], Loss: 0.0398\n",
      "Epoch [154/360], Batch [5/196], Loss: 0.0572\n",
      "Epoch [154/360], Batch [10/196], Loss: 0.0471\n",
      "Epoch [154/360], Batch [15/196], Loss: 0.0469\n",
      "Epoch [154/360], Batch [20/196], Loss: 0.0808\n",
      "Epoch [154/360], Batch [25/196], Loss: 0.0731\n",
      "Epoch [154/360], Batch [30/196], Loss: 0.0681\n",
      "Epoch [154/360], Batch [35/196], Loss: 0.0632\n",
      "Epoch [154/360], Batch [40/196], Loss: 0.0583\n",
      "Epoch [154/360], Batch [45/196], Loss: 0.0566\n",
      "Epoch [154/360], Batch [50/196], Loss: 0.0809\n",
      "Epoch [154/360], Batch [55/196], Loss: 0.0527\n",
      "Epoch [154/360], Batch [60/196], Loss: 0.0294\n",
      "Epoch [154/360], Batch [65/196], Loss: 0.0441\n",
      "Epoch [154/360], Batch [70/196], Loss: 0.0748\n",
      "Epoch [154/360], Batch [75/196], Loss: 0.0638\n",
      "Epoch [154/360], Batch [80/196], Loss: 0.0420\n",
      "Epoch [154/360], Batch [85/196], Loss: 0.0544\n",
      "Epoch [154/360], Batch [90/196], Loss: 0.0594\n",
      "Epoch [154/360], Batch [95/196], Loss: 0.0721\n",
      "Epoch [154/360], Batch [100/196], Loss: 0.0669\n",
      "Epoch [154/360], Batch [105/196], Loss: 0.0690\n",
      "Epoch [154/360], Batch [110/196], Loss: 0.1919\n",
      "Epoch [154/360], Batch [115/196], Loss: 0.1590\n",
      "Epoch [154/360], Batch [120/196], Loss: 0.1167\n",
      "Epoch [154/360], Batch [125/196], Loss: 0.0811\n",
      "Epoch [154/360], Batch [130/196], Loss: 0.1346\n",
      "Epoch [154/360], Batch [135/196], Loss: 0.1263\n",
      "Epoch [154/360], Batch [140/196], Loss: 0.1030\n",
      "Epoch [154/360], Batch [145/196], Loss: 0.1294\n",
      "Epoch [154/360], Batch [150/196], Loss: 0.1759\n",
      "Epoch [154/360], Batch [155/196], Loss: 0.2100\n",
      "Epoch [154/360], Batch [160/196], Loss: 0.0863\n",
      "Epoch [154/360], Batch [165/196], Loss: 0.1006\n",
      "Epoch [154/360], Batch [170/196], Loss: 0.0960\n",
      "Epoch [154/360], Batch [175/196], Loss: 0.0886\n",
      "Epoch [154/360], Batch [180/196], Loss: 0.1271\n",
      "Epoch [154/360], Batch [185/196], Loss: 0.1297\n",
      "Epoch [154/360], Batch [190/196], Loss: 0.0853\n",
      "Epoch [154/360], Batch [195/196], Loss: 0.1023\n",
      "Epoch [155/360], Batch [5/196], Loss: 0.0526\n",
      "Epoch [155/360], Batch [10/196], Loss: 0.1246\n",
      "Epoch [155/360], Batch [15/196], Loss: 0.0509\n",
      "Epoch [155/360], Batch [20/196], Loss: 0.0927\n",
      "Epoch [155/360], Batch [25/196], Loss: 0.0749\n",
      "Epoch [155/360], Batch [30/196], Loss: 0.0886\n",
      "Epoch [155/360], Batch [35/196], Loss: 0.0729\n",
      "Epoch [155/360], Batch [40/196], Loss: 0.0711\n",
      "Epoch [155/360], Batch [45/196], Loss: 0.0502\n",
      "Epoch [155/360], Batch [50/196], Loss: 0.0805\n",
      "Epoch [155/360], Batch [55/196], Loss: 0.0689\n",
      "Epoch [155/360], Batch [60/196], Loss: 0.0648\n",
      "Epoch [155/360], Batch [65/196], Loss: 0.0874\n",
      "Epoch [155/360], Batch [70/196], Loss: 0.0977\n",
      "Epoch [155/360], Batch [75/196], Loss: 0.0877\n",
      "Epoch [155/360], Batch [80/196], Loss: 0.0736\n",
      "Epoch [155/360], Batch [85/196], Loss: 0.1032\n",
      "Epoch [155/360], Batch [90/196], Loss: 0.0726\n",
      "Epoch [155/360], Batch [95/196], Loss: 0.0971\n",
      "Epoch [155/360], Batch [100/196], Loss: 0.0732\n",
      "Epoch [155/360], Batch [105/196], Loss: 0.0817\n",
      "Epoch [155/360], Batch [110/196], Loss: 0.0893\n",
      "Epoch [155/360], Batch [115/196], Loss: 0.0732\n",
      "Epoch [155/360], Batch [120/196], Loss: 0.0814\n",
      "Epoch [155/360], Batch [125/196], Loss: 0.0690\n",
      "Epoch [155/360], Batch [130/196], Loss: 0.1132\n",
      "Epoch [155/360], Batch [135/196], Loss: 0.1129\n",
      "Epoch [155/360], Batch [140/196], Loss: 0.0664\n",
      "Epoch [155/360], Batch [145/196], Loss: 0.0739\n",
      "Epoch [155/360], Batch [150/196], Loss: 0.0571\n",
      "Epoch [155/360], Batch [155/196], Loss: 0.0958\n",
      "Epoch [155/360], Batch [160/196], Loss: 0.0749\n",
      "Epoch [155/360], Batch [165/196], Loss: 0.0870\n",
      "Epoch [155/360], Batch [170/196], Loss: 0.0848\n",
      "Epoch [155/360], Batch [175/196], Loss: 0.0994\n",
      "Epoch [155/360], Batch [180/196], Loss: 0.0776\n",
      "Epoch [155/360], Batch [185/196], Loss: 0.0908\n",
      "Epoch [155/360], Batch [190/196], Loss: 0.0482\n",
      "Epoch [155/360], Batch [195/196], Loss: 0.0794\n",
      "Epoch [156/360], Batch [5/196], Loss: 0.0883\n",
      "Epoch [156/360], Batch [10/196], Loss: 0.0570\n",
      "Epoch [156/360], Batch [15/196], Loss: 0.0606\n",
      "Epoch [156/360], Batch [20/196], Loss: 0.0586\n",
      "Epoch [156/360], Batch [25/196], Loss: 0.0742\n",
      "Epoch [156/360], Batch [30/196], Loss: 0.0832\n",
      "Epoch [156/360], Batch [35/196], Loss: 0.0629\n",
      "Epoch [156/360], Batch [40/196], Loss: 0.0713\n",
      "Epoch [156/360], Batch [45/196], Loss: 0.0533\n",
      "Epoch [156/360], Batch [50/196], Loss: 0.0944\n",
      "Epoch [156/360], Batch [55/196], Loss: 0.0522\n",
      "Epoch [156/360], Batch [60/196], Loss: 0.0587\n",
      "Epoch [156/360], Batch [65/196], Loss: 0.0701\n",
      "Epoch [156/360], Batch [70/196], Loss: 0.0678\n",
      "Epoch [156/360], Batch [75/196], Loss: 0.0342\n",
      "Epoch [156/360], Batch [80/196], Loss: 0.0655\n",
      "Epoch [156/360], Batch [85/196], Loss: 0.0547\n",
      "Epoch [156/360], Batch [90/196], Loss: 0.0700\n",
      "Epoch [156/360], Batch [95/196], Loss: 0.0706\n",
      "Epoch [156/360], Batch [100/196], Loss: 0.0465\n",
      "Epoch [156/360], Batch [105/196], Loss: 0.0657\n",
      "Epoch [156/360], Batch [110/196], Loss: 0.0515\n",
      "Epoch [156/360], Batch [115/196], Loss: 0.0529\n",
      "Epoch [156/360], Batch [120/196], Loss: 0.0585\n",
      "Epoch [156/360], Batch [125/196], Loss: 0.0549\n",
      "Epoch [156/360], Batch [130/196], Loss: 0.0799\n",
      "Epoch [156/360], Batch [135/196], Loss: 0.0419\n",
      "Epoch [156/360], Batch [140/196], Loss: 0.0648\n",
      "Epoch [156/360], Batch [145/196], Loss: 0.0608\n",
      "Epoch [156/360], Batch [150/196], Loss: 0.0610\n",
      "Epoch [156/360], Batch [155/196], Loss: 0.0502\n",
      "Epoch [156/360], Batch [160/196], Loss: 0.0941\n",
      "Epoch [156/360], Batch [165/196], Loss: 0.0692\n",
      "Epoch [156/360], Batch [170/196], Loss: 0.1022\n",
      "Epoch [156/360], Batch [175/196], Loss: 0.0663\n",
      "Epoch [156/360], Batch [180/196], Loss: 0.0706\n",
      "Epoch [156/360], Batch [185/196], Loss: 0.0554\n",
      "Epoch [156/360], Batch [190/196], Loss: 0.0698\n",
      "Epoch [156/360], Batch [195/196], Loss: 0.0650\n",
      "Epoch [157/360], Batch [5/196], Loss: 0.0610\n",
      "Epoch [157/360], Batch [10/196], Loss: 0.0528\n",
      "Epoch [157/360], Batch [15/196], Loss: 0.0717\n",
      "Epoch [157/360], Batch [20/196], Loss: 0.0373\n",
      "Epoch [157/360], Batch [25/196], Loss: 0.0911\n",
      "Epoch [157/360], Batch [30/196], Loss: 0.0564\n",
      "Epoch [157/360], Batch [35/196], Loss: 0.0714\n",
      "Epoch [157/360], Batch [40/196], Loss: 0.0687\n",
      "Epoch [157/360], Batch [45/196], Loss: 0.0746\n",
      "Epoch [157/360], Batch [50/196], Loss: 0.0672\n",
      "Epoch [157/360], Batch [55/196], Loss: 0.1129\n",
      "Epoch [157/360], Batch [60/196], Loss: 0.0663\n",
      "Epoch [157/360], Batch [65/196], Loss: 0.1428\n",
      "Epoch [157/360], Batch [70/196], Loss: 0.1039\n",
      "Epoch [157/360], Batch [75/196], Loss: 0.0880\n",
      "Epoch [157/360], Batch [80/196], Loss: 0.1114\n",
      "Epoch [157/360], Batch [85/196], Loss: 0.1885\n",
      "Epoch [157/360], Batch [90/196], Loss: 0.1130\n",
      "Epoch [157/360], Batch [95/196], Loss: 0.1330\n",
      "Epoch [157/360], Batch [100/196], Loss: 0.0607\n",
      "Epoch [157/360], Batch [105/196], Loss: 0.0736\n",
      "Epoch [157/360], Batch [110/196], Loss: 0.0956\n",
      "Epoch [157/360], Batch [115/196], Loss: 0.0743\n",
      "Epoch [157/360], Batch [120/196], Loss: 0.1123\n",
      "Epoch [157/360], Batch [125/196], Loss: 0.0793\n",
      "Epoch [157/360], Batch [130/196], Loss: 0.0755\n",
      "Epoch [157/360], Batch [135/196], Loss: 0.0983\n",
      "Epoch [157/360], Batch [140/196], Loss: 0.0827\n",
      "Epoch [157/360], Batch [145/196], Loss: 0.0679\n",
      "Epoch [157/360], Batch [150/196], Loss: 0.1264\n",
      "Epoch [157/360], Batch [155/196], Loss: 0.0368\n",
      "Epoch [157/360], Batch [160/196], Loss: 0.0602\n",
      "Epoch [157/360], Batch [165/196], Loss: 0.0543\n",
      "Epoch [157/360], Batch [170/196], Loss: 0.0588\n",
      "Epoch [157/360], Batch [175/196], Loss: 0.0587\n",
      "Epoch [157/360], Batch [180/196], Loss: 0.0696\n",
      "Epoch [157/360], Batch [185/196], Loss: 0.0527\n",
      "Epoch [157/360], Batch [190/196], Loss: 0.0534\n",
      "Epoch [157/360], Batch [195/196], Loss: 0.0504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [158/360], Batch [5/196], Loss: 0.0588\n",
      "Epoch [158/360], Batch [10/196], Loss: 0.0602\n",
      "Epoch [158/360], Batch [15/196], Loss: 0.0859\n",
      "Epoch [158/360], Batch [20/196], Loss: 0.0500\n",
      "Epoch [158/360], Batch [25/196], Loss: 0.1026\n",
      "Epoch [158/360], Batch [30/196], Loss: 0.0628\n",
      "Epoch [158/360], Batch [35/196], Loss: 0.0472\n",
      "Epoch [158/360], Batch [40/196], Loss: 0.0464\n",
      "Epoch [158/360], Batch [45/196], Loss: 0.0386\n",
      "Epoch [158/360], Batch [50/196], Loss: 0.0819\n",
      "Epoch [158/360], Batch [55/196], Loss: 0.0538\n",
      "Epoch [158/360], Batch [60/196], Loss: 0.0486\n",
      "Epoch [158/360], Batch [65/196], Loss: 0.0470\n",
      "Epoch [158/360], Batch [70/196], Loss: 0.0426\n",
      "Epoch [158/360], Batch [75/196], Loss: 0.0502\n",
      "Epoch [158/360], Batch [80/196], Loss: 0.0555\n",
      "Epoch [158/360], Batch [85/196], Loss: 0.0547\n",
      "Epoch [158/360], Batch [90/196], Loss: 0.0364\n",
      "Epoch [158/360], Batch [95/196], Loss: 0.0439\n",
      "Epoch [158/360], Batch [100/196], Loss: 0.0456\n",
      "Epoch [158/360], Batch [105/196], Loss: 0.0683\n",
      "Epoch [158/360], Batch [110/196], Loss: 0.0530\n",
      "Epoch [158/360], Batch [115/196], Loss: 0.0349\n",
      "Epoch [158/360], Batch [120/196], Loss: 0.0433\n",
      "Epoch [158/360], Batch [125/196], Loss: 0.0348\n",
      "Epoch [158/360], Batch [130/196], Loss: 0.0835\n",
      "Epoch [158/360], Batch [135/196], Loss: 0.0764\n",
      "Epoch [158/360], Batch [140/196], Loss: 0.0612\n",
      "Epoch [158/360], Batch [145/196], Loss: 0.0479\n",
      "Epoch [158/360], Batch [150/196], Loss: 0.0509\n",
      "Epoch [158/360], Batch [155/196], Loss: 0.0664\n",
      "Epoch [158/360], Batch [160/196], Loss: 0.0537\n",
      "Epoch [158/360], Batch [165/196], Loss: 0.0689\n",
      "Epoch [158/360], Batch [170/196], Loss: 0.0455\n",
      "Epoch [158/360], Batch [175/196], Loss: 0.0385\n",
      "Epoch [158/360], Batch [180/196], Loss: 0.0481\n",
      "Epoch [158/360], Batch [185/196], Loss: 0.0447\n",
      "Epoch [158/360], Batch [190/196], Loss: 0.0639\n",
      "Epoch [158/360], Batch [195/196], Loss: 0.0512\n",
      "Epoch [159/360], Batch [5/196], Loss: 0.0412\n",
      "Epoch [159/360], Batch [10/196], Loss: 0.0530\n",
      "Epoch [159/360], Batch [15/196], Loss: 0.0672\n",
      "Epoch [159/360], Batch [20/196], Loss: 0.0223\n",
      "Epoch [159/360], Batch [25/196], Loss: 0.0520\n",
      "Epoch [159/360], Batch [30/196], Loss: 0.0327\n",
      "Epoch [159/360], Batch [35/196], Loss: 0.0396\n",
      "Epoch [159/360], Batch [40/196], Loss: 0.0452\n",
      "Epoch [159/360], Batch [45/196], Loss: 0.0421\n",
      "Epoch [159/360], Batch [50/196], Loss: 0.0401\n",
      "Epoch [159/360], Batch [55/196], Loss: 0.0428\n",
      "Epoch [159/360], Batch [60/196], Loss: 0.0479\n",
      "Epoch [159/360], Batch [65/196], Loss: 0.0348\n",
      "Epoch [159/360], Batch [70/196], Loss: 0.0301\n",
      "Epoch [159/360], Batch [75/196], Loss: 0.0376\n",
      "Epoch [159/360], Batch [80/196], Loss: 0.0454\n",
      "Epoch [159/360], Batch [85/196], Loss: 0.0350\n",
      "Epoch [159/360], Batch [90/196], Loss: 0.0365\n",
      "Epoch [159/360], Batch [95/196], Loss: 0.0241\n",
      "Epoch [159/360], Batch [100/196], Loss: 0.0303\n",
      "Epoch [159/360], Batch [105/196], Loss: 0.0380\n",
      "Epoch [159/360], Batch [110/196], Loss: 0.0327\n",
      "Epoch [159/360], Batch [115/196], Loss: 0.0321\n",
      "Epoch [159/360], Batch [120/196], Loss: 0.0409\n",
      "Epoch [159/360], Batch [125/196], Loss: 0.0413\n",
      "Epoch [159/360], Batch [130/196], Loss: 0.0439\n",
      "Epoch [159/360], Batch [135/196], Loss: 0.0291\n",
      "Epoch [159/360], Batch [140/196], Loss: 0.0402\n",
      "Epoch [159/360], Batch [145/196], Loss: 0.0354\n",
      "Epoch [159/360], Batch [150/196], Loss: 0.0333\n",
      "Epoch [159/360], Batch [155/196], Loss: 0.0259\n",
      "Epoch [159/360], Batch [160/196], Loss: 0.0353\n",
      "Epoch [159/360], Batch [165/196], Loss: 0.0466\n",
      "Epoch [159/360], Batch [170/196], Loss: 0.0451\n",
      "Epoch [159/360], Batch [175/196], Loss: 0.0554\n",
      "Epoch [159/360], Batch [180/196], Loss: 0.0340\n",
      "Epoch [159/360], Batch [185/196], Loss: 0.0400\n",
      "Epoch [159/360], Batch [190/196], Loss: 0.0206\n",
      "Epoch [159/360], Batch [195/196], Loss: 0.0583\n",
      "Epoch [160/360], Batch [5/196], Loss: 0.0247\n",
      "Epoch [160/360], Batch [10/196], Loss: 0.0253\n",
      "Epoch [160/360], Batch [15/196], Loss: 0.0296\n",
      "Epoch [160/360], Batch [20/196], Loss: 0.0336\n",
      "Epoch [160/360], Batch [25/196], Loss: 0.0240\n",
      "Epoch [160/360], Batch [30/196], Loss: 0.0746\n",
      "Epoch [160/360], Batch [35/196], Loss: 0.1049\n",
      "Epoch [160/360], Batch [40/196], Loss: 0.0725\n",
      "Epoch [160/360], Batch [45/196], Loss: 0.0863\n",
      "Epoch [160/360], Batch [50/196], Loss: 0.0717\n",
      "Epoch [160/360], Batch [55/196], Loss: 0.0616\n",
      "Epoch [160/360], Batch [60/196], Loss: 0.0492\n",
      "Epoch [160/360], Batch [65/196], Loss: 0.0702\n",
      "Epoch [160/360], Batch [70/196], Loss: 0.0544\n",
      "Epoch [160/360], Batch [75/196], Loss: 0.0791\n",
      "Epoch [160/360], Batch [80/196], Loss: 0.0729\n",
      "Epoch [160/360], Batch [85/196], Loss: 0.0714\n",
      "Epoch [160/360], Batch [90/196], Loss: 0.0579\n",
      "Epoch [160/360], Batch [95/196], Loss: 0.0605\n",
      "Epoch [160/360], Batch [100/196], Loss: 0.0727\n",
      "Epoch [160/360], Batch [105/196], Loss: 0.0529\n",
      "Epoch [160/360], Batch [110/196], Loss: 0.0558\n",
      "Epoch [160/360], Batch [115/196], Loss: 0.0507\n",
      "Epoch [160/360], Batch [120/196], Loss: 0.1079\n",
      "Epoch [160/360], Batch [125/196], Loss: 0.0728\n",
      "Epoch [160/360], Batch [130/196], Loss: 0.0457\n",
      "Epoch [160/360], Batch [135/196], Loss: 0.0761\n",
      "Epoch [160/360], Batch [140/196], Loss: 0.0506\n",
      "Epoch [160/360], Batch [145/196], Loss: 0.0521\n",
      "Epoch [160/360], Batch [150/196], Loss: 0.0332\n",
      "Epoch [160/360], Batch [155/196], Loss: 0.0391\n",
      "Epoch [160/360], Batch [160/196], Loss: 0.0431\n",
      "Epoch [160/360], Batch [165/196], Loss: 0.0630\n",
      "Epoch [160/360], Batch [170/196], Loss: 0.0660\n",
      "Epoch [160/360], Batch [175/196], Loss: 0.0481\n",
      "Epoch [160/360], Batch [180/196], Loss: 0.0571\n",
      "Epoch [160/360], Batch [185/196], Loss: 0.0496\n",
      "Epoch [160/360], Batch [190/196], Loss: 0.0571\n",
      "Epoch [160/360], Batch [195/196], Loss: 0.0647\n",
      "Epoch [161/360], Batch [5/196], Loss: 0.0655\n",
      "Epoch [161/360], Batch [10/196], Loss: 0.0770\n",
      "Epoch [161/360], Batch [15/196], Loss: 0.0406\n",
      "Epoch [161/360], Batch [20/196], Loss: 0.4374\n",
      "Epoch [161/360], Batch [25/196], Loss: 0.0439\n",
      "Epoch [161/360], Batch [30/196], Loss: 0.0742\n",
      "Epoch [161/360], Batch [35/196], Loss: 0.0878\n",
      "Epoch [161/360], Batch [40/196], Loss: 0.0554\n",
      "Epoch [161/360], Batch [45/196], Loss: 0.0560\n",
      "Epoch [161/360], Batch [50/196], Loss: 0.0618\n",
      "Epoch [161/360], Batch [55/196], Loss: 0.0413\n",
      "Epoch [161/360], Batch [60/196], Loss: 0.0572\n",
      "Epoch [161/360], Batch [65/196], Loss: 0.0402\n",
      "Epoch [161/360], Batch [70/196], Loss: 0.0542\n",
      "Epoch [161/360], Batch [75/196], Loss: 0.0523\n",
      "Epoch [161/360], Batch [80/196], Loss: 0.0512\n",
      "Epoch [161/360], Batch [85/196], Loss: 0.0390\n",
      "Epoch [161/360], Batch [90/196], Loss: 0.0321\n",
      "Epoch [161/360], Batch [95/196], Loss: 0.0671\n",
      "Epoch [161/360], Batch [100/196], Loss: 0.0457\n",
      "Epoch [161/360], Batch [105/196], Loss: 0.0785\n",
      "Epoch [161/360], Batch [110/196], Loss: 0.0421\n",
      "Epoch [161/360], Batch [115/196], Loss: 0.0771\n",
      "Epoch [161/360], Batch [120/196], Loss: 0.0675\n",
      "Epoch [161/360], Batch [125/196], Loss: 0.0419\n",
      "Epoch [161/360], Batch [130/196], Loss: 0.0464\n",
      "Epoch [161/360], Batch [135/196], Loss: 0.0382\n",
      "Epoch [161/360], Batch [140/196], Loss: 0.0528\n",
      "Epoch [161/360], Batch [145/196], Loss: 0.0502\n",
      "Epoch [161/360], Batch [150/196], Loss: 0.0689\n",
      "Epoch [161/360], Batch [155/196], Loss: 0.0433\n",
      "Epoch [161/360], Batch [160/196], Loss: 0.0300\n",
      "Epoch [161/360], Batch [165/196], Loss: 0.0414\n",
      "Epoch [161/360], Batch [170/196], Loss: 0.0704\n",
      "Epoch [161/360], Batch [175/196], Loss: 0.0508\n",
      "Epoch [161/360], Batch [180/196], Loss: 0.0368\n",
      "Epoch [161/360], Batch [185/196], Loss: 0.0596\n",
      "Epoch [161/360], Batch [190/196], Loss: 0.0419\n",
      "Epoch [161/360], Batch [195/196], Loss: 0.0648\n",
      "Epoch [162/360], Batch [5/196], Loss: 0.0257\n",
      "Epoch [162/360], Batch [10/196], Loss: 0.0469\n",
      "Epoch [162/360], Batch [15/196], Loss: 0.0408\n",
      "Epoch [162/360], Batch [20/196], Loss: 0.0405\n",
      "Epoch [162/360], Batch [25/196], Loss: 0.0356\n",
      "Epoch [162/360], Batch [30/196], Loss: 0.0482\n",
      "Epoch [162/360], Batch [35/196], Loss: 0.0388\n",
      "Epoch [162/360], Batch [40/196], Loss: 0.0335\n",
      "Epoch [162/360], Batch [45/196], Loss: 0.0370\n",
      "Epoch [162/360], Batch [50/196], Loss: 0.0321\n",
      "Epoch [162/360], Batch [55/196], Loss: 0.0324\n",
      "Epoch [162/360], Batch [60/196], Loss: 0.0321\n",
      "Epoch [162/360], Batch [65/196], Loss: 0.0210\n",
      "Epoch [162/360], Batch [70/196], Loss: 0.0459\n",
      "Epoch [162/360], Batch [75/196], Loss: 0.0340\n",
      "Epoch [162/360], Batch [80/196], Loss: 0.0546\n",
      "Epoch [162/360], Batch [85/196], Loss: 0.0389\n",
      "Epoch [162/360], Batch [90/196], Loss: 0.0322\n",
      "Epoch [162/360], Batch [95/196], Loss: 0.0416\n",
      "Epoch [162/360], Batch [100/196], Loss: 0.0409\n",
      "Epoch [162/360], Batch [105/196], Loss: 0.0407\n",
      "Epoch [162/360], Batch [110/196], Loss: 0.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [162/360], Batch [115/196], Loss: 0.0478\n",
      "Epoch [162/360], Batch [120/196], Loss: 0.0379\n",
      "Epoch [162/360], Batch [125/196], Loss: 0.0365\n",
      "Epoch [162/360], Batch [130/196], Loss: 0.0505\n",
      "Epoch [162/360], Batch [135/196], Loss: 0.0358\n",
      "Epoch [162/360], Batch [140/196], Loss: 0.0548\n",
      "Epoch [162/360], Batch [145/196], Loss: 0.0686\n",
      "Epoch [162/360], Batch [150/196], Loss: 0.0357\n",
      "Epoch [162/360], Batch [155/196], Loss: 0.0550\n",
      "Epoch [162/360], Batch [160/196], Loss: 0.0476\n",
      "Epoch [162/360], Batch [165/196], Loss: 0.0365\n",
      "Epoch [162/360], Batch [170/196], Loss: 0.0452\n",
      "Epoch [162/360], Batch [175/196], Loss: 0.0399\n",
      "Epoch [162/360], Batch [180/196], Loss: 0.0267\n",
      "Epoch [162/360], Batch [185/196], Loss: 0.0509\n",
      "Epoch [162/360], Batch [190/196], Loss: 0.0460\n",
      "Epoch [162/360], Batch [195/196], Loss: 0.0351\n",
      "Epoch [163/360], Batch [5/196], Loss: 0.0363\n",
      "Epoch [163/360], Batch [10/196], Loss: 0.0390\n",
      "Epoch [163/360], Batch [15/196], Loss: 0.0633\n",
      "Epoch [163/360], Batch [20/196], Loss: 0.0629\n",
      "Epoch [163/360], Batch [25/196], Loss: 0.0287\n",
      "Epoch [163/360], Batch [30/196], Loss: 0.0328\n",
      "Epoch [163/360], Batch [35/196], Loss: 0.0404\n",
      "Epoch [163/360], Batch [40/196], Loss: 0.0274\n",
      "Epoch [163/360], Batch [45/196], Loss: 0.0372\n",
      "Epoch [163/360], Batch [50/196], Loss: 0.0334\n",
      "Epoch [163/360], Batch [55/196], Loss: 0.0252\n",
      "Epoch [163/360], Batch [60/196], Loss: 0.0274\n",
      "Epoch [163/360], Batch [65/196], Loss: 0.0259\n",
      "Epoch [163/360], Batch [70/196], Loss: 0.2087\n",
      "Epoch [163/360], Batch [75/196], Loss: 0.0355\n",
      "Epoch [163/360], Batch [80/196], Loss: 0.0307\n",
      "Epoch [163/360], Batch [85/196], Loss: 0.0440\n",
      "Epoch [163/360], Batch [90/196], Loss: 0.0332\n",
      "Epoch [163/360], Batch [95/196], Loss: 0.0313\n",
      "Epoch [163/360], Batch [100/196], Loss: 0.0364\n",
      "Epoch [163/360], Batch [105/196], Loss: 0.0306\n",
      "Epoch [163/360], Batch [110/196], Loss: 0.0611\n",
      "Epoch [163/360], Batch [115/196], Loss: 0.0280\n",
      "Epoch [163/360], Batch [120/196], Loss: 0.0513\n",
      "Epoch [163/360], Batch [125/196], Loss: 0.0438\n",
      "Epoch [163/360], Batch [130/196], Loss: 0.0394\n",
      "Epoch [163/360], Batch [135/196], Loss: 0.0356\n",
      "Epoch [163/360], Batch [140/196], Loss: 0.0524\n",
      "Epoch [163/360], Batch [145/196], Loss: 0.0568\n",
      "Epoch [163/360], Batch [150/196], Loss: 0.0586\n",
      "Epoch [163/360], Batch [155/196], Loss: 0.0396\n",
      "Epoch [163/360], Batch [160/196], Loss: 0.0325\n",
      "Epoch [163/360], Batch [165/196], Loss: 0.0359\n",
      "Epoch [163/360], Batch [170/196], Loss: 0.0347\n",
      "Epoch [163/360], Batch [175/196], Loss: 0.0398\n",
      "Epoch [163/360], Batch [180/196], Loss: 0.0293\n",
      "Epoch [163/360], Batch [185/196], Loss: 0.0442\n",
      "Epoch [163/360], Batch [190/196], Loss: 0.0530\n",
      "Epoch [163/360], Batch [195/196], Loss: 0.0374\n",
      "Epoch [164/360], Batch [5/196], Loss: 0.0450\n",
      "Epoch [164/360], Batch [10/196], Loss: 0.0410\n",
      "Epoch [164/360], Batch [15/196], Loss: 0.0682\n",
      "Epoch [164/360], Batch [20/196], Loss: 0.0706\n",
      "Epoch [164/360], Batch [25/196], Loss: 0.0544\n",
      "Epoch [164/360], Batch [30/196], Loss: 0.0593\n",
      "Epoch [164/360], Batch [35/196], Loss: 0.0424\n",
      "Epoch [164/360], Batch [40/196], Loss: 0.0549\n",
      "Epoch [164/360], Batch [45/196], Loss: 0.0569\n",
      "Epoch [164/360], Batch [50/196], Loss: 0.0550\n",
      "Epoch [164/360], Batch [55/196], Loss: 0.0805\n",
      "Epoch [164/360], Batch [60/196], Loss: 0.0534\n",
      "Epoch [164/360], Batch [65/196], Loss: 0.0536\n",
      "Epoch [164/360], Batch [70/196], Loss: 0.0484\n",
      "Epoch [164/360], Batch [75/196], Loss: 0.0385\n",
      "Epoch [164/360], Batch [80/196], Loss: 0.0487\n",
      "Epoch [164/360], Batch [85/196], Loss: 0.0443\n",
      "Epoch [164/360], Batch [90/196], Loss: 0.0339\n",
      "Epoch [164/360], Batch [95/196], Loss: 0.0541\n",
      "Epoch [164/360], Batch [100/196], Loss: 0.0446\n",
      "Epoch [164/360], Batch [105/196], Loss: 0.0419\n",
      "Epoch [164/360], Batch [110/196], Loss: 0.0347\n",
      "Epoch [164/360], Batch [115/196], Loss: 0.0322\n",
      "Epoch [164/360], Batch [120/196], Loss: 0.0496\n",
      "Epoch [164/360], Batch [125/196], Loss: 0.0420\n",
      "Epoch [164/360], Batch [130/196], Loss: 0.0483\n",
      "Epoch [164/360], Batch [135/196], Loss: 0.0634\n",
      "Epoch [164/360], Batch [140/196], Loss: 0.0388\n",
      "Epoch [164/360], Batch [145/196], Loss: 0.0385\n",
      "Epoch [164/360], Batch [150/196], Loss: 0.0472\n",
      "Epoch [164/360], Batch [155/196], Loss: 0.0445\n",
      "Epoch [164/360], Batch [160/196], Loss: 0.0336\n",
      "Epoch [164/360], Batch [165/196], Loss: 0.0445\n",
      "Epoch [164/360], Batch [170/196], Loss: 0.0508\n",
      "Epoch [164/360], Batch [175/196], Loss: 0.0511\n",
      "Epoch [164/360], Batch [180/196], Loss: 0.0373\n",
      "Epoch [164/360], Batch [185/196], Loss: 0.0534\n",
      "Epoch [164/360], Batch [190/196], Loss: 0.0426\n",
      "Epoch [164/360], Batch [195/196], Loss: 0.0466\n",
      "Epoch [165/360], Batch [5/196], Loss: 0.0303\n",
      "Epoch [165/360], Batch [10/196], Loss: 0.0320\n",
      "Epoch [165/360], Batch [15/196], Loss: 0.0486\n",
      "Epoch [165/360], Batch [20/196], Loss: 0.0486\n",
      "Epoch [165/360], Batch [25/196], Loss: 0.0441\n",
      "Epoch [165/360], Batch [30/196], Loss: 0.0377\n",
      "Epoch [165/360], Batch [35/196], Loss: 0.0347\n",
      "Epoch [165/360], Batch [40/196], Loss: 0.0331\n",
      "Epoch [165/360], Batch [45/196], Loss: 0.0545\n",
      "Epoch [165/360], Batch [50/196], Loss: 0.0437\n",
      "Epoch [165/360], Batch [55/196], Loss: 0.0825\n",
      "Epoch [165/360], Batch [60/196], Loss: 0.0617\n",
      "Epoch [165/360], Batch [65/196], Loss: 0.0597\n",
      "Epoch [165/360], Batch [70/196], Loss: 0.0743\n",
      "Epoch [165/360], Batch [75/196], Loss: 0.0857\n",
      "Epoch [165/360], Batch [80/196], Loss: 0.0668\n",
      "Epoch [165/360], Batch [85/196], Loss: 0.0693\n",
      "Epoch [165/360], Batch [90/196], Loss: 0.1247\n",
      "Epoch [165/360], Batch [95/196], Loss: 0.0467\n",
      "Epoch [165/360], Batch [100/196], Loss: 0.0639\n",
      "Epoch [165/360], Batch [105/196], Loss: 0.0930\n",
      "Epoch [165/360], Batch [110/196], Loss: 0.0681\n",
      "Epoch [165/360], Batch [115/196], Loss: 0.0583\n",
      "Epoch [165/360], Batch [120/196], Loss: 0.0640\n",
      "Epoch [165/360], Batch [125/196], Loss: 0.0615\n",
      "Epoch [165/360], Batch [130/196], Loss: 0.0669\n",
      "Epoch [165/360], Batch [135/196], Loss: 0.0644\n",
      "Epoch [165/360], Batch [140/196], Loss: 0.0680\n",
      "Epoch [165/360], Batch [145/196], Loss: 0.0485\n",
      "Epoch [165/360], Batch [150/196], Loss: 0.0448\n",
      "Epoch [165/360], Batch [155/196], Loss: 0.1893\n",
      "Epoch [165/360], Batch [160/196], Loss: 0.0507\n",
      "Epoch [165/360], Batch [165/196], Loss: 0.0535\n",
      "Epoch [165/360], Batch [170/196], Loss: 0.0657\n",
      "Epoch [165/360], Batch [175/196], Loss: 0.0675\n",
      "Epoch [165/360], Batch [180/196], Loss: 0.0700\n",
      "Epoch [165/360], Batch [185/196], Loss: 0.0664\n",
      "Epoch [165/360], Batch [190/196], Loss: 0.0494\n",
      "Epoch [165/360], Batch [195/196], Loss: 0.0558\n",
      "Epoch [166/360], Batch [5/196], Loss: 0.0853\n",
      "Epoch [166/360], Batch [10/196], Loss: 0.0474\n",
      "Epoch [166/360], Batch [15/196], Loss: 0.0698\n",
      "Epoch [166/360], Batch [20/196], Loss: 0.0532\n",
      "Epoch [166/360], Batch [25/196], Loss: 0.0486\n",
      "Epoch [166/360], Batch [30/196], Loss: 0.0571\n",
      "Epoch [166/360], Batch [35/196], Loss: 0.0643\n",
      "Epoch [166/360], Batch [40/196], Loss: 0.0450\n",
      "Epoch [166/360], Batch [45/196], Loss: 0.0817\n",
      "Epoch [166/360], Batch [50/196], Loss: 0.0550\n",
      "Epoch [166/360], Batch [55/196], Loss: 0.0669\n",
      "Epoch [166/360], Batch [60/196], Loss: 0.0879\n",
      "Epoch [166/360], Batch [65/196], Loss: 0.0490\n",
      "Epoch [166/360], Batch [70/196], Loss: 0.0409\n",
      "Epoch [166/360], Batch [75/196], Loss: 0.0728\n",
      "Epoch [166/360], Batch [80/196], Loss: 0.0567\n",
      "Epoch [166/360], Batch [85/196], Loss: 0.0639\n",
      "Epoch [166/360], Batch [90/196], Loss: 0.0448\n",
      "Epoch [166/360], Batch [95/196], Loss: 0.0448\n",
      "Epoch [166/360], Batch [100/196], Loss: 0.0392\n",
      "Epoch [166/360], Batch [105/196], Loss: 0.0411\n",
      "Epoch [166/360], Batch [110/196], Loss: 0.0516\n",
      "Epoch [166/360], Batch [115/196], Loss: 0.0625\n",
      "Epoch [166/360], Batch [120/196], Loss: 0.0397\n",
      "Epoch [166/360], Batch [125/196], Loss: 0.0801\n",
      "Epoch [166/360], Batch [130/196], Loss: 0.2690\n",
      "Epoch [166/360], Batch [135/196], Loss: 0.4038\n",
      "Epoch [166/360], Batch [140/196], Loss: 0.2957\n",
      "Epoch [166/360], Batch [145/196], Loss: 0.3336\n",
      "Epoch [166/360], Batch [150/196], Loss: 0.3685\n",
      "Epoch [166/360], Batch [155/196], Loss: 0.2421\n",
      "Epoch [166/360], Batch [160/196], Loss: 0.2734\n",
      "Epoch [166/360], Batch [165/196], Loss: 0.1850\n",
      "Epoch [166/360], Batch [170/196], Loss: 0.2493\n",
      "Epoch [166/360], Batch [175/196], Loss: 0.2046\n",
      "Epoch [166/360], Batch [180/196], Loss: 0.2266\n",
      "Epoch [166/360], Batch [185/196], Loss: 0.2611\n",
      "Epoch [166/360], Batch [190/196], Loss: 0.2163\n",
      "Epoch [166/360], Batch [195/196], Loss: 0.2591\n",
      "Epoch [167/360], Batch [5/196], Loss: 0.1780\n",
      "Epoch [167/360], Batch [10/196], Loss: 0.4136\n",
      "Epoch [167/360], Batch [15/196], Loss: 0.2101\n",
      "Epoch [167/360], Batch [20/196], Loss: 0.2502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/360], Batch [25/196], Loss: 0.2102\n",
      "Epoch [167/360], Batch [30/196], Loss: 0.2121\n",
      "Epoch [167/360], Batch [35/196], Loss: 0.1768\n",
      "Epoch [167/360], Batch [40/196], Loss: 0.2207\n",
      "Epoch [167/360], Batch [45/196], Loss: 0.1404\n",
      "Epoch [167/360], Batch [50/196], Loss: 0.1520\n",
      "Epoch [167/360], Batch [55/196], Loss: 0.2308\n",
      "Epoch [167/360], Batch [60/196], Loss: 0.1450\n",
      "Epoch [167/360], Batch [65/196], Loss: 0.1847\n",
      "Epoch [167/360], Batch [70/196], Loss: 0.1746\n",
      "Epoch [167/360], Batch [75/196], Loss: 0.1886\n",
      "Epoch [167/360], Batch [80/196], Loss: 0.1861\n",
      "Epoch [167/360], Batch [85/196], Loss: 0.1726\n",
      "Epoch [167/360], Batch [90/196], Loss: 0.1797\n",
      "Epoch [167/360], Batch [95/196], Loss: 0.2212\n",
      "Epoch [167/360], Batch [100/196], Loss: 0.1101\n",
      "Epoch [167/360], Batch [105/196], Loss: 0.1507\n",
      "Epoch [167/360], Batch [110/196], Loss: 0.1269\n",
      "Epoch [167/360], Batch [115/196], Loss: 0.2064\n",
      "Epoch [167/360], Batch [120/196], Loss: 0.2468\n",
      "Epoch [167/360], Batch [125/196], Loss: 0.1682\n",
      "Epoch [167/360], Batch [130/196], Loss: 0.2307\n",
      "Epoch [167/360], Batch [135/196], Loss: 0.1148\n",
      "Epoch [167/360], Batch [140/196], Loss: 0.2506\n",
      "Epoch [167/360], Batch [145/196], Loss: 0.0881\n",
      "Epoch [167/360], Batch [150/196], Loss: 0.0849\n",
      "Epoch [167/360], Batch [155/196], Loss: 0.2049\n",
      "Epoch [167/360], Batch [160/196], Loss: 0.2306\n",
      "Epoch [167/360], Batch [165/196], Loss: 0.2337\n",
      "Epoch [167/360], Batch [170/196], Loss: 0.1515\n",
      "Epoch [167/360], Batch [175/196], Loss: 0.2189\n",
      "Epoch [167/360], Batch [180/196], Loss: 0.1620\n",
      "Epoch [167/360], Batch [185/196], Loss: 0.1119\n",
      "Epoch [167/360], Batch [190/196], Loss: 0.2331\n",
      "Epoch [167/360], Batch [195/196], Loss: 0.2047\n",
      "Epoch [168/360], Batch [5/196], Loss: 0.2468\n",
      "Epoch [168/360], Batch [10/196], Loss: 0.2416\n",
      "Epoch [168/360], Batch [15/196], Loss: 0.1722\n",
      "Epoch [168/360], Batch [20/196], Loss: 0.1364\n",
      "Epoch [168/360], Batch [25/196], Loss: 0.2518\n",
      "Epoch [168/360], Batch [30/196], Loss: 0.2552\n",
      "Epoch [168/360], Batch [35/196], Loss: 0.1554\n",
      "Epoch [168/360], Batch [40/196], Loss: 0.1631\n",
      "Epoch [168/360], Batch [45/196], Loss: 0.2246\n",
      "Epoch [168/360], Batch [50/196], Loss: 0.1978\n",
      "Epoch [168/360], Batch [55/196], Loss: 0.2445\n",
      "Epoch [168/360], Batch [60/196], Loss: 0.1915\n",
      "Epoch [168/360], Batch [65/196], Loss: 0.1450\n",
      "Epoch [168/360], Batch [70/196], Loss: 0.1081\n",
      "Epoch [168/360], Batch [75/196], Loss: 0.1575\n",
      "Epoch [168/360], Batch [80/196], Loss: 0.1213\n",
      "Epoch [168/360], Batch [85/196], Loss: 0.1391\n",
      "Epoch [168/360], Batch [90/196], Loss: 0.2467\n",
      "Epoch [168/360], Batch [95/196], Loss: 0.1631\n",
      "Epoch [168/360], Batch [100/196], Loss: 0.1826\n",
      "Epoch [168/360], Batch [105/196], Loss: 0.1192\n",
      "Epoch [168/360], Batch [110/196], Loss: 0.1389\n",
      "Epoch [168/360], Batch [115/196], Loss: 0.1510\n",
      "Epoch [168/360], Batch [120/196], Loss: 0.1423\n",
      "Epoch [168/360], Batch [125/196], Loss: 0.2158\n",
      "Epoch [168/360], Batch [130/196], Loss: 0.1161\n",
      "Epoch [168/360], Batch [135/196], Loss: 0.1759\n",
      "Epoch [168/360], Batch [140/196], Loss: 0.1138\n",
      "Epoch [168/360], Batch [145/196], Loss: 0.1283\n",
      "Epoch [168/360], Batch [150/196], Loss: 0.0925\n",
      "Epoch [168/360], Batch [155/196], Loss: 0.1325\n",
      "Epoch [168/360], Batch [160/196], Loss: 0.1181\n",
      "Epoch [168/360], Batch [165/196], Loss: 0.0976\n",
      "Epoch [168/360], Batch [170/196], Loss: 0.1947\n",
      "Epoch [168/360], Batch [175/196], Loss: 0.1533\n",
      "Epoch [168/360], Batch [180/196], Loss: 0.0806\n",
      "Epoch [168/360], Batch [185/196], Loss: 0.1095\n",
      "Epoch [168/360], Batch [190/196], Loss: 0.1147\n",
      "Epoch [168/360], Batch [195/196], Loss: 0.0766\n",
      "Epoch [169/360], Batch [5/196], Loss: 0.0817\n",
      "Epoch [169/360], Batch [10/196], Loss: 0.0540\n",
      "Epoch [169/360], Batch [15/196], Loss: 0.0763\n",
      "Epoch [169/360], Batch [20/196], Loss: 0.0729\n",
      "Epoch [169/360], Batch [25/196], Loss: 0.0624\n",
      "Epoch [169/360], Batch [30/196], Loss: 0.0766\n",
      "Epoch [169/360], Batch [35/196], Loss: 0.0908\n",
      "Epoch [169/360], Batch [40/196], Loss: 0.0555\n",
      "Epoch [169/360], Batch [45/196], Loss: 0.0522\n",
      "Epoch [169/360], Batch [50/196], Loss: 0.0806\n",
      "Epoch [169/360], Batch [55/196], Loss: 0.1190\n",
      "Epoch [169/360], Batch [60/196], Loss: 0.0644\n",
      "Epoch [169/360], Batch [65/196], Loss: 0.1021\n",
      "Epoch [169/360], Batch [70/196], Loss: 0.0602\n",
      "Epoch [169/360], Batch [75/196], Loss: 0.0755\n",
      "Epoch [169/360], Batch [80/196], Loss: 0.0768\n",
      "Epoch [169/360], Batch [85/196], Loss: 0.0852\n",
      "Epoch [169/360], Batch [90/196], Loss: 0.0341\n",
      "Epoch [169/360], Batch [95/196], Loss: 0.0720\n",
      "Epoch [169/360], Batch [100/196], Loss: 0.0698\n",
      "Epoch [169/360], Batch [105/196], Loss: 0.0585\n",
      "Epoch [169/360], Batch [110/196], Loss: 0.0500\n",
      "Epoch [169/360], Batch [115/196], Loss: 0.0762\n",
      "Epoch [169/360], Batch [120/196], Loss: 0.0789\n",
      "Epoch [169/360], Batch [125/196], Loss: 0.0590\n",
      "Epoch [169/360], Batch [130/196], Loss: 0.0489\n",
      "Epoch [169/360], Batch [135/196], Loss: 0.1273\n",
      "Epoch [169/360], Batch [140/196], Loss: 0.0623\n",
      "Epoch [169/360], Batch [145/196], Loss: 0.0546\n",
      "Epoch [169/360], Batch [150/196], Loss: 0.0757\n",
      "Epoch [169/360], Batch [155/196], Loss: 0.0609\n",
      "Epoch [169/360], Batch [160/196], Loss: 0.0660\n",
      "Epoch [169/360], Batch [165/196], Loss: 0.0599\n",
      "Epoch [169/360], Batch [170/196], Loss: 0.0699\n",
      "Epoch [169/360], Batch [175/196], Loss: 0.0697\n",
      "Epoch [169/360], Batch [180/196], Loss: 0.1315\n",
      "Epoch [169/360], Batch [185/196], Loss: 0.1081\n",
      "Epoch [169/360], Batch [190/196], Loss: 0.1791\n",
      "Epoch [169/360], Batch [195/196], Loss: 0.1719\n",
      "Epoch [170/360], Batch [5/196], Loss: 0.1292\n",
      "Epoch [170/360], Batch [10/196], Loss: 0.0619\n",
      "Epoch [170/360], Batch [15/196], Loss: 0.0944\n",
      "Epoch [170/360], Batch [20/196], Loss: 0.0948\n",
      "Epoch [170/360], Batch [25/196], Loss: 0.0702\n",
      "Epoch [170/360], Batch [30/196], Loss: 0.0656\n",
      "Epoch [170/360], Batch [35/196], Loss: 0.0750\n",
      "Epoch [170/360], Batch [40/196], Loss: 0.0628\n",
      "Epoch [170/360], Batch [45/196], Loss: 0.0467\n",
      "Epoch [170/360], Batch [50/196], Loss: 0.0782\n",
      "Epoch [170/360], Batch [55/196], Loss: 0.0566\n",
      "Epoch [170/360], Batch [60/196], Loss: 0.0370\n",
      "Epoch [170/360], Batch [65/196], Loss: 0.0527\n",
      "Epoch [170/360], Batch [70/196], Loss: 0.0716\n",
      "Epoch [170/360], Batch [75/196], Loss: 0.0453\n",
      "Epoch [170/360], Batch [80/196], Loss: 0.0545\n",
      "Epoch [170/360], Batch [85/196], Loss: 0.0661\n",
      "Epoch [170/360], Batch [90/196], Loss: 0.0672\n",
      "Epoch [170/360], Batch [95/196], Loss: 0.0641\n",
      "Epoch [170/360], Batch [100/196], Loss: 0.0373\n",
      "Epoch [170/360], Batch [105/196], Loss: 0.0770\n",
      "Epoch [170/360], Batch [110/196], Loss: 0.0387\n",
      "Epoch [170/360], Batch [115/196], Loss: 0.0416\n",
      "Epoch [170/360], Batch [120/196], Loss: 0.0377\n",
      "Epoch [170/360], Batch [125/196], Loss: 0.0426\n",
      "Epoch [170/360], Batch [130/196], Loss: 0.0386\n",
      "Epoch [170/360], Batch [135/196], Loss: 0.0451\n",
      "Epoch [170/360], Batch [140/196], Loss: 0.0428\n",
      "Epoch [170/360], Batch [145/196], Loss: 0.0441\n",
      "Epoch [170/360], Batch [150/196], Loss: 0.0534\n",
      "Epoch [170/360], Batch [155/196], Loss: 0.0448\n",
      "Epoch [170/360], Batch [160/196], Loss: 0.0566\n",
      "Epoch [170/360], Batch [165/196], Loss: 0.0434\n",
      "Epoch [170/360], Batch [170/196], Loss: 0.0497\n",
      "Epoch [170/360], Batch [175/196], Loss: 0.0442\n",
      "Epoch [170/360], Batch [180/196], Loss: 0.0522\n",
      "Epoch [170/360], Batch [185/196], Loss: 0.0732\n",
      "Epoch [170/360], Batch [190/196], Loss: 0.0419\n",
      "Epoch [170/360], Batch [195/196], Loss: 0.0419\n",
      "Epoch [171/360], Batch [5/196], Loss: 0.0283\n",
      "Epoch [171/360], Batch [10/196], Loss: 0.0421\n",
      "Epoch [171/360], Batch [15/196], Loss: 0.0500\n",
      "Epoch [171/360], Batch [20/196], Loss: 0.0394\n",
      "Epoch [171/360], Batch [25/196], Loss: 0.0365\n",
      "Epoch [171/360], Batch [30/196], Loss: 0.0322\n",
      "Epoch [171/360], Batch [35/196], Loss: 0.0271\n",
      "Epoch [171/360], Batch [40/196], Loss: 0.0219\n",
      "Epoch [171/360], Batch [45/196], Loss: 0.0316\n",
      "Epoch [171/360], Batch [50/196], Loss: 0.0191\n",
      "Epoch [171/360], Batch [55/196], Loss: 0.0236\n",
      "Epoch [171/360], Batch [60/196], Loss: 0.0273\n",
      "Epoch [171/360], Batch [65/196], Loss: 0.0418\n",
      "Epoch [171/360], Batch [70/196], Loss: 0.0198\n",
      "Epoch [171/360], Batch [75/196], Loss: 0.0379\n",
      "Epoch [171/360], Batch [80/196], Loss: 0.0245\n",
      "Epoch [171/360], Batch [85/196], Loss: 0.0308\n",
      "Epoch [171/360], Batch [90/196], Loss: 0.0360\n",
      "Epoch [171/360], Batch [95/196], Loss: 0.0419\n",
      "Epoch [171/360], Batch [100/196], Loss: 0.0565\n",
      "Epoch [171/360], Batch [105/196], Loss: 0.0278\n",
      "Epoch [171/360], Batch [110/196], Loss: 0.0448\n",
      "Epoch [171/360], Batch [115/196], Loss: 0.0301\n",
      "Epoch [171/360], Batch [120/196], Loss: 0.0281\n",
      "Epoch [171/360], Batch [125/196], Loss: 0.0372\n",
      "Epoch [171/360], Batch [130/196], Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/360], Batch [135/196], Loss: 0.0432\n",
      "Epoch [171/360], Batch [140/196], Loss: 0.0336\n",
      "Epoch [171/360], Batch [145/196], Loss: 0.0272\n",
      "Epoch [171/360], Batch [150/196], Loss: 0.0304\n",
      "Epoch [171/360], Batch [155/196], Loss: 0.0219\n",
      "Epoch [171/360], Batch [160/196], Loss: 0.0298\n",
      "Epoch [171/360], Batch [165/196], Loss: 0.0291\n",
      "Epoch [171/360], Batch [170/196], Loss: 0.0362\n",
      "Epoch [171/360], Batch [175/196], Loss: 0.0205\n",
      "Epoch [171/360], Batch [180/196], Loss: 0.0392\n",
      "Epoch [171/360], Batch [185/196], Loss: 0.0312\n",
      "Epoch [171/360], Batch [190/196], Loss: 0.0279\n",
      "Epoch [171/360], Batch [195/196], Loss: 0.0341\n",
      "Epoch [172/360], Batch [5/196], Loss: 0.0156\n",
      "Epoch [172/360], Batch [10/196], Loss: 0.0212\n",
      "Epoch [172/360], Batch [15/196], Loss: 0.0189\n",
      "Epoch [172/360], Batch [20/196], Loss: 0.0245\n",
      "Epoch [172/360], Batch [25/196], Loss: 0.0159\n",
      "Epoch [172/360], Batch [30/196], Loss: 0.0232\n",
      "Epoch [172/360], Batch [35/196], Loss: 0.0191\n",
      "Epoch [172/360], Batch [40/196], Loss: 0.0216\n",
      "Epoch [172/360], Batch [45/196], Loss: 0.0180\n",
      "Epoch [172/360], Batch [50/196], Loss: 0.0255\n",
      "Epoch [172/360], Batch [55/196], Loss: 0.0315\n",
      "Epoch [172/360], Batch [60/196], Loss: 0.0232\n",
      "Epoch [172/360], Batch [65/196], Loss: 0.0270\n",
      "Epoch [172/360], Batch [70/196], Loss: 0.0211\n",
      "Epoch [172/360], Batch [75/196], Loss: 0.0252\n",
      "Epoch [172/360], Batch [80/196], Loss: 0.0260\n",
      "Epoch [172/360], Batch [85/196], Loss: 0.0272\n",
      "Epoch [172/360], Batch [90/196], Loss: 0.0260\n",
      "Epoch [172/360], Batch [95/196], Loss: 0.0216\n",
      "Epoch [172/360], Batch [100/196], Loss: 0.0254\n",
      "Epoch [172/360], Batch [105/196], Loss: 0.0185\n",
      "Epoch [172/360], Batch [110/196], Loss: 0.0241\n",
      "Epoch [172/360], Batch [115/196], Loss: 0.0175\n",
      "Epoch [172/360], Batch [120/196], Loss: 0.0317\n",
      "Epoch [172/360], Batch [125/196], Loss: 0.0267\n",
      "Epoch [172/360], Batch [130/196], Loss: 0.0189\n",
      "Epoch [172/360], Batch [135/196], Loss: 0.0166\n",
      "Epoch [172/360], Batch [140/196], Loss: 0.0239\n",
      "Epoch [172/360], Batch [145/196], Loss: 0.0218\n",
      "Epoch [172/360], Batch [150/196], Loss: 0.0242\n",
      "Epoch [172/360], Batch [155/196], Loss: 0.0267\n",
      "Epoch [172/360], Batch [160/196], Loss: 0.0205\n",
      "Epoch [172/360], Batch [165/196], Loss: 0.0337\n",
      "Epoch [172/360], Batch [170/196], Loss: 0.0224\n",
      "Epoch [172/360], Batch [175/196], Loss: 0.0260\n",
      "Epoch [172/360], Batch [180/196], Loss: 0.0230\n",
      "Epoch [172/360], Batch [185/196], Loss: 0.0231\n",
      "Epoch [172/360], Batch [190/196], Loss: 0.0214\n",
      "Epoch [172/360], Batch [195/196], Loss: 0.0232\n",
      "Epoch [173/360], Batch [5/196], Loss: 0.0144\n",
      "Epoch [173/360], Batch [10/196], Loss: 0.0179\n",
      "Epoch [173/360], Batch [15/196], Loss: 0.0173\n",
      "Epoch [173/360], Batch [20/196], Loss: 0.0165\n",
      "Epoch [173/360], Batch [25/196], Loss: 0.0173\n",
      "Epoch [173/360], Batch [30/196], Loss: 0.0147\n",
      "Epoch [173/360], Batch [35/196], Loss: 0.0224\n",
      "Epoch [173/360], Batch [40/196], Loss: 0.0224\n",
      "Epoch [173/360], Batch [45/196], Loss: 0.0195\n",
      "Epoch [173/360], Batch [50/196], Loss: 0.0146\n",
      "Epoch [173/360], Batch [55/196], Loss: 0.0154\n",
      "Epoch [173/360], Batch [60/196], Loss: 0.0173\n",
      "Epoch [173/360], Batch [65/196], Loss: 0.0563\n",
      "Epoch [173/360], Batch [70/196], Loss: 0.0480\n",
      "Epoch [173/360], Batch [75/196], Loss: 0.0604\n",
      "Epoch [173/360], Batch [80/196], Loss: 0.0510\n",
      "Epoch [173/360], Batch [85/196], Loss: 0.0308\n",
      "Epoch [173/360], Batch [90/196], Loss: 0.0344\n",
      "Epoch [173/360], Batch [95/196], Loss: 0.0393\n",
      "Epoch [173/360], Batch [100/196], Loss: 0.0454\n",
      "Epoch [173/360], Batch [105/196], Loss: 0.0364\n",
      "Epoch [173/360], Batch [110/196], Loss: 0.0459\n",
      "Epoch [173/360], Batch [115/196], Loss: 0.0368\n",
      "Epoch [173/360], Batch [120/196], Loss: 0.0324\n",
      "Epoch [173/360], Batch [125/196], Loss: 0.0379\n",
      "Epoch [173/360], Batch [130/196], Loss: 0.0257\n",
      "Epoch [173/360], Batch [135/196], Loss: 0.0295\n",
      "Epoch [173/360], Batch [140/196], Loss: 0.0372\n",
      "Epoch [173/360], Batch [145/196], Loss: 0.0608\n",
      "Epoch [173/360], Batch [150/196], Loss: 0.0364\n",
      "Epoch [173/360], Batch [155/196], Loss: 0.0255\n",
      "Epoch [173/360], Batch [160/196], Loss: 0.0289\n",
      "Epoch [173/360], Batch [165/196], Loss: 0.0262\n",
      "Epoch [173/360], Batch [170/196], Loss: 0.0227\n",
      "Epoch [173/360], Batch [175/196], Loss: 0.0265\n",
      "Epoch [173/360], Batch [180/196], Loss: 0.0378\n",
      "Epoch [173/360], Batch [185/196], Loss: 0.0360\n",
      "Epoch [173/360], Batch [190/196], Loss: 0.0312\n",
      "Epoch [173/360], Batch [195/196], Loss: 0.0347\n",
      "Epoch [174/360], Batch [5/196], Loss: 0.0262\n",
      "Epoch [174/360], Batch [10/196], Loss: 0.0261\n",
      "Epoch [174/360], Batch [15/196], Loss: 0.0239\n",
      "Epoch [174/360], Batch [20/196], Loss: 0.0303\n",
      "Epoch [174/360], Batch [25/196], Loss: 0.0159\n",
      "Epoch [174/360], Batch [30/196], Loss: 0.0367\n",
      "Epoch [174/360], Batch [35/196], Loss: 0.0236\n",
      "Epoch [174/360], Batch [40/196], Loss: 0.0202\n",
      "Epoch [174/360], Batch [45/196], Loss: 0.0204\n",
      "Epoch [174/360], Batch [50/196], Loss: 0.0232\n",
      "Epoch [174/360], Batch [55/196], Loss: 0.0192\n",
      "Epoch [174/360], Batch [60/196], Loss: 0.0254\n",
      "Epoch [174/360], Batch [65/196], Loss: 0.0192\n",
      "Epoch [174/360], Batch [70/196], Loss: 0.0275\n",
      "Epoch [174/360], Batch [75/196], Loss: 0.0296\n",
      "Epoch [174/360], Batch [80/196], Loss: 0.0181\n",
      "Epoch [174/360], Batch [85/196], Loss: 0.0257\n",
      "Epoch [174/360], Batch [90/196], Loss: 0.1136\n",
      "Epoch [174/360], Batch [95/196], Loss: 0.0265\n",
      "Epoch [174/360], Batch [100/196], Loss: 0.0216\n",
      "Epoch [174/360], Batch [105/196], Loss: 0.0220\n",
      "Epoch [174/360], Batch [110/196], Loss: 0.0272\n",
      "Epoch [174/360], Batch [115/196], Loss: 0.0252\n",
      "Epoch [174/360], Batch [120/196], Loss: 0.0265\n",
      "Epoch [174/360], Batch [125/196], Loss: 0.0338\n",
      "Epoch [174/360], Batch [130/196], Loss: 0.0384\n",
      "Epoch [174/360], Batch [135/196], Loss: 0.0144\n",
      "Epoch [174/360], Batch [140/196], Loss: 0.0223\n",
      "Epoch [174/360], Batch [145/196], Loss: 0.0319\n",
      "Epoch [174/360], Batch [150/196], Loss: 0.0321\n",
      "Epoch [174/360], Batch [155/196], Loss: 0.0374\n",
      "Epoch [174/360], Batch [160/196], Loss: 0.0260\n",
      "Epoch [174/360], Batch [165/196], Loss: 0.0348\n",
      "Epoch [174/360], Batch [170/196], Loss: 0.0334\n",
      "Epoch [174/360], Batch [175/196], Loss: 0.0369\n",
      "Epoch [174/360], Batch [180/196], Loss: 0.0301\n",
      "Epoch [174/360], Batch [185/196], Loss: 0.0236\n",
      "Epoch [174/360], Batch [190/196], Loss: 0.0270\n",
      "Epoch [174/360], Batch [195/196], Loss: 0.0278\n",
      "Epoch [175/360], Batch [5/196], Loss: 0.0158\n",
      "Epoch [175/360], Batch [10/196], Loss: 0.0187\n",
      "Epoch [175/360], Batch [15/196], Loss: 0.0205\n",
      "Epoch [175/360], Batch [20/196], Loss: 0.0318\n",
      "Epoch [175/360], Batch [25/196], Loss: 0.0186\n",
      "Epoch [175/360], Batch [30/196], Loss: 0.0255\n",
      "Epoch [175/360], Batch [35/196], Loss: 0.0191\n",
      "Epoch [175/360], Batch [40/196], Loss: 0.0228\n",
      "Epoch [175/360], Batch [45/196], Loss: 0.0230\n",
      "Epoch [175/360], Batch [50/196], Loss: 0.0233\n",
      "Epoch [175/360], Batch [55/196], Loss: 0.0208\n",
      "Epoch [175/360], Batch [60/196], Loss: 0.0285\n",
      "Epoch [175/360], Batch [65/196], Loss: 0.0227\n",
      "Epoch [175/360], Batch [70/196], Loss: 0.0217\n",
      "Epoch [175/360], Batch [75/196], Loss: 0.0284\n",
      "Epoch [175/360], Batch [80/196], Loss: 0.0237\n",
      "Epoch [175/360], Batch [85/196], Loss: 0.0202\n",
      "Epoch [175/360], Batch [90/196], Loss: 0.0743\n",
      "Epoch [175/360], Batch [95/196], Loss: 0.0171\n",
      "Epoch [175/360], Batch [100/196], Loss: 0.0374\n",
      "Epoch [175/360], Batch [105/196], Loss: 0.0215\n",
      "Epoch [175/360], Batch [110/196], Loss: 0.0265\n",
      "Epoch [175/360], Batch [115/196], Loss: 0.0227\n",
      "Epoch [175/360], Batch [120/196], Loss: 0.0316\n",
      "Epoch [175/360], Batch [125/196], Loss: 0.0342\n",
      "Epoch [175/360], Batch [130/196], Loss: 0.0181\n",
      "Epoch [175/360], Batch [135/196], Loss: 0.0214\n",
      "Epoch [175/360], Batch [140/196], Loss: 0.0255\n",
      "Epoch [175/360], Batch [145/196], Loss: 0.0194\n",
      "Epoch [175/360], Batch [150/196], Loss: 0.0292\n",
      "Epoch [175/360], Batch [155/196], Loss: 0.0187\n",
      "Epoch [175/360], Batch [160/196], Loss: 0.0292\n",
      "Epoch [175/360], Batch [165/196], Loss: 0.0208\n",
      "Epoch [175/360], Batch [170/196], Loss: 0.0288\n",
      "Epoch [175/360], Batch [175/196], Loss: 0.0351\n",
      "Epoch [175/360], Batch [180/196], Loss: 0.0182\n",
      "Epoch [175/360], Batch [185/196], Loss: 0.0286\n",
      "Epoch [175/360], Batch [190/196], Loss: 0.0300\n",
      "Epoch [175/360], Batch [195/196], Loss: 0.0216\n",
      "Epoch [176/360], Batch [5/196], Loss: 0.0302\n",
      "Epoch [176/360], Batch [10/196], Loss: 0.0177\n",
      "Epoch [176/360], Batch [15/196], Loss: 0.0129\n",
      "Epoch [176/360], Batch [20/196], Loss: 0.0279\n",
      "Epoch [176/360], Batch [25/196], Loss: 0.0236\n",
      "Epoch [176/360], Batch [30/196], Loss: 0.0185\n",
      "Epoch [176/360], Batch [35/196], Loss: 0.0257\n",
      "Epoch [176/360], Batch [40/196], Loss: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/360], Batch [45/196], Loss: 0.0211\n",
      "Epoch [176/360], Batch [50/196], Loss: 0.0149\n",
      "Epoch [176/360], Batch [55/196], Loss: 0.0188\n",
      "Epoch [176/360], Batch [60/196], Loss: 0.0276\n",
      "Epoch [176/360], Batch [65/196], Loss: 0.0222\n",
      "Epoch [176/360], Batch [70/196], Loss: 0.0249\n",
      "Epoch [176/360], Batch [75/196], Loss: 0.0206\n",
      "Epoch [176/360], Batch [80/196], Loss: 0.0147\n",
      "Epoch [176/360], Batch [85/196], Loss: 0.0245\n",
      "Epoch [176/360], Batch [90/196], Loss: 0.0185\n",
      "Epoch [176/360], Batch [95/196], Loss: 0.0224\n",
      "Epoch [176/360], Batch [100/196], Loss: 0.0224\n",
      "Epoch [176/360], Batch [105/196], Loss: 0.0317\n",
      "Epoch [176/360], Batch [110/196], Loss: 0.0274\n",
      "Epoch [176/360], Batch [115/196], Loss: 0.0166\n",
      "Epoch [176/360], Batch [120/196], Loss: 0.0216\n",
      "Epoch [176/360], Batch [125/196], Loss: 0.0169\n",
      "Epoch [176/360], Batch [130/196], Loss: 0.0437\n",
      "Epoch [176/360], Batch [135/196], Loss: 0.0257\n",
      "Epoch [176/360], Batch [140/196], Loss: 0.0263\n",
      "Epoch [176/360], Batch [145/196], Loss: 0.0237\n",
      "Epoch [176/360], Batch [150/196], Loss: 0.0239\n",
      "Epoch [176/360], Batch [155/196], Loss: 0.0246\n",
      "Epoch [176/360], Batch [160/196], Loss: 0.0225\n",
      "Epoch [176/360], Batch [165/196], Loss: 0.0312\n",
      "Epoch [176/360], Batch [170/196], Loss: 0.0294\n",
      "Epoch [176/360], Batch [175/196], Loss: 0.0418\n",
      "Epoch [176/360], Batch [180/196], Loss: 0.0356\n",
      "Epoch [176/360], Batch [185/196], Loss: 0.0416\n",
      "Epoch [176/360], Batch [190/196], Loss: 0.0293\n",
      "Epoch [176/360], Batch [195/196], Loss: 0.0218\n",
      "Epoch [177/360], Batch [5/196], Loss: 0.0464\n",
      "Epoch [177/360], Batch [10/196], Loss: 0.0383\n",
      "Epoch [177/360], Batch [15/196], Loss: 0.0274\n",
      "Epoch [177/360], Batch [20/196], Loss: 0.0223\n",
      "Epoch [177/360], Batch [25/196], Loss: 0.0273\n",
      "Epoch [177/360], Batch [30/196], Loss: 0.0321\n",
      "Epoch [177/360], Batch [35/196], Loss: 0.0362\n",
      "Epoch [177/360], Batch [40/196], Loss: 0.0248\n",
      "Epoch [177/360], Batch [45/196], Loss: 0.0304\n",
      "Epoch [177/360], Batch [50/196], Loss: 0.0239\n",
      "Epoch [177/360], Batch [55/196], Loss: 0.0231\n",
      "Epoch [177/360], Batch [60/196], Loss: 0.0257\n",
      "Epoch [177/360], Batch [65/196], Loss: 0.0489\n",
      "Epoch [177/360], Batch [70/196], Loss: 0.0299\n",
      "Epoch [177/360], Batch [75/196], Loss: 0.0179\n",
      "Epoch [177/360], Batch [80/196], Loss: 0.0255\n",
      "Epoch [177/360], Batch [85/196], Loss: 0.0235\n",
      "Epoch [177/360], Batch [90/196], Loss: 0.0175\n",
      "Epoch [177/360], Batch [95/196], Loss: 0.0236\n",
      "Epoch [177/360], Batch [100/196], Loss: 0.0189\n",
      "Epoch [177/360], Batch [105/196], Loss: 0.0207\n",
      "Epoch [177/360], Batch [110/196], Loss: 0.0220\n",
      "Epoch [177/360], Batch [115/196], Loss: 0.0222\n",
      "Epoch [177/360], Batch [120/196], Loss: 0.0281\n",
      "Epoch [177/360], Batch [125/196], Loss: 0.0163\n",
      "Epoch [177/360], Batch [130/196], Loss: 0.0243\n",
      "Epoch [177/360], Batch [135/196], Loss: 0.0214\n",
      "Epoch [177/360], Batch [140/196], Loss: 0.0188\n",
      "Epoch [177/360], Batch [145/196], Loss: 0.0320\n",
      "Epoch [177/360], Batch [150/196], Loss: 0.0301\n",
      "Epoch [177/360], Batch [155/196], Loss: 0.0416\n",
      "Epoch [177/360], Batch [160/196], Loss: 0.0277\n",
      "Epoch [177/360], Batch [165/196], Loss: 0.0270\n",
      "Epoch [177/360], Batch [170/196], Loss: 0.0251\n",
      "Epoch [177/360], Batch [175/196], Loss: 0.0248\n",
      "Epoch [177/360], Batch [180/196], Loss: 0.0234\n",
      "Epoch [177/360], Batch [185/196], Loss: 0.0349\n",
      "Epoch [177/360], Batch [190/196], Loss: 0.0192\n",
      "Epoch [177/360], Batch [195/196], Loss: 0.0294\n",
      "Epoch [178/360], Batch [5/196], Loss: 0.0211\n",
      "Epoch [178/360], Batch [10/196], Loss: 0.0214\n",
      "Epoch [178/360], Batch [15/196], Loss: 0.0252\n",
      "Epoch [178/360], Batch [20/196], Loss: 0.1046\n",
      "Epoch [178/360], Batch [25/196], Loss: 0.0301\n",
      "Epoch [178/360], Batch [30/196], Loss: 0.0401\n",
      "Epoch [178/360], Batch [35/196], Loss: 0.0371\n",
      "Epoch [178/360], Batch [40/196], Loss: 0.0309\n",
      "Epoch [178/360], Batch [45/196], Loss: 0.0208\n",
      "Epoch [178/360], Batch [50/196], Loss: 0.0333\n",
      "Epoch [178/360], Batch [55/196], Loss: 0.0336\n",
      "Epoch [178/360], Batch [60/196], Loss: 0.0344\n",
      "Epoch [178/360], Batch [65/196], Loss: 0.0394\n",
      "Epoch [178/360], Batch [70/196], Loss: 0.0332\n",
      "Epoch [178/360], Batch [75/196], Loss: 0.0397\n",
      "Epoch [178/360], Batch [80/196], Loss: 0.0323\n",
      "Epoch [178/360], Batch [85/196], Loss: 0.0329\n",
      "Epoch [178/360], Batch [90/196], Loss: 0.0386\n",
      "Epoch [178/360], Batch [95/196], Loss: 0.0222\n",
      "Epoch [178/360], Batch [100/196], Loss: 0.0292\n",
      "Epoch [178/360], Batch [105/196], Loss: 0.0323\n",
      "Epoch [178/360], Batch [110/196], Loss: 0.0327\n",
      "Epoch [178/360], Batch [115/196], Loss: 0.0333\n",
      "Epoch [178/360], Batch [120/196], Loss: 0.0398\n",
      "Epoch [178/360], Batch [125/196], Loss: 0.0279\n",
      "Epoch [178/360], Batch [130/196], Loss: 0.0313\n",
      "Epoch [178/360], Batch [135/196], Loss: 0.0339\n",
      "Epoch [178/360], Batch [140/196], Loss: 0.0327\n",
      "Epoch [178/360], Batch [145/196], Loss: 0.0292\n",
      "Epoch [178/360], Batch [150/196], Loss: 0.0269\n",
      "Epoch [178/360], Batch [155/196], Loss: 0.0294\n",
      "Epoch [178/360], Batch [160/196], Loss: 0.0270\n",
      "Epoch [178/360], Batch [165/196], Loss: 0.0272\n",
      "Epoch [178/360], Batch [170/196], Loss: 0.0352\n",
      "Epoch [178/360], Batch [175/196], Loss: 0.0280\n",
      "Epoch [178/360], Batch [180/196], Loss: 0.0207\n",
      "Epoch [178/360], Batch [185/196], Loss: 0.0222\n",
      "Epoch [178/360], Batch [190/196], Loss: 0.0251\n",
      "Epoch [178/360], Batch [195/196], Loss: 0.0234\n",
      "Epoch [179/360], Batch [5/196], Loss: 0.0319\n",
      "Epoch [179/360], Batch [10/196], Loss: 0.0255\n",
      "Epoch [179/360], Batch [15/196], Loss: 0.0163\n",
      "Epoch [179/360], Batch [20/196], Loss: 0.0290\n",
      "Epoch [179/360], Batch [25/196], Loss: 0.0231\n",
      "Epoch [179/360], Batch [30/196], Loss: 0.0293\n",
      "Epoch [179/360], Batch [35/196], Loss: 0.0272\n",
      "Epoch [179/360], Batch [40/196], Loss: 0.0254\n",
      "Epoch [179/360], Batch [45/196], Loss: 0.0201\n",
      "Epoch [179/360], Batch [50/196], Loss: 0.0241\n",
      "Epoch [179/360], Batch [55/196], Loss: 0.0214\n",
      "Epoch [179/360], Batch [60/196], Loss: 0.0321\n",
      "Epoch [179/360], Batch [65/196], Loss: 0.0294\n",
      "Epoch [179/360], Batch [70/196], Loss: 0.0236\n",
      "Epoch [179/360], Batch [75/196], Loss: 0.0375\n",
      "Epoch [179/360], Batch [80/196], Loss: 0.0270\n",
      "Epoch [179/360], Batch [85/196], Loss: 0.0258\n",
      "Epoch [179/360], Batch [90/196], Loss: 0.0224\n",
      "Epoch [179/360], Batch [95/196], Loss: 0.0331\n",
      "Epoch [179/360], Batch [100/196], Loss: 0.0192\n",
      "Epoch [179/360], Batch [105/196], Loss: 0.0311\n",
      "Epoch [179/360], Batch [110/196], Loss: 0.0248\n",
      "Epoch [179/360], Batch [115/196], Loss: 0.0339\n",
      "Epoch [179/360], Batch [120/196], Loss: 0.0223\n",
      "Epoch [179/360], Batch [125/196], Loss: 0.0342\n",
      "Epoch [179/360], Batch [130/196], Loss: 0.0394\n",
      "Epoch [179/360], Batch [135/196], Loss: 0.0258\n",
      "Epoch [179/360], Batch [140/196], Loss: 0.0374\n",
      "Epoch [179/360], Batch [145/196], Loss: 0.0193\n",
      "Epoch [179/360], Batch [150/196], Loss: 0.0283\n",
      "Epoch [179/360], Batch [155/196], Loss: 0.0411\n",
      "Epoch [179/360], Batch [160/196], Loss: 0.0258\n",
      "Epoch [179/360], Batch [165/196], Loss: 0.0390\n",
      "Epoch [179/360], Batch [170/196], Loss: 0.0284\n",
      "Epoch [179/360], Batch [175/196], Loss: 0.0296\n",
      "Epoch [179/360], Batch [180/196], Loss: 0.0242\n",
      "Epoch [179/360], Batch [185/196], Loss: 0.0299\n",
      "Epoch [179/360], Batch [190/196], Loss: 0.0370\n",
      "Epoch [179/360], Batch [195/196], Loss: 0.0235\n",
      "Epoch [180/360], Batch [5/196], Loss: 0.0421\n",
      "Epoch [180/360], Batch [10/196], Loss: 0.0221\n",
      "Epoch [180/360], Batch [15/196], Loss: 0.0264\n",
      "Epoch [180/360], Batch [20/196], Loss: 0.0183\n",
      "Epoch [180/360], Batch [25/196], Loss: 0.0291\n",
      "Epoch [180/360], Batch [30/196], Loss: 0.0415\n",
      "Epoch [180/360], Batch [35/196], Loss: 0.0305\n",
      "Epoch [180/360], Batch [40/196], Loss: 0.0213\n",
      "Epoch [180/360], Batch [45/196], Loss: 0.0238\n",
      "Epoch [180/360], Batch [50/196], Loss: 0.0264\n",
      "Epoch [180/360], Batch [55/196], Loss: 0.0213\n",
      "Epoch [180/360], Batch [60/196], Loss: 0.0558\n",
      "Epoch [180/360], Batch [65/196], Loss: 0.0308\n",
      "Epoch [180/360], Batch [70/196], Loss: 0.0363\n",
      "Epoch [180/360], Batch [75/196], Loss: 0.0244\n",
      "Epoch [180/360], Batch [80/196], Loss: 0.0231\n",
      "Epoch [180/360], Batch [85/196], Loss: 0.0242\n",
      "Epoch [180/360], Batch [90/196], Loss: 0.0297\n",
      "Epoch [180/360], Batch [95/196], Loss: 0.0269\n",
      "Epoch [180/360], Batch [100/196], Loss: 0.0238\n",
      "Epoch [180/360], Batch [105/196], Loss: 0.0264\n",
      "Epoch [180/360], Batch [110/196], Loss: 0.0415\n",
      "Epoch [180/360], Batch [115/196], Loss: 0.0540\n",
      "Epoch [180/360], Batch [120/196], Loss: 0.0322\n",
      "Epoch [180/360], Batch [125/196], Loss: 0.0364\n",
      "Epoch [180/360], Batch [130/196], Loss: 0.0219\n",
      "Epoch [180/360], Batch [135/196], Loss: 0.0255\n",
      "Epoch [180/360], Batch [140/196], Loss: 0.0216\n",
      "Epoch [180/360], Batch [145/196], Loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [180/360], Batch [150/196], Loss: 0.0286\n",
      "Epoch [180/360], Batch [155/196], Loss: 0.0439\n",
      "Epoch [180/360], Batch [160/196], Loss: 0.0412\n",
      "Epoch [180/360], Batch [165/196], Loss: 0.0669\n",
      "Epoch [180/360], Batch [170/196], Loss: 0.0236\n",
      "Epoch [180/360], Batch [175/196], Loss: 0.0208\n",
      "Epoch [180/360], Batch [180/196], Loss: 0.0285\n",
      "Epoch [180/360], Batch [185/196], Loss: 0.0412\n",
      "Epoch [180/360], Batch [190/196], Loss: 0.0266\n",
      "Epoch [180/360], Batch [195/196], Loss: 0.0380\n",
      "Epoch [181/360], Batch [5/196], Loss: 0.0340\n",
      "Epoch [181/360], Batch [10/196], Loss: 0.0447\n",
      "Epoch [181/360], Batch [15/196], Loss: 0.0313\n",
      "Epoch [181/360], Batch [20/196], Loss: 0.0352\n",
      "Epoch [181/360], Batch [25/196], Loss: 0.0404\n",
      "Epoch [181/360], Batch [30/196], Loss: 0.0353\n",
      "Epoch [181/360], Batch [35/196], Loss: 0.0540\n",
      "Epoch [181/360], Batch [40/196], Loss: 0.0371\n",
      "Epoch [181/360], Batch [45/196], Loss: 0.0264\n",
      "Epoch [181/360], Batch [50/196], Loss: 0.0289\n",
      "Epoch [181/360], Batch [55/196], Loss: 0.0326\n",
      "Epoch [181/360], Batch [60/196], Loss: 0.0323\n",
      "Epoch [181/360], Batch [65/196], Loss: 0.0240\n",
      "Epoch [181/360], Batch [70/196], Loss: 0.0281\n",
      "Epoch [181/360], Batch [75/196], Loss: 0.0425\n",
      "Epoch [181/360], Batch [80/196], Loss: 0.0411\n",
      "Epoch [181/360], Batch [85/196], Loss: 0.0410\n",
      "Epoch [181/360], Batch [90/196], Loss: 0.0300\n",
      "Epoch [181/360], Batch [95/196], Loss: 0.0376\n",
      "Epoch [181/360], Batch [100/196], Loss: 0.0503\n",
      "Epoch [181/360], Batch [105/196], Loss: 0.0434\n",
      "Epoch [181/360], Batch [110/196], Loss: 0.0352\n",
      "Epoch [181/360], Batch [115/196], Loss: 0.0392\n",
      "Epoch [181/360], Batch [120/196], Loss: 0.0276\n",
      "Epoch [181/360], Batch [125/196], Loss: 0.0432\n",
      "Epoch [181/360], Batch [130/196], Loss: 0.0298\n",
      "Epoch [181/360], Batch [135/196], Loss: 0.0250\n",
      "Epoch [181/360], Batch [140/196], Loss: 0.0250\n",
      "Epoch [181/360], Batch [145/196], Loss: 0.0252\n",
      "Epoch [181/360], Batch [150/196], Loss: 0.0365\n",
      "Epoch [181/360], Batch [155/196], Loss: 0.0444\n",
      "Epoch [181/360], Batch [160/196], Loss: 0.0388\n",
      "Epoch [181/360], Batch [165/196], Loss: 0.0337\n",
      "Epoch [181/360], Batch [170/196], Loss: 0.0287\n",
      "Epoch [181/360], Batch [175/196], Loss: 0.0410\n",
      "Epoch [181/360], Batch [180/196], Loss: 0.0338\n",
      "Epoch [181/360], Batch [185/196], Loss: 0.0426\n",
      "Epoch [181/360], Batch [190/196], Loss: 0.0568\n",
      "Epoch [181/360], Batch [195/196], Loss: 0.0371\n",
      "Epoch [182/360], Batch [5/196], Loss: 0.0605\n",
      "Epoch [182/360], Batch [10/196], Loss: 0.0434\n",
      "Epoch [182/360], Batch [15/196], Loss: 0.0177\n",
      "Epoch [182/360], Batch [20/196], Loss: 0.0273\n",
      "Epoch [182/360], Batch [25/196], Loss: 0.0379\n",
      "Epoch [182/360], Batch [30/196], Loss: 0.0232\n",
      "Epoch [182/360], Batch [35/196], Loss: 0.0389\n",
      "Epoch [182/360], Batch [40/196], Loss: 0.0404\n",
      "Epoch [182/360], Batch [45/196], Loss: 0.0306\n",
      "Epoch [182/360], Batch [50/196], Loss: 0.0269\n",
      "Epoch [182/360], Batch [55/196], Loss: 0.0330\n",
      "Epoch [182/360], Batch [60/196], Loss: 0.0298\n",
      "Epoch [182/360], Batch [65/196], Loss: 0.0377\n",
      "Epoch [182/360], Batch [70/196], Loss: 0.0347\n",
      "Epoch [182/360], Batch [75/196], Loss: 0.0291\n",
      "Epoch [182/360], Batch [80/196], Loss: 0.0350\n",
      "Epoch [182/360], Batch [85/196], Loss: 0.0683\n",
      "Epoch [182/360], Batch [90/196], Loss: 0.0337\n",
      "Epoch [182/360], Batch [95/196], Loss: 0.0242\n",
      "Epoch [182/360], Batch [100/196], Loss: 0.1020\n",
      "Epoch [182/360], Batch [105/196], Loss: 0.0291\n",
      "Epoch [182/360], Batch [110/196], Loss: 0.0339\n",
      "Epoch [182/360], Batch [115/196], Loss: 0.0546\n",
      "Epoch [182/360], Batch [120/196], Loss: 0.0257\n",
      "Epoch [182/360], Batch [125/196], Loss: 0.0299\n",
      "Epoch [182/360], Batch [130/196], Loss: 0.0454\n",
      "Epoch [182/360], Batch [135/196], Loss: 0.0477\n",
      "Epoch [182/360], Batch [140/196], Loss: 0.0290\n",
      "Epoch [182/360], Batch [145/196], Loss: 0.0359\n",
      "Epoch [182/360], Batch [150/196], Loss: 0.0452\n",
      "Epoch [182/360], Batch [155/196], Loss: 0.0361\n",
      "Epoch [182/360], Batch [160/196], Loss: 0.0567\n",
      "Epoch [182/360], Batch [165/196], Loss: 0.0505\n",
      "Epoch [182/360], Batch [170/196], Loss: 0.0442\n",
      "Epoch [182/360], Batch [175/196], Loss: 0.0329\n",
      "Epoch [182/360], Batch [180/196], Loss: 0.0319\n",
      "Epoch [182/360], Batch [185/196], Loss: 0.0385\n",
      "Epoch [182/360], Batch [190/196], Loss: 0.0348\n",
      "Epoch [182/360], Batch [195/196], Loss: 0.0377\n",
      "Epoch [183/360], Batch [5/196], Loss: 0.0331\n",
      "Epoch [183/360], Batch [10/196], Loss: 0.0301\n",
      "Epoch [183/360], Batch [15/196], Loss: 0.0432\n",
      "Epoch [183/360], Batch [20/196], Loss: 0.0342\n",
      "Epoch [183/360], Batch [25/196], Loss: 0.0424\n",
      "Epoch [183/360], Batch [30/196], Loss: 0.0359\n",
      "Epoch [183/360], Batch [35/196], Loss: 0.0369\n",
      "Epoch [183/360], Batch [40/196], Loss: 0.0393\n",
      "Epoch [183/360], Batch [45/196], Loss: 0.0320\n",
      "Epoch [183/360], Batch [50/196], Loss: 0.0238\n",
      "Epoch [183/360], Batch [55/196], Loss: 0.0379\n",
      "Epoch [183/360], Batch [60/196], Loss: 0.0573\n",
      "Epoch [183/360], Batch [65/196], Loss: 0.0344\n",
      "Epoch [183/360], Batch [70/196], Loss: 0.0433\n",
      "Epoch [183/360], Batch [75/196], Loss: 0.0370\n",
      "Epoch [183/360], Batch [80/196], Loss: 0.0476\n",
      "Epoch [183/360], Batch [85/196], Loss: 0.0396\n",
      "Epoch [183/360], Batch [90/196], Loss: 0.0249\n",
      "Epoch [183/360], Batch [95/196], Loss: 0.0400\n",
      "Epoch [183/360], Batch [100/196], Loss: 0.0558\n",
      "Epoch [183/360], Batch [105/196], Loss: 0.0507\n",
      "Epoch [183/360], Batch [110/196], Loss: 0.0247\n",
      "Epoch [183/360], Batch [115/196], Loss: 0.0321\n",
      "Epoch [183/360], Batch [120/196], Loss: 0.0837\n",
      "Epoch [183/360], Batch [125/196], Loss: 0.0502\n",
      "Epoch [183/360], Batch [130/196], Loss: 0.0528\n",
      "Epoch [183/360], Batch [135/196], Loss: 0.0503\n",
      "Epoch [183/360], Batch [140/196], Loss: 0.0302\n",
      "Epoch [183/360], Batch [145/196], Loss: 0.0278\n",
      "Epoch [183/360], Batch [150/196], Loss: 0.0477\n",
      "Epoch [183/360], Batch [155/196], Loss: 0.0323\n",
      "Epoch [183/360], Batch [160/196], Loss: 0.0453\n",
      "Epoch [183/360], Batch [165/196], Loss: 0.0264\n",
      "Epoch [183/360], Batch [170/196], Loss: 0.0297\n",
      "Epoch [183/360], Batch [175/196], Loss: 0.0364\n",
      "Epoch [183/360], Batch [180/196], Loss: 0.0407\n",
      "Epoch [183/360], Batch [185/196], Loss: 0.0308\n",
      "Epoch [183/360], Batch [190/196], Loss: 0.0176\n",
      "Epoch [183/360], Batch [195/196], Loss: 0.0410\n",
      "Epoch [184/360], Batch [5/196], Loss: 0.0588\n",
      "Epoch [184/360], Batch [10/196], Loss: 0.0317\n",
      "Epoch [184/360], Batch [15/196], Loss: 0.0309\n",
      "Epoch [184/360], Batch [20/196], Loss: 0.0885\n",
      "Epoch [184/360], Batch [25/196], Loss: 0.0553\n",
      "Epoch [184/360], Batch [30/196], Loss: 0.0608\n",
      "Epoch [184/360], Batch [35/196], Loss: 0.0916\n",
      "Epoch [184/360], Batch [40/196], Loss: 0.0576\n",
      "Epoch [184/360], Batch [45/196], Loss: 0.0678\n",
      "Epoch [184/360], Batch [50/196], Loss: 0.0486\n",
      "Epoch [184/360], Batch [55/196], Loss: 0.0959\n",
      "Epoch [184/360], Batch [60/196], Loss: 0.0638\n",
      "Epoch [184/360], Batch [65/196], Loss: 0.0662\n",
      "Epoch [184/360], Batch [70/196], Loss: 0.0537\n",
      "Epoch [184/360], Batch [75/196], Loss: 0.0721\n",
      "Epoch [184/360], Batch [80/196], Loss: 0.0606\n",
      "Epoch [184/360], Batch [85/196], Loss: 0.0339\n",
      "Epoch [184/360], Batch [90/196], Loss: 0.0467\n",
      "Epoch [184/360], Batch [95/196], Loss: 0.0498\n",
      "Epoch [184/360], Batch [100/196], Loss: 0.0478\n",
      "Epoch [184/360], Batch [105/196], Loss: 0.0409\n",
      "Epoch [184/360], Batch [110/196], Loss: 0.0311\n",
      "Epoch [184/360], Batch [115/196], Loss: 0.0705\n",
      "Epoch [184/360], Batch [120/196], Loss: 0.0597\n",
      "Epoch [184/360], Batch [125/196], Loss: 0.0527\n",
      "Epoch [184/360], Batch [130/196], Loss: 0.0830\n",
      "Epoch [184/360], Batch [135/196], Loss: 0.0562\n",
      "Epoch [184/360], Batch [140/196], Loss: 0.0500\n",
      "Epoch [184/360], Batch [145/196], Loss: 0.0401\n",
      "Epoch [184/360], Batch [150/196], Loss: 0.0541\n",
      "Epoch [184/360], Batch [155/196], Loss: 0.0518\n",
      "Epoch [184/360], Batch [160/196], Loss: 0.0394\n",
      "Epoch [184/360], Batch [165/196], Loss: 0.0480\n",
      "Epoch [184/360], Batch [170/196], Loss: 0.0437\n",
      "Epoch [184/360], Batch [175/196], Loss: 0.0711\n",
      "Epoch [184/360], Batch [180/196], Loss: 0.0685\n",
      "Epoch [184/360], Batch [185/196], Loss: 0.0446\n",
      "Epoch [184/360], Batch [190/196], Loss: 0.0302\n",
      "Epoch [184/360], Batch [195/196], Loss: 0.0361\n",
      "Epoch [185/360], Batch [5/196], Loss: 0.0254\n",
      "Epoch [185/360], Batch [10/196], Loss: 0.0432\n",
      "Epoch [185/360], Batch [15/196], Loss: 0.0377\n",
      "Epoch [185/360], Batch [20/196], Loss: 0.0448\n",
      "Epoch [185/360], Batch [25/196], Loss: 0.0793\n",
      "Epoch [185/360], Batch [30/196], Loss: 0.0804\n",
      "Epoch [185/360], Batch [35/196], Loss: 0.0890\n",
      "Epoch [185/360], Batch [40/196], Loss: 0.0750\n",
      "Epoch [185/360], Batch [45/196], Loss: 0.0679\n",
      "Epoch [185/360], Batch [50/196], Loss: 0.1036\n",
      "Epoch [185/360], Batch [55/196], Loss: 0.1020\n",
      "Epoch [185/360], Batch [60/196], Loss: 0.1414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [185/360], Batch [65/196], Loss: 0.0607\n",
      "Epoch [185/360], Batch [70/196], Loss: 0.0774\n",
      "Epoch [185/360], Batch [75/196], Loss: 0.0713\n",
      "Epoch [185/360], Batch [80/196], Loss: 0.0569\n",
      "Epoch [185/360], Batch [85/196], Loss: 0.0634\n",
      "Epoch [185/360], Batch [90/196], Loss: 0.0660\n",
      "Epoch [185/360], Batch [95/196], Loss: 0.0726\n",
      "Epoch [185/360], Batch [100/196], Loss: 0.0489\n",
      "Epoch [185/360], Batch [105/196], Loss: 0.0317\n",
      "Epoch [185/360], Batch [110/196], Loss: 0.1665\n",
      "Epoch [185/360], Batch [115/196], Loss: 0.0732\n",
      "Epoch [185/360], Batch [120/196], Loss: 0.0443\n",
      "Epoch [185/360], Batch [125/196], Loss: 0.0786\n",
      "Epoch [185/360], Batch [130/196], Loss: 0.0750\n",
      "Epoch [185/360], Batch [135/196], Loss: 0.1022\n",
      "Epoch [185/360], Batch [140/196], Loss: 0.0683\n",
      "Epoch [185/360], Batch [145/196], Loss: 0.0837\n",
      "Epoch [185/360], Batch [150/196], Loss: 0.0564\n",
      "Epoch [185/360], Batch [155/196], Loss: 0.1352\n",
      "Epoch [185/360], Batch [160/196], Loss: 0.0812\n",
      "Epoch [185/360], Batch [165/196], Loss: 0.1127\n",
      "Epoch [185/360], Batch [170/196], Loss: 0.0825\n",
      "Epoch [185/360], Batch [175/196], Loss: 0.0563\n",
      "Epoch [185/360], Batch [180/196], Loss: 0.0834\n",
      "Epoch [185/360], Batch [185/196], Loss: 0.0710\n",
      "Epoch [185/360], Batch [190/196], Loss: 0.0810\n",
      "Epoch [185/360], Batch [195/196], Loss: 0.0550\n",
      "Epoch [186/360], Batch [5/196], Loss: 0.0588\n",
      "Epoch [186/360], Batch [10/196], Loss: 0.0508\n",
      "Epoch [186/360], Batch [15/196], Loss: 0.1247\n",
      "Epoch [186/360], Batch [20/196], Loss: 0.0625\n",
      "Epoch [186/360], Batch [25/196], Loss: 0.0484\n",
      "Epoch [186/360], Batch [30/196], Loss: 0.0386\n",
      "Epoch [186/360], Batch [35/196], Loss: 0.0697\n",
      "Epoch [186/360], Batch [40/196], Loss: 0.1001\n",
      "Epoch [186/360], Batch [45/196], Loss: 0.0749\n",
      "Epoch [186/360], Batch [50/196], Loss: 0.0689\n",
      "Epoch [186/360], Batch [55/196], Loss: 0.0840\n",
      "Epoch [186/360], Batch [60/196], Loss: 0.0466\n",
      "Epoch [186/360], Batch [65/196], Loss: 0.1031\n",
      "Epoch [186/360], Batch [70/196], Loss: 0.0488\n",
      "Epoch [186/360], Batch [75/196], Loss: 0.0726\n",
      "Epoch [186/360], Batch [80/196], Loss: 0.0605\n",
      "Epoch [186/360], Batch [85/196], Loss: 0.0717\n",
      "Epoch [186/360], Batch [90/196], Loss: 0.0705\n",
      "Epoch [186/360], Batch [95/196], Loss: 0.0754\n",
      "Epoch [186/360], Batch [100/196], Loss: 0.0719\n",
      "Epoch [186/360], Batch [105/196], Loss: 0.0521\n",
      "Epoch [186/360], Batch [110/196], Loss: 0.0317\n",
      "Epoch [186/360], Batch [115/196], Loss: 0.0506\n",
      "Epoch [186/360], Batch [120/196], Loss: 0.0506\n",
      "Epoch [186/360], Batch [125/196], Loss: 0.0496\n",
      "Epoch [186/360], Batch [130/196], Loss: 0.0676\n",
      "Epoch [186/360], Batch [135/196], Loss: 0.0494\n",
      "Epoch [186/360], Batch [140/196], Loss: 0.0531\n",
      "Epoch [186/360], Batch [145/196], Loss: 0.0984\n",
      "Epoch [186/360], Batch [150/196], Loss: 0.0648\n",
      "Epoch [186/360], Batch [155/196], Loss: 0.0523\n",
      "Epoch [186/360], Batch [160/196], Loss: 0.0586\n",
      "Epoch [186/360], Batch [165/196], Loss: 0.0621\n",
      "Epoch [186/360], Batch [170/196], Loss: 0.0538\n",
      "Epoch [186/360], Batch [175/196], Loss: 0.0532\n",
      "Epoch [186/360], Batch [180/196], Loss: 0.0584\n",
      "Epoch [186/360], Batch [185/196], Loss: 0.0587\n",
      "Epoch [186/360], Batch [190/196], Loss: 0.0399\n",
      "Epoch [186/360], Batch [195/196], Loss: 0.0536\n",
      "Epoch [187/360], Batch [5/196], Loss: 0.0606\n",
      "Epoch [187/360], Batch [10/196], Loss: 0.0388\n",
      "Epoch [187/360], Batch [15/196], Loss: 0.0392\n",
      "Epoch [187/360], Batch [20/196], Loss: 0.0466\n",
      "Epoch [187/360], Batch [25/196], Loss: 0.0778\n",
      "Epoch [187/360], Batch [30/196], Loss: 0.0425\n",
      "Epoch [187/360], Batch [35/196], Loss: 0.0574\n",
      "Epoch [187/360], Batch [40/196], Loss: 0.0260\n",
      "Epoch [187/360], Batch [45/196], Loss: 0.0542\n",
      "Epoch [187/360], Batch [50/196], Loss: 0.0407\n",
      "Epoch [187/360], Batch [55/196], Loss: 0.0309\n",
      "Epoch [187/360], Batch [60/196], Loss: 0.0598\n",
      "Epoch [187/360], Batch [65/196], Loss: 0.0338\n",
      "Epoch [187/360], Batch [70/196], Loss: 0.0418\n",
      "Epoch [187/360], Batch [75/196], Loss: 0.0446\n",
      "Epoch [187/360], Batch [80/196], Loss: 0.0418\n",
      "Epoch [187/360], Batch [85/196], Loss: 0.0376\n",
      "Epoch [187/360], Batch [90/196], Loss: 0.0322\n",
      "Epoch [187/360], Batch [95/196], Loss: 0.0314\n",
      "Epoch [187/360], Batch [100/196], Loss: 0.0514\n",
      "Epoch [187/360], Batch [105/196], Loss: 0.0381\n",
      "Epoch [187/360], Batch [110/196], Loss: 0.0520\n",
      "Epoch [187/360], Batch [115/196], Loss: 0.0467\n",
      "Epoch [187/360], Batch [120/196], Loss: 0.0264\n",
      "Epoch [187/360], Batch [125/196], Loss: 0.0395\n",
      "Epoch [187/360], Batch [130/196], Loss: 0.0549\n",
      "Epoch [187/360], Batch [135/196], Loss: 0.0293\n",
      "Epoch [187/360], Batch [140/196], Loss: 0.0497\n",
      "Epoch [187/360], Batch [145/196], Loss: 0.0681\n",
      "Epoch [187/360], Batch [150/196], Loss: 0.0293\n",
      "Epoch [187/360], Batch [155/196], Loss: 0.0356\n",
      "Epoch [187/360], Batch [160/196], Loss: 0.0457\n",
      "Epoch [187/360], Batch [165/196], Loss: 0.0266\n",
      "Epoch [187/360], Batch [170/196], Loss: 0.0288\n",
      "Epoch [187/360], Batch [175/196], Loss: 0.0393\n",
      "Epoch [187/360], Batch [180/196], Loss: 0.0529\n",
      "Epoch [187/360], Batch [185/196], Loss: 0.0521\n",
      "Epoch [187/360], Batch [190/196], Loss: 0.0586\n",
      "Epoch [187/360], Batch [195/196], Loss: 0.0575\n",
      "Epoch [188/360], Batch [5/196], Loss: 0.0301\n",
      "Epoch [188/360], Batch [10/196], Loss: 0.0437\n",
      "Epoch [188/360], Batch [15/196], Loss: 0.0477\n",
      "Epoch [188/360], Batch [20/196], Loss: 0.0467\n",
      "Epoch [188/360], Batch [25/196], Loss: 0.0404\n",
      "Epoch [188/360], Batch [30/196], Loss: 0.0336\n",
      "Epoch [188/360], Batch [35/196], Loss: 0.0346\n",
      "Epoch [188/360], Batch [40/196], Loss: 0.0436\n",
      "Epoch [188/360], Batch [45/196], Loss: 0.0246\n",
      "Epoch [188/360], Batch [50/196], Loss: 0.0344\n",
      "Epoch [188/360], Batch [55/196], Loss: 0.0257\n",
      "Epoch [188/360], Batch [60/196], Loss: 0.0325\n",
      "Epoch [188/360], Batch [65/196], Loss: 0.0297\n",
      "Epoch [188/360], Batch [70/196], Loss: 0.0290\n",
      "Epoch [188/360], Batch [75/196], Loss: 0.0254\n",
      "Epoch [188/360], Batch [80/196], Loss: 0.0221\n",
      "Epoch [188/360], Batch [85/196], Loss: 0.0296\n",
      "Epoch [188/360], Batch [90/196], Loss: 0.0252\n",
      "Epoch [188/360], Batch [95/196], Loss: 0.0284\n",
      "Epoch [188/360], Batch [100/196], Loss: 0.0375\n",
      "Epoch [188/360], Batch [105/196], Loss: 0.0241\n",
      "Epoch [188/360], Batch [110/196], Loss: 0.0365\n",
      "Epoch [188/360], Batch [115/196], Loss: 0.0398\n",
      "Epoch [188/360], Batch [120/196], Loss: 0.0306\n",
      "Epoch [188/360], Batch [125/196], Loss: 0.0261\n",
      "Epoch [188/360], Batch [130/196], Loss: 0.0293\n",
      "Epoch [188/360], Batch [135/196], Loss: 0.0226\n",
      "Epoch [188/360], Batch [140/196], Loss: 0.0323\n",
      "Epoch [188/360], Batch [145/196], Loss: 0.0226\n",
      "Epoch [188/360], Batch [150/196], Loss: 0.0313\n",
      "Epoch [188/360], Batch [155/196], Loss: 0.0285\n",
      "Epoch [188/360], Batch [160/196], Loss: 0.0327\n",
      "Epoch [188/360], Batch [165/196], Loss: 0.0427\n",
      "Epoch [188/360], Batch [170/196], Loss: 0.0343\n",
      "Epoch [188/360], Batch [175/196], Loss: 0.0428\n",
      "Epoch [188/360], Batch [180/196], Loss: 0.0298\n",
      "Epoch [188/360], Batch [185/196], Loss: 0.0312\n",
      "Epoch [188/360], Batch [190/196], Loss: 0.0489\n",
      "Epoch [188/360], Batch [195/196], Loss: 0.0401\n",
      "Epoch [189/360], Batch [5/196], Loss: 0.0225\n",
      "Epoch [189/360], Batch [10/196], Loss: 0.0344\n",
      "Epoch [189/360], Batch [15/196], Loss: 0.0234\n",
      "Epoch [189/360], Batch [20/196], Loss: 0.0168\n",
      "Epoch [189/360], Batch [25/196], Loss: 0.0251\n",
      "Epoch [189/360], Batch [30/196], Loss: 0.0346\n",
      "Epoch [189/360], Batch [35/196], Loss: 0.0293\n",
      "Epoch [189/360], Batch [40/196], Loss: 0.0155\n",
      "Epoch [189/360], Batch [45/196], Loss: 0.0304\n",
      "Epoch [189/360], Batch [50/196], Loss: 0.0261\n",
      "Epoch [189/360], Batch [55/196], Loss: 0.0284\n",
      "Epoch [189/360], Batch [60/196], Loss: 0.0419\n",
      "Epoch [189/360], Batch [65/196], Loss: 0.0435\n",
      "Epoch [189/360], Batch [70/196], Loss: 0.0217\n",
      "Epoch [189/360], Batch [75/196], Loss: 0.0233\n",
      "Epoch [189/360], Batch [80/196], Loss: 0.0232\n",
      "Epoch [189/360], Batch [85/196], Loss: 0.0232\n",
      "Epoch [189/360], Batch [90/196], Loss: 0.0327\n",
      "Epoch [189/360], Batch [95/196], Loss: 0.0267\n",
      "Epoch [189/360], Batch [100/196], Loss: 0.0301\n",
      "Epoch [189/360], Batch [105/196], Loss: 0.0236\n",
      "Epoch [189/360], Batch [110/196], Loss: 0.0266\n",
      "Epoch [189/360], Batch [115/196], Loss: 0.0322\n",
      "Epoch [189/360], Batch [120/196], Loss: 0.0384\n",
      "Epoch [189/360], Batch [125/196], Loss: 0.0264\n",
      "Epoch [189/360], Batch [130/196], Loss: 0.0232\n",
      "Epoch [189/360], Batch [135/196], Loss: 0.0327\n",
      "Epoch [189/360], Batch [140/196], Loss: 0.0311\n",
      "Epoch [189/360], Batch [145/196], Loss: 0.0188\n",
      "Epoch [189/360], Batch [150/196], Loss: 0.0207\n",
      "Epoch [189/360], Batch [155/196], Loss: 0.0447\n",
      "Epoch [189/360], Batch [160/196], Loss: 0.0536\n",
      "Epoch [189/360], Batch [165/196], Loss: 0.0347\n",
      "Epoch [189/360], Batch [170/196], Loss: 0.0328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [189/360], Batch [175/196], Loss: 0.0314\n",
      "Epoch [189/360], Batch [180/196], Loss: 0.0194\n",
      "Epoch [189/360], Batch [185/196], Loss: 0.0202\n",
      "Epoch [189/360], Batch [190/196], Loss: 0.0277\n",
      "Epoch [189/360], Batch [195/196], Loss: 0.0344\n",
      "Epoch [190/360], Batch [5/196], Loss: 0.0759\n",
      "Epoch [190/360], Batch [10/196], Loss: 0.0194\n",
      "Epoch [190/360], Batch [15/196], Loss: 0.0343\n",
      "Epoch [190/360], Batch [20/196], Loss: 0.0318\n",
      "Epoch [190/360], Batch [25/196], Loss: 0.0519\n",
      "Epoch [190/360], Batch [30/196], Loss: 0.0695\n",
      "Epoch [190/360], Batch [35/196], Loss: 0.0358\n",
      "Epoch [190/360], Batch [40/196], Loss: 0.0723\n",
      "Epoch [190/360], Batch [45/196], Loss: 0.0329\n",
      "Epoch [190/360], Batch [50/196], Loss: 0.0655\n",
      "Epoch [190/360], Batch [55/196], Loss: 0.0353\n",
      "Epoch [190/360], Batch [60/196], Loss: 0.0371\n",
      "Epoch [190/360], Batch [65/196], Loss: 0.0355\n",
      "Epoch [190/360], Batch [70/196], Loss: 0.0365\n",
      "Epoch [190/360], Batch [75/196], Loss: 0.0278\n",
      "Epoch [190/360], Batch [80/196], Loss: 0.0361\n",
      "Epoch [190/360], Batch [85/196], Loss: 0.0315\n",
      "Epoch [190/360], Batch [90/196], Loss: 0.0382\n",
      "Epoch [190/360], Batch [95/196], Loss: 0.0447\n",
      "Epoch [190/360], Batch [100/196], Loss: 0.0299\n",
      "Epoch [190/360], Batch [105/196], Loss: 0.0284\n",
      "Epoch [190/360], Batch [110/196], Loss: 0.0343\n",
      "Epoch [190/360], Batch [115/196], Loss: 0.0366\n",
      "Epoch [190/360], Batch [120/196], Loss: 0.0356\n",
      "Epoch [190/360], Batch [125/196], Loss: 0.0386\n",
      "Epoch [190/360], Batch [130/196], Loss: 0.0320\n",
      "Epoch [190/360], Batch [135/196], Loss: 0.0352\n",
      "Epoch [190/360], Batch [140/196], Loss: 0.0279\n",
      "Epoch [190/360], Batch [145/196], Loss: 0.0358\n",
      "Epoch [190/360], Batch [150/196], Loss: 0.0291\n",
      "Epoch [190/360], Batch [155/196], Loss: 0.0287\n",
      "Epoch [190/360], Batch [160/196], Loss: 0.0314\n",
      "Epoch [190/360], Batch [165/196], Loss: 0.0284\n",
      "Epoch [190/360], Batch [170/196], Loss: 0.0357\n",
      "Epoch [190/360], Batch [175/196], Loss: 0.0408\n",
      "Epoch [190/360], Batch [180/196], Loss: 0.0291\n",
      "Epoch [190/360], Batch [185/196], Loss: 0.0312\n",
      "Epoch [190/360], Batch [190/196], Loss: 0.0395\n",
      "Epoch [190/360], Batch [195/196], Loss: 0.0397\n",
      "Epoch [191/360], Batch [5/196], Loss: 0.0316\n",
      "Epoch [191/360], Batch [10/196], Loss: 0.0175\n",
      "Epoch [191/360], Batch [15/196], Loss: 0.0193\n",
      "Epoch [191/360], Batch [20/196], Loss: 0.0325\n",
      "Epoch [191/360], Batch [25/196], Loss: 0.0210\n",
      "Epoch [191/360], Batch [30/196], Loss: 0.0249\n",
      "Epoch [191/360], Batch [35/196], Loss: 0.0255\n",
      "Epoch [191/360], Batch [40/196], Loss: 0.0226\n",
      "Epoch [191/360], Batch [45/196], Loss: 0.0398\n",
      "Epoch [191/360], Batch [50/196], Loss: 0.0354\n",
      "Epoch [191/360], Batch [55/196], Loss: 0.0293\n",
      "Epoch [191/360], Batch [60/196], Loss: 0.0280\n",
      "Epoch [191/360], Batch [65/196], Loss: 0.0231\n",
      "Epoch [191/360], Batch [70/196], Loss: 0.0231\n",
      "Epoch [191/360], Batch [75/196], Loss: 0.0409\n",
      "Epoch [191/360], Batch [80/196], Loss: 0.0310\n",
      "Epoch [191/360], Batch [85/196], Loss: 0.0239\n",
      "Epoch [191/360], Batch [90/196], Loss: 0.0317\n",
      "Epoch [191/360], Batch [95/196], Loss: 0.0246\n",
      "Epoch [191/360], Batch [100/196], Loss: 0.0238\n",
      "Epoch [191/360], Batch [105/196], Loss: 0.0317\n",
      "Epoch [191/360], Batch [110/196], Loss: 0.0259\n",
      "Epoch [191/360], Batch [115/196], Loss: 0.0143\n",
      "Epoch [191/360], Batch [120/196], Loss: 0.0336\n",
      "Epoch [191/360], Batch [125/196], Loss: 0.0320\n",
      "Epoch [191/360], Batch [130/196], Loss: 0.0393\n",
      "Epoch [191/360], Batch [135/196], Loss: 0.0325\n",
      "Epoch [191/360], Batch [140/196], Loss: 0.0333\n",
      "Epoch [191/360], Batch [145/196], Loss: 0.0241\n",
      "Epoch [191/360], Batch [150/196], Loss: 0.0223\n",
      "Epoch [191/360], Batch [155/196], Loss: 0.0409\n",
      "Epoch [191/360], Batch [160/196], Loss: 0.0240\n",
      "Epoch [191/360], Batch [165/196], Loss: 0.0268\n",
      "Epoch [191/360], Batch [170/196], Loss: 0.0345\n",
      "Epoch [191/360], Batch [175/196], Loss: 0.0324\n",
      "Epoch [191/360], Batch [180/196], Loss: 0.0382\n",
      "Epoch [191/360], Batch [185/196], Loss: 0.0218\n",
      "Epoch [191/360], Batch [190/196], Loss: 0.0318\n",
      "Epoch [191/360], Batch [195/196], Loss: 0.0248\n",
      "Epoch [192/360], Batch [5/196], Loss: 0.0301\n",
      "Epoch [192/360], Batch [10/196], Loss: 0.0292\n",
      "Epoch [192/360], Batch [15/196], Loss: 0.0374\n",
      "Epoch [192/360], Batch [20/196], Loss: 0.0421\n",
      "Epoch [192/360], Batch [25/196], Loss: 0.0349\n",
      "Epoch [192/360], Batch [30/196], Loss: 0.0263\n",
      "Epoch [192/360], Batch [35/196], Loss: 0.0385\n",
      "Epoch [192/360], Batch [40/196], Loss: 0.0269\n",
      "Epoch [192/360], Batch [45/196], Loss: 0.0186\n",
      "Epoch [192/360], Batch [50/196], Loss: 0.0207\n",
      "Epoch [192/360], Batch [55/196], Loss: 0.0285\n",
      "Epoch [192/360], Batch [60/196], Loss: 0.0269\n",
      "Epoch [192/360], Batch [65/196], Loss: 0.0308\n",
      "Epoch [192/360], Batch [70/196], Loss: 0.0219\n",
      "Epoch [192/360], Batch [75/196], Loss: 0.0151\n",
      "Epoch [192/360], Batch [80/196], Loss: 0.0237\n",
      "Epoch [192/360], Batch [85/196], Loss: 0.0212\n",
      "Epoch [192/360], Batch [90/196], Loss: 0.0185\n",
      "Epoch [192/360], Batch [95/196], Loss: 0.0465\n",
      "Epoch [192/360], Batch [100/196], Loss: 0.0379\n",
      "Epoch [192/360], Batch [105/196], Loss: 0.0262\n",
      "Epoch [192/360], Batch [110/196], Loss: 0.0302\n",
      "Epoch [192/360], Batch [115/196], Loss: 0.0306\n",
      "Epoch [192/360], Batch [120/196], Loss: 0.0331\n",
      "Epoch [192/360], Batch [125/196], Loss: 0.0307\n",
      "Epoch [192/360], Batch [130/196], Loss: 0.0404\n",
      "Epoch [192/360], Batch [135/196], Loss: 0.0327\n",
      "Epoch [192/360], Batch [140/196], Loss: 0.0279\n",
      "Epoch [192/360], Batch [145/196], Loss: 0.0359\n",
      "Epoch [192/360], Batch [150/196], Loss: 0.0328\n",
      "Epoch [192/360], Batch [155/196], Loss: 0.0415\n",
      "Epoch [192/360], Batch [160/196], Loss: 0.0280\n",
      "Epoch [192/360], Batch [165/196], Loss: 0.0255\n",
      "Epoch [192/360], Batch [170/196], Loss: 0.0181\n",
      "Epoch [192/360], Batch [175/196], Loss: 0.0303\n",
      "Epoch [192/360], Batch [180/196], Loss: 0.0324\n",
      "Epoch [192/360], Batch [185/196], Loss: 0.0288\n",
      "Epoch [192/360], Batch [190/196], Loss: 0.0395\n",
      "Epoch [192/360], Batch [195/196], Loss: 0.0280\n",
      "Epoch [193/360], Batch [5/196], Loss: 0.0199\n",
      "Epoch [193/360], Batch [10/196], Loss: 0.0210\n",
      "Epoch [193/360], Batch [15/196], Loss: 0.0310\n",
      "Epoch [193/360], Batch [20/196], Loss: 0.0337\n",
      "Epoch [193/360], Batch [25/196], Loss: 0.0335\n",
      "Epoch [193/360], Batch [30/196], Loss: 0.0332\n",
      "Epoch [193/360], Batch [35/196], Loss: 0.0187\n",
      "Epoch [193/360], Batch [40/196], Loss: 0.0369\n",
      "Epoch [193/360], Batch [45/196], Loss: 0.0194\n",
      "Epoch [193/360], Batch [50/196], Loss: 0.0292\n",
      "Epoch [193/360], Batch [55/196], Loss: 0.0356\n",
      "Epoch [193/360], Batch [60/196], Loss: 0.0261\n",
      "Epoch [193/360], Batch [65/196], Loss: 0.0211\n",
      "Epoch [193/360], Batch [70/196], Loss: 0.0324\n",
      "Epoch [193/360], Batch [75/196], Loss: 0.0294\n",
      "Epoch [193/360], Batch [80/196], Loss: 0.0340\n",
      "Epoch [193/360], Batch [85/196], Loss: 0.0322\n",
      "Epoch [193/360], Batch [90/196], Loss: 0.0239\n",
      "Epoch [193/360], Batch [95/196], Loss: 0.0260\n",
      "Epoch [193/360], Batch [100/196], Loss: 0.0383\n",
      "Epoch [193/360], Batch [105/196], Loss: 0.0378\n",
      "Epoch [193/360], Batch [110/196], Loss: 0.0250\n",
      "Epoch [193/360], Batch [115/196], Loss: 0.0345\n",
      "Epoch [193/360], Batch [120/196], Loss: 0.0250\n",
      "Epoch [193/360], Batch [125/196], Loss: 0.0221\n",
      "Epoch [193/360], Batch [130/196], Loss: 0.0172\n",
      "Epoch [193/360], Batch [135/196], Loss: 0.1047\n",
      "Epoch [193/360], Batch [140/196], Loss: 0.0273\n",
      "Epoch [193/360], Batch [145/196], Loss: 0.0359\n",
      "Epoch [193/360], Batch [150/196], Loss: 0.0270\n",
      "Epoch [193/360], Batch [155/196], Loss: 0.0551\n",
      "Epoch [193/360], Batch [160/196], Loss: 0.0212\n",
      "Epoch [193/360], Batch [165/196], Loss: 0.0281\n",
      "Epoch [193/360], Batch [170/196], Loss: 0.0294\n",
      "Epoch [193/360], Batch [175/196], Loss: 0.0261\n",
      "Epoch [193/360], Batch [180/196], Loss: 0.0174\n",
      "Epoch [193/360], Batch [185/196], Loss: 0.0197\n",
      "Epoch [193/360], Batch [190/196], Loss: 0.0210\n",
      "Epoch [193/360], Batch [195/196], Loss: 0.0217\n",
      "Epoch [194/360], Batch [5/196], Loss: 0.0256\n",
      "Epoch [194/360], Batch [10/196], Loss: 0.0260\n",
      "Epoch [194/360], Batch [15/196], Loss: 0.0457\n",
      "Epoch [194/360], Batch [20/196], Loss: 0.0354\n",
      "Epoch [194/360], Batch [25/196], Loss: 0.0253\n",
      "Epoch [194/360], Batch [30/196], Loss: 0.0189\n",
      "Epoch [194/360], Batch [35/196], Loss: 0.0269\n",
      "Epoch [194/360], Batch [40/196], Loss: 0.0178\n",
      "Epoch [194/360], Batch [45/196], Loss: 0.0248\n",
      "Epoch [194/360], Batch [50/196], Loss: 0.0209\n",
      "Epoch [194/360], Batch [55/196], Loss: 0.0272\n",
      "Epoch [194/360], Batch [60/196], Loss: 0.0251\n",
      "Epoch [194/360], Batch [65/196], Loss: 0.0329\n",
      "Epoch [194/360], Batch [70/196], Loss: 0.0367\n",
      "Epoch [194/360], Batch [75/196], Loss: 0.0272\n",
      "Epoch [194/360], Batch [80/196], Loss: 0.0231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [194/360], Batch [85/196], Loss: 0.0279\n",
      "Epoch [194/360], Batch [90/196], Loss: 0.0276\n",
      "Epoch [194/360], Batch [95/196], Loss: 0.0222\n",
      "Epoch [194/360], Batch [100/196], Loss: 0.0309\n",
      "Epoch [194/360], Batch [105/196], Loss: 0.0176\n",
      "Epoch [194/360], Batch [110/196], Loss: 0.0223\n",
      "Epoch [194/360], Batch [115/196], Loss: 0.0321\n",
      "Epoch [194/360], Batch [120/196], Loss: 0.0363\n",
      "Epoch [194/360], Batch [125/196], Loss: 0.0468\n",
      "Epoch [194/360], Batch [130/196], Loss: 0.0578\n",
      "Epoch [194/360], Batch [135/196], Loss: 0.0451\n",
      "Epoch [194/360], Batch [140/196], Loss: 0.0607\n",
      "Epoch [194/360], Batch [145/196], Loss: 0.0602\n",
      "Epoch [194/360], Batch [150/196], Loss: 0.0505\n",
      "Epoch [194/360], Batch [155/196], Loss: 0.0633\n",
      "Epoch [194/360], Batch [160/196], Loss: 0.0628\n",
      "Epoch [194/360], Batch [165/196], Loss: 0.0930\n",
      "Epoch [194/360], Batch [170/196], Loss: 0.0375\n",
      "Epoch [194/360], Batch [175/196], Loss: 0.0548\n",
      "Epoch [194/360], Batch [180/196], Loss: 0.0727\n",
      "Epoch [194/360], Batch [185/196], Loss: 0.0474\n",
      "Epoch [194/360], Batch [190/196], Loss: 0.0437\n",
      "Epoch [194/360], Batch [195/196], Loss: 0.0331\n",
      "Epoch [195/360], Batch [5/196], Loss: 0.0428\n",
      "Epoch [195/360], Batch [10/196], Loss: 0.0609\n",
      "Epoch [195/360], Batch [15/196], Loss: 0.0562\n",
      "Epoch [195/360], Batch [20/196], Loss: 0.0613\n",
      "Epoch [195/360], Batch [25/196], Loss: 0.0371\n",
      "Epoch [195/360], Batch [30/196], Loss: 0.0653\n",
      "Epoch [195/360], Batch [35/196], Loss: 0.0432\n",
      "Epoch [195/360], Batch [40/196], Loss: 0.0530\n",
      "Epoch [195/360], Batch [45/196], Loss: 0.0301\n",
      "Epoch [195/360], Batch [50/196], Loss: 0.0335\n",
      "Epoch [195/360], Batch [55/196], Loss: 0.0525\n",
      "Epoch [195/360], Batch [60/196], Loss: 0.0482\n",
      "Epoch [195/360], Batch [65/196], Loss: 0.0461\n",
      "Epoch [195/360], Batch [70/196], Loss: 0.0515\n",
      "Epoch [195/360], Batch [75/196], Loss: 0.0399\n",
      "Epoch [195/360], Batch [80/196], Loss: 0.0281\n",
      "Epoch [195/360], Batch [85/196], Loss: 0.0564\n",
      "Epoch [195/360], Batch [90/196], Loss: 0.0375\n",
      "Epoch [195/360], Batch [95/196], Loss: 0.0230\n",
      "Epoch [195/360], Batch [100/196], Loss: 0.0275\n",
      "Epoch [195/360], Batch [105/196], Loss: 0.0378\n",
      "Epoch [195/360], Batch [110/196], Loss: 0.0323\n",
      "Epoch [195/360], Batch [115/196], Loss: 0.0212\n",
      "Epoch [195/360], Batch [120/196], Loss: 0.0410\n",
      "Epoch [195/360], Batch [125/196], Loss: 0.0349\n",
      "Epoch [195/360], Batch [130/196], Loss: 0.0434\n",
      "Epoch [195/360], Batch [135/196], Loss: 0.0242\n",
      "Epoch [195/360], Batch [140/196], Loss: 0.0586\n",
      "Epoch [195/360], Batch [145/196], Loss: 0.0434\n",
      "Epoch [195/360], Batch [150/196], Loss: 0.0503\n",
      "Epoch [195/360], Batch [155/196], Loss: 0.0631\n",
      "Epoch [195/360], Batch [160/196], Loss: 0.0452\n",
      "Epoch [195/360], Batch [165/196], Loss: 0.0275\n",
      "Epoch [195/360], Batch [170/196], Loss: 0.0298\n",
      "Epoch [195/360], Batch [175/196], Loss: 0.0493\n",
      "Epoch [195/360], Batch [180/196], Loss: 0.0324\n",
      "Epoch [195/360], Batch [185/196], Loss: 0.0339\n",
      "Epoch [195/360], Batch [190/196], Loss: 0.0660\n",
      "Epoch [195/360], Batch [195/196], Loss: 0.0492\n",
      "Epoch [196/360], Batch [5/196], Loss: 0.0356\n",
      "Epoch [196/360], Batch [10/196], Loss: 0.0500\n",
      "Epoch [196/360], Batch [15/196], Loss: 0.0297\n",
      "Epoch [196/360], Batch [20/196], Loss: 0.0677\n",
      "Epoch [196/360], Batch [25/196], Loss: 0.0282\n",
      "Epoch [196/360], Batch [30/196], Loss: 0.0328\n",
      "Epoch [196/360], Batch [35/196], Loss: 0.0352\n",
      "Epoch [196/360], Batch [40/196], Loss: 0.0455\n",
      "Epoch [196/360], Batch [45/196], Loss: 0.0231\n",
      "Epoch [196/360], Batch [50/196], Loss: 0.0355\n",
      "Epoch [196/360], Batch [55/196], Loss: 0.0483\n",
      "Epoch [196/360], Batch [60/196], Loss: 0.0350\n",
      "Epoch [196/360], Batch [65/196], Loss: 0.0423\n",
      "Epoch [196/360], Batch [70/196], Loss: 0.0404\n",
      "Epoch [196/360], Batch [75/196], Loss: 0.0332\n",
      "Epoch [196/360], Batch [80/196], Loss: 0.0461\n",
      "Epoch [196/360], Batch [85/196], Loss: 0.0330\n",
      "Epoch [196/360], Batch [90/196], Loss: 0.0969\n",
      "Epoch [196/360], Batch [95/196], Loss: 0.0324\n",
      "Epoch [196/360], Batch [100/196], Loss: 0.0352\n",
      "Epoch [196/360], Batch [105/196], Loss: 0.0514\n",
      "Epoch [196/360], Batch [110/196], Loss: 0.0367\n",
      "Epoch [196/360], Batch [115/196], Loss: 0.0368\n",
      "Epoch [196/360], Batch [120/196], Loss: 0.0535\n",
      "Epoch [196/360], Batch [125/196], Loss: 0.0387\n",
      "Epoch [196/360], Batch [130/196], Loss: 0.0368\n",
      "Epoch [196/360], Batch [135/196], Loss: 0.0437\n",
      "Epoch [196/360], Batch [140/196], Loss: 0.0327\n",
      "Epoch [196/360], Batch [145/196], Loss: 0.0471\n",
      "Epoch [196/360], Batch [150/196], Loss: 0.0419\n",
      "Epoch [196/360], Batch [155/196], Loss: 0.0405\n",
      "Epoch [196/360], Batch [160/196], Loss: 0.0404\n",
      "Epoch [196/360], Batch [165/196], Loss: 0.0334\n",
      "Epoch [196/360], Batch [170/196], Loss: 0.0321\n",
      "Epoch [196/360], Batch [175/196], Loss: 0.0391\n",
      "Epoch [196/360], Batch [180/196], Loss: 0.0534\n",
      "Epoch [196/360], Batch [185/196], Loss: 0.1082\n",
      "Epoch [196/360], Batch [190/196], Loss: 0.1073\n",
      "Epoch [196/360], Batch [195/196], Loss: 0.0913\n",
      "Epoch [197/360], Batch [5/196], Loss: 0.1244\n",
      "Epoch [197/360], Batch [10/196], Loss: 0.1194\n",
      "Epoch [197/360], Batch [15/196], Loss: 0.1322\n",
      "Epoch [197/360], Batch [20/196], Loss: 0.1291\n",
      "Epoch [197/360], Batch [25/196], Loss: 0.0801\n",
      "Epoch [197/360], Batch [30/196], Loss: 0.0912\n",
      "Epoch [197/360], Batch [35/196], Loss: 0.0727\n",
      "Epoch [197/360], Batch [40/196], Loss: 0.0949\n",
      "Epoch [197/360], Batch [45/196], Loss: 0.1111\n",
      "Epoch [197/360], Batch [50/196], Loss: 0.1420\n",
      "Epoch [197/360], Batch [55/196], Loss: 0.0985\n",
      "Epoch [197/360], Batch [60/196], Loss: 0.0891\n",
      "Epoch [197/360], Batch [65/196], Loss: 0.0972\n",
      "Epoch [197/360], Batch [70/196], Loss: 0.0537\n",
      "Epoch [197/360], Batch [75/196], Loss: 0.0972\n",
      "Epoch [197/360], Batch [80/196], Loss: 0.1049\n",
      "Epoch [197/360], Batch [85/196], Loss: 0.0891\n",
      "Epoch [197/360], Batch [90/196], Loss: 0.0630\n",
      "Epoch [197/360], Batch [95/196], Loss: 0.0976\n",
      "Epoch [197/360], Batch [100/196], Loss: 0.0580\n",
      "Epoch [197/360], Batch [105/196], Loss: 0.0741\n",
      "Epoch [197/360], Batch [110/196], Loss: 0.0780\n",
      "Epoch [197/360], Batch [115/196], Loss: 0.0919\n",
      "Epoch [197/360], Batch [120/196], Loss: 0.0812\n",
      "Epoch [197/360], Batch [125/196], Loss: 0.1033\n",
      "Epoch [197/360], Batch [130/196], Loss: 0.0819\n",
      "Epoch [197/360], Batch [135/196], Loss: 0.0617\n",
      "Epoch [197/360], Batch [140/196], Loss: 0.0834\n",
      "Epoch [197/360], Batch [145/196], Loss: 0.1241\n",
      "Epoch [197/360], Batch [150/196], Loss: 0.1407\n",
      "Epoch [197/360], Batch [155/196], Loss: 0.0796\n",
      "Epoch [197/360], Batch [160/196], Loss: 0.0830\n",
      "Epoch [197/360], Batch [165/196], Loss: 0.0836\n",
      "Epoch [197/360], Batch [170/196], Loss: 0.0774\n",
      "Epoch [197/360], Batch [175/196], Loss: 0.0943\n",
      "Epoch [197/360], Batch [180/196], Loss: 0.0867\n",
      "Epoch [197/360], Batch [185/196], Loss: 0.0574\n",
      "Epoch [197/360], Batch [190/196], Loss: 0.0942\n",
      "Epoch [197/360], Batch [195/196], Loss: 0.0480\n",
      "Epoch [198/360], Batch [5/196], Loss: 0.0555\n",
      "Epoch [198/360], Batch [10/196], Loss: 0.0900\n",
      "Epoch [198/360], Batch [15/196], Loss: 0.0519\n",
      "Epoch [198/360], Batch [20/196], Loss: 0.0691\n",
      "Epoch [198/360], Batch [25/196], Loss: 0.0698\n",
      "Epoch [198/360], Batch [30/196], Loss: 0.0463\n",
      "Epoch [198/360], Batch [35/196], Loss: 0.1068\n",
      "Epoch [198/360], Batch [40/196], Loss: 0.0700\n",
      "Epoch [198/360], Batch [45/196], Loss: 0.0752\n",
      "Epoch [198/360], Batch [50/196], Loss: 0.0588\n",
      "Epoch [198/360], Batch [55/196], Loss: 0.0520\n",
      "Epoch [198/360], Batch [60/196], Loss: 0.0916\n",
      "Epoch [198/360], Batch [65/196], Loss: 0.0693\n",
      "Epoch [198/360], Batch [70/196], Loss: 0.1015\n",
      "Epoch [198/360], Batch [75/196], Loss: 0.0723\n",
      "Epoch [198/360], Batch [80/196], Loss: 0.0643\n",
      "Epoch [198/360], Batch [85/196], Loss: 0.0541\n",
      "Epoch [198/360], Batch [90/196], Loss: 0.0931\n",
      "Epoch [198/360], Batch [95/196], Loss: 0.1206\n",
      "Epoch [198/360], Batch [100/196], Loss: 0.1340\n",
      "Epoch [198/360], Batch [105/196], Loss: 0.0793\n",
      "Epoch [198/360], Batch [110/196], Loss: 0.0649\n",
      "Epoch [198/360], Batch [115/196], Loss: 0.1195\n",
      "Epoch [198/360], Batch [120/196], Loss: 0.0789\n",
      "Epoch [198/360], Batch [125/196], Loss: 0.1283\n",
      "Epoch [198/360], Batch [130/196], Loss: 0.0920\n",
      "Epoch [198/360], Batch [135/196], Loss: 0.1851\n",
      "Epoch [198/360], Batch [140/196], Loss: 0.0889\n",
      "Epoch [198/360], Batch [145/196], Loss: 0.0783\n",
      "Epoch [198/360], Batch [150/196], Loss: 0.0715\n",
      "Epoch [198/360], Batch [155/196], Loss: 0.0862\n",
      "Epoch [198/360], Batch [160/196], Loss: 0.0836\n",
      "Epoch [198/360], Batch [165/196], Loss: 0.0742\n",
      "Epoch [198/360], Batch [170/196], Loss: 0.0865\n",
      "Epoch [198/360], Batch [175/196], Loss: 0.0795\n",
      "Epoch [198/360], Batch [180/196], Loss: 0.0516\n",
      "Epoch [198/360], Batch [185/196], Loss: 0.1041\n",
      "Epoch [198/360], Batch [190/196], Loss: 0.0776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [198/360], Batch [195/196], Loss: 0.0685\n",
      "Epoch [199/360], Batch [5/196], Loss: 0.0473\n",
      "Epoch [199/360], Batch [10/196], Loss: 0.0425\n",
      "Epoch [199/360], Batch [15/196], Loss: 0.0745\n",
      "Epoch [199/360], Batch [20/196], Loss: 0.0696\n",
      "Epoch [199/360], Batch [25/196], Loss: 0.1141\n",
      "Epoch [199/360], Batch [30/196], Loss: 0.1361\n",
      "Epoch [199/360], Batch [35/196], Loss: 0.0656\n",
      "Epoch [199/360], Batch [40/196], Loss: 0.0713\n",
      "Epoch [199/360], Batch [45/196], Loss: 0.1002\n",
      "Epoch [199/360], Batch [50/196], Loss: 0.1908\n",
      "Epoch [199/360], Batch [55/196], Loss: 0.0602\n",
      "Epoch [199/360], Batch [60/196], Loss: 0.1174\n",
      "Epoch [199/360], Batch [65/196], Loss: 0.0927\n",
      "Epoch [199/360], Batch [70/196], Loss: 0.0747\n",
      "Epoch [199/360], Batch [75/196], Loss: 0.0455\n",
      "Epoch [199/360], Batch [80/196], Loss: 0.0890\n",
      "Epoch [199/360], Batch [85/196], Loss: 0.0625\n",
      "Epoch [199/360], Batch [90/196], Loss: 0.0597\n",
      "Epoch [199/360], Batch [95/196], Loss: 0.0527\n",
      "Epoch [199/360], Batch [100/196], Loss: 0.0569\n",
      "Epoch [199/360], Batch [105/196], Loss: 0.0474\n",
      "Epoch [199/360], Batch [110/196], Loss: 0.0630\n",
      "Epoch [199/360], Batch [115/196], Loss: 0.0357\n",
      "Epoch [199/360], Batch [120/196], Loss: 0.3238\n",
      "Epoch [199/360], Batch [125/196], Loss: 0.2036\n",
      "Epoch [199/360], Batch [130/196], Loss: 0.3573\n",
      "Epoch [199/360], Batch [135/196], Loss: 0.1976\n",
      "Epoch [199/360], Batch [140/196], Loss: 0.2681\n",
      "Epoch [199/360], Batch [145/196], Loss: 0.1911\n",
      "Epoch [199/360], Batch [150/196], Loss: 0.2877\n",
      "Epoch [199/360], Batch [155/196], Loss: 0.1896\n",
      "Epoch [199/360], Batch [160/196], Loss: 0.2181\n",
      "Epoch [199/360], Batch [165/196], Loss: 0.2453\n",
      "Epoch [199/360], Batch [170/196], Loss: 0.1523\n",
      "Epoch [199/360], Batch [175/196], Loss: 0.2344\n",
      "Epoch [199/360], Batch [180/196], Loss: 0.2445\n",
      "Epoch [199/360], Batch [185/196], Loss: 0.1428\n",
      "Epoch [199/360], Batch [190/196], Loss: 0.1316\n",
      "Epoch [199/360], Batch [195/196], Loss: 0.1265\n",
      "Epoch [200/360], Batch [5/196], Loss: 0.1267\n",
      "Epoch [200/360], Batch [10/196], Loss: 0.1093\n",
      "Epoch [200/360], Batch [15/196], Loss: 0.0993\n",
      "Epoch [200/360], Batch [20/196], Loss: 0.1204\n",
      "Epoch [200/360], Batch [25/196], Loss: 0.3491\n",
      "Epoch [200/360], Batch [30/196], Loss: 0.3530\n",
      "Epoch [200/360], Batch [35/196], Loss: 0.2505\n",
      "Epoch [200/360], Batch [40/196], Loss: 0.2177\n",
      "Epoch [200/360], Batch [45/196], Loss: 0.1796\n",
      "Epoch [200/360], Batch [50/196], Loss: 0.2056\n",
      "Epoch [200/360], Batch [55/196], Loss: 0.2448\n",
      "Epoch [200/360], Batch [60/196], Loss: 0.2160\n",
      "Epoch [200/360], Batch [65/196], Loss: 0.2072\n",
      "Epoch [200/360], Batch [70/196], Loss: 0.1498\n",
      "Epoch [200/360], Batch [75/196], Loss: 0.2299\n",
      "Epoch [200/360], Batch [80/196], Loss: 0.1137\n",
      "Epoch [200/360], Batch [85/196], Loss: 0.1155\n",
      "Epoch [200/360], Batch [90/196], Loss: 0.1250\n",
      "Epoch [200/360], Batch [95/196], Loss: 0.1980\n",
      "Epoch [200/360], Batch [100/196], Loss: 0.1062\n",
      "Epoch [200/360], Batch [105/196], Loss: 0.1564\n",
      "Epoch [200/360], Batch [110/196], Loss: 0.1621\n",
      "Epoch [200/360], Batch [115/196], Loss: 0.1269\n",
      "Epoch [200/360], Batch [120/196], Loss: 0.1383\n",
      "Epoch [200/360], Batch [125/196], Loss: 0.1294\n",
      "Epoch [200/360], Batch [130/196], Loss: 0.2137\n",
      "Epoch [200/360], Batch [135/196], Loss: 0.1094\n",
      "Epoch [200/360], Batch [140/196], Loss: 0.1996\n",
      "Epoch [200/360], Batch [145/196], Loss: 0.1155\n",
      "Epoch [200/360], Batch [150/196], Loss: 0.1804\n",
      "Epoch [200/360], Batch [155/196], Loss: 0.0852\n",
      "Epoch [200/360], Batch [160/196], Loss: 0.1067\n",
      "Epoch [200/360], Batch [165/196], Loss: 0.0922\n",
      "Epoch [200/360], Batch [170/196], Loss: 0.1048\n",
      "Epoch [200/360], Batch [175/196], Loss: 0.0712\n",
      "Epoch [200/360], Batch [180/196], Loss: 0.1217\n",
      "Epoch [200/360], Batch [185/196], Loss: 0.1577\n",
      "Epoch [200/360], Batch [190/196], Loss: 0.0738\n",
      "Epoch [200/360], Batch [195/196], Loss: 0.1001\n",
      "Epoch [201/360], Batch [5/196], Loss: 0.0675\n",
      "Epoch [201/360], Batch [10/196], Loss: 0.0624\n",
      "Epoch [201/360], Batch [15/196], Loss: 0.0834\n",
      "Epoch [201/360], Batch [20/196], Loss: 0.0804\n",
      "Epoch [201/360], Batch [25/196], Loss: 0.0513\n",
      "Epoch [201/360], Batch [30/196], Loss: 0.0750\n",
      "Epoch [201/360], Batch [35/196], Loss: 0.0831\n",
      "Epoch [201/360], Batch [40/196], Loss: 0.0882\n",
      "Epoch [201/360], Batch [45/196], Loss: 0.0760\n",
      "Epoch [201/360], Batch [50/196], Loss: 0.0361\n",
      "Epoch [201/360], Batch [55/196], Loss: 0.0647\n",
      "Epoch [201/360], Batch [60/196], Loss: 0.0512\n",
      "Epoch [201/360], Batch [65/196], Loss: 0.1723\n",
      "Epoch [201/360], Batch [70/196], Loss: 0.0969\n",
      "Epoch [201/360], Batch [75/196], Loss: 0.2969\n",
      "Epoch [201/360], Batch [80/196], Loss: 0.1586\n",
      "Epoch [201/360], Batch [85/196], Loss: 0.2142\n",
      "Epoch [201/360], Batch [90/196], Loss: 0.1644\n",
      "Epoch [201/360], Batch [95/196], Loss: 0.1409\n",
      "Epoch [201/360], Batch [100/196], Loss: 0.1367\n",
      "Epoch [201/360], Batch [105/196], Loss: 0.0974\n",
      "Epoch [201/360], Batch [110/196], Loss: 0.0724\n",
      "Epoch [201/360], Batch [115/196], Loss: 0.1205\n",
      "Epoch [201/360], Batch [120/196], Loss: 0.0787\n",
      "Epoch [201/360], Batch [125/196], Loss: 0.0802\n",
      "Epoch [201/360], Batch [130/196], Loss: 0.0717\n",
      "Epoch [201/360], Batch [135/196], Loss: 0.0777\n",
      "Epoch [201/360], Batch [140/196], Loss: 0.0786\n",
      "Epoch [201/360], Batch [145/196], Loss: 0.1323\n",
      "Epoch [201/360], Batch [150/196], Loss: 0.0948\n",
      "Epoch [201/360], Batch [155/196], Loss: 0.0721\n",
      "Epoch [201/360], Batch [160/196], Loss: 0.0694\n",
      "Epoch [201/360], Batch [165/196], Loss: 0.0844\n",
      "Epoch [201/360], Batch [170/196], Loss: 0.0499\n",
      "Epoch [201/360], Batch [175/196], Loss: 0.1026\n",
      "Epoch [201/360], Batch [180/196], Loss: 0.0733\n",
      "Epoch [201/360], Batch [185/196], Loss: 0.0866\n",
      "Epoch [201/360], Batch [190/196], Loss: 0.0586\n",
      "Epoch [201/360], Batch [195/196], Loss: 0.0921\n",
      "Epoch [202/360], Batch [5/196], Loss: 0.0557\n",
      "Epoch [202/360], Batch [10/196], Loss: 0.0467\n",
      "Epoch [202/360], Batch [15/196], Loss: 0.0862\n",
      "Epoch [202/360], Batch [20/196], Loss: 0.0392\n",
      "Epoch [202/360], Batch [25/196], Loss: 0.0432\n",
      "Epoch [202/360], Batch [30/196], Loss: 0.0394\n",
      "Epoch [202/360], Batch [35/196], Loss: 0.0488\n",
      "Epoch [202/360], Batch [40/196], Loss: 0.0413\n",
      "Epoch [202/360], Batch [45/196], Loss: 0.0466\n",
      "Epoch [202/360], Batch [50/196], Loss: 0.0361\n",
      "Epoch [202/360], Batch [55/196], Loss: 0.0593\n",
      "Epoch [202/360], Batch [60/196], Loss: 0.0484\n",
      "Epoch [202/360], Batch [65/196], Loss: 0.0524\n",
      "Epoch [202/360], Batch [70/196], Loss: 0.0480\n",
      "Epoch [202/360], Batch [75/196], Loss: 0.0402\n",
      "Epoch [202/360], Batch [80/196], Loss: 0.0356\n",
      "Epoch [202/360], Batch [85/196], Loss: 0.0338\n",
      "Epoch [202/360], Batch [90/196], Loss: 0.0575\n",
      "Epoch [202/360], Batch [95/196], Loss: 0.0521\n",
      "Epoch [202/360], Batch [100/196], Loss: 0.0423\n",
      "Epoch [202/360], Batch [105/196], Loss: 0.0377\n",
      "Epoch [202/360], Batch [110/196], Loss: 0.0266\n",
      "Epoch [202/360], Batch [115/196], Loss: 0.0403\n",
      "Epoch [202/360], Batch [120/196], Loss: 0.0632\n",
      "Epoch [202/360], Batch [125/196], Loss: 0.0476\n",
      "Epoch [202/360], Batch [130/196], Loss: 0.0491\n",
      "Epoch [202/360], Batch [135/196], Loss: 0.0433\n",
      "Epoch [202/360], Batch [140/196], Loss: 0.0361\n",
      "Epoch [202/360], Batch [145/196], Loss: 0.0729\n",
      "Epoch [202/360], Batch [150/196], Loss: 0.0380\n",
      "Epoch [202/360], Batch [155/196], Loss: 0.0469\n",
      "Epoch [202/360], Batch [160/196], Loss: 0.1437\n",
      "Epoch [202/360], Batch [165/196], Loss: 0.0448\n",
      "Epoch [202/360], Batch [170/196], Loss: 0.0370\n",
      "Epoch [202/360], Batch [175/196], Loss: 0.0470\n",
      "Epoch [202/360], Batch [180/196], Loss: 0.0409\n",
      "Epoch [202/360], Batch [185/196], Loss: 0.0488\n",
      "Epoch [202/360], Batch [190/196], Loss: 0.0520\n",
      "Epoch [202/360], Batch [195/196], Loss: 0.0521\n",
      "Epoch [203/360], Batch [5/196], Loss: 0.0324\n",
      "Epoch [203/360], Batch [10/196], Loss: 0.0260\n",
      "Epoch [203/360], Batch [15/196], Loss: 0.0270\n",
      "Epoch [203/360], Batch [20/196], Loss: 0.0318\n",
      "Epoch [203/360], Batch [25/196], Loss: 0.0284\n",
      "Epoch [203/360], Batch [30/196], Loss: 0.0288\n",
      "Epoch [203/360], Batch [35/196], Loss: 0.0364\n",
      "Epoch [203/360], Batch [40/196], Loss: 0.0293\n",
      "Epoch [203/360], Batch [45/196], Loss: 0.0294\n",
      "Epoch [203/360], Batch [50/196], Loss: 0.0243\n",
      "Epoch [203/360], Batch [55/196], Loss: 0.0325\n",
      "Epoch [203/360], Batch [60/196], Loss: 0.0409\n",
      "Epoch [203/360], Batch [65/196], Loss: 0.0285\n",
      "Epoch [203/360], Batch [70/196], Loss: 0.0249\n",
      "Epoch [203/360], Batch [75/196], Loss: 0.0288\n",
      "Epoch [203/360], Batch [80/196], Loss: 0.0363\n",
      "Epoch [203/360], Batch [85/196], Loss: 0.0313\n",
      "Epoch [203/360], Batch [90/196], Loss: 0.0317\n",
      "Epoch [203/360], Batch [95/196], Loss: 0.0254\n",
      "Epoch [203/360], Batch [100/196], Loss: 0.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/360], Batch [105/196], Loss: 0.0328\n",
      "Epoch [203/360], Batch [110/196], Loss: 0.0303\n",
      "Epoch [203/360], Batch [115/196], Loss: 0.0336\n",
      "Epoch [203/360], Batch [120/196], Loss: 0.0320\n",
      "Epoch [203/360], Batch [125/196], Loss: 0.0348\n",
      "Epoch [203/360], Batch [130/196], Loss: 0.0250\n",
      "Epoch [203/360], Batch [135/196], Loss: 0.0241\n",
      "Epoch [203/360], Batch [140/196], Loss: 0.0324\n",
      "Epoch [203/360], Batch [145/196], Loss: 0.0192\n",
      "Epoch [203/360], Batch [150/196], Loss: 0.0331\n",
      "Epoch [203/360], Batch [155/196], Loss: 0.0177\n",
      "Epoch [203/360], Batch [160/196], Loss: 0.0268\n",
      "Epoch [203/360], Batch [165/196], Loss: 0.0292\n",
      "Epoch [203/360], Batch [170/196], Loss: 0.0217\n",
      "Epoch [203/360], Batch [175/196], Loss: 0.0235\n",
      "Epoch [203/360], Batch [180/196], Loss: 0.0203\n",
      "Epoch [203/360], Batch [185/196], Loss: 0.0207\n",
      "Epoch [203/360], Batch [190/196], Loss: 0.0539\n",
      "Epoch [203/360], Batch [195/196], Loss: 0.0258\n",
      "Epoch [204/360], Batch [5/196], Loss: 0.0261\n",
      "Epoch [204/360], Batch [10/196], Loss: 0.0319\n",
      "Epoch [204/360], Batch [15/196], Loss: 0.0116\n",
      "Epoch [204/360], Batch [20/196], Loss: 0.0171\n",
      "Epoch [204/360], Batch [25/196], Loss: 0.0212\n",
      "Epoch [204/360], Batch [30/196], Loss: 0.0196\n",
      "Epoch [204/360], Batch [35/196], Loss: 0.0200\n",
      "Epoch [204/360], Batch [40/196], Loss: 0.0151\n",
      "Epoch [204/360], Batch [45/196], Loss: 0.0174\n",
      "Epoch [204/360], Batch [50/196], Loss: 0.0226\n",
      "Epoch [204/360], Batch [55/196], Loss: 0.0231\n",
      "Epoch [204/360], Batch [60/196], Loss: 0.0250\n",
      "Epoch [204/360], Batch [65/196], Loss: 0.0215\n",
      "Epoch [204/360], Batch [70/196], Loss: 0.0198\n",
      "Epoch [204/360], Batch [75/196], Loss: 0.0178\n",
      "Epoch [204/360], Batch [80/196], Loss: 0.0163\n",
      "Epoch [204/360], Batch [85/196], Loss: 0.0241\n",
      "Epoch [204/360], Batch [90/196], Loss: 0.0204\n",
      "Epoch [204/360], Batch [95/196], Loss: 0.0128\n",
      "Epoch [204/360], Batch [100/196], Loss: 0.0119\n",
      "Epoch [204/360], Batch [105/196], Loss: 0.0145\n",
      "Epoch [204/360], Batch [110/196], Loss: 0.0229\n",
      "Epoch [204/360], Batch [115/196], Loss: 0.0155\n",
      "Epoch [204/360], Batch [120/196], Loss: 0.0223\n",
      "Epoch [204/360], Batch [125/196], Loss: 0.0129\n",
      "Epoch [204/360], Batch [130/196], Loss: 0.0260\n",
      "Epoch [204/360], Batch [135/196], Loss: 0.0165\n",
      "Epoch [204/360], Batch [140/196], Loss: 0.0206\n",
      "Epoch [204/360], Batch [145/196], Loss: 0.0170\n",
      "Epoch [204/360], Batch [150/196], Loss: 0.0205\n",
      "Epoch [204/360], Batch [155/196], Loss: 0.0145\n",
      "Epoch [204/360], Batch [160/196], Loss: 0.0204\n",
      "Epoch [204/360], Batch [165/196], Loss: 0.0229\n",
      "Epoch [204/360], Batch [170/196], Loss: 0.0335\n",
      "Epoch [204/360], Batch [175/196], Loss: 0.0171\n",
      "Epoch [204/360], Batch [180/196], Loss: 0.0192\n",
      "Epoch [204/360], Batch [185/196], Loss: 0.0178\n",
      "Epoch [204/360], Batch [190/196], Loss: 0.0249\n",
      "Epoch [204/360], Batch [195/196], Loss: 0.0170\n",
      "Epoch [205/360], Batch [5/196], Loss: 0.0130\n",
      "Epoch [205/360], Batch [10/196], Loss: 0.0120\n",
      "Epoch [205/360], Batch [15/196], Loss: 0.0170\n",
      "Epoch [205/360], Batch [20/196], Loss: 0.0131\n",
      "Epoch [205/360], Batch [25/196], Loss: 0.0169\n",
      "Epoch [205/360], Batch [30/196], Loss: 0.0136\n",
      "Epoch [205/360], Batch [35/196], Loss: 0.0126\n",
      "Epoch [205/360], Batch [40/196], Loss: 0.0115\n",
      "Epoch [205/360], Batch [45/196], Loss: 0.0194\n",
      "Epoch [205/360], Batch [50/196], Loss: 0.0203\n",
      "Epoch [205/360], Batch [55/196], Loss: 0.0150\n",
      "Epoch [205/360], Batch [60/196], Loss: 0.0133\n",
      "Epoch [205/360], Batch [65/196], Loss: 0.0151\n",
      "Epoch [205/360], Batch [70/196], Loss: 0.0100\n",
      "Epoch [205/360], Batch [75/196], Loss: 0.0148\n",
      "Epoch [205/360], Batch [80/196], Loss: 0.0168\n",
      "Epoch [205/360], Batch [85/196], Loss: 0.0104\n",
      "Epoch [205/360], Batch [90/196], Loss: 0.0135\n",
      "Epoch [205/360], Batch [95/196], Loss: 0.0140\n",
      "Epoch [205/360], Batch [100/196], Loss: 0.0299\n",
      "Epoch [205/360], Batch [105/196], Loss: 0.0172\n",
      "Epoch [205/360], Batch [110/196], Loss: 0.0107\n",
      "Epoch [205/360], Batch [115/196], Loss: 0.0148\n",
      "Epoch [205/360], Batch [120/196], Loss: 0.0383\n",
      "Epoch [205/360], Batch [125/196], Loss: 0.0199\n",
      "Epoch [205/360], Batch [130/196], Loss: 0.0161\n",
      "Epoch [205/360], Batch [135/196], Loss: 0.0136\n",
      "Epoch [205/360], Batch [140/196], Loss: 0.0157\n",
      "Epoch [205/360], Batch [145/196], Loss: 0.0164\n",
      "Epoch [205/360], Batch [150/196], Loss: 0.0153\n",
      "Epoch [205/360], Batch [155/196], Loss: 0.0104\n",
      "Epoch [205/360], Batch [160/196], Loss: 0.0205\n",
      "Epoch [205/360], Batch [165/196], Loss: 0.0100\n",
      "Epoch [205/360], Batch [170/196], Loss: 0.0180\n",
      "Epoch [205/360], Batch [175/196], Loss: 0.0134\n",
      "Epoch [205/360], Batch [180/196], Loss: 0.0131\n",
      "Epoch [205/360], Batch [185/196], Loss: 0.0143\n",
      "Epoch [205/360], Batch [190/196], Loss: 0.0160\n",
      "Epoch [205/360], Batch [195/196], Loss: 0.0123\n",
      "Epoch [206/360], Batch [5/196], Loss: 0.0148\n",
      "Epoch [206/360], Batch [10/196], Loss: 0.0118\n",
      "Epoch [206/360], Batch [15/196], Loss: 0.0120\n",
      "Epoch [206/360], Batch [20/196], Loss: 0.0079\n",
      "Epoch [206/360], Batch [25/196], Loss: 0.0108\n",
      "Epoch [206/360], Batch [30/196], Loss: 0.0103\n",
      "Epoch [206/360], Batch [35/196], Loss: 0.0118\n",
      "Epoch [206/360], Batch [40/196], Loss: 0.0110\n",
      "Epoch [206/360], Batch [45/196], Loss: 0.0160\n",
      "Epoch [206/360], Batch [50/196], Loss: 0.0108\n",
      "Epoch [206/360], Batch [55/196], Loss: 0.0155\n",
      "Epoch [206/360], Batch [60/196], Loss: 0.0111\n",
      "Epoch [206/360], Batch [65/196], Loss: 0.0123\n",
      "Epoch [206/360], Batch [70/196], Loss: 0.0627\n",
      "Epoch [206/360], Batch [75/196], Loss: 0.0133\n",
      "Epoch [206/360], Batch [80/196], Loss: 0.0133\n",
      "Epoch [206/360], Batch [85/196], Loss: 0.0180\n",
      "Epoch [206/360], Batch [90/196], Loss: 0.0179\n",
      "Epoch [206/360], Batch [95/196], Loss: 0.0104\n",
      "Epoch [206/360], Batch [100/196], Loss: 0.0136\n",
      "Epoch [206/360], Batch [105/196], Loss: 0.0148\n",
      "Epoch [206/360], Batch [110/196], Loss: 0.0096\n",
      "Epoch [206/360], Batch [115/196], Loss: 0.0088\n",
      "Epoch [206/360], Batch [120/196], Loss: 0.0161\n",
      "Epoch [206/360], Batch [125/196], Loss: 0.0119\n",
      "Epoch [206/360], Batch [130/196], Loss: 0.0124\n",
      "Epoch [206/360], Batch [135/196], Loss: 0.0097\n",
      "Epoch [206/360], Batch [140/196], Loss: 0.0177\n",
      "Epoch [206/360], Batch [145/196], Loss: 0.0131\n",
      "Epoch [206/360], Batch [150/196], Loss: 0.0133\n",
      "Epoch [206/360], Batch [155/196], Loss: 0.0121\n",
      "Epoch [206/360], Batch [160/196], Loss: 0.0095\n",
      "Epoch [206/360], Batch [165/196], Loss: 0.0158\n",
      "Epoch [206/360], Batch [170/196], Loss: 0.0133\n",
      "Epoch [206/360], Batch [175/196], Loss: 0.0111\n",
      "Epoch [206/360], Batch [180/196], Loss: 0.0119\n",
      "Epoch [206/360], Batch [185/196], Loss: 0.0111\n",
      "Epoch [206/360], Batch [190/196], Loss: 0.0106\n",
      "Epoch [206/360], Batch [195/196], Loss: 0.0123\n",
      "Epoch [207/360], Batch [5/196], Loss: 0.0119\n",
      "Epoch [207/360], Batch [10/196], Loss: 0.0133\n",
      "Epoch [207/360], Batch [15/196], Loss: 0.0078\n",
      "Epoch [207/360], Batch [20/196], Loss: 0.0103\n",
      "Epoch [207/360], Batch [25/196], Loss: 0.0089\n",
      "Epoch [207/360], Batch [30/196], Loss: 0.0125\n",
      "Epoch [207/360], Batch [35/196], Loss: 0.0088\n",
      "Epoch [207/360], Batch [40/196], Loss: 0.0103\n",
      "Epoch [207/360], Batch [45/196], Loss: 0.0137\n",
      "Epoch [207/360], Batch [50/196], Loss: 0.0085\n",
      "Epoch [207/360], Batch [55/196], Loss: 0.0135\n",
      "Epoch [207/360], Batch [60/196], Loss: 0.0081\n",
      "Epoch [207/360], Batch [65/196], Loss: 0.0125\n",
      "Epoch [207/360], Batch [70/196], Loss: 0.0068\n",
      "Epoch [207/360], Batch [75/196], Loss: 0.0120\n",
      "Epoch [207/360], Batch [80/196], Loss: 0.0093\n",
      "Epoch [207/360], Batch [85/196], Loss: 0.0088\n",
      "Epoch [207/360], Batch [90/196], Loss: 0.0093\n",
      "Epoch [207/360], Batch [95/196], Loss: 0.0100\n",
      "Epoch [207/360], Batch [100/196], Loss: 0.0102\n",
      "Epoch [207/360], Batch [105/196], Loss: 0.0119\n",
      "Epoch [207/360], Batch [110/196], Loss: 0.0081\n",
      "Epoch [207/360], Batch [115/196], Loss: 0.0130\n",
      "Epoch [207/360], Batch [120/196], Loss: 0.0084\n",
      "Epoch [207/360], Batch [125/196], Loss: 0.0088\n",
      "Epoch [207/360], Batch [130/196], Loss: 0.0093\n",
      "Epoch [207/360], Batch [135/196], Loss: 0.0182\n",
      "Epoch [207/360], Batch [140/196], Loss: 0.0084\n",
      "Epoch [207/360], Batch [145/196], Loss: 0.0122\n",
      "Epoch [207/360], Batch [150/196], Loss: 0.0099\n",
      "Epoch [207/360], Batch [155/196], Loss: 0.0099\n",
      "Epoch [207/360], Batch [160/196], Loss: 0.0163\n",
      "Epoch [207/360], Batch [165/196], Loss: 0.0139\n",
      "Epoch [207/360], Batch [170/196], Loss: 0.0161\n",
      "Epoch [207/360], Batch [175/196], Loss: 0.0140\n",
      "Epoch [207/360], Batch [180/196], Loss: 0.0134\n",
      "Epoch [207/360], Batch [185/196], Loss: 0.0104\n",
      "Epoch [207/360], Batch [190/196], Loss: 0.0100\n",
      "Epoch [207/360], Batch [195/196], Loss: 0.0127\n",
      "Epoch [208/360], Batch [5/196], Loss: 0.0089\n",
      "Epoch [208/360], Batch [10/196], Loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [208/360], Batch [15/196], Loss: 0.0056\n",
      "Epoch [208/360], Batch [20/196], Loss: 0.0089\n",
      "Epoch [208/360], Batch [25/196], Loss: 0.0118\n",
      "Epoch [208/360], Batch [30/196], Loss: 0.0088\n",
      "Epoch [208/360], Batch [35/196], Loss: 0.0129\n",
      "Epoch [208/360], Batch [40/196], Loss: 0.0099\n",
      "Epoch [208/360], Batch [45/196], Loss: 0.0090\n",
      "Epoch [208/360], Batch [50/196], Loss: 0.0108\n",
      "Epoch [208/360], Batch [55/196], Loss: 0.0110\n",
      "Epoch [208/360], Batch [60/196], Loss: 0.0072\n",
      "Epoch [208/360], Batch [65/196], Loss: 0.0090\n",
      "Epoch [208/360], Batch [70/196], Loss: 0.0270\n",
      "Epoch [208/360], Batch [75/196], Loss: 0.0129\n",
      "Epoch [208/360], Batch [80/196], Loss: 0.0208\n",
      "Epoch [208/360], Batch [85/196], Loss: 0.0273\n",
      "Epoch [208/360], Batch [90/196], Loss: 0.0159\n",
      "Epoch [208/360], Batch [95/196], Loss: 0.0171\n",
      "Epoch [208/360], Batch [100/196], Loss: 0.0325\n",
      "Epoch [208/360], Batch [105/196], Loss: 0.0231\n",
      "Epoch [208/360], Batch [110/196], Loss: 0.0134\n",
      "Epoch [208/360], Batch [115/196], Loss: 0.0136\n",
      "Epoch [208/360], Batch [120/196], Loss: 0.0208\n",
      "Epoch [208/360], Batch [125/196], Loss: 0.0159\n",
      "Epoch [208/360], Batch [130/196], Loss: 0.0252\n",
      "Epoch [208/360], Batch [135/196], Loss: 0.0293\n",
      "Epoch [208/360], Batch [140/196], Loss: 0.0292\n",
      "Epoch [208/360], Batch [145/196], Loss: 0.0198\n",
      "Epoch [208/360], Batch [150/196], Loss: 0.0222\n",
      "Epoch [208/360], Batch [155/196], Loss: 0.0191\n",
      "Epoch [208/360], Batch [160/196], Loss: 0.0296\n",
      "Epoch [208/360], Batch [165/196], Loss: 0.0213\n",
      "Epoch [208/360], Batch [170/196], Loss: 0.0180\n",
      "Epoch [208/360], Batch [175/196], Loss: 0.0183\n",
      "Epoch [208/360], Batch [180/196], Loss: 0.0226\n",
      "Epoch [208/360], Batch [185/196], Loss: 0.0215\n",
      "Epoch [208/360], Batch [190/196], Loss: 0.0160\n",
      "Epoch [208/360], Batch [195/196], Loss: 0.0164\n",
      "Epoch [209/360], Batch [5/196], Loss: 0.0137\n",
      "Epoch [209/360], Batch [10/196], Loss: 0.0133\n",
      "Epoch [209/360], Batch [15/196], Loss: 0.0172\n",
      "Epoch [209/360], Batch [20/196], Loss: 0.0172\n",
      "Epoch [209/360], Batch [25/196], Loss: 0.0376\n",
      "Epoch [209/360], Batch [30/196], Loss: 0.0140\n",
      "Epoch [209/360], Batch [35/196], Loss: 0.0200\n",
      "Epoch [209/360], Batch [40/196], Loss: 0.0188\n",
      "Epoch [209/360], Batch [45/196], Loss: 0.0182\n",
      "Epoch [209/360], Batch [50/196], Loss: 0.0635\n",
      "Epoch [209/360], Batch [55/196], Loss: 0.0220\n",
      "Epoch [209/360], Batch [60/196], Loss: 0.0207\n",
      "Epoch [209/360], Batch [65/196], Loss: 0.0274\n",
      "Epoch [209/360], Batch [70/196], Loss: 0.0110\n",
      "Epoch [209/360], Batch [75/196], Loss: 0.0297\n",
      "Epoch [209/360], Batch [80/196], Loss: 0.0253\n",
      "Epoch [209/360], Batch [85/196], Loss: 0.0277\n",
      "Epoch [209/360], Batch [90/196], Loss: 0.0300\n",
      "Epoch [209/360], Batch [95/196], Loss: 0.0159\n",
      "Epoch [209/360], Batch [100/196], Loss: 0.0213\n",
      "Epoch [209/360], Batch [105/196], Loss: 0.0232\n",
      "Epoch [209/360], Batch [110/196], Loss: 0.0226\n",
      "Epoch [209/360], Batch [115/196], Loss: 0.0195\n",
      "Epoch [209/360], Batch [120/196], Loss: 0.0273\n",
      "Epoch [209/360], Batch [125/196], Loss: 0.0144\n",
      "Epoch [209/360], Batch [130/196], Loss: 0.0260\n",
      "Epoch [209/360], Batch [135/196], Loss: 0.0287\n",
      "Epoch [209/360], Batch [140/196], Loss: 0.0213\n",
      "Epoch [209/360], Batch [145/196], Loss: 0.0283\n",
      "Epoch [209/360], Batch [150/196], Loss: 0.0222\n",
      "Epoch [209/360], Batch [155/196], Loss: 0.0173\n",
      "Epoch [209/360], Batch [160/196], Loss: 0.0221\n",
      "Epoch [209/360], Batch [165/196], Loss: 0.0238\n",
      "Epoch [209/360], Batch [170/196], Loss: 0.0361\n",
      "Epoch [209/360], Batch [175/196], Loss: 0.0157\n",
      "Epoch [209/360], Batch [180/196], Loss: 0.0213\n",
      "Epoch [209/360], Batch [185/196], Loss: 0.0246\n",
      "Epoch [209/360], Batch [190/196], Loss: 0.0213\n",
      "Epoch [209/360], Batch [195/196], Loss: 0.0199\n",
      "Epoch [210/360], Batch [5/196], Loss: 0.0186\n",
      "Epoch [210/360], Batch [10/196], Loss: 0.0165\n",
      "Epoch [210/360], Batch [15/196], Loss: 0.0201\n",
      "Epoch [210/360], Batch [20/196], Loss: 0.0272\n",
      "Epoch [210/360], Batch [25/196], Loss: 0.0188\n",
      "Epoch [210/360], Batch [30/196], Loss: 0.0235\n",
      "Epoch [210/360], Batch [35/196], Loss: 0.0237\n",
      "Epoch [210/360], Batch [40/196], Loss: 0.0229\n",
      "Epoch [210/360], Batch [45/196], Loss: 0.0385\n",
      "Epoch [210/360], Batch [50/196], Loss: 0.0337\n",
      "Epoch [210/360], Batch [55/196], Loss: 0.0179\n",
      "Epoch [210/360], Batch [60/196], Loss: 0.0234\n",
      "Epoch [210/360], Batch [65/196], Loss: 0.0166\n",
      "Epoch [210/360], Batch [70/196], Loss: 0.0311\n",
      "Epoch [210/360], Batch [75/196], Loss: 0.0215\n",
      "Epoch [210/360], Batch [80/196], Loss: 0.0285\n",
      "Epoch [210/360], Batch [85/196], Loss: 0.0234\n",
      "Epoch [210/360], Batch [90/196], Loss: 0.0147\n",
      "Epoch [210/360], Batch [95/196], Loss: 0.0247\n",
      "Epoch [210/360], Batch [100/196], Loss: 0.0382\n",
      "Epoch [210/360], Batch [105/196], Loss: 0.0235\n",
      "Epoch [210/360], Batch [110/196], Loss: 0.0213\n",
      "Epoch [210/360], Batch [115/196], Loss: 0.0352\n",
      "Epoch [210/360], Batch [120/196], Loss: 0.0309\n",
      "Epoch [210/360], Batch [125/196], Loss: 0.0243\n",
      "Epoch [210/360], Batch [130/196], Loss: 0.0149\n",
      "Epoch [210/360], Batch [135/196], Loss: 0.0237\n",
      "Epoch [210/360], Batch [140/196], Loss: 0.0354\n",
      "Epoch [210/360], Batch [145/196], Loss: 0.0218\n",
      "Epoch [210/360], Batch [150/196], Loss: 0.0235\n",
      "Epoch [210/360], Batch [155/196], Loss: 0.0199\n",
      "Epoch [210/360], Batch [160/196], Loss: 0.0301\n",
      "Epoch [210/360], Batch [165/196], Loss: 0.0224\n",
      "Epoch [210/360], Batch [170/196], Loss: 0.0216\n",
      "Epoch [210/360], Batch [175/196], Loss: 0.0191\n",
      "Epoch [210/360], Batch [180/196], Loss: 0.0176\n",
      "Epoch [210/360], Batch [185/196], Loss: 0.0198\n",
      "Epoch [210/360], Batch [190/196], Loss: 0.0231\n",
      "Epoch [210/360], Batch [195/196], Loss: 0.0226\n",
      "Epoch [211/360], Batch [5/196], Loss: 0.0280\n",
      "Epoch [211/360], Batch [10/196], Loss: 0.0196\n",
      "Epoch [211/360], Batch [15/196], Loss: 0.0185\n",
      "Epoch [211/360], Batch [20/196], Loss: 0.0242\n",
      "Epoch [211/360], Batch [25/196], Loss: 0.0185\n",
      "Epoch [211/360], Batch [30/196], Loss: 0.0257\n",
      "Epoch [211/360], Batch [35/196], Loss: 0.0196\n",
      "Epoch [211/360], Batch [40/196], Loss: 0.0384\n",
      "Epoch [211/360], Batch [45/196], Loss: 0.0197\n",
      "Epoch [211/360], Batch [50/196], Loss: 0.0347\n",
      "Epoch [211/360], Batch [55/196], Loss: 0.0217\n",
      "Epoch [211/360], Batch [60/196], Loss: 0.0228\n",
      "Epoch [211/360], Batch [65/196], Loss: 0.0173\n",
      "Epoch [211/360], Batch [70/196], Loss: 0.0256\n",
      "Epoch [211/360], Batch [75/196], Loss: 0.0213\n",
      "Epoch [211/360], Batch [80/196], Loss: 0.0230\n",
      "Epoch [211/360], Batch [85/196], Loss: 0.0290\n",
      "Epoch [211/360], Batch [90/196], Loss: 0.0214\n",
      "Epoch [211/360], Batch [95/196], Loss: 0.0267\n",
      "Epoch [211/360], Batch [100/196], Loss: 0.0189\n",
      "Epoch [211/360], Batch [105/196], Loss: 0.0232\n",
      "Epoch [211/360], Batch [110/196], Loss: 0.0186\n",
      "Epoch [211/360], Batch [115/196], Loss: 0.0342\n",
      "Epoch [211/360], Batch [120/196], Loss: 0.0245\n",
      "Epoch [211/360], Batch [125/196], Loss: 0.0169\n",
      "Epoch [211/360], Batch [130/196], Loss: 0.0164\n",
      "Epoch [211/360], Batch [135/196], Loss: 0.0249\n",
      "Epoch [211/360], Batch [140/196], Loss: 0.0209\n",
      "Epoch [211/360], Batch [145/196], Loss: 0.0273\n",
      "Epoch [211/360], Batch [150/196], Loss: 0.0276\n",
      "Epoch [211/360], Batch [155/196], Loss: 0.0276\n",
      "Epoch [211/360], Batch [160/196], Loss: 0.0191\n",
      "Epoch [211/360], Batch [165/196], Loss: 0.0156\n",
      "Epoch [211/360], Batch [170/196], Loss: 0.0285\n",
      "Epoch [211/360], Batch [175/196], Loss: 0.0258\n",
      "Epoch [211/360], Batch [180/196], Loss: 0.0258\n",
      "Epoch [211/360], Batch [185/196], Loss: 0.0243\n",
      "Epoch [211/360], Batch [190/196], Loss: 0.0195\n",
      "Epoch [211/360], Batch [195/196], Loss: 0.0164\n",
      "Epoch [212/360], Batch [5/196], Loss: 0.0326\n",
      "Epoch [212/360], Batch [10/196], Loss: 0.0163\n",
      "Epoch [212/360], Batch [15/196], Loss: 0.0726\n",
      "Epoch [212/360], Batch [20/196], Loss: 0.0193\n",
      "Epoch [212/360], Batch [25/196], Loss: 0.0496\n",
      "Epoch [212/360], Batch [30/196], Loss: 0.0216\n",
      "Epoch [212/360], Batch [35/196], Loss: 0.0206\n",
      "Epoch [212/360], Batch [40/196], Loss: 0.0331\n",
      "Epoch [212/360], Batch [45/196], Loss: 0.0293\n",
      "Epoch [212/360], Batch [50/196], Loss: 0.0194\n",
      "Epoch [212/360], Batch [55/196], Loss: 0.0236\n",
      "Epoch [212/360], Batch [60/196], Loss: 0.0222\n",
      "Epoch [212/360], Batch [65/196], Loss: 0.0249\n",
      "Epoch [212/360], Batch [70/196], Loss: 0.0192\n",
      "Epoch [212/360], Batch [75/196], Loss: 0.0241\n",
      "Epoch [212/360], Batch [80/196], Loss: 0.0244\n",
      "Epoch [212/360], Batch [85/196], Loss: 0.0309\n",
      "Epoch [212/360], Batch [90/196], Loss: 0.0226\n",
      "Epoch [212/360], Batch [95/196], Loss: 0.0230\n",
      "Epoch [212/360], Batch [100/196], Loss: 0.0263\n",
      "Epoch [212/360], Batch [105/196], Loss: 0.0168\n",
      "Epoch [212/360], Batch [110/196], Loss: 0.0294\n",
      "Epoch [212/360], Batch [115/196], Loss: 0.0390\n",
      "Epoch [212/360], Batch [120/196], Loss: 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [212/360], Batch [125/196], Loss: 0.0329\n",
      "Epoch [212/360], Batch [130/196], Loss: 0.0184\n",
      "Epoch [212/360], Batch [135/196], Loss: 0.0224\n",
      "Epoch [212/360], Batch [140/196], Loss: 0.0210\n",
      "Epoch [212/360], Batch [145/196], Loss: 0.0178\n",
      "Epoch [212/360], Batch [150/196], Loss: 0.0230\n",
      "Epoch [212/360], Batch [155/196], Loss: 0.0165\n",
      "Epoch [212/360], Batch [160/196], Loss: 0.0243\n",
      "Epoch [212/360], Batch [165/196], Loss: 0.0174\n",
      "Epoch [212/360], Batch [170/196], Loss: 0.0189\n",
      "Epoch [212/360], Batch [175/196], Loss: 0.0303\n",
      "Epoch [212/360], Batch [180/196], Loss: 0.0257\n",
      "Epoch [212/360], Batch [185/196], Loss: 0.0372\n",
      "Epoch [212/360], Batch [190/196], Loss: 0.0276\n",
      "Epoch [212/360], Batch [195/196], Loss: 0.0236\n",
      "Epoch [213/360], Batch [5/196], Loss: 0.0209\n",
      "Epoch [213/360], Batch [10/196], Loss: 0.0193\n",
      "Epoch [213/360], Batch [15/196], Loss: 0.0196\n",
      "Epoch [213/360], Batch [20/196], Loss: 0.0231\n",
      "Epoch [213/360], Batch [25/196], Loss: 0.0329\n",
      "Epoch [213/360], Batch [30/196], Loss: 0.0174\n",
      "Epoch [213/360], Batch [35/196], Loss: 0.0329\n",
      "Epoch [213/360], Batch [40/196], Loss: 0.0174\n",
      "Epoch [213/360], Batch [45/196], Loss: 0.0304\n",
      "Epoch [213/360], Batch [50/196], Loss: 0.0383\n",
      "Epoch [213/360], Batch [55/196], Loss: 0.0473\n",
      "Epoch [213/360], Batch [60/196], Loss: 0.0271\n",
      "Epoch [213/360], Batch [65/196], Loss: 0.0279\n",
      "Epoch [213/360], Batch [70/196], Loss: 0.0226\n",
      "Epoch [213/360], Batch [75/196], Loss: 0.0310\n",
      "Epoch [213/360], Batch [80/196], Loss: 0.0215\n",
      "Epoch [213/360], Batch [85/196], Loss: 0.0251\n",
      "Epoch [213/360], Batch [90/196], Loss: 0.0403\n",
      "Epoch [213/360], Batch [95/196], Loss: 0.0419\n",
      "Epoch [213/360], Batch [100/196], Loss: 0.0311\n",
      "Epoch [213/360], Batch [105/196], Loss: 0.0252\n",
      "Epoch [213/360], Batch [110/196], Loss: 0.0238\n",
      "Epoch [213/360], Batch [115/196], Loss: 0.0235\n",
      "Epoch [213/360], Batch [120/196], Loss: 0.0295\n",
      "Epoch [213/360], Batch [125/196], Loss: 0.0233\n",
      "Epoch [213/360], Batch [130/196], Loss: 0.0263\n",
      "Epoch [213/360], Batch [135/196], Loss: 0.0324\n",
      "Epoch [213/360], Batch [140/196], Loss: 0.0229\n",
      "Epoch [213/360], Batch [145/196], Loss: 0.0205\n",
      "Epoch [213/360], Batch [150/196], Loss: 0.0253\n",
      "Epoch [213/360], Batch [155/196], Loss: 0.0223\n",
      "Epoch [213/360], Batch [160/196], Loss: 0.0196\n",
      "Epoch [213/360], Batch [165/196], Loss: 0.0187\n",
      "Epoch [213/360], Batch [170/196], Loss: 0.0212\n",
      "Epoch [213/360], Batch [175/196], Loss: 0.0374\n",
      "Epoch [213/360], Batch [180/196], Loss: 0.0222\n",
      "Epoch [213/360], Batch [185/196], Loss: 0.0244\n",
      "Epoch [213/360], Batch [190/196], Loss: 0.0294\n",
      "Epoch [213/360], Batch [195/196], Loss: 0.0350\n",
      "Epoch [214/360], Batch [5/196], Loss: 0.0237\n",
      "Epoch [214/360], Batch [10/196], Loss: 0.0253\n",
      "Epoch [214/360], Batch [15/196], Loss: 0.0248\n",
      "Epoch [214/360], Batch [20/196], Loss: 0.0210\n",
      "Epoch [214/360], Batch [25/196], Loss: 0.0160\n",
      "Epoch [214/360], Batch [30/196], Loss: 0.0283\n",
      "Epoch [214/360], Batch [35/196], Loss: 0.0456\n",
      "Epoch [214/360], Batch [40/196], Loss: 0.0303\n",
      "Epoch [214/360], Batch [45/196], Loss: 0.0236\n",
      "Epoch [214/360], Batch [50/196], Loss: 0.0464\n",
      "Epoch [214/360], Batch [55/196], Loss: 0.0572\n",
      "Epoch [214/360], Batch [60/196], Loss: 0.0268\n",
      "Epoch [214/360], Batch [65/196], Loss: 0.0245\n",
      "Epoch [214/360], Batch [70/196], Loss: 0.0271\n",
      "Epoch [214/360], Batch [75/196], Loss: 0.0254\n",
      "Epoch [214/360], Batch [80/196], Loss: 0.0322\n",
      "Epoch [214/360], Batch [85/196], Loss: 0.0368\n",
      "Epoch [214/360], Batch [90/196], Loss: 0.0221\n",
      "Epoch [214/360], Batch [95/196], Loss: 0.0303\n",
      "Epoch [214/360], Batch [100/196], Loss: 0.0203\n",
      "Epoch [214/360], Batch [105/196], Loss: 0.0267\n",
      "Epoch [214/360], Batch [110/196], Loss: 0.0499\n",
      "Epoch [214/360], Batch [115/196], Loss: 0.0206\n",
      "Epoch [214/360], Batch [120/196], Loss: 0.0125\n",
      "Epoch [214/360], Batch [125/196], Loss: 0.0273\n",
      "Epoch [214/360], Batch [130/196], Loss: 0.0285\n",
      "Epoch [214/360], Batch [135/196], Loss: 0.0270\n",
      "Epoch [214/360], Batch [140/196], Loss: 0.0347\n",
      "Epoch [214/360], Batch [145/196], Loss: 0.0302\n",
      "Epoch [214/360], Batch [150/196], Loss: 0.0234\n",
      "Epoch [214/360], Batch [155/196], Loss: 0.0225\n",
      "Epoch [214/360], Batch [160/196], Loss: 0.0340\n",
      "Epoch [214/360], Batch [165/196], Loss: 0.0166\n",
      "Epoch [214/360], Batch [170/196], Loss: 0.0386\n",
      "Epoch [214/360], Batch [175/196], Loss: 0.0351\n",
      "Epoch [214/360], Batch [180/196], Loss: 0.0367\n",
      "Epoch [214/360], Batch [185/196], Loss: 0.0179\n",
      "Epoch [214/360], Batch [190/196], Loss: 0.0264\n",
      "Epoch [214/360], Batch [195/196], Loss: 0.0333\n",
      "Epoch [215/360], Batch [5/196], Loss: 0.0215\n",
      "Epoch [215/360], Batch [10/196], Loss: 0.0215\n",
      "Epoch [215/360], Batch [15/196], Loss: 0.0288\n",
      "Epoch [215/360], Batch [20/196], Loss: 0.0395\n",
      "Epoch [215/360], Batch [25/196], Loss: 0.0234\n",
      "Epoch [215/360], Batch [30/196], Loss: 0.0312\n",
      "Epoch [215/360], Batch [35/196], Loss: 0.0309\n",
      "Epoch [215/360], Batch [40/196], Loss: 0.0389\n",
      "Epoch [215/360], Batch [45/196], Loss: 0.0299\n",
      "Epoch [215/360], Batch [50/196], Loss: 0.0268\n",
      "Epoch [215/360], Batch [55/196], Loss: 0.0261\n",
      "Epoch [215/360], Batch [60/196], Loss: 0.0230\n",
      "Epoch [215/360], Batch [65/196], Loss: 0.0189\n",
      "Epoch [215/360], Batch [70/196], Loss: 0.0335\n",
      "Epoch [215/360], Batch [75/196], Loss: 0.0373\n",
      "Epoch [215/360], Batch [80/196], Loss: 0.0263\n",
      "Epoch [215/360], Batch [85/196], Loss: 0.0215\n",
      "Epoch [215/360], Batch [90/196], Loss: 0.0222\n",
      "Epoch [215/360], Batch [95/196], Loss: 0.0265\n",
      "Epoch [215/360], Batch [100/196], Loss: 0.0158\n",
      "Epoch [215/360], Batch [105/196], Loss: 0.0293\n",
      "Epoch [215/360], Batch [110/196], Loss: 0.0459\n",
      "Epoch [215/360], Batch [115/196], Loss: 0.0154\n",
      "Epoch [215/360], Batch [120/196], Loss: 0.0142\n",
      "Epoch [215/360], Batch [125/196], Loss: 0.0133\n",
      "Epoch [215/360], Batch [130/196], Loss: 0.0284\n",
      "Epoch [215/360], Batch [135/196], Loss: 0.0394\n",
      "Epoch [215/360], Batch [140/196], Loss: 0.0273\n",
      "Epoch [215/360], Batch [145/196], Loss: 0.0324\n",
      "Epoch [215/360], Batch [150/196], Loss: 0.0227\n",
      "Epoch [215/360], Batch [155/196], Loss: 0.0200\n",
      "Epoch [215/360], Batch [160/196], Loss: 0.0364\n",
      "Epoch [215/360], Batch [165/196], Loss: 0.0394\n",
      "Epoch [215/360], Batch [170/196], Loss: 0.0340\n",
      "Epoch [215/360], Batch [175/196], Loss: 0.0246\n",
      "Epoch [215/360], Batch [180/196], Loss: 0.0309\n",
      "Epoch [215/360], Batch [185/196], Loss: 0.0246\n",
      "Epoch [215/360], Batch [190/196], Loss: 0.0405\n",
      "Epoch [215/360], Batch [195/196], Loss: 0.0243\n",
      "Epoch [216/360], Batch [5/196], Loss: 0.0475\n",
      "Epoch [216/360], Batch [10/196], Loss: 0.0251\n",
      "Epoch [216/360], Batch [15/196], Loss: 0.0405\n",
      "Epoch [216/360], Batch [20/196], Loss: 0.0470\n",
      "Epoch [216/360], Batch [25/196], Loss: 0.0376\n",
      "Epoch [216/360], Batch [30/196], Loss: 0.0546\n",
      "Epoch [216/360], Batch [35/196], Loss: 0.0299\n",
      "Epoch [216/360], Batch [40/196], Loss: 0.0298\n",
      "Epoch [216/360], Batch [45/196], Loss: 0.0446\n",
      "Epoch [216/360], Batch [50/196], Loss: 0.0303\n",
      "Epoch [216/360], Batch [55/196], Loss: 0.0212\n",
      "Epoch [216/360], Batch [60/196], Loss: 0.0246\n",
      "Epoch [216/360], Batch [65/196], Loss: 0.0524\n",
      "Epoch [216/360], Batch [70/196], Loss: 0.0381\n",
      "Epoch [216/360], Batch [75/196], Loss: 0.0293\n",
      "Epoch [216/360], Batch [80/196], Loss: 0.0277\n",
      "Epoch [216/360], Batch [85/196], Loss: 0.0443\n",
      "Epoch [216/360], Batch [90/196], Loss: 0.0281\n",
      "Epoch [216/360], Batch [95/196], Loss: 0.0315\n",
      "Epoch [216/360], Batch [100/196], Loss: 0.0264\n",
      "Epoch [216/360], Batch [105/196], Loss: 0.0474\n",
      "Epoch [216/360], Batch [110/196], Loss: 0.0253\n",
      "Epoch [216/360], Batch [115/196], Loss: 0.0372\n",
      "Epoch [216/360], Batch [120/196], Loss: 0.0668\n",
      "Epoch [216/360], Batch [125/196], Loss: 0.0306\n",
      "Epoch [216/360], Batch [130/196], Loss: 0.0288\n",
      "Epoch [216/360], Batch [135/196], Loss: 0.0177\n",
      "Epoch [216/360], Batch [140/196], Loss: 0.0368\n",
      "Epoch [216/360], Batch [145/196], Loss: 0.0210\n",
      "Epoch [216/360], Batch [150/196], Loss: 0.0194\n",
      "Epoch [216/360], Batch [155/196], Loss: 0.0335\n",
      "Epoch [216/360], Batch [160/196], Loss: 0.0280\n",
      "Epoch [216/360], Batch [165/196], Loss: 0.0457\n",
      "Epoch [216/360], Batch [170/196], Loss: 0.0377\n",
      "Epoch [216/360], Batch [175/196], Loss: 0.0272\n",
      "Epoch [216/360], Batch [180/196], Loss: 0.0564\n",
      "Epoch [216/360], Batch [185/196], Loss: 0.0522\n",
      "Epoch [216/360], Batch [190/196], Loss: 0.0868\n",
      "Epoch [216/360], Batch [195/196], Loss: 0.0568\n",
      "Epoch [217/360], Batch [5/196], Loss: 0.2317\n",
      "Epoch [217/360], Batch [10/196], Loss: 0.2410\n",
      "Epoch [217/360], Batch [15/196], Loss: 0.4983\n",
      "Epoch [217/360], Batch [20/196], Loss: 0.2871\n",
      "Epoch [217/360], Batch [25/196], Loss: 0.4162\n",
      "Epoch [217/360], Batch [30/196], Loss: 0.2559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [217/360], Batch [35/196], Loss: 0.6040\n",
      "Epoch [217/360], Batch [40/196], Loss: 0.6308\n",
      "Epoch [217/360], Batch [45/196], Loss: 0.3942\n",
      "Epoch [217/360], Batch [50/196], Loss: 0.1980\n",
      "Epoch [217/360], Batch [55/196], Loss: 0.3199\n",
      "Epoch [217/360], Batch [60/196], Loss: 0.3007\n",
      "Epoch [217/360], Batch [65/196], Loss: 0.3194\n",
      "Epoch [217/360], Batch [70/196], Loss: 0.2006\n",
      "Epoch [217/360], Batch [75/196], Loss: 0.3245\n",
      "Epoch [217/360], Batch [80/196], Loss: 0.2204\n",
      "Epoch [217/360], Batch [85/196], Loss: 0.3121\n",
      "Epoch [217/360], Batch [90/196], Loss: 0.2386\n",
      "Epoch [217/360], Batch [95/196], Loss: 0.2912\n",
      "Epoch [217/360], Batch [100/196], Loss: 0.3039\n",
      "Epoch [217/360], Batch [105/196], Loss: 0.2378\n",
      "Epoch [217/360], Batch [110/196], Loss: 0.2292\n",
      "Epoch [217/360], Batch [115/196], Loss: 0.1336\n",
      "Epoch [217/360], Batch [120/196], Loss: 0.1552\n",
      "Epoch [217/360], Batch [125/196], Loss: 0.1845\n",
      "Epoch [217/360], Batch [130/196], Loss: 0.1679\n",
      "Epoch [217/360], Batch [135/196], Loss: 0.1420\n",
      "Epoch [217/360], Batch [140/196], Loss: 0.1072\n",
      "Epoch [217/360], Batch [145/196], Loss: 0.1482\n",
      "Epoch [217/360], Batch [150/196], Loss: 0.1401\n",
      "Epoch [217/360], Batch [155/196], Loss: 0.1827\n",
      "Epoch [217/360], Batch [160/196], Loss: 0.1305\n",
      "Epoch [217/360], Batch [165/196], Loss: 0.1555\n",
      "Epoch [217/360], Batch [170/196], Loss: 0.1755\n",
      "Epoch [217/360], Batch [175/196], Loss: 0.1118\n",
      "Epoch [217/360], Batch [180/196], Loss: 0.2906\n",
      "Epoch [217/360], Batch [185/196], Loss: 0.1456\n",
      "Epoch [217/360], Batch [190/196], Loss: 0.1435\n",
      "Epoch [217/360], Batch [195/196], Loss: 0.1451\n",
      "Epoch [218/360], Batch [5/196], Loss: 0.0924\n",
      "Epoch [218/360], Batch [10/196], Loss: 0.0812\n",
      "Epoch [218/360], Batch [15/196], Loss: 0.1213\n",
      "Epoch [218/360], Batch [20/196], Loss: 0.1752\n",
      "Epoch [218/360], Batch [25/196], Loss: 0.0976\n",
      "Epoch [218/360], Batch [30/196], Loss: 0.1034\n",
      "Epoch [218/360], Batch [35/196], Loss: 0.0718\n",
      "Epoch [218/360], Batch [40/196], Loss: 0.1079\n",
      "Epoch [218/360], Batch [45/196], Loss: 0.1482\n",
      "Epoch [218/360], Batch [50/196], Loss: 0.1143\n",
      "Epoch [218/360], Batch [55/196], Loss: 0.0937\n",
      "Epoch [218/360], Batch [60/196], Loss: 0.1141\n",
      "Epoch [218/360], Batch [65/196], Loss: 0.0853\n",
      "Epoch [218/360], Batch [70/196], Loss: 0.0998\n",
      "Epoch [218/360], Batch [75/196], Loss: 0.0570\n",
      "Epoch [218/360], Batch [80/196], Loss: 0.1582\n",
      "Epoch [218/360], Batch [85/196], Loss: 0.1041\n",
      "Epoch [218/360], Batch [90/196], Loss: 0.0996\n",
      "Epoch [218/360], Batch [95/196], Loss: 0.0429\n",
      "Epoch [218/360], Batch [100/196], Loss: 0.0873\n",
      "Epoch [218/360], Batch [105/196], Loss: 0.0814\n",
      "Epoch [218/360], Batch [110/196], Loss: 0.0675\n",
      "Epoch [218/360], Batch [115/196], Loss: 0.0842\n",
      "Epoch [218/360], Batch [120/196], Loss: 0.0669\n",
      "Epoch [218/360], Batch [125/196], Loss: 0.0897\n",
      "Epoch [218/360], Batch [130/196], Loss: 0.1113\n",
      "Epoch [218/360], Batch [135/196], Loss: 0.0752\n",
      "Epoch [218/360], Batch [140/196], Loss: 0.0875\n",
      "Epoch [218/360], Batch [145/196], Loss: 0.0632\n",
      "Epoch [218/360], Batch [150/196], Loss: 0.0680\n",
      "Epoch [218/360], Batch [155/196], Loss: 0.0752\n",
      "Epoch [218/360], Batch [160/196], Loss: 0.0398\n",
      "Epoch [218/360], Batch [165/196], Loss: 0.0790\n",
      "Epoch [218/360], Batch [170/196], Loss: 0.0432\n",
      "Epoch [218/360], Batch [175/196], Loss: 0.0876\n",
      "Epoch [218/360], Batch [180/196], Loss: 0.1093\n",
      "Epoch [218/360], Batch [185/196], Loss: 0.0758\n",
      "Epoch [218/360], Batch [190/196], Loss: 0.0488\n",
      "Epoch [218/360], Batch [195/196], Loss: 0.0652\n",
      "Epoch [219/360], Batch [5/196], Loss: 0.0333\n",
      "Epoch [219/360], Batch [10/196], Loss: 0.0382\n",
      "Epoch [219/360], Batch [15/196], Loss: 0.0358\n",
      "Epoch [219/360], Batch [20/196], Loss: 0.0325\n",
      "Epoch [219/360], Batch [25/196], Loss: 0.0273\n",
      "Epoch [219/360], Batch [30/196], Loss: 0.0257\n",
      "Epoch [219/360], Batch [35/196], Loss: 0.0485\n",
      "Epoch [219/360], Batch [40/196], Loss: 0.0433\n",
      "Epoch [219/360], Batch [45/196], Loss: 0.0303\n",
      "Epoch [219/360], Batch [50/196], Loss: 0.0455\n",
      "Epoch [219/360], Batch [55/196], Loss: 0.0430\n",
      "Epoch [219/360], Batch [60/196], Loss: 0.0322\n",
      "Epoch [219/360], Batch [65/196], Loss: 0.0456\n",
      "Epoch [219/360], Batch [70/196], Loss: 0.0333\n",
      "Epoch [219/360], Batch [75/196], Loss: 0.0388\n",
      "Epoch [219/360], Batch [80/196], Loss: 0.0275\n",
      "Epoch [219/360], Batch [85/196], Loss: 0.0844\n",
      "Epoch [219/360], Batch [90/196], Loss: 0.0242\n",
      "Epoch [219/360], Batch [95/196], Loss: 0.0370\n",
      "Epoch [219/360], Batch [100/196], Loss: 0.0850\n",
      "Epoch [219/360], Batch [105/196], Loss: 0.0373\n",
      "Epoch [219/360], Batch [110/196], Loss: 0.0447\n",
      "Epoch [219/360], Batch [115/196], Loss: 0.0360\n",
      "Epoch [219/360], Batch [120/196], Loss: 0.0342\n",
      "Epoch [219/360], Batch [125/196], Loss: 0.0523\n",
      "Epoch [219/360], Batch [130/196], Loss: 0.0279\n",
      "Epoch [219/360], Batch [135/196], Loss: 0.0328\n",
      "Epoch [219/360], Batch [140/196], Loss: 0.0485\n",
      "Epoch [219/360], Batch [145/196], Loss: 0.0331\n",
      "Epoch [219/360], Batch [150/196], Loss: 0.0332\n",
      "Epoch [219/360], Batch [155/196], Loss: 0.0241\n",
      "Epoch [219/360], Batch [160/196], Loss: 0.0378\n",
      "Epoch [219/360], Batch [165/196], Loss: 0.0359\n",
      "Epoch [219/360], Batch [170/196], Loss: 0.0362\n",
      "Epoch [219/360], Batch [175/196], Loss: 0.0385\n",
      "Epoch [219/360], Batch [180/196], Loss: 0.0577\n",
      "Epoch [219/360], Batch [185/196], Loss: 0.0352\n",
      "Epoch [219/360], Batch [190/196], Loss: 0.0302\n",
      "Epoch [219/360], Batch [195/196], Loss: 0.0376\n",
      "Epoch [220/360], Batch [5/196], Loss: 0.0194\n",
      "Epoch [220/360], Batch [10/196], Loss: 0.0138\n",
      "Epoch [220/360], Batch [15/196], Loss: 0.0189\n",
      "Epoch [220/360], Batch [20/196], Loss: 0.0149\n",
      "Epoch [220/360], Batch [25/196], Loss: 0.0209\n",
      "Epoch [220/360], Batch [30/196], Loss: 0.0212\n",
      "Epoch [220/360], Batch [35/196], Loss: 0.0159\n",
      "Epoch [220/360], Batch [40/196], Loss: 0.0237\n",
      "Epoch [220/360], Batch [45/196], Loss: 0.0184\n",
      "Epoch [220/360], Batch [50/196], Loss: 0.0199\n",
      "Epoch [220/360], Batch [55/196], Loss: 0.0185\n",
      "Epoch [220/360], Batch [60/196], Loss: 0.0244\n",
      "Epoch [220/360], Batch [65/196], Loss: 0.0512\n",
      "Epoch [220/360], Batch [70/196], Loss: 0.0156\n",
      "Epoch [220/360], Batch [75/196], Loss: 0.0180\n",
      "Epoch [220/360], Batch [80/196], Loss: 0.0184\n",
      "Epoch [220/360], Batch [85/196], Loss: 0.0173\n",
      "Epoch [220/360], Batch [90/196], Loss: 0.0192\n",
      "Epoch [220/360], Batch [95/196], Loss: 0.0178\n",
      "Epoch [220/360], Batch [100/196], Loss: 0.0207\n",
      "Epoch [220/360], Batch [105/196], Loss: 0.0223\n",
      "Epoch [220/360], Batch [110/196], Loss: 0.0223\n",
      "Epoch [220/360], Batch [115/196], Loss: 0.0241\n",
      "Epoch [220/360], Batch [120/196], Loss: 0.0208\n",
      "Epoch [220/360], Batch [125/196], Loss: 0.0295\n",
      "Epoch [220/360], Batch [130/196], Loss: 0.0205\n",
      "Epoch [220/360], Batch [135/196], Loss: 0.0202\n",
      "Epoch [220/360], Batch [140/196], Loss: 0.1151\n",
      "Epoch [220/360], Batch [145/196], Loss: 0.0267\n",
      "Epoch [220/360], Batch [150/196], Loss: 0.0138\n",
      "Epoch [220/360], Batch [155/196], Loss: 0.0261\n",
      "Epoch [220/360], Batch [160/196], Loss: 0.0227\n",
      "Epoch [220/360], Batch [165/196], Loss: 0.0154\n",
      "Epoch [220/360], Batch [170/196], Loss: 0.0303\n",
      "Epoch [220/360], Batch [175/196], Loss: 0.0227\n",
      "Epoch [220/360], Batch [180/196], Loss: 0.0262\n",
      "Epoch [220/360], Batch [185/196], Loss: 0.0248\n",
      "Epoch [220/360], Batch [190/196], Loss: 0.0188\n",
      "Epoch [220/360], Batch [195/196], Loss: 0.0226\n",
      "Epoch [221/360], Batch [5/196], Loss: 0.0196\n",
      "Epoch [221/360], Batch [10/196], Loss: 0.0203\n",
      "Epoch [221/360], Batch [15/196], Loss: 0.0455\n",
      "Epoch [221/360], Batch [20/196], Loss: 0.0201\n",
      "Epoch [221/360], Batch [25/196], Loss: 0.0249\n",
      "Epoch [221/360], Batch [30/196], Loss: 0.0194\n",
      "Epoch [221/360], Batch [35/196], Loss: 0.0159\n",
      "Epoch [221/360], Batch [40/196], Loss: 0.0150\n",
      "Epoch [221/360], Batch [45/196], Loss: 0.0325\n",
      "Epoch [221/360], Batch [50/196], Loss: 0.0160\n",
      "Epoch [221/360], Batch [55/196], Loss: 0.0117\n",
      "Epoch [221/360], Batch [60/196], Loss: 0.0160\n",
      "Epoch [221/360], Batch [65/196], Loss: 0.0202\n",
      "Epoch [221/360], Batch [70/196], Loss: 0.0228\n",
      "Epoch [221/360], Batch [75/196], Loss: 0.0115\n",
      "Epoch [221/360], Batch [80/196], Loss: 0.0167\n",
      "Epoch [221/360], Batch [85/196], Loss: 0.0283\n",
      "Epoch [221/360], Batch [90/196], Loss: 0.0188\n",
      "Epoch [221/360], Batch [95/196], Loss: 0.0165\n",
      "Epoch [221/360], Batch [100/196], Loss: 0.0150\n",
      "Epoch [221/360], Batch [105/196], Loss: 0.0167\n",
      "Epoch [221/360], Batch [110/196], Loss: 0.0167\n",
      "Epoch [221/360], Batch [115/196], Loss: 0.0153\n",
      "Epoch [221/360], Batch [120/196], Loss: 0.0189\n",
      "Epoch [221/360], Batch [125/196], Loss: 0.0174\n",
      "Epoch [221/360], Batch [130/196], Loss: 0.0172\n",
      "Epoch [221/360], Batch [135/196], Loss: 0.0189\n",
      "Epoch [221/360], Batch [140/196], Loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [221/360], Batch [145/196], Loss: 0.0115\n",
      "Epoch [221/360], Batch [150/196], Loss: 0.0227\n",
      "Epoch [221/360], Batch [155/196], Loss: 0.0152\n",
      "Epoch [221/360], Batch [160/196], Loss: 0.0196\n",
      "Epoch [221/360], Batch [165/196], Loss: 0.0152\n",
      "Epoch [221/360], Batch [170/196], Loss: 0.0170\n",
      "Epoch [221/360], Batch [175/196], Loss: 0.0123\n",
      "Epoch [221/360], Batch [180/196], Loss: 0.0190\n",
      "Epoch [221/360], Batch [185/196], Loss: 0.0195\n",
      "Epoch [221/360], Batch [190/196], Loss: 0.0128\n",
      "Epoch [221/360], Batch [195/196], Loss: 0.0151\n",
      "Epoch [222/360], Batch [5/196], Loss: 0.0116\n",
      "Epoch [222/360], Batch [10/196], Loss: 0.0165\n",
      "Epoch [222/360], Batch [15/196], Loss: 0.0205\n",
      "Epoch [222/360], Batch [20/196], Loss: 0.0106\n",
      "Epoch [222/360], Batch [25/196], Loss: 0.0119\n",
      "Epoch [222/360], Batch [30/196], Loss: 0.0089\n",
      "Epoch [222/360], Batch [35/196], Loss: 0.0071\n",
      "Epoch [222/360], Batch [40/196], Loss: 0.0081\n",
      "Epoch [222/360], Batch [45/196], Loss: 0.0098\n",
      "Epoch [222/360], Batch [50/196], Loss: 0.0113\n",
      "Epoch [222/360], Batch [55/196], Loss: 0.0100\n",
      "Epoch [222/360], Batch [60/196], Loss: 0.0096\n",
      "Epoch [222/360], Batch [65/196], Loss: 0.0094\n",
      "Epoch [222/360], Batch [70/196], Loss: 0.0139\n",
      "Epoch [222/360], Batch [75/196], Loss: 0.0115\n",
      "Epoch [222/360], Batch [80/196], Loss: 0.0127\n",
      "Epoch [222/360], Batch [85/196], Loss: 0.0149\n",
      "Epoch [222/360], Batch [90/196], Loss: 0.0198\n",
      "Epoch [222/360], Batch [95/196], Loss: 0.0084\n",
      "Epoch [222/360], Batch [100/196], Loss: 0.0111\n",
      "Epoch [222/360], Batch [105/196], Loss: 0.0093\n",
      "Epoch [222/360], Batch [110/196], Loss: 0.0132\n",
      "Epoch [222/360], Batch [115/196], Loss: 0.0126\n",
      "Epoch [222/360], Batch [120/196], Loss: 0.0136\n",
      "Epoch [222/360], Batch [125/196], Loss: 0.0138\n",
      "Epoch [222/360], Batch [130/196], Loss: 0.0144\n",
      "Epoch [222/360], Batch [135/196], Loss: 0.0095\n",
      "Epoch [222/360], Batch [140/196], Loss: 0.0101\n",
      "Epoch [222/360], Batch [145/196], Loss: 0.0110\n",
      "Epoch [222/360], Batch [150/196], Loss: 0.0241\n",
      "Epoch [222/360], Batch [155/196], Loss: 0.0114\n",
      "Epoch [222/360], Batch [160/196], Loss: 0.0112\n",
      "Epoch [222/360], Batch [165/196], Loss: 0.0124\n",
      "Epoch [222/360], Batch [170/196], Loss: 0.0112\n",
      "Epoch [222/360], Batch [175/196], Loss: 0.0169\n",
      "Epoch [222/360], Batch [180/196], Loss: 0.0094\n",
      "Epoch [222/360], Batch [185/196], Loss: 0.0104\n",
      "Epoch [222/360], Batch [190/196], Loss: 0.0120\n",
      "Epoch [222/360], Batch [195/196], Loss: 0.0160\n",
      "Epoch [223/360], Batch [5/196], Loss: 0.0075\n",
      "Epoch [223/360], Batch [10/196], Loss: 0.0119\n",
      "Epoch [223/360], Batch [15/196], Loss: 0.0100\n",
      "Epoch [223/360], Batch [20/196], Loss: 0.0088\n",
      "Epoch [223/360], Batch [25/196], Loss: 0.0087\n",
      "Epoch [223/360], Batch [30/196], Loss: 0.0073\n",
      "Epoch [223/360], Batch [35/196], Loss: 0.0053\n",
      "Epoch [223/360], Batch [40/196], Loss: 0.0113\n",
      "Epoch [223/360], Batch [45/196], Loss: 0.0095\n",
      "Epoch [223/360], Batch [50/196], Loss: 0.0125\n",
      "Epoch [223/360], Batch [55/196], Loss: 0.0100\n",
      "Epoch [223/360], Batch [60/196], Loss: 0.0085\n",
      "Epoch [223/360], Batch [65/196], Loss: 0.0104\n",
      "Epoch [223/360], Batch [70/196], Loss: 0.0088\n",
      "Epoch [223/360], Batch [75/196], Loss: 0.0100\n",
      "Epoch [223/360], Batch [80/196], Loss: 0.0191\n",
      "Epoch [223/360], Batch [85/196], Loss: 0.0057\n",
      "Epoch [223/360], Batch [90/196], Loss: 0.0107\n",
      "Epoch [223/360], Batch [95/196], Loss: 0.0098\n",
      "Epoch [223/360], Batch [100/196], Loss: 0.0123\n",
      "Epoch [223/360], Batch [105/196], Loss: 0.0138\n",
      "Epoch [223/360], Batch [110/196], Loss: 0.0142\n",
      "Epoch [223/360], Batch [115/196], Loss: 0.0137\n",
      "Epoch [223/360], Batch [120/196], Loss: 0.0075\n",
      "Epoch [223/360], Batch [125/196], Loss: 0.0078\n",
      "Epoch [223/360], Batch [130/196], Loss: 0.0090\n",
      "Epoch [223/360], Batch [135/196], Loss: 0.0084\n",
      "Epoch [223/360], Batch [140/196], Loss: 0.0087\n",
      "Epoch [223/360], Batch [145/196], Loss: 0.0089\n",
      "Epoch [223/360], Batch [150/196], Loss: 0.0101\n",
      "Epoch [223/360], Batch [155/196], Loss: 0.0186\n",
      "Epoch [223/360], Batch [160/196], Loss: 0.0128\n",
      "Epoch [223/360], Batch [165/196], Loss: 0.0137\n",
      "Epoch [223/360], Batch [170/196], Loss: 0.0115\n",
      "Epoch [223/360], Batch [175/196], Loss: 0.0128\n",
      "Epoch [223/360], Batch [180/196], Loss: 0.0117\n",
      "Epoch [223/360], Batch [185/196], Loss: 0.0134\n",
      "Epoch [223/360], Batch [190/196], Loss: 0.0113\n",
      "Epoch [223/360], Batch [195/196], Loss: 0.0101\n",
      "Epoch [224/360], Batch [5/196], Loss: 0.0179\n",
      "Epoch [224/360], Batch [10/196], Loss: 0.0122\n",
      "Epoch [224/360], Batch [15/196], Loss: 0.0139\n",
      "Epoch [224/360], Batch [20/196], Loss: 0.0057\n",
      "Epoch [224/360], Batch [25/196], Loss: 0.0079\n",
      "Epoch [224/360], Batch [30/196], Loss: 0.0114\n",
      "Epoch [224/360], Batch [35/196], Loss: 0.0079\n",
      "Epoch [224/360], Batch [40/196], Loss: 0.0090\n",
      "Epoch [224/360], Batch [45/196], Loss: 0.0145\n",
      "Epoch [224/360], Batch [50/196], Loss: 0.0124\n",
      "Epoch [224/360], Batch [55/196], Loss: 0.0071\n",
      "Epoch [224/360], Batch [60/196], Loss: 0.0079\n",
      "Epoch [224/360], Batch [65/196], Loss: 0.0106\n",
      "Epoch [224/360], Batch [70/196], Loss: 0.0166\n",
      "Epoch [224/360], Batch [75/196], Loss: 0.0084\n",
      "Epoch [224/360], Batch [80/196], Loss: 0.0114\n",
      "Epoch [224/360], Batch [85/196], Loss: 0.0106\n",
      "Epoch [224/360], Batch [90/196], Loss: 0.0076\n",
      "Epoch [224/360], Batch [95/196], Loss: 0.0097\n",
      "Epoch [224/360], Batch [100/196], Loss: 0.0165\n",
      "Epoch [224/360], Batch [105/196], Loss: 0.0294\n",
      "Epoch [224/360], Batch [110/196], Loss: 0.0240\n",
      "Epoch [224/360], Batch [115/196], Loss: 0.0243\n",
      "Epoch [224/360], Batch [120/196], Loss: 0.0188\n",
      "Epoch [224/360], Batch [125/196], Loss: 0.0296\n",
      "Epoch [224/360], Batch [130/196], Loss: 0.0171\n",
      "Epoch [224/360], Batch [135/196], Loss: 0.0334\n",
      "Epoch [224/360], Batch [140/196], Loss: 0.0146\n",
      "Epoch [224/360], Batch [145/196], Loss: 0.0238\n",
      "Epoch [224/360], Batch [150/196], Loss: 0.0141\n",
      "Epoch [224/360], Batch [155/196], Loss: 0.0153\n",
      "Epoch [224/360], Batch [160/196], Loss: 0.0397\n",
      "Epoch [224/360], Batch [165/196], Loss: 0.0169\n",
      "Epoch [224/360], Batch [170/196], Loss: 0.0293\n",
      "Epoch [224/360], Batch [175/196], Loss: 0.0227\n",
      "Epoch [224/360], Batch [180/196], Loss: 0.0137\n",
      "Epoch [224/360], Batch [185/196], Loss: 0.0254\n",
      "Epoch [224/360], Batch [190/196], Loss: 0.0158\n",
      "Epoch [224/360], Batch [195/196], Loss: 0.0250\n",
      "Epoch [225/360], Batch [5/196], Loss: 0.0153\n",
      "Epoch [225/360], Batch [10/196], Loss: 0.0135\n",
      "Epoch [225/360], Batch [15/196], Loss: 0.0253\n",
      "Epoch [225/360], Batch [20/196], Loss: 0.0192\n",
      "Epoch [225/360], Batch [25/196], Loss: 0.0185\n",
      "Epoch [225/360], Batch [30/196], Loss: 0.0188\n",
      "Epoch [225/360], Batch [35/196], Loss: 0.0215\n",
      "Epoch [225/360], Batch [40/196], Loss: 0.0220\n",
      "Epoch [225/360], Batch [45/196], Loss: 0.0149\n",
      "Epoch [225/360], Batch [50/196], Loss: 0.0238\n",
      "Epoch [225/360], Batch [55/196], Loss: 0.0222\n",
      "Epoch [225/360], Batch [60/196], Loss: 0.0175\n",
      "Epoch [225/360], Batch [65/196], Loss: 0.0149\n",
      "Epoch [225/360], Batch [70/196], Loss: 0.0150\n",
      "Epoch [225/360], Batch [75/196], Loss: 0.0105\n",
      "Epoch [225/360], Batch [80/196], Loss: 0.0132\n",
      "Epoch [225/360], Batch [85/196], Loss: 0.0118\n",
      "Epoch [225/360], Batch [90/196], Loss: 0.0128\n",
      "Epoch [225/360], Batch [95/196], Loss: 0.0193\n",
      "Epoch [225/360], Batch [100/196], Loss: 0.0160\n",
      "Epoch [225/360], Batch [105/196], Loss: 0.0281\n",
      "Epoch [225/360], Batch [110/196], Loss: 0.0201\n",
      "Epoch [225/360], Batch [115/196], Loss: 0.0186\n",
      "Epoch [225/360], Batch [120/196], Loss: 0.0231\n",
      "Epoch [225/360], Batch [125/196], Loss: 0.0124\n",
      "Epoch [225/360], Batch [130/196], Loss: 0.0243\n",
      "Epoch [225/360], Batch [135/196], Loss: 0.0347\n",
      "Epoch [225/360], Batch [140/196], Loss: 0.0212\n",
      "Epoch [225/360], Batch [145/196], Loss: 0.0207\n",
      "Epoch [225/360], Batch [150/196], Loss: 0.0198\n",
      "Epoch [225/360], Batch [155/196], Loss: 0.0226\n",
      "Epoch [225/360], Batch [160/196], Loss: 0.0108\n",
      "Epoch [225/360], Batch [165/196], Loss: 0.0175\n",
      "Epoch [225/360], Batch [170/196], Loss: 0.0190\n",
      "Epoch [225/360], Batch [175/196], Loss: 0.0139\n",
      "Epoch [225/360], Batch [180/196], Loss: 0.0137\n",
      "Epoch [225/360], Batch [185/196], Loss: 0.0247\n",
      "Epoch [225/360], Batch [190/196], Loss: 0.0296\n",
      "Epoch [225/360], Batch [195/196], Loss: 0.0215\n",
      "Epoch [226/360], Batch [5/196], Loss: 0.0194\n",
      "Epoch [226/360], Batch [10/196], Loss: 0.0141\n",
      "Epoch [226/360], Batch [15/196], Loss: 0.0165\n",
      "Epoch [226/360], Batch [20/196], Loss: 0.0206\n",
      "Epoch [226/360], Batch [25/196], Loss: 0.0172\n",
      "Epoch [226/360], Batch [30/196], Loss: 0.0217\n",
      "Epoch [226/360], Batch [35/196], Loss: 0.0336\n",
      "Epoch [226/360], Batch [40/196], Loss: 0.0612\n",
      "Epoch [226/360], Batch [45/196], Loss: 0.0443\n",
      "Epoch [226/360], Batch [50/196], Loss: 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [226/360], Batch [55/196], Loss: 0.0714\n",
      "Epoch [226/360], Batch [60/196], Loss: 0.0581\n",
      "Epoch [226/360], Batch [65/196], Loss: 0.0373\n",
      "Epoch [226/360], Batch [70/196], Loss: 0.0525\n",
      "Epoch [226/360], Batch [75/196], Loss: 0.0863\n",
      "Epoch [226/360], Batch [80/196], Loss: 0.0941\n",
      "Epoch [226/360], Batch [85/196], Loss: 0.0698\n",
      "Epoch [226/360], Batch [90/196], Loss: 0.0682\n",
      "Epoch [226/360], Batch [95/196], Loss: 0.0739\n",
      "Epoch [226/360], Batch [100/196], Loss: 0.0496\n",
      "Epoch [226/360], Batch [105/196], Loss: 0.0461\n",
      "Epoch [226/360], Batch [110/196], Loss: 0.0563\n",
      "Epoch [226/360], Batch [115/196], Loss: 0.0465\n",
      "Epoch [226/360], Batch [120/196], Loss: 0.0649\n",
      "Epoch [226/360], Batch [125/196], Loss: 0.0424\n",
      "Epoch [226/360], Batch [130/196], Loss: 0.0442\n",
      "Epoch [226/360], Batch [135/196], Loss: 0.0522\n",
      "Epoch [226/360], Batch [140/196], Loss: 0.0407\n",
      "Epoch [226/360], Batch [145/196], Loss: 0.0846\n",
      "Epoch [226/360], Batch [150/196], Loss: 0.0430\n",
      "Epoch [226/360], Batch [155/196], Loss: 0.0553\n",
      "Epoch [226/360], Batch [160/196], Loss: 0.0777\n",
      "Epoch [226/360], Batch [165/196], Loss: 0.1159\n",
      "Epoch [226/360], Batch [170/196], Loss: 0.0644\n",
      "Epoch [226/360], Batch [175/196], Loss: 0.0590\n",
      "Epoch [226/360], Batch [180/196], Loss: 0.0317\n",
      "Epoch [226/360], Batch [185/196], Loss: 0.0613\n",
      "Epoch [226/360], Batch [190/196], Loss: 0.0469\n",
      "Epoch [226/360], Batch [195/196], Loss: 0.0668\n",
      "Epoch [227/360], Batch [5/196], Loss: 0.0374\n",
      "Epoch [227/360], Batch [10/196], Loss: 0.0653\n",
      "Epoch [227/360], Batch [15/196], Loss: 0.1162\n",
      "Epoch [227/360], Batch [20/196], Loss: 0.0404\n",
      "Epoch [227/360], Batch [25/196], Loss: 0.0547\n",
      "Epoch [227/360], Batch [30/196], Loss: 0.0350\n",
      "Epoch [227/360], Batch [35/196], Loss: 0.0423\n",
      "Epoch [227/360], Batch [40/196], Loss: 0.0573\n",
      "Epoch [227/360], Batch [45/196], Loss: 0.0319\n",
      "Epoch [227/360], Batch [50/196], Loss: 0.0359\n",
      "Epoch [227/360], Batch [55/196], Loss: 0.0285\n",
      "Epoch [227/360], Batch [60/196], Loss: 0.0388\n",
      "Epoch [227/360], Batch [65/196], Loss: 0.0515\n",
      "Epoch [227/360], Batch [70/196], Loss: 0.0276\n",
      "Epoch [227/360], Batch [75/196], Loss: 0.0275\n",
      "Epoch [227/360], Batch [80/196], Loss: 0.0461\n",
      "Epoch [227/360], Batch [85/196], Loss: 0.0558\n",
      "Epoch [227/360], Batch [90/196], Loss: 0.0262\n",
      "Epoch [227/360], Batch [95/196], Loss: 0.0297\n",
      "Epoch [227/360], Batch [100/196], Loss: 0.0304\n",
      "Epoch [227/360], Batch [105/196], Loss: 0.0335\n",
      "Epoch [227/360], Batch [110/196], Loss: 0.0854\n",
      "Epoch [227/360], Batch [115/196], Loss: 0.0419\n",
      "Epoch [227/360], Batch [120/196], Loss: 0.0179\n",
      "Epoch [227/360], Batch [125/196], Loss: 0.0244\n",
      "Epoch [227/360], Batch [130/196], Loss: 0.0276\n",
      "Epoch [227/360], Batch [135/196], Loss: 0.0324\n",
      "Epoch [227/360], Batch [140/196], Loss: 0.0285\n",
      "Epoch [227/360], Batch [145/196], Loss: 0.0485\n",
      "Epoch [227/360], Batch [150/196], Loss: 0.0389\n",
      "Epoch [227/360], Batch [155/196], Loss: 0.0617\n",
      "Epoch [227/360], Batch [160/196], Loss: 0.0753\n",
      "Epoch [227/360], Batch [165/196], Loss: 0.0918\n",
      "Epoch [227/360], Batch [170/196], Loss: 0.1275\n",
      "Epoch [227/360], Batch [175/196], Loss: 0.1348\n",
      "Epoch [227/360], Batch [180/196], Loss: 0.0759\n",
      "Epoch [227/360], Batch [185/196], Loss: 0.1167\n",
      "Epoch [227/360], Batch [190/196], Loss: 0.1174\n",
      "Epoch [227/360], Batch [195/196], Loss: 0.1067\n",
      "Epoch [228/360], Batch [5/196], Loss: 0.1423\n",
      "Epoch [228/360], Batch [10/196], Loss: 0.1657\n",
      "Epoch [228/360], Batch [15/196], Loss: 0.0746\n",
      "Epoch [228/360], Batch [20/196], Loss: 0.1599\n",
      "Epoch [228/360], Batch [25/196], Loss: 0.1267\n",
      "Epoch [228/360], Batch [30/196], Loss: 0.1488\n",
      "Epoch [228/360], Batch [35/196], Loss: 0.1647\n",
      "Epoch [228/360], Batch [40/196], Loss: 0.1248\n",
      "Epoch [228/360], Batch [45/196], Loss: 0.1513\n",
      "Epoch [228/360], Batch [50/196], Loss: 0.6685\n",
      "Epoch [228/360], Batch [55/196], Loss: 0.0843\n",
      "Epoch [228/360], Batch [60/196], Loss: 0.2208\n",
      "Epoch [228/360], Batch [65/196], Loss: 0.1198\n",
      "Epoch [228/360], Batch [70/196], Loss: 0.1627\n",
      "Epoch [228/360], Batch [75/196], Loss: 0.1146\n",
      "Epoch [228/360], Batch [80/196], Loss: 0.3262\n",
      "Epoch [228/360], Batch [85/196], Loss: 0.0906\n",
      "Epoch [228/360], Batch [90/196], Loss: 0.1315\n",
      "Epoch [228/360], Batch [95/196], Loss: 0.1761\n",
      "Epoch [228/360], Batch [100/196], Loss: 0.0843\n",
      "Epoch [228/360], Batch [105/196], Loss: 0.0738\n",
      "Epoch [228/360], Batch [110/196], Loss: 0.0769\n",
      "Epoch [228/360], Batch [115/196], Loss: 0.0621\n",
      "Epoch [228/360], Batch [120/196], Loss: 0.0749\n",
      "Epoch [228/360], Batch [125/196], Loss: 0.1182\n",
      "Epoch [228/360], Batch [130/196], Loss: 0.0842\n",
      "Epoch [228/360], Batch [135/196], Loss: 0.0864\n",
      "Epoch [228/360], Batch [140/196], Loss: 0.0630\n",
      "Epoch [228/360], Batch [145/196], Loss: 0.0951\n",
      "Epoch [228/360], Batch [150/196], Loss: 0.0945\n",
      "Epoch [228/360], Batch [155/196], Loss: 0.0873\n",
      "Epoch [228/360], Batch [160/196], Loss: 0.0847\n",
      "Epoch [228/360], Batch [165/196], Loss: 0.0795\n",
      "Epoch [228/360], Batch [170/196], Loss: 0.0608\n",
      "Epoch [228/360], Batch [175/196], Loss: 0.0720\n",
      "Epoch [228/360], Batch [180/196], Loss: 0.0593\n",
      "Epoch [228/360], Batch [185/196], Loss: 0.0518\n",
      "Epoch [228/360], Batch [190/196], Loss: 0.0747\n",
      "Epoch [228/360], Batch [195/196], Loss: 0.0549\n",
      "Epoch [229/360], Batch [5/196], Loss: 0.0246\n",
      "Epoch [229/360], Batch [10/196], Loss: 0.0419\n",
      "Epoch [229/360], Batch [15/196], Loss: 0.0429\n",
      "Epoch [229/360], Batch [20/196], Loss: 0.0631\n",
      "Epoch [229/360], Batch [25/196], Loss: 0.0525\n",
      "Epoch [229/360], Batch [30/196], Loss: 0.0336\n",
      "Epoch [229/360], Batch [35/196], Loss: 0.0608\n",
      "Epoch [229/360], Batch [40/196], Loss: 0.0441\n",
      "Epoch [229/360], Batch [45/196], Loss: 0.0364\n",
      "Epoch [229/360], Batch [50/196], Loss: 0.0778\n",
      "Epoch [229/360], Batch [55/196], Loss: 0.0552\n",
      "Epoch [229/360], Batch [60/196], Loss: 0.0358\n",
      "Epoch [229/360], Batch [65/196], Loss: 0.0433\n",
      "Epoch [229/360], Batch [70/196], Loss: 0.0481\n",
      "Epoch [229/360], Batch [75/196], Loss: 0.0418\n",
      "Epoch [229/360], Batch [80/196], Loss: 0.0573\n",
      "Epoch [229/360], Batch [85/196], Loss: 0.0337\n",
      "Epoch [229/360], Batch [90/196], Loss: 0.0378\n",
      "Epoch [229/360], Batch [95/196], Loss: 0.0322\n",
      "Epoch [229/360], Batch [100/196], Loss: 0.0321\n",
      "Epoch [229/360], Batch [105/196], Loss: 0.0366\n",
      "Epoch [229/360], Batch [110/196], Loss: 0.0364\n",
      "Epoch [229/360], Batch [115/196], Loss: 0.0499\n",
      "Epoch [229/360], Batch [120/196], Loss: 0.1003\n",
      "Epoch [229/360], Batch [125/196], Loss: 0.0543\n",
      "Epoch [229/360], Batch [130/196], Loss: 0.0430\n",
      "Epoch [229/360], Batch [135/196], Loss: 0.0457\n",
      "Epoch [229/360], Batch [140/196], Loss: 0.0422\n",
      "Epoch [229/360], Batch [145/196], Loss: 0.0283\n",
      "Epoch [229/360], Batch [150/196], Loss: 0.0389\n",
      "Epoch [229/360], Batch [155/196], Loss: 0.0381\n",
      "Epoch [229/360], Batch [160/196], Loss: 0.0423\n",
      "Epoch [229/360], Batch [165/196], Loss: 0.0805\n",
      "Epoch [229/360], Batch [170/196], Loss: 0.0315\n",
      "Epoch [229/360], Batch [175/196], Loss: 0.0352\n",
      "Epoch [229/360], Batch [180/196], Loss: 0.0418\n",
      "Epoch [229/360], Batch [185/196], Loss: 0.0485\n",
      "Epoch [229/360], Batch [190/196], Loss: 0.0386\n",
      "Epoch [229/360], Batch [195/196], Loss: 0.0530\n",
      "Epoch [230/360], Batch [5/196], Loss: 0.0513\n",
      "Epoch [230/360], Batch [10/196], Loss: 0.0364\n",
      "Epoch [230/360], Batch [15/196], Loss: 0.0278\n",
      "Epoch [230/360], Batch [20/196], Loss: 0.0296\n",
      "Epoch [230/360], Batch [25/196], Loss: 0.0231\n",
      "Epoch [230/360], Batch [30/196], Loss: 0.0259\n",
      "Epoch [230/360], Batch [35/196], Loss: 0.0207\n",
      "Epoch [230/360], Batch [40/196], Loss: 0.0197\n",
      "Epoch [230/360], Batch [45/196], Loss: 0.0290\n",
      "Epoch [230/360], Batch [50/196], Loss: 0.0210\n",
      "Epoch [230/360], Batch [55/196], Loss: 0.0189\n",
      "Epoch [230/360], Batch [60/196], Loss: 0.0287\n",
      "Epoch [230/360], Batch [65/196], Loss: 0.0231\n",
      "Epoch [230/360], Batch [70/196], Loss: 0.0229\n",
      "Epoch [230/360], Batch [75/196], Loss: 0.0201\n",
      "Epoch [230/360], Batch [80/196], Loss: 0.0192\n",
      "Epoch [230/360], Batch [85/196], Loss: 0.0300\n",
      "Epoch [230/360], Batch [90/196], Loss: 0.0218\n",
      "Epoch [230/360], Batch [95/196], Loss: 0.0361\n",
      "Epoch [230/360], Batch [100/196], Loss: 0.0177\n",
      "Epoch [230/360], Batch [105/196], Loss: 0.0391\n",
      "Epoch [230/360], Batch [110/196], Loss: 0.0223\n",
      "Epoch [230/360], Batch [115/196], Loss: 0.0249\n",
      "Epoch [230/360], Batch [120/196], Loss: 0.0178\n",
      "Epoch [230/360], Batch [125/196], Loss: 0.0220\n",
      "Epoch [230/360], Batch [130/196], Loss: 0.0276\n",
      "Epoch [230/360], Batch [135/196], Loss: 0.0140\n",
      "Epoch [230/360], Batch [140/196], Loss: 0.0282\n",
      "Epoch [230/360], Batch [145/196], Loss: 0.0197\n",
      "Epoch [230/360], Batch [150/196], Loss: 0.0154\n",
      "Epoch [230/360], Batch [155/196], Loss: 0.0315\n",
      "Epoch [230/360], Batch [160/196], Loss: 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [230/360], Batch [165/196], Loss: 0.0203\n",
      "Epoch [230/360], Batch [170/196], Loss: 0.0277\n",
      "Epoch [230/360], Batch [175/196], Loss: 0.0334\n",
      "Epoch [230/360], Batch [180/196], Loss: 0.0217\n",
      "Epoch [230/360], Batch [185/196], Loss: 0.0178\n",
      "Epoch [230/360], Batch [190/196], Loss: 0.0254\n",
      "Epoch [230/360], Batch [195/196], Loss: 0.0227\n",
      "Epoch [231/360], Batch [5/196], Loss: 0.0133\n",
      "Epoch [231/360], Batch [10/196], Loss: 0.0170\n",
      "Epoch [231/360], Batch [15/196], Loss: 0.0218\n",
      "Epoch [231/360], Batch [20/196], Loss: 0.0206\n",
      "Epoch [231/360], Batch [25/196], Loss: 0.0159\n",
      "Epoch [231/360], Batch [30/196], Loss: 0.0131\n",
      "Epoch [231/360], Batch [35/196], Loss: 0.0136\n",
      "Epoch [231/360], Batch [40/196], Loss: 0.0140\n",
      "Epoch [231/360], Batch [45/196], Loss: 0.0171\n",
      "Epoch [231/360], Batch [50/196], Loss: 0.0143\n",
      "Epoch [231/360], Batch [55/196], Loss: 0.0189\n",
      "Epoch [231/360], Batch [60/196], Loss: 0.0150\n",
      "Epoch [231/360], Batch [65/196], Loss: 0.0112\n",
      "Epoch [231/360], Batch [70/196], Loss: 0.0109\n",
      "Epoch [231/360], Batch [75/196], Loss: 0.0226\n",
      "Epoch [231/360], Batch [80/196], Loss: 0.0272\n",
      "Epoch [231/360], Batch [85/196], Loss: 0.0107\n",
      "Epoch [231/360], Batch [90/196], Loss: 0.0153\n",
      "Epoch [231/360], Batch [95/196], Loss: 0.0143\n",
      "Epoch [231/360], Batch [100/196], Loss: 0.0241\n",
      "Epoch [231/360], Batch [105/196], Loss: 0.0256\n",
      "Epoch [231/360], Batch [110/196], Loss: 0.0222\n",
      "Epoch [231/360], Batch [115/196], Loss: 0.0221\n",
      "Epoch [231/360], Batch [120/196], Loss: 0.0230\n",
      "Epoch [231/360], Batch [125/196], Loss: 0.0237\n",
      "Epoch [231/360], Batch [130/196], Loss: 0.0263\n",
      "Epoch [231/360], Batch [135/196], Loss: 0.0253\n",
      "Epoch [231/360], Batch [140/196], Loss: 0.0432\n",
      "Epoch [231/360], Batch [145/196], Loss: 0.0291\n",
      "Epoch [231/360], Batch [150/196], Loss: 0.0173\n",
      "Epoch [231/360], Batch [155/196], Loss: 0.0286\n",
      "Epoch [231/360], Batch [160/196], Loss: 0.0215\n",
      "Epoch [231/360], Batch [165/196], Loss: 0.0190\n",
      "Epoch [231/360], Batch [170/196], Loss: 0.0225\n",
      "Epoch [231/360], Batch [175/196], Loss: 0.0180\n",
      "Epoch [231/360], Batch [180/196], Loss: 0.0140\n",
      "Epoch [231/360], Batch [185/196], Loss: 0.0210\n",
      "Epoch [231/360], Batch [190/196], Loss: 0.0180\n",
      "Epoch [231/360], Batch [195/196], Loss: 0.0142\n",
      "Epoch [232/360], Batch [5/196], Loss: 0.0206\n",
      "Epoch [232/360], Batch [10/196], Loss: 0.0132\n",
      "Epoch [232/360], Batch [15/196], Loss: 0.0150\n",
      "Epoch [232/360], Batch [20/196], Loss: 0.0229\n",
      "Epoch [232/360], Batch [25/196], Loss: 0.0216\n",
      "Epoch [232/360], Batch [30/196], Loss: 0.0206\n",
      "Epoch [232/360], Batch [35/196], Loss: 0.0211\n",
      "Epoch [232/360], Batch [40/196], Loss: 0.0233\n",
      "Epoch [232/360], Batch [45/196], Loss: 0.0140\n",
      "Epoch [232/360], Batch [50/196], Loss: 0.0173\n",
      "Epoch [232/360], Batch [55/196], Loss: 0.0219\n",
      "Epoch [232/360], Batch [60/196], Loss: 0.0283\n",
      "Epoch [232/360], Batch [65/196], Loss: 0.0118\n",
      "Epoch [232/360], Batch [70/196], Loss: 0.0143\n",
      "Epoch [232/360], Batch [75/196], Loss: 0.0146\n",
      "Epoch [232/360], Batch [80/196], Loss: 0.0185\n",
      "Epoch [232/360], Batch [85/196], Loss: 0.0155\n",
      "Epoch [232/360], Batch [90/196], Loss: 0.0080\n",
      "Epoch [232/360], Batch [95/196], Loss: 0.0176\n",
      "Epoch [232/360], Batch [100/196], Loss: 0.0136\n",
      "Epoch [232/360], Batch [105/196], Loss: 0.0153\n",
      "Epoch [232/360], Batch [110/196], Loss: 0.0151\n",
      "Epoch [232/360], Batch [115/196], Loss: 0.0126\n",
      "Epoch [232/360], Batch [120/196], Loss: 0.0191\n",
      "Epoch [232/360], Batch [125/196], Loss: 0.0145\n",
      "Epoch [232/360], Batch [130/196], Loss: 0.0101\n",
      "Epoch [232/360], Batch [135/196], Loss: 0.0189\n",
      "Epoch [232/360], Batch [140/196], Loss: 0.0115\n",
      "Epoch [232/360], Batch [145/196], Loss: 0.0123\n",
      "Epoch [232/360], Batch [150/196], Loss: 0.0236\n",
      "Epoch [232/360], Batch [155/196], Loss: 0.0217\n",
      "Epoch [232/360], Batch [160/196], Loss: 0.0226\n",
      "Epoch [232/360], Batch [165/196], Loss: 0.0200\n",
      "Epoch [232/360], Batch [170/196], Loss: 0.0139\n",
      "Epoch [232/360], Batch [175/196], Loss: 0.0194\n",
      "Epoch [232/360], Batch [180/196], Loss: 0.0190\n",
      "Epoch [232/360], Batch [185/196], Loss: 0.0209\n",
      "Epoch [232/360], Batch [190/196], Loss: 0.0196\n",
      "Epoch [232/360], Batch [195/196], Loss: 0.0216\n",
      "Epoch [233/360], Batch [5/196], Loss: 0.0114\n",
      "Epoch [233/360], Batch [10/196], Loss: 0.0142\n",
      "Epoch [233/360], Batch [15/196], Loss: 0.0187\n",
      "Epoch [233/360], Batch [20/196], Loss: 0.0131\n",
      "Epoch [233/360], Batch [25/196], Loss: 0.0166\n",
      "Epoch [233/360], Batch [30/196], Loss: 0.0164\n",
      "Epoch [233/360], Batch [35/196], Loss: 0.0215\n",
      "Epoch [233/360], Batch [40/196], Loss: 0.0186\n",
      "Epoch [233/360], Batch [45/196], Loss: 0.0106\n",
      "Epoch [233/360], Batch [50/196], Loss: 0.0111\n",
      "Epoch [233/360], Batch [55/196], Loss: 0.0186\n",
      "Epoch [233/360], Batch [60/196], Loss: 0.0117\n",
      "Epoch [233/360], Batch [65/196], Loss: 0.0165\n",
      "Epoch [233/360], Batch [70/196], Loss: 0.0137\n",
      "Epoch [233/360], Batch [75/196], Loss: 0.0184\n",
      "Epoch [233/360], Batch [80/196], Loss: 0.0126\n",
      "Epoch [233/360], Batch [85/196], Loss: 0.0202\n",
      "Epoch [233/360], Batch [90/196], Loss: 0.0143\n",
      "Epoch [233/360], Batch [95/196], Loss: 0.0135\n",
      "Epoch [233/360], Batch [100/196], Loss: 0.0119\n",
      "Epoch [233/360], Batch [105/196], Loss: 0.0148\n",
      "Epoch [233/360], Batch [110/196], Loss: 0.0098\n",
      "Epoch [233/360], Batch [115/196], Loss: 0.0188\n",
      "Epoch [233/360], Batch [120/196], Loss: 0.0115\n",
      "Epoch [233/360], Batch [125/196], Loss: 0.0129\n",
      "Epoch [233/360], Batch [130/196], Loss: 0.0108\n",
      "Epoch [233/360], Batch [135/196], Loss: 0.0161\n",
      "Epoch [233/360], Batch [140/196], Loss: 0.0072\n",
      "Epoch [233/360], Batch [145/196], Loss: 0.0102\n",
      "Epoch [233/360], Batch [150/196], Loss: 0.0181\n",
      "Epoch [233/360], Batch [155/196], Loss: 0.0112\n",
      "Epoch [233/360], Batch [160/196], Loss: 0.0108\n",
      "Epoch [233/360], Batch [165/196], Loss: 0.0115\n",
      "Epoch [233/360], Batch [170/196], Loss: 0.0123\n",
      "Epoch [233/360], Batch [175/196], Loss: 0.0096\n",
      "Epoch [233/360], Batch [180/196], Loss: 0.0110\n",
      "Epoch [233/360], Batch [185/196], Loss: 0.0102\n",
      "Epoch [233/360], Batch [190/196], Loss: 0.0131\n",
      "Epoch [233/360], Batch [195/196], Loss: 0.0166\n",
      "Epoch [234/360], Batch [5/196], Loss: 0.0125\n",
      "Epoch [234/360], Batch [10/196], Loss: 0.0118\n",
      "Epoch [234/360], Batch [15/196], Loss: 0.0129\n",
      "Epoch [234/360], Batch [20/196], Loss: 0.0137\n",
      "Epoch [234/360], Batch [25/196], Loss: 0.0164\n",
      "Epoch [234/360], Batch [30/196], Loss: 0.0100\n",
      "Epoch [234/360], Batch [35/196], Loss: 0.0127\n",
      "Epoch [234/360], Batch [40/196], Loss: 0.0109\n",
      "Epoch [234/360], Batch [45/196], Loss: 0.0153\n",
      "Epoch [234/360], Batch [50/196], Loss: 0.0143\n",
      "Epoch [234/360], Batch [55/196], Loss: 0.0095\n",
      "Epoch [234/360], Batch [60/196], Loss: 0.0112\n",
      "Epoch [234/360], Batch [65/196], Loss: 0.0093\n",
      "Epoch [234/360], Batch [70/196], Loss: 0.0099\n",
      "Epoch [234/360], Batch [75/196], Loss: 0.0103\n",
      "Epoch [234/360], Batch [80/196], Loss: 0.0103\n",
      "Epoch [234/360], Batch [85/196], Loss: 0.0096\n",
      "Epoch [234/360], Batch [90/196], Loss: 0.0154\n",
      "Epoch [234/360], Batch [95/196], Loss: 0.0062\n",
      "Epoch [234/360], Batch [100/196], Loss: 0.0105\n",
      "Epoch [234/360], Batch [105/196], Loss: 0.0123\n",
      "Epoch [234/360], Batch [110/196], Loss: 0.0108\n",
      "Epoch [234/360], Batch [115/196], Loss: 0.0139\n",
      "Epoch [234/360], Batch [120/196], Loss: 0.0128\n",
      "Epoch [234/360], Batch [125/196], Loss: 0.0081\n",
      "Epoch [234/360], Batch [130/196], Loss: 0.0092\n",
      "Epoch [234/360], Batch [135/196], Loss: 0.0088\n",
      "Epoch [234/360], Batch [140/196], Loss: 0.0106\n",
      "Epoch [234/360], Batch [145/196], Loss: 0.0143\n",
      "Epoch [234/360], Batch [150/196], Loss: 0.0081\n",
      "Epoch [234/360], Batch [155/196], Loss: 0.0094\n",
      "Epoch [234/360], Batch [160/196], Loss: 0.0133\n",
      "Epoch [234/360], Batch [165/196], Loss: 0.0093\n",
      "Epoch [234/360], Batch [170/196], Loss: 0.0124\n",
      "Epoch [234/360], Batch [175/196], Loss: 0.0128\n",
      "Epoch [234/360], Batch [180/196], Loss: 0.0120\n",
      "Epoch [234/360], Batch [185/196], Loss: 0.0080\n",
      "Epoch [234/360], Batch [190/196], Loss: 0.0097\n",
      "Epoch [234/360], Batch [195/196], Loss: 0.0084\n",
      "Epoch [235/360], Batch [5/196], Loss: 0.0149\n",
      "Epoch [235/360], Batch [10/196], Loss: 0.0092\n",
      "Epoch [235/360], Batch [15/196], Loss: 0.0069\n",
      "Epoch [235/360], Batch [20/196], Loss: 0.0108\n",
      "Epoch [235/360], Batch [25/196], Loss: 0.0073\n",
      "Epoch [235/360], Batch [30/196], Loss: 0.0105\n",
      "Epoch [235/360], Batch [35/196], Loss: 0.0077\n",
      "Epoch [235/360], Batch [40/196], Loss: 0.0159\n",
      "Epoch [235/360], Batch [45/196], Loss: 0.0084\n",
      "Epoch [235/360], Batch [50/196], Loss: 0.0083\n",
      "Epoch [235/360], Batch [55/196], Loss: 0.0062\n",
      "Epoch [235/360], Batch [60/196], Loss: 0.0103\n",
      "Epoch [235/360], Batch [65/196], Loss: 0.0066\n",
      "Epoch [235/360], Batch [70/196], Loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [235/360], Batch [75/196], Loss: 0.0131\n",
      "Epoch [235/360], Batch [80/196], Loss: 0.0064\n",
      "Epoch [235/360], Batch [85/196], Loss: 0.0089\n",
      "Epoch [235/360], Batch [90/196], Loss: 0.0081\n",
      "Epoch [235/360], Batch [95/196], Loss: 0.0126\n",
      "Epoch [235/360], Batch [100/196], Loss: 0.0096\n",
      "Epoch [235/360], Batch [105/196], Loss: 0.0135\n",
      "Epoch [235/360], Batch [110/196], Loss: 0.0097\n",
      "Epoch [235/360], Batch [115/196], Loss: 0.0138\n",
      "Epoch [235/360], Batch [120/196], Loss: 0.0063\n",
      "Epoch [235/360], Batch [125/196], Loss: 0.0078\n",
      "Epoch [235/360], Batch [130/196], Loss: 0.0174\n",
      "Epoch [235/360], Batch [135/196], Loss: 0.0073\n",
      "Epoch [235/360], Batch [140/196], Loss: 0.0079\n",
      "Epoch [235/360], Batch [145/196], Loss: 0.0074\n",
      "Epoch [235/360], Batch [150/196], Loss: 0.0100\n",
      "Epoch [235/360], Batch [155/196], Loss: 0.0117\n",
      "Epoch [235/360], Batch [160/196], Loss: 0.0057\n",
      "Epoch [235/360], Batch [165/196], Loss: 0.0130\n",
      "Epoch [235/360], Batch [170/196], Loss: 0.0120\n",
      "Epoch [235/360], Batch [175/196], Loss: 0.0073\n",
      "Epoch [235/360], Batch [180/196], Loss: 0.0106\n",
      "Epoch [235/360], Batch [185/196], Loss: 0.0126\n",
      "Epoch [235/360], Batch [190/196], Loss: 0.0070\n",
      "Epoch [235/360], Batch [195/196], Loss: 0.0081\n",
      "Epoch [236/360], Batch [5/196], Loss: 0.0067\n",
      "Epoch [236/360], Batch [10/196], Loss: 0.0086\n",
      "Epoch [236/360], Batch [15/196], Loss: 0.0166\n",
      "Epoch [236/360], Batch [20/196], Loss: 0.0088\n",
      "Epoch [236/360], Batch [25/196], Loss: 0.0065\n",
      "Epoch [236/360], Batch [30/196], Loss: 0.0118\n",
      "Epoch [236/360], Batch [35/196], Loss: 0.0111\n",
      "Epoch [236/360], Batch [40/196], Loss: 0.0199\n",
      "Epoch [236/360], Batch [45/196], Loss: 0.0150\n",
      "Epoch [236/360], Batch [50/196], Loss: 0.0137\n",
      "Epoch [236/360], Batch [55/196], Loss: 0.0441\n",
      "Epoch [236/360], Batch [60/196], Loss: 0.0208\n",
      "Epoch [236/360], Batch [65/196], Loss: 0.0195\n",
      "Epoch [236/360], Batch [70/196], Loss: 0.0196\n",
      "Epoch [236/360], Batch [75/196], Loss: 0.0255\n",
      "Epoch [236/360], Batch [80/196], Loss: 0.0344\n",
      "Epoch [236/360], Batch [85/196], Loss: 0.0505\n",
      "Epoch [236/360], Batch [90/196], Loss: 0.0434\n",
      "Epoch [236/360], Batch [95/196], Loss: 0.0934\n",
      "Epoch [236/360], Batch [100/196], Loss: 0.2611\n",
      "Epoch [236/360], Batch [105/196], Loss: 0.1251\n",
      "Epoch [236/360], Batch [110/196], Loss: 0.1159\n",
      "Epoch [236/360], Batch [115/196], Loss: 0.1755\n",
      "Epoch [236/360], Batch [120/196], Loss: 0.1562\n",
      "Epoch [236/360], Batch [125/196], Loss: 0.2096\n",
      "Epoch [236/360], Batch [130/196], Loss: 0.1959\n",
      "Epoch [236/360], Batch [135/196], Loss: 0.1610\n",
      "Epoch [236/360], Batch [140/196], Loss: 0.1049\n",
      "Epoch [236/360], Batch [145/196], Loss: 0.0734\n",
      "Epoch [236/360], Batch [150/196], Loss: 0.1048\n",
      "Epoch [236/360], Batch [155/196], Loss: 0.1007\n",
      "Epoch [236/360], Batch [160/196], Loss: 0.0784\n",
      "Epoch [236/360], Batch [165/196], Loss: 0.1050\n",
      "Epoch [236/360], Batch [170/196], Loss: 0.0804\n",
      "Epoch [236/360], Batch [175/196], Loss: 0.0806\n",
      "Epoch [236/360], Batch [180/196], Loss: 0.0792\n",
      "Epoch [236/360], Batch [185/196], Loss: 0.0577\n",
      "Epoch [236/360], Batch [190/196], Loss: 0.0785\n",
      "Epoch [236/360], Batch [195/196], Loss: 0.0761\n",
      "Epoch [237/360], Batch [5/196], Loss: 0.0796\n",
      "Epoch [237/360], Batch [10/196], Loss: 0.0668\n",
      "Epoch [237/360], Batch [15/196], Loss: 0.1052\n",
      "Epoch [237/360], Batch [20/196], Loss: 0.0603\n",
      "Epoch [237/360], Batch [25/196], Loss: 0.0713\n",
      "Epoch [237/360], Batch [30/196], Loss: 0.0864\n",
      "Epoch [237/360], Batch [35/196], Loss: 0.0560\n",
      "Epoch [237/360], Batch [40/196], Loss: 0.0932\n",
      "Epoch [237/360], Batch [45/196], Loss: 0.0664\n",
      "Epoch [237/360], Batch [50/196], Loss: 0.0917\n",
      "Epoch [237/360], Batch [55/196], Loss: 0.0619\n",
      "Epoch [237/360], Batch [60/196], Loss: 0.0831\n",
      "Epoch [237/360], Batch [65/196], Loss: 0.0758\n",
      "Epoch [237/360], Batch [70/196], Loss: 0.0630\n",
      "Epoch [237/360], Batch [75/196], Loss: 0.0567\n",
      "Epoch [237/360], Batch [80/196], Loss: 0.0576\n",
      "Epoch [237/360], Batch [85/196], Loss: 0.0503\n",
      "Epoch [237/360], Batch [90/196], Loss: 0.0490\n",
      "Epoch [237/360], Batch [95/196], Loss: 0.0550\n",
      "Epoch [237/360], Batch [100/196], Loss: 0.0845\n",
      "Epoch [237/360], Batch [105/196], Loss: 0.0408\n",
      "Epoch [237/360], Batch [110/196], Loss: 0.0529\n",
      "Epoch [237/360], Batch [115/196], Loss: 0.0400\n",
      "Epoch [237/360], Batch [120/196], Loss: 0.0542\n",
      "Epoch [237/360], Batch [125/196], Loss: 0.0898\n",
      "Epoch [237/360], Batch [130/196], Loss: 0.0538\n",
      "Epoch [237/360], Batch [135/196], Loss: 0.0512\n",
      "Epoch [237/360], Batch [140/196], Loss: 0.0605\n",
      "Epoch [237/360], Batch [145/196], Loss: 0.0478\n",
      "Epoch [237/360], Batch [150/196], Loss: 0.0379\n",
      "Epoch [237/360], Batch [155/196], Loss: 0.0479\n",
      "Epoch [237/360], Batch [160/196], Loss: 0.0378\n",
      "Epoch [237/360], Batch [165/196], Loss: 0.0541\n",
      "Epoch [237/360], Batch [170/196], Loss: 0.0515\n",
      "Epoch [237/360], Batch [175/196], Loss: 0.0330\n",
      "Epoch [237/360], Batch [180/196], Loss: 0.0418\n",
      "Epoch [237/360], Batch [185/196], Loss: 0.0678\n",
      "Epoch [237/360], Batch [190/196], Loss: 0.0430\n",
      "Epoch [237/360], Batch [195/196], Loss: 0.0540\n",
      "Epoch [238/360], Batch [5/196], Loss: 0.0264\n",
      "Epoch [238/360], Batch [10/196], Loss: 0.0202\n",
      "Epoch [238/360], Batch [15/196], Loss: 0.0403\n",
      "Epoch [238/360], Batch [20/196], Loss: 0.0711\n",
      "Epoch [238/360], Batch [25/196], Loss: 0.0297\n",
      "Epoch [238/360], Batch [30/196], Loss: 0.0407\n",
      "Epoch [238/360], Batch [35/196], Loss: 0.0608\n",
      "Epoch [238/360], Batch [40/196], Loss: 0.0383\n",
      "Epoch [238/360], Batch [45/196], Loss: 0.0437\n",
      "Epoch [238/360], Batch [50/196], Loss: 0.0434\n",
      "Epoch [238/360], Batch [55/196], Loss: 0.0465\n",
      "Epoch [238/360], Batch [60/196], Loss: 0.0307\n",
      "Epoch [238/360], Batch [65/196], Loss: 0.0259\n",
      "Epoch [238/360], Batch [70/196], Loss: 0.0334\n",
      "Epoch [238/360], Batch [75/196], Loss: 0.0374\n",
      "Epoch [238/360], Batch [80/196], Loss: 0.0531\n",
      "Epoch [238/360], Batch [85/196], Loss: 0.0328\n",
      "Epoch [238/360], Batch [90/196], Loss: 0.0386\n",
      "Epoch [238/360], Batch [95/196], Loss: 0.0214\n",
      "Epoch [238/360], Batch [100/196], Loss: 0.0457\n",
      "Epoch [238/360], Batch [105/196], Loss: 0.0231\n",
      "Epoch [238/360], Batch [110/196], Loss: 0.0232\n",
      "Epoch [238/360], Batch [115/196], Loss: 0.0361\n",
      "Epoch [238/360], Batch [120/196], Loss: 0.0210\n",
      "Epoch [238/360], Batch [125/196], Loss: 0.0255\n",
      "Epoch [238/360], Batch [130/196], Loss: 0.0302\n",
      "Epoch [238/360], Batch [135/196], Loss: 0.0309\n",
      "Epoch [238/360], Batch [140/196], Loss: 0.0439\n",
      "Epoch [238/360], Batch [145/196], Loss: 0.0310\n",
      "Epoch [238/360], Batch [150/196], Loss: 0.0345\n",
      "Epoch [238/360], Batch [155/196], Loss: 0.0433\n",
      "Epoch [238/360], Batch [160/196], Loss: 0.0371\n",
      "Epoch [238/360], Batch [165/196], Loss: 0.0413\n",
      "Epoch [238/360], Batch [170/196], Loss: 0.0216\n",
      "Epoch [238/360], Batch [175/196], Loss: 0.0310\n",
      "Epoch [238/360], Batch [180/196], Loss: 0.0195\n",
      "Epoch [238/360], Batch [185/196], Loss: 0.0284\n",
      "Epoch [238/360], Batch [190/196], Loss: 0.0213\n",
      "Epoch [238/360], Batch [195/196], Loss: 0.0229\n",
      "Epoch [239/360], Batch [5/196], Loss: 0.0144\n",
      "Epoch [239/360], Batch [10/196], Loss: 0.0178\n",
      "Epoch [239/360], Batch [15/196], Loss: 0.0159\n",
      "Epoch [239/360], Batch [20/196], Loss: 0.0415\n",
      "Epoch [239/360], Batch [25/196], Loss: 0.0230\n",
      "Epoch [239/360], Batch [30/196], Loss: 0.0186\n",
      "Epoch [239/360], Batch [35/196], Loss: 0.0209\n",
      "Epoch [239/360], Batch [40/196], Loss: 0.0232\n",
      "Epoch [239/360], Batch [45/196], Loss: 0.0210\n",
      "Epoch [239/360], Batch [50/196], Loss: 0.0204\n",
      "Epoch [239/360], Batch [55/196], Loss: 0.0180\n",
      "Epoch [239/360], Batch [60/196], Loss: 0.0161\n",
      "Epoch [239/360], Batch [65/196], Loss: 0.0198\n",
      "Epoch [239/360], Batch [70/196], Loss: 0.0189\n",
      "Epoch [239/360], Batch [75/196], Loss: 0.0133\n",
      "Epoch [239/360], Batch [80/196], Loss: 0.0247\n",
      "Epoch [239/360], Batch [85/196], Loss: 0.0197\n",
      "Epoch [239/360], Batch [90/196], Loss: 0.0154\n",
      "Epoch [239/360], Batch [95/196], Loss: 0.0201\n",
      "Epoch [239/360], Batch [100/196], Loss: 0.0161\n",
      "Epoch [239/360], Batch [105/196], Loss: 0.0175\n",
      "Epoch [239/360], Batch [110/196], Loss: 0.0140\n",
      "Epoch [239/360], Batch [115/196], Loss: 0.0250\n",
      "Epoch [239/360], Batch [120/196], Loss: 0.0207\n",
      "Epoch [239/360], Batch [125/196], Loss: 0.0207\n",
      "Epoch [239/360], Batch [130/196], Loss: 0.0206\n",
      "Epoch [239/360], Batch [135/196], Loss: 0.0137\n",
      "Epoch [239/360], Batch [140/196], Loss: 0.0176\n",
      "Epoch [239/360], Batch [145/196], Loss: 0.0161\n",
      "Epoch [239/360], Batch [150/196], Loss: 0.0182\n",
      "Epoch [239/360], Batch [155/196], Loss: 0.0153\n",
      "Epoch [239/360], Batch [160/196], Loss: 0.0158\n",
      "Epoch [239/360], Batch [165/196], Loss: 0.0177\n",
      "Epoch [239/360], Batch [170/196], Loss: 0.0134\n",
      "Epoch [239/360], Batch [175/196], Loss: 0.0164\n",
      "Epoch [239/360], Batch [180/196], Loss: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [239/360], Batch [185/196], Loss: 0.0213\n",
      "Epoch [239/360], Batch [190/196], Loss: 0.0148\n",
      "Epoch [239/360], Batch [195/196], Loss: 0.0200\n",
      "Epoch [240/360], Batch [5/196], Loss: 0.0162\n",
      "Epoch [240/360], Batch [10/196], Loss: 0.0143\n",
      "Epoch [240/360], Batch [15/196], Loss: 0.0187\n",
      "Epoch [240/360], Batch [20/196], Loss: 0.0153\n",
      "Epoch [240/360], Batch [25/196], Loss: 0.0212\n",
      "Epoch [240/360], Batch [30/196], Loss: 0.0078\n",
      "Epoch [240/360], Batch [35/196], Loss: 0.0127\n",
      "Epoch [240/360], Batch [40/196], Loss: 0.0195\n",
      "Epoch [240/360], Batch [45/196], Loss: 0.0131\n",
      "Epoch [240/360], Batch [50/196], Loss: 0.0111\n",
      "Epoch [240/360], Batch [55/196], Loss: 0.0159\n",
      "Epoch [240/360], Batch [60/196], Loss: 0.0189\n",
      "Epoch [240/360], Batch [65/196], Loss: 0.0171\n",
      "Epoch [240/360], Batch [70/196], Loss: 0.0130\n",
      "Epoch [240/360], Batch [75/196], Loss: 0.0186\n",
      "Epoch [240/360], Batch [80/196], Loss: 0.0136\n",
      "Epoch [240/360], Batch [85/196], Loss: 0.0104\n",
      "Epoch [240/360], Batch [90/196], Loss: 0.0116\n",
      "Epoch [240/360], Batch [95/196], Loss: 0.0109\n",
      "Epoch [240/360], Batch [100/196], Loss: 0.0174\n",
      "Epoch [240/360], Batch [105/196], Loss: 0.0138\n",
      "Epoch [240/360], Batch [110/196], Loss: 0.0137\n",
      "Epoch [240/360], Batch [115/196], Loss: 0.0111\n",
      "Epoch [240/360], Batch [120/196], Loss: 0.0163\n",
      "Epoch [240/360], Batch [125/196], Loss: 0.0171\n",
      "Epoch [240/360], Batch [130/196], Loss: 0.0110\n",
      "Epoch [240/360], Batch [135/196], Loss: 0.0098\n",
      "Epoch [240/360], Batch [140/196], Loss: 0.0083\n",
      "Epoch [240/360], Batch [145/196], Loss: 0.0139\n",
      "Epoch [240/360], Batch [150/196], Loss: 0.0130\n",
      "Epoch [240/360], Batch [155/196], Loss: 0.0129\n",
      "Epoch [240/360], Batch [160/196], Loss: 0.0110\n",
      "Epoch [240/360], Batch [165/196], Loss: 0.0164\n",
      "Epoch [240/360], Batch [170/196], Loss: 0.0185\n",
      "Epoch [240/360], Batch [175/196], Loss: 0.0135\n",
      "Epoch [240/360], Batch [180/196], Loss: 0.0128\n",
      "Epoch [240/360], Batch [185/196], Loss: 0.0163\n",
      "Epoch [240/360], Batch [190/196], Loss: 0.0122\n",
      "Epoch [240/360], Batch [195/196], Loss: 0.0107\n",
      "Epoch [241/360], Batch [5/196], Loss: 0.0100\n",
      "Epoch [241/360], Batch [10/196], Loss: 0.0119\n",
      "Epoch [241/360], Batch [15/196], Loss: 0.0118\n",
      "Epoch [241/360], Batch [20/196], Loss: 0.0107\n",
      "Epoch [241/360], Batch [25/196], Loss: 0.0090\n",
      "Epoch [241/360], Batch [30/196], Loss: 0.0119\n",
      "Epoch [241/360], Batch [35/196], Loss: 0.0111\n",
      "Epoch [241/360], Batch [40/196], Loss: 0.0122\n",
      "Epoch [241/360], Batch [45/196], Loss: 0.0083\n",
      "Epoch [241/360], Batch [50/196], Loss: 0.0183\n",
      "Epoch [241/360], Batch [55/196], Loss: 0.0109\n",
      "Epoch [241/360], Batch [60/196], Loss: 0.0107\n",
      "Epoch [241/360], Batch [65/196], Loss: 0.0113\n",
      "Epoch [241/360], Batch [70/196], Loss: 0.0113\n",
      "Epoch [241/360], Batch [75/196], Loss: 0.0140\n",
      "Epoch [241/360], Batch [80/196], Loss: 0.0159\n",
      "Epoch [241/360], Batch [85/196], Loss: 0.0110\n",
      "Epoch [241/360], Batch [90/196], Loss: 0.0132\n",
      "Epoch [241/360], Batch [95/196], Loss: 0.0072\n",
      "Epoch [241/360], Batch [100/196], Loss: 0.0438\n",
      "Epoch [241/360], Batch [105/196], Loss: 0.0124\n",
      "Epoch [241/360], Batch [110/196], Loss: 0.0118\n",
      "Epoch [241/360], Batch [115/196], Loss: 0.0099\n",
      "Epoch [241/360], Batch [120/196], Loss: 0.0107\n",
      "Epoch [241/360], Batch [125/196], Loss: 0.0217\n",
      "Epoch [241/360], Batch [130/196], Loss: 0.0133\n",
      "Epoch [241/360], Batch [135/196], Loss: 0.0129\n",
      "Epoch [241/360], Batch [140/196], Loss: 0.0096\n",
      "Epoch [241/360], Batch [145/196], Loss: 0.0103\n",
      "Epoch [241/360], Batch [150/196], Loss: 0.0191\n",
      "Epoch [241/360], Batch [155/196], Loss: 0.0143\n",
      "Epoch [241/360], Batch [160/196], Loss: 0.0109\n",
      "Epoch [241/360], Batch [165/196], Loss: 0.0138\n",
      "Epoch [241/360], Batch [170/196], Loss: 0.0120\n",
      "Epoch [241/360], Batch [175/196], Loss: 0.0122\n",
      "Epoch [241/360], Batch [180/196], Loss: 0.0141\n",
      "Epoch [241/360], Batch [185/196], Loss: 0.0131\n",
      "Epoch [241/360], Batch [190/196], Loss: 0.0108\n",
      "Epoch [241/360], Batch [195/196], Loss: 0.0079\n",
      "Epoch [242/360], Batch [5/196], Loss: 0.0109\n",
      "Epoch [242/360], Batch [10/196], Loss: 0.0107\n",
      "Epoch [242/360], Batch [15/196], Loss: 0.0107\n",
      "Epoch [242/360], Batch [20/196], Loss: 0.0077\n",
      "Epoch [242/360], Batch [25/196], Loss: 0.0092\n",
      "Epoch [242/360], Batch [30/196], Loss: 0.0051\n",
      "Epoch [242/360], Batch [35/196], Loss: 0.0147\n",
      "Epoch [242/360], Batch [40/196], Loss: 0.0111\n",
      "Epoch [242/360], Batch [45/196], Loss: 0.0210\n",
      "Epoch [242/360], Batch [50/196], Loss: 0.0134\n",
      "Epoch [242/360], Batch [55/196], Loss: 0.0140\n",
      "Epoch [242/360], Batch [60/196], Loss: 0.0073\n",
      "Epoch [242/360], Batch [65/196], Loss: 0.0159\n",
      "Epoch [242/360], Batch [70/196], Loss: 0.0094\n",
      "Epoch [242/360], Batch [75/196], Loss: 0.0164\n",
      "Epoch [242/360], Batch [80/196], Loss: 0.0105\n",
      "Epoch [242/360], Batch [85/196], Loss: 0.0271\n",
      "Epoch [242/360], Batch [90/196], Loss: 0.0145\n",
      "Epoch [242/360], Batch [95/196], Loss: 0.0094\n",
      "Epoch [242/360], Batch [100/196], Loss: 0.0132\n",
      "Epoch [242/360], Batch [105/196], Loss: 0.0080\n",
      "Epoch [242/360], Batch [110/196], Loss: 0.0096\n",
      "Epoch [242/360], Batch [115/196], Loss: 0.0122\n",
      "Epoch [242/360], Batch [120/196], Loss: 0.0107\n",
      "Epoch [242/360], Batch [125/196], Loss: 0.0073\n",
      "Epoch [242/360], Batch [130/196], Loss: 0.0186\n",
      "Epoch [242/360], Batch [135/196], Loss: 0.0090\n",
      "Epoch [242/360], Batch [140/196], Loss: 0.0132\n",
      "Epoch [242/360], Batch [145/196], Loss: 0.0150\n",
      "Epoch [242/360], Batch [150/196], Loss: 0.0139\n",
      "Epoch [242/360], Batch [155/196], Loss: 0.0086\n",
      "Epoch [242/360], Batch [160/196], Loss: 0.0125\n",
      "Epoch [242/360], Batch [165/196], Loss: 0.0109\n",
      "Epoch [242/360], Batch [170/196], Loss: 0.0097\n",
      "Epoch [242/360], Batch [175/196], Loss: 0.0151\n",
      "Epoch [242/360], Batch [180/196], Loss: 0.0087\n",
      "Epoch [242/360], Batch [185/196], Loss: 0.0095\n",
      "Epoch [242/360], Batch [190/196], Loss: 0.0135\n",
      "Epoch [242/360], Batch [195/196], Loss: 0.0172\n",
      "Epoch [243/360], Batch [5/196], Loss: 0.0080\n",
      "Epoch [243/360], Batch [10/196], Loss: 0.0130\n",
      "Epoch [243/360], Batch [15/196], Loss: 0.0090\n",
      "Epoch [243/360], Batch [20/196], Loss: 0.0166\n",
      "Epoch [243/360], Batch [25/196], Loss: 0.0117\n",
      "Epoch [243/360], Batch [30/196], Loss: 0.0184\n",
      "Epoch [243/360], Batch [35/196], Loss: 0.0141\n",
      "Epoch [243/360], Batch [40/196], Loss: 0.0100\n",
      "Epoch [243/360], Batch [45/196], Loss: 0.0109\n",
      "Epoch [243/360], Batch [50/196], Loss: 0.0110\n",
      "Epoch [243/360], Batch [55/196], Loss: 0.0146\n",
      "Epoch [243/360], Batch [60/196], Loss: 0.0126\n",
      "Epoch [243/360], Batch [65/196], Loss: 0.0150\n",
      "Epoch [243/360], Batch [70/196], Loss: 0.0099\n",
      "Epoch [243/360], Batch [75/196], Loss: 0.0144\n",
      "Epoch [243/360], Batch [80/196], Loss: 0.0109\n",
      "Epoch [243/360], Batch [85/196], Loss: 0.0163\n",
      "Epoch [243/360], Batch [90/196], Loss: 0.0121\n",
      "Epoch [243/360], Batch [95/196], Loss: 0.0135\n",
      "Epoch [243/360], Batch [100/196], Loss: 0.0159\n",
      "Epoch [243/360], Batch [105/196], Loss: 0.0170\n",
      "Epoch [243/360], Batch [110/196], Loss: 0.0261\n",
      "Epoch [243/360], Batch [115/196], Loss: 0.0161\n",
      "Epoch [243/360], Batch [120/196], Loss: 0.0156\n",
      "Epoch [243/360], Batch [125/196], Loss: 0.0163\n",
      "Epoch [243/360], Batch [130/196], Loss: 0.0126\n",
      "Epoch [243/360], Batch [135/196], Loss: 0.0177\n",
      "Epoch [243/360], Batch [140/196], Loss: 0.0352\n",
      "Epoch [243/360], Batch [145/196], Loss: 0.0199\n",
      "Epoch [243/360], Batch [150/196], Loss: 0.0125\n",
      "Epoch [243/360], Batch [155/196], Loss: 0.0122\n",
      "Epoch [243/360], Batch [160/196], Loss: 0.0143\n",
      "Epoch [243/360], Batch [165/196], Loss: 0.0174\n",
      "Epoch [243/360], Batch [170/196], Loss: 0.0153\n",
      "Epoch [243/360], Batch [175/196], Loss: 0.0179\n",
      "Epoch [243/360], Batch [180/196], Loss: 0.0102\n",
      "Epoch [243/360], Batch [185/196], Loss: 0.0166\n",
      "Epoch [243/360], Batch [190/196], Loss: 0.0225\n",
      "Epoch [243/360], Batch [195/196], Loss: 0.0153\n",
      "Epoch [244/360], Batch [5/196], Loss: 0.0179\n",
      "Epoch [244/360], Batch [10/196], Loss: 0.0136\n",
      "Epoch [244/360], Batch [15/196], Loss: 0.0202\n",
      "Epoch [244/360], Batch [20/196], Loss: 0.0201\n",
      "Epoch [244/360], Batch [25/196], Loss: 0.0097\n",
      "Epoch [244/360], Batch [30/196], Loss: 0.0167\n",
      "Epoch [244/360], Batch [35/196], Loss: 0.0159\n",
      "Epoch [244/360], Batch [40/196], Loss: 0.0147\n",
      "Epoch [244/360], Batch [45/196], Loss: 0.0152\n",
      "Epoch [244/360], Batch [50/196], Loss: 0.0231\n",
      "Epoch [244/360], Batch [55/196], Loss: 0.0158\n",
      "Epoch [244/360], Batch [60/196], Loss: 0.0335\n",
      "Epoch [244/360], Batch [65/196], Loss: 0.0174\n",
      "Epoch [244/360], Batch [70/196], Loss: 0.0150\n",
      "Epoch [244/360], Batch [75/196], Loss: 0.0107\n",
      "Epoch [244/360], Batch [80/196], Loss: 0.0209\n",
      "Epoch [244/360], Batch [85/196], Loss: 0.0111\n",
      "Epoch [244/360], Batch [90/196], Loss: 0.0179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [244/360], Batch [95/196], Loss: 0.0133\n",
      "Epoch [244/360], Batch [100/196], Loss: 0.0845\n",
      "Epoch [244/360], Batch [105/196], Loss: 0.0184\n",
      "Epoch [244/360], Batch [110/196], Loss: 0.0740\n",
      "Epoch [244/360], Batch [115/196], Loss: 0.0126\n",
      "Epoch [244/360], Batch [120/196], Loss: 0.0230\n",
      "Epoch [244/360], Batch [125/196], Loss: 0.0244\n",
      "Epoch [244/360], Batch [130/196], Loss: 0.0161\n",
      "Epoch [244/360], Batch [135/196], Loss: 0.0300\n",
      "Epoch [244/360], Batch [140/196], Loss: 0.0194\n",
      "Epoch [244/360], Batch [145/196], Loss: 0.0244\n",
      "Epoch [244/360], Batch [150/196], Loss: 0.0223\n",
      "Epoch [244/360], Batch [155/196], Loss: 0.0168\n",
      "Epoch [244/360], Batch [160/196], Loss: 0.0219\n",
      "Epoch [244/360], Batch [165/196], Loss: 0.0180\n",
      "Epoch [244/360], Batch [170/196], Loss: 0.0158\n",
      "Epoch [244/360], Batch [175/196], Loss: 0.0162\n",
      "Epoch [244/360], Batch [180/196], Loss: 0.0240\n",
      "Epoch [244/360], Batch [185/196], Loss: 0.0228\n",
      "Epoch [244/360], Batch [190/196], Loss: 0.0191\n",
      "Epoch [244/360], Batch [195/196], Loss: 0.0345\n",
      "Epoch [245/360], Batch [5/196], Loss: 0.0462\n",
      "Epoch [245/360], Batch [10/196], Loss: 0.0188\n",
      "Epoch [245/360], Batch [15/196], Loss: 0.0200\n",
      "Epoch [245/360], Batch [20/196], Loss: 0.0238\n",
      "Epoch [245/360], Batch [25/196], Loss: 0.0161\n",
      "Epoch [245/360], Batch [30/196], Loss: 0.0143\n",
      "Epoch [245/360], Batch [35/196], Loss: 0.0181\n",
      "Epoch [245/360], Batch [40/196], Loss: 0.0632\n",
      "Epoch [245/360], Batch [45/196], Loss: 0.0268\n",
      "Epoch [245/360], Batch [50/196], Loss: 0.0326\n",
      "Epoch [245/360], Batch [55/196], Loss: 0.0345\n",
      "Epoch [245/360], Batch [60/196], Loss: 0.0154\n",
      "Epoch [245/360], Batch [65/196], Loss: 0.0164\n",
      "Epoch [245/360], Batch [70/196], Loss: 0.0271\n",
      "Epoch [245/360], Batch [75/196], Loss: 0.0173\n",
      "Epoch [245/360], Batch [80/196], Loss: 0.0186\n",
      "Epoch [245/360], Batch [85/196], Loss: 0.1341\n",
      "Epoch [245/360], Batch [90/196], Loss: 0.0170\n",
      "Epoch [245/360], Batch [95/196], Loss: 0.0231\n",
      "Epoch [245/360], Batch [100/196], Loss: 0.0255\n",
      "Epoch [245/360], Batch [105/196], Loss: 0.0153\n",
      "Epoch [245/360], Batch [110/196], Loss: 0.0330\n",
      "Epoch [245/360], Batch [115/196], Loss: 0.0330\n",
      "Epoch [245/360], Batch [120/196], Loss: 0.0290\n",
      "Epoch [245/360], Batch [125/196], Loss: 0.0175\n",
      "Epoch [245/360], Batch [130/196], Loss: 0.0272\n",
      "Epoch [245/360], Batch [135/196], Loss: 0.0184\n",
      "Epoch [245/360], Batch [140/196], Loss: 0.0292\n",
      "Epoch [245/360], Batch [145/196], Loss: 0.0195\n",
      "Epoch [245/360], Batch [150/196], Loss: 0.0222\n",
      "Epoch [245/360], Batch [155/196], Loss: 0.0303\n",
      "Epoch [245/360], Batch [160/196], Loss: 0.0228\n",
      "Epoch [245/360], Batch [165/196], Loss: 0.0294\n",
      "Epoch [245/360], Batch [170/196], Loss: 0.0268\n",
      "Epoch [245/360], Batch [175/196], Loss: 0.0285\n",
      "Epoch [245/360], Batch [180/196], Loss: 0.0301\n",
      "Epoch [245/360], Batch [185/196], Loss: 0.0265\n",
      "Epoch [245/360], Batch [190/196], Loss: 0.0271\n",
      "Epoch [245/360], Batch [195/196], Loss: 0.0321\n",
      "Epoch [246/360], Batch [5/196], Loss: 0.0198\n",
      "Epoch [246/360], Batch [10/196], Loss: 0.0232\n",
      "Epoch [246/360], Batch [15/196], Loss: 0.0182\n",
      "Epoch [246/360], Batch [20/196], Loss: 0.0475\n",
      "Epoch [246/360], Batch [25/196], Loss: 0.0385\n",
      "Epoch [246/360], Batch [30/196], Loss: 0.0838\n",
      "Epoch [246/360], Batch [35/196], Loss: 0.0219\n",
      "Epoch [246/360], Batch [40/196], Loss: 0.0146\n",
      "Epoch [246/360], Batch [45/196], Loss: 0.0390\n",
      "Epoch [246/360], Batch [50/196], Loss: 0.0237\n",
      "Epoch [246/360], Batch [55/196], Loss: 0.0298\n",
      "Epoch [246/360], Batch [60/196], Loss: 0.0345\n",
      "Epoch [246/360], Batch [65/196], Loss: 0.0159\n",
      "Epoch [246/360], Batch [70/196], Loss: 0.0309\n",
      "Epoch [246/360], Batch [75/196], Loss: 0.0314\n",
      "Epoch [246/360], Batch [80/196], Loss: 0.0357\n",
      "Epoch [246/360], Batch [85/196], Loss: 0.0505\n",
      "Epoch [246/360], Batch [90/196], Loss: 0.0260\n",
      "Epoch [246/360], Batch [95/196], Loss: 0.0307\n",
      "Epoch [246/360], Batch [100/196], Loss: 0.0412\n",
      "Epoch [246/360], Batch [105/196], Loss: 0.0301\n",
      "Epoch [246/360], Batch [110/196], Loss: 0.0211\n",
      "Epoch [246/360], Batch [115/196], Loss: 0.0371\n",
      "Epoch [246/360], Batch [120/196], Loss: 0.0354\n",
      "Epoch [246/360], Batch [125/196], Loss: 0.0279\n",
      "Epoch [246/360], Batch [130/196], Loss: 0.0277\n",
      "Epoch [246/360], Batch [135/196], Loss: 0.0375\n",
      "Epoch [246/360], Batch [140/196], Loss: 0.0487\n",
      "Epoch [246/360], Batch [145/196], Loss: 0.0294\n",
      "Epoch [246/360], Batch [150/196], Loss: 0.0454\n",
      "Epoch [246/360], Batch [155/196], Loss: 0.0354\n",
      "Epoch [246/360], Batch [160/196], Loss: 0.0471\n",
      "Epoch [246/360], Batch [165/196], Loss: 0.0240\n",
      "Epoch [246/360], Batch [170/196], Loss: 0.0358\n",
      "Epoch [246/360], Batch [175/196], Loss: 0.0253\n",
      "Epoch [246/360], Batch [180/196], Loss: 0.0283\n",
      "Epoch [246/360], Batch [185/196], Loss: 0.0274\n",
      "Epoch [246/360], Batch [190/196], Loss: 0.0305\n",
      "Epoch [246/360], Batch [195/196], Loss: 0.0321\n",
      "Epoch [247/360], Batch [5/196], Loss: 0.0248\n",
      "Epoch [247/360], Batch [10/196], Loss: 0.0259\n",
      "Epoch [247/360], Batch [15/196], Loss: 0.0327\n",
      "Epoch [247/360], Batch [20/196], Loss: 0.0297\n",
      "Epoch [247/360], Batch [25/196], Loss: 0.0338\n",
      "Epoch [247/360], Batch [30/196], Loss: 0.0342\n",
      "Epoch [247/360], Batch [35/196], Loss: 0.0273\n",
      "Epoch [247/360], Batch [40/196], Loss: 0.0364\n",
      "Epoch [247/360], Batch [45/196], Loss: 0.0386\n",
      "Epoch [247/360], Batch [50/196], Loss: 0.0341\n",
      "Epoch [247/360], Batch [55/196], Loss: 0.0304\n",
      "Epoch [247/360], Batch [60/196], Loss: 0.0377\n",
      "Epoch [247/360], Batch [65/196], Loss: 0.0409\n",
      "Epoch [247/360], Batch [70/196], Loss: 0.0540\n",
      "Epoch [247/360], Batch [75/196], Loss: 0.0229\n",
      "Epoch [247/360], Batch [80/196], Loss: 0.0343\n",
      "Epoch [247/360], Batch [85/196], Loss: 0.0303\n",
      "Epoch [247/360], Batch [90/196], Loss: 0.0509\n",
      "Epoch [247/360], Batch [95/196], Loss: 0.0255\n",
      "Epoch [247/360], Batch [100/196], Loss: 0.0823\n",
      "Epoch [247/360], Batch [105/196], Loss: 0.0326\n",
      "Epoch [247/360], Batch [110/196], Loss: 0.0319\n",
      "Epoch [247/360], Batch [115/196], Loss: 0.0279\n",
      "Epoch [247/360], Batch [120/196], Loss: 0.0348\n",
      "Epoch [247/360], Batch [125/196], Loss: 0.0379\n",
      "Epoch [247/360], Batch [130/196], Loss: 0.0441\n",
      "Epoch [247/360], Batch [135/196], Loss: 0.0311\n",
      "Epoch [247/360], Batch [140/196], Loss: 0.0396\n",
      "Epoch [247/360], Batch [145/196], Loss: 0.0145\n",
      "Epoch [247/360], Batch [150/196], Loss: 0.0376\n",
      "Epoch [247/360], Batch [155/196], Loss: 0.0262\n",
      "Epoch [247/360], Batch [160/196], Loss: 0.0661\n",
      "Epoch [247/360], Batch [165/196], Loss: 0.0437\n",
      "Epoch [247/360], Batch [170/196], Loss: 0.0286\n",
      "Epoch [247/360], Batch [175/196], Loss: 0.0348\n",
      "Epoch [247/360], Batch [180/196], Loss: 0.0345\n",
      "Epoch [247/360], Batch [185/196], Loss: 0.0343\n",
      "Epoch [247/360], Batch [190/196], Loss: 0.0291\n",
      "Epoch [247/360], Batch [195/196], Loss: 0.0398\n",
      "Epoch [248/360], Batch [5/196], Loss: 0.0275\n",
      "Epoch [248/360], Batch [10/196], Loss: 0.0344\n",
      "Epoch [248/360], Batch [15/196], Loss: 0.0330\n",
      "Epoch [248/360], Batch [20/196], Loss: 0.0320\n",
      "Epoch [248/360], Batch [25/196], Loss: 0.0266\n",
      "Epoch [248/360], Batch [30/196], Loss: 0.0289\n",
      "Epoch [248/360], Batch [35/196], Loss: 0.0480\n",
      "Epoch [248/360], Batch [40/196], Loss: 0.0318\n",
      "Epoch [248/360], Batch [45/196], Loss: 0.0218\n",
      "Epoch [248/360], Batch [50/196], Loss: 0.0409\n",
      "Epoch [248/360], Batch [55/196], Loss: 0.0299\n",
      "Epoch [248/360], Batch [60/196], Loss: 0.0257\n",
      "Epoch [248/360], Batch [65/196], Loss: 0.0469\n",
      "Epoch [248/360], Batch [70/196], Loss: 0.0170\n",
      "Epoch [248/360], Batch [75/196], Loss: 0.0775\n",
      "Epoch [248/360], Batch [80/196], Loss: 0.0206\n",
      "Epoch [248/360], Batch [85/196], Loss: 0.0329\n",
      "Epoch [248/360], Batch [90/196], Loss: 0.0300\n",
      "Epoch [248/360], Batch [95/196], Loss: 0.0420\n",
      "Epoch [248/360], Batch [100/196], Loss: 0.0341\n",
      "Epoch [248/360], Batch [105/196], Loss: 0.0284\n",
      "Epoch [248/360], Batch [110/196], Loss: 0.0305\n",
      "Epoch [248/360], Batch [115/196], Loss: 0.0643\n",
      "Epoch [248/360], Batch [120/196], Loss: 0.0389\n",
      "Epoch [248/360], Batch [125/196], Loss: 0.0280\n",
      "Epoch [248/360], Batch [130/196], Loss: 0.0210\n",
      "Epoch [248/360], Batch [135/196], Loss: 0.0298\n",
      "Epoch [248/360], Batch [140/196], Loss: 0.0408\n",
      "Epoch [248/360], Batch [145/196], Loss: 0.0399\n",
      "Epoch [248/360], Batch [150/196], Loss: 0.0283\n",
      "Epoch [248/360], Batch [155/196], Loss: 0.0280\n",
      "Epoch [248/360], Batch [160/196], Loss: 0.0266\n",
      "Epoch [248/360], Batch [165/196], Loss: 0.0238\n",
      "Epoch [248/360], Batch [170/196], Loss: 0.0620\n",
      "Epoch [248/360], Batch [175/196], Loss: 0.0678\n",
      "Epoch [248/360], Batch [180/196], Loss: 0.0170\n",
      "Epoch [248/360], Batch [185/196], Loss: 0.0473\n",
      "Epoch [248/360], Batch [190/196], Loss: 0.0334\n",
      "Epoch [248/360], Batch [195/196], Loss: 0.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [249/360], Batch [5/196], Loss: 0.0286\n",
      "Epoch [249/360], Batch [10/196], Loss: 0.0241\n",
      "Epoch [249/360], Batch [15/196], Loss: 0.0698\n",
      "Epoch [249/360], Batch [20/196], Loss: 0.0966\n",
      "Epoch [249/360], Batch [25/196], Loss: 0.0857\n",
      "Epoch [249/360], Batch [30/196], Loss: 0.0812\n",
      "Epoch [249/360], Batch [35/196], Loss: 0.0637\n",
      "Epoch [249/360], Batch [40/196], Loss: 0.0578\n",
      "Epoch [249/360], Batch [45/196], Loss: 0.0685\n",
      "Epoch [249/360], Batch [50/196], Loss: 0.1549\n",
      "Epoch [249/360], Batch [55/196], Loss: 0.0544\n",
      "Epoch [249/360], Batch [60/196], Loss: 0.0682\n",
      "Epoch [249/360], Batch [65/196], Loss: 0.0785\n",
      "Epoch [249/360], Batch [70/196], Loss: 0.0487\n",
      "Epoch [249/360], Batch [75/196], Loss: 0.0669\n",
      "Epoch [249/360], Batch [80/196], Loss: 0.0428\n",
      "Epoch [249/360], Batch [85/196], Loss: 0.0458\n",
      "Epoch [249/360], Batch [90/196], Loss: 0.0501\n",
      "Epoch [249/360], Batch [95/196], Loss: 0.0340\n",
      "Epoch [249/360], Batch [100/196], Loss: 0.0472\n",
      "Epoch [249/360], Batch [105/196], Loss: 0.0373\n",
      "Epoch [249/360], Batch [110/196], Loss: 0.0698\n",
      "Epoch [249/360], Batch [115/196], Loss: 0.0439\n",
      "Epoch [249/360], Batch [120/196], Loss: 0.0386\n",
      "Epoch [249/360], Batch [125/196], Loss: 0.0468\n",
      "Epoch [249/360], Batch [130/196], Loss: 0.0446\n",
      "Epoch [249/360], Batch [135/196], Loss: 0.0602\n",
      "Epoch [249/360], Batch [140/196], Loss: 0.0426\n",
      "Epoch [249/360], Batch [145/196], Loss: 0.1014\n",
      "Epoch [249/360], Batch [150/196], Loss: 0.1121\n",
      "Epoch [249/360], Batch [155/196], Loss: 0.1002\n",
      "Epoch [249/360], Batch [160/196], Loss: 0.0778\n",
      "Epoch [249/360], Batch [165/196], Loss: 0.0889\n",
      "Epoch [249/360], Batch [170/196], Loss: 0.0725\n",
      "Epoch [249/360], Batch [175/196], Loss: 0.0708\n",
      "Epoch [249/360], Batch [180/196], Loss: 0.1477\n",
      "Epoch [249/360], Batch [185/196], Loss: 0.1897\n",
      "Epoch [249/360], Batch [190/196], Loss: 0.1031\n",
      "Epoch [249/360], Batch [195/196], Loss: 0.1511\n",
      "Epoch [250/360], Batch [5/196], Loss: 0.0802\n",
      "Epoch [250/360], Batch [10/196], Loss: 0.0807\n",
      "Epoch [250/360], Batch [15/196], Loss: 0.1097\n",
      "Epoch [250/360], Batch [20/196], Loss: 0.0915\n",
      "Epoch [250/360], Batch [25/196], Loss: 0.1366\n",
      "Epoch [250/360], Batch [30/196], Loss: 0.1110\n",
      "Epoch [250/360], Batch [35/196], Loss: 0.1530\n",
      "Epoch [250/360], Batch [40/196], Loss: 0.1472\n",
      "Epoch [250/360], Batch [45/196], Loss: 0.1762\n",
      "Epoch [250/360], Batch [50/196], Loss: 0.2876\n",
      "Epoch [250/360], Batch [55/196], Loss: 0.1230\n",
      "Epoch [250/360], Batch [60/196], Loss: 0.2057\n",
      "Epoch [250/360], Batch [65/196], Loss: 0.1486\n",
      "Epoch [250/360], Batch [70/196], Loss: 0.1341\n",
      "Epoch [250/360], Batch [75/196], Loss: 0.1618\n",
      "Epoch [250/360], Batch [80/196], Loss: 0.0816\n",
      "Epoch [250/360], Batch [85/196], Loss: 0.1272\n",
      "Epoch [250/360], Batch [90/196], Loss: 0.1687\n",
      "Epoch [250/360], Batch [95/196], Loss: 0.1244\n",
      "Epoch [250/360], Batch [100/196], Loss: 0.1303\n",
      "Epoch [250/360], Batch [105/196], Loss: 0.0625\n",
      "Epoch [250/360], Batch [110/196], Loss: 0.1065\n",
      "Epoch [250/360], Batch [115/196], Loss: 0.0963\n",
      "Epoch [250/360], Batch [120/196], Loss: 0.1055\n",
      "Epoch [250/360], Batch [125/196], Loss: 0.0788\n",
      "Epoch [250/360], Batch [130/196], Loss: 0.0939\n",
      "Epoch [250/360], Batch [135/196], Loss: 0.0717\n",
      "Epoch [250/360], Batch [140/196], Loss: 0.1294\n",
      "Epoch [250/360], Batch [145/196], Loss: 0.0946\n",
      "Epoch [250/360], Batch [150/196], Loss: 0.1035\n",
      "Epoch [250/360], Batch [155/196], Loss: 0.1195\n",
      "Epoch [250/360], Batch [160/196], Loss: 0.0932\n",
      "Epoch [250/360], Batch [165/196], Loss: 0.0968\n",
      "Epoch [250/360], Batch [170/196], Loss: 0.2185\n",
      "Epoch [250/360], Batch [175/196], Loss: 0.0818\n",
      "Epoch [250/360], Batch [180/196], Loss: 0.1644\n",
      "Epoch [250/360], Batch [185/196], Loss: 0.1218\n",
      "Epoch [250/360], Batch [190/196], Loss: 0.1214\n",
      "Epoch [250/360], Batch [195/196], Loss: 0.1656\n",
      "Epoch [251/360], Batch [5/196], Loss: 0.0681\n",
      "Epoch [251/360], Batch [10/196], Loss: 0.0761\n",
      "Epoch [251/360], Batch [15/196], Loss: 0.0736\n",
      "Epoch [251/360], Batch [20/196], Loss: 0.0615\n",
      "Epoch [251/360], Batch [25/196], Loss: 0.0873\n",
      "Epoch [251/360], Batch [30/196], Loss: 0.0801\n",
      "Epoch [251/360], Batch [35/196], Loss: 0.0540\n",
      "Epoch [251/360], Batch [40/196], Loss: 0.0672\n",
      "Epoch [251/360], Batch [45/196], Loss: 0.0505\n",
      "Epoch [251/360], Batch [50/196], Loss: 0.0866\n",
      "Epoch [251/360], Batch [55/196], Loss: 0.1202\n",
      "Epoch [251/360], Batch [60/196], Loss: 0.0981\n",
      "Epoch [251/360], Batch [65/196], Loss: 0.0527\n",
      "Epoch [251/360], Batch [70/196], Loss: 0.0708\n",
      "Epoch [251/360], Batch [75/196], Loss: 0.0793\n",
      "Epoch [251/360], Batch [80/196], Loss: 0.0710\n",
      "Epoch [251/360], Batch [85/196], Loss: 0.1116\n",
      "Epoch [251/360], Batch [90/196], Loss: 0.0558\n",
      "Epoch [251/360], Batch [95/196], Loss: 0.1518\n",
      "Epoch [251/360], Batch [100/196], Loss: 0.1245\n",
      "Epoch [251/360], Batch [105/196], Loss: 0.0617\n",
      "Epoch [251/360], Batch [110/196], Loss: 0.0984\n",
      "Epoch [251/360], Batch [115/196], Loss: 0.0451\n",
      "Epoch [251/360], Batch [120/196], Loss: 0.0604\n",
      "Epoch [251/360], Batch [125/196], Loss: 0.0427\n",
      "Epoch [251/360], Batch [130/196], Loss: 0.0376\n",
      "Epoch [251/360], Batch [135/196], Loss: 0.0804\n",
      "Epoch [251/360], Batch [140/196], Loss: 0.0525\n",
      "Epoch [251/360], Batch [145/196], Loss: 0.0464\n",
      "Epoch [251/360], Batch [150/196], Loss: 0.0421\n",
      "Epoch [251/360], Batch [155/196], Loss: 0.1386\n",
      "Epoch [251/360], Batch [160/196], Loss: 0.0537\n",
      "Epoch [251/360], Batch [165/196], Loss: 0.0579\n",
      "Epoch [251/360], Batch [170/196], Loss: 0.0471\n",
      "Epoch [251/360], Batch [175/196], Loss: 0.0522\n",
      "Epoch [251/360], Batch [180/196], Loss: 0.0670\n",
      "Epoch [251/360], Batch [185/196], Loss: 0.0553\n",
      "Epoch [251/360], Batch [190/196], Loss: 0.0804\n",
      "Epoch [251/360], Batch [195/196], Loss: 0.0585\n",
      "Epoch [252/360], Batch [5/196], Loss: 0.0355\n",
      "Epoch [252/360], Batch [10/196], Loss: 0.0546\n",
      "Epoch [252/360], Batch [15/196], Loss: 0.0353\n",
      "Epoch [252/360], Batch [20/196], Loss: 0.0304\n",
      "Epoch [252/360], Batch [25/196], Loss: 0.0513\n",
      "Epoch [252/360], Batch [30/196], Loss: 0.0231\n",
      "Epoch [252/360], Batch [35/196], Loss: 0.0349\n",
      "Epoch [252/360], Batch [40/196], Loss: 0.0364\n",
      "Epoch [252/360], Batch [45/196], Loss: 0.0153\n",
      "Epoch [252/360], Batch [50/196], Loss: 0.0383\n",
      "Epoch [252/360], Batch [55/196], Loss: 0.0365\n",
      "Epoch [252/360], Batch [60/196], Loss: 0.0362\n",
      "Epoch [252/360], Batch [65/196], Loss: 0.0305\n",
      "Epoch [252/360], Batch [70/196], Loss: 0.0405\n",
      "Epoch [252/360], Batch [75/196], Loss: 0.0240\n",
      "Epoch [252/360], Batch [80/196], Loss: 0.0246\n",
      "Epoch [252/360], Batch [85/196], Loss: 0.0324\n",
      "Epoch [252/360], Batch [90/196], Loss: 0.0450\n",
      "Epoch [252/360], Batch [95/196], Loss: 0.0294\n",
      "Epoch [252/360], Batch [100/196], Loss: 0.0425\n",
      "Epoch [252/360], Batch [105/196], Loss: 0.0157\n",
      "Epoch [252/360], Batch [110/196], Loss: 0.0377\n",
      "Epoch [252/360], Batch [115/196], Loss: 0.0230\n",
      "Epoch [252/360], Batch [120/196], Loss: 0.0217\n",
      "Epoch [252/360], Batch [125/196], Loss: 0.0207\n",
      "Epoch [252/360], Batch [130/196], Loss: 0.0395\n",
      "Epoch [252/360], Batch [135/196], Loss: 0.0277\n",
      "Epoch [252/360], Batch [140/196], Loss: 0.0212\n",
      "Epoch [252/360], Batch [145/196], Loss: 0.0277\n",
      "Epoch [252/360], Batch [150/196], Loss: 0.0263\n",
      "Epoch [252/360], Batch [155/196], Loss: 0.0239\n",
      "Epoch [252/360], Batch [160/196], Loss: 0.0231\n",
      "Epoch [252/360], Batch [165/196], Loss: 0.0190\n",
      "Epoch [252/360], Batch [170/196], Loss: 0.0481\n",
      "Epoch [252/360], Batch [175/196], Loss: 0.0208\n",
      "Epoch [252/360], Batch [180/196], Loss: 0.0408\n",
      "Epoch [252/360], Batch [185/196], Loss: 0.0372\n",
      "Epoch [252/360], Batch [190/196], Loss: 0.0235\n",
      "Epoch [252/360], Batch [195/196], Loss: 0.0271\n",
      "Epoch [253/360], Batch [5/196], Loss: 0.0195\n",
      "Epoch [253/360], Batch [10/196], Loss: 0.0167\n",
      "Epoch [253/360], Batch [15/196], Loss: 0.0093\n",
      "Epoch [253/360], Batch [20/196], Loss: 0.0172\n",
      "Epoch [253/360], Batch [25/196], Loss: 0.0105\n",
      "Epoch [253/360], Batch [30/196], Loss: 0.0131\n",
      "Epoch [253/360], Batch [35/196], Loss: 0.0619\n",
      "Epoch [253/360], Batch [40/196], Loss: 0.0137\n",
      "Epoch [253/360], Batch [45/196], Loss: 0.0148\n",
      "Epoch [253/360], Batch [50/196], Loss: 0.0144\n",
      "Epoch [253/360], Batch [55/196], Loss: 0.0177\n",
      "Epoch [253/360], Batch [60/196], Loss: 0.0157\n",
      "Epoch [253/360], Batch [65/196], Loss: 0.0117\n",
      "Epoch [253/360], Batch [70/196], Loss: 0.0182\n",
      "Epoch [253/360], Batch [75/196], Loss: 0.0328\n",
      "Epoch [253/360], Batch [80/196], Loss: 0.0108\n",
      "Epoch [253/360], Batch [85/196], Loss: 0.0171\n",
      "Epoch [253/360], Batch [90/196], Loss: 0.0174\n",
      "Epoch [253/360], Batch [95/196], Loss: 0.0142\n",
      "Epoch [253/360], Batch [100/196], Loss: 0.0216\n",
      "Epoch [253/360], Batch [105/196], Loss: 0.0114\n",
      "Epoch [253/360], Batch [110/196], Loss: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [253/360], Batch [115/196], Loss: 0.0127\n",
      "Epoch [253/360], Batch [120/196], Loss: 0.0179\n",
      "Epoch [253/360], Batch [125/196], Loss: 0.0125\n",
      "Epoch [253/360], Batch [130/196], Loss: 0.0163\n",
      "Epoch [253/360], Batch [135/196], Loss: 0.0206\n",
      "Epoch [253/360], Batch [140/196], Loss: 0.0105\n",
      "Epoch [253/360], Batch [145/196], Loss: 0.0188\n",
      "Epoch [253/360], Batch [150/196], Loss: 0.0181\n",
      "Epoch [253/360], Batch [155/196], Loss: 0.0183\n",
      "Epoch [253/360], Batch [160/196], Loss: 0.0166\n",
      "Epoch [253/360], Batch [165/196], Loss: 0.0130\n",
      "Epoch [253/360], Batch [170/196], Loss: 0.0171\n",
      "Epoch [253/360], Batch [175/196], Loss: 0.0200\n",
      "Epoch [253/360], Batch [180/196], Loss: 0.0157\n",
      "Epoch [253/360], Batch [185/196], Loss: 0.0126\n",
      "Epoch [253/360], Batch [190/196], Loss: 0.0190\n",
      "Epoch [253/360], Batch [195/196], Loss: 0.0130\n",
      "Epoch [254/360], Batch [5/196], Loss: 0.0124\n",
      "Epoch [254/360], Batch [10/196], Loss: 0.0092\n",
      "Epoch [254/360], Batch [15/196], Loss: 0.0123\n",
      "Epoch [254/360], Batch [20/196], Loss: 0.0132\n",
      "Epoch [254/360], Batch [25/196], Loss: 0.0172\n",
      "Epoch [254/360], Batch [30/196], Loss: 0.0230\n",
      "Epoch [254/360], Batch [35/196], Loss: 0.0563\n",
      "Epoch [254/360], Batch [40/196], Loss: 0.0235\n",
      "Epoch [254/360], Batch [45/196], Loss: 0.0134\n",
      "Epoch [254/360], Batch [50/196], Loss: 0.0168\n",
      "Epoch [254/360], Batch [55/196], Loss: 0.0168\n",
      "Epoch [254/360], Batch [60/196], Loss: 0.0219\n",
      "Epoch [254/360], Batch [65/196], Loss: 0.0156\n",
      "Epoch [254/360], Batch [70/196], Loss: 0.0115\n",
      "Epoch [254/360], Batch [75/196], Loss: 0.0119\n",
      "Epoch [254/360], Batch [80/196], Loss: 0.0186\n",
      "Epoch [254/360], Batch [85/196], Loss: 0.0207\n",
      "Epoch [254/360], Batch [90/196], Loss: 0.0130\n",
      "Epoch [254/360], Batch [95/196], Loss: 0.0221\n",
      "Epoch [254/360], Batch [100/196], Loss: 0.0172\n",
      "Epoch [254/360], Batch [105/196], Loss: 0.0237\n",
      "Epoch [254/360], Batch [110/196], Loss: 0.0200\n",
      "Epoch [254/360], Batch [115/196], Loss: 0.0192\n",
      "Epoch [254/360], Batch [120/196], Loss: 0.0394\n",
      "Epoch [254/360], Batch [125/196], Loss: 0.0288\n",
      "Epoch [254/360], Batch [130/196], Loss: 0.0382\n",
      "Epoch [254/360], Batch [135/196], Loss: 0.0659\n",
      "Epoch [254/360], Batch [140/196], Loss: 0.0632\n",
      "Epoch [254/360], Batch [145/196], Loss: 0.1037\n",
      "Epoch [254/360], Batch [150/196], Loss: 0.0882\n",
      "Epoch [254/360], Batch [155/196], Loss: 0.0840\n",
      "Epoch [254/360], Batch [160/196], Loss: 0.0611\n",
      "Epoch [254/360], Batch [165/196], Loss: 0.0655\n",
      "Epoch [254/360], Batch [170/196], Loss: 0.0675\n",
      "Epoch [254/360], Batch [175/196], Loss: 0.0541\n",
      "Epoch [254/360], Batch [180/196], Loss: 0.0610\n",
      "Epoch [254/360], Batch [185/196], Loss: 0.0726\n",
      "Epoch [254/360], Batch [190/196], Loss: 0.0594\n",
      "Epoch [254/360], Batch [195/196], Loss: 0.0550\n",
      "Epoch [255/360], Batch [5/196], Loss: 0.0525\n",
      "Epoch [255/360], Batch [10/196], Loss: 0.0629\n",
      "Epoch [255/360], Batch [15/196], Loss: 0.0349\n",
      "Epoch [255/360], Batch [20/196], Loss: 0.0516\n",
      "Epoch [255/360], Batch [25/196], Loss: 0.0732\n",
      "Epoch [255/360], Batch [30/196], Loss: 0.0320\n",
      "Epoch [255/360], Batch [35/196], Loss: 0.0454\n",
      "Epoch [255/360], Batch [40/196], Loss: 0.0652\n",
      "Epoch [255/360], Batch [45/196], Loss: 0.0559\n",
      "Epoch [255/360], Batch [50/196], Loss: 0.0380\n",
      "Epoch [255/360], Batch [55/196], Loss: 0.0363\n",
      "Epoch [255/360], Batch [60/196], Loss: 0.0478\n",
      "Epoch [255/360], Batch [65/196], Loss: 0.0277\n",
      "Epoch [255/360], Batch [70/196], Loss: 0.0558\n",
      "Epoch [255/360], Batch [75/196], Loss: 0.0382\n",
      "Epoch [255/360], Batch [80/196], Loss: 0.0904\n",
      "Epoch [255/360], Batch [85/196], Loss: 0.1234\n",
      "Epoch [255/360], Batch [90/196], Loss: 0.0717\n",
      "Epoch [255/360], Batch [95/196], Loss: 0.0891\n",
      "Epoch [255/360], Batch [100/196], Loss: 0.0622\n",
      "Epoch [255/360], Batch [105/196], Loss: 0.0550\n",
      "Epoch [255/360], Batch [110/196], Loss: 0.0461\n",
      "Epoch [255/360], Batch [115/196], Loss: 0.0484\n",
      "Epoch [255/360], Batch [120/196], Loss: 0.0706\n",
      "Epoch [255/360], Batch [125/196], Loss: 0.0730\n",
      "Epoch [255/360], Batch [130/196], Loss: 0.0389\n",
      "Epoch [255/360], Batch [135/196], Loss: 0.0664\n",
      "Epoch [255/360], Batch [140/196], Loss: 0.0546\n",
      "Epoch [255/360], Batch [145/196], Loss: 0.0362\n",
      "Epoch [255/360], Batch [150/196], Loss: 0.0525\n",
      "Epoch [255/360], Batch [155/196], Loss: 0.0310\n",
      "Epoch [255/360], Batch [160/196], Loss: 0.0485\n",
      "Epoch [255/360], Batch [165/196], Loss: 0.0551\n",
      "Epoch [255/360], Batch [170/196], Loss: 0.0380\n",
      "Epoch [255/360], Batch [175/196], Loss: 0.0453\n",
      "Epoch [255/360], Batch [180/196], Loss: 0.0370\n",
      "Epoch [255/360], Batch [185/196], Loss: 0.0454\n",
      "Epoch [255/360], Batch [190/196], Loss: 0.0459\n",
      "Epoch [255/360], Batch [195/196], Loss: 0.0449\n",
      "Epoch [256/360], Batch [5/196], Loss: 0.0387\n",
      "Epoch [256/360], Batch [10/196], Loss: 0.0425\n",
      "Epoch [256/360], Batch [15/196], Loss: 0.0244\n",
      "Epoch [256/360], Batch [20/196], Loss: 0.0316\n",
      "Epoch [256/360], Batch [25/196], Loss: 0.0354\n",
      "Epoch [256/360], Batch [30/196], Loss: 0.0304\n",
      "Epoch [256/360], Batch [35/196], Loss: 0.0234\n",
      "Epoch [256/360], Batch [40/196], Loss: 0.0299\n",
      "Epoch [256/360], Batch [45/196], Loss: 0.0239\n",
      "Epoch [256/360], Batch [50/196], Loss: 0.0340\n",
      "Epoch [256/360], Batch [55/196], Loss: 0.0331\n",
      "Epoch [256/360], Batch [60/196], Loss: 0.0213\n",
      "Epoch [256/360], Batch [65/196], Loss: 0.0234\n",
      "Epoch [256/360], Batch [70/196], Loss: 0.0172\n",
      "Epoch [256/360], Batch [75/196], Loss: 0.0217\n",
      "Epoch [256/360], Batch [80/196], Loss: 0.0271\n",
      "Epoch [256/360], Batch [85/196], Loss: 0.0239\n",
      "Epoch [256/360], Batch [90/196], Loss: 0.0260\n",
      "Epoch [256/360], Batch [95/196], Loss: 0.0383\n",
      "Epoch [256/360], Batch [100/196], Loss: 0.0202\n",
      "Epoch [256/360], Batch [105/196], Loss: 0.0250\n",
      "Epoch [256/360], Batch [110/196], Loss: 0.0195\n",
      "Epoch [256/360], Batch [115/196], Loss: 0.0232\n",
      "Epoch [256/360], Batch [120/196], Loss: 0.0212\n",
      "Epoch [256/360], Batch [125/196], Loss: 0.0293\n",
      "Epoch [256/360], Batch [130/196], Loss: 0.0334\n",
      "Epoch [256/360], Batch [135/196], Loss: 0.0236\n",
      "Epoch [256/360], Batch [140/196], Loss: 0.0296\n",
      "Epoch [256/360], Batch [145/196], Loss: 0.0168\n",
      "Epoch [256/360], Batch [150/196], Loss: 0.0273\n",
      "Epoch [256/360], Batch [155/196], Loss: 0.0234\n",
      "Epoch [256/360], Batch [160/196], Loss: 0.0234\n",
      "Epoch [256/360], Batch [165/196], Loss: 0.0400\n",
      "Epoch [256/360], Batch [170/196], Loss: 0.0454\n",
      "Epoch [256/360], Batch [175/196], Loss: 0.0290\n",
      "Epoch [256/360], Batch [180/196], Loss: 0.0232\n",
      "Epoch [256/360], Batch [185/196], Loss: 0.0224\n",
      "Epoch [256/360], Batch [190/196], Loss: 0.0242\n",
      "Epoch [256/360], Batch [195/196], Loss: 0.0276\n",
      "Epoch [257/360], Batch [5/196], Loss: 0.0224\n",
      "Epoch [257/360], Batch [10/196], Loss: 0.0104\n",
      "Epoch [257/360], Batch [15/196], Loss: 0.0267\n",
      "Epoch [257/360], Batch [20/196], Loss: 0.0285\n",
      "Epoch [257/360], Batch [25/196], Loss: 0.0235\n",
      "Epoch [257/360], Batch [30/196], Loss: 0.0227\n",
      "Epoch [257/360], Batch [35/196], Loss: 0.0305\n",
      "Epoch [257/360], Batch [40/196], Loss: 0.0414\n",
      "Epoch [257/360], Batch [45/196], Loss: 0.0210\n",
      "Epoch [257/360], Batch [50/196], Loss: 0.0280\n",
      "Epoch [257/360], Batch [55/196], Loss: 0.0191\n",
      "Epoch [257/360], Batch [60/196], Loss: 0.0170\n",
      "Epoch [257/360], Batch [65/196], Loss: 0.0279\n",
      "Epoch [257/360], Batch [70/196], Loss: 0.0318\n",
      "Epoch [257/360], Batch [75/196], Loss: 0.0280\n",
      "Epoch [257/360], Batch [80/196], Loss: 0.0276\n",
      "Epoch [257/360], Batch [85/196], Loss: 0.0238\n",
      "Epoch [257/360], Batch [90/196], Loss: 0.0139\n",
      "Epoch [257/360], Batch [95/196], Loss: 0.0252\n",
      "Epoch [257/360], Batch [100/196], Loss: 0.0301\n",
      "Epoch [257/360], Batch [105/196], Loss: 0.0261\n",
      "Epoch [257/360], Batch [110/196], Loss: 0.0204\n",
      "Epoch [257/360], Batch [115/196], Loss: 0.0143\n",
      "Epoch [257/360], Batch [120/196], Loss: 0.0209\n",
      "Epoch [257/360], Batch [125/196], Loss: 0.0124\n",
      "Epoch [257/360], Batch [130/196], Loss: 0.0260\n",
      "Epoch [257/360], Batch [135/196], Loss: 0.0187\n",
      "Epoch [257/360], Batch [140/196], Loss: 0.0221\n",
      "Epoch [257/360], Batch [145/196], Loss: 0.0174\n",
      "Epoch [257/360], Batch [150/196], Loss: 0.0129\n",
      "Epoch [257/360], Batch [155/196], Loss: 0.0230\n",
      "Epoch [257/360], Batch [160/196], Loss: 0.0213\n",
      "Epoch [257/360], Batch [165/196], Loss: 0.0190\n",
      "Epoch [257/360], Batch [170/196], Loss: 0.0197\n",
      "Epoch [257/360], Batch [175/196], Loss: 0.0221\n",
      "Epoch [257/360], Batch [180/196], Loss: 0.0242\n",
      "Epoch [257/360], Batch [185/196], Loss: 0.0261\n",
      "Epoch [257/360], Batch [190/196], Loss: 0.0224\n",
      "Epoch [257/360], Batch [195/196], Loss: 0.0226\n",
      "Epoch [258/360], Batch [5/196], Loss: 0.0104\n",
      "Epoch [258/360], Batch [10/196], Loss: 0.0167\n",
      "Epoch [258/360], Batch [15/196], Loss: 0.0088\n",
      "Epoch [258/360], Batch [20/196], Loss: 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [258/360], Batch [25/196], Loss: 0.0161\n",
      "Epoch [258/360], Batch [30/196], Loss: 0.0145\n",
      "Epoch [258/360], Batch [35/196], Loss: 0.0218\n",
      "Epoch [258/360], Batch [40/196], Loss: 0.0190\n",
      "Epoch [258/360], Batch [45/196], Loss: 0.0192\n",
      "Epoch [258/360], Batch [50/196], Loss: 0.0227\n",
      "Epoch [258/360], Batch [55/196], Loss: 0.0197\n",
      "Epoch [258/360], Batch [60/196], Loss: 0.0142\n",
      "Epoch [258/360], Batch [65/196], Loss: 0.0149\n",
      "Epoch [258/360], Batch [70/196], Loss: 0.0164\n",
      "Epoch [258/360], Batch [75/196], Loss: 0.0171\n",
      "Epoch [258/360], Batch [80/196], Loss: 0.0183\n",
      "Epoch [258/360], Batch [85/196], Loss: 0.0170\n",
      "Epoch [258/360], Batch [90/196], Loss: 0.0195\n",
      "Epoch [258/360], Batch [95/196], Loss: 0.0126\n",
      "Epoch [258/360], Batch [100/196], Loss: 0.0170\n",
      "Epoch [258/360], Batch [105/196], Loss: 0.0157\n",
      "Epoch [258/360], Batch [110/196], Loss: 0.0133\n",
      "Epoch [258/360], Batch [115/196], Loss: 0.0152\n",
      "Epoch [258/360], Batch [120/196], Loss: 0.0140\n",
      "Epoch [258/360], Batch [125/196], Loss: 0.0155\n",
      "Epoch [258/360], Batch [130/196], Loss: 0.0139\n",
      "Epoch [258/360], Batch [135/196], Loss: 0.0142\n",
      "Epoch [258/360], Batch [140/196], Loss: 0.0155\n",
      "Epoch [258/360], Batch [145/196], Loss: 0.0119\n",
      "Epoch [258/360], Batch [150/196], Loss: 0.0224\n",
      "Epoch [258/360], Batch [155/196], Loss: 0.0300\n",
      "Epoch [258/360], Batch [160/196], Loss: 0.0198\n",
      "Epoch [258/360], Batch [165/196], Loss: 0.0154\n",
      "Epoch [258/360], Batch [170/196], Loss: 0.0201\n",
      "Epoch [258/360], Batch [175/196], Loss: 0.0255\n",
      "Epoch [258/360], Batch [180/196], Loss: 0.0176\n",
      "Epoch [258/360], Batch [185/196], Loss: 0.0281\n",
      "Epoch [258/360], Batch [190/196], Loss: 0.0289\n",
      "Epoch [258/360], Batch [195/196], Loss: 0.0169\n",
      "Epoch [259/360], Batch [5/196], Loss: 0.0175\n",
      "Epoch [259/360], Batch [10/196], Loss: 0.0188\n",
      "Epoch [259/360], Batch [15/196], Loss: 0.0146\n",
      "Epoch [259/360], Batch [20/196], Loss: 0.0270\n",
      "Epoch [259/360], Batch [25/196], Loss: 0.0141\n",
      "Epoch [259/360], Batch [30/196], Loss: 0.0299\n",
      "Epoch [259/360], Batch [35/196], Loss: 0.0245\n",
      "Epoch [259/360], Batch [40/196], Loss: 0.0126\n",
      "Epoch [259/360], Batch [45/196], Loss: 0.0216\n",
      "Epoch [259/360], Batch [50/196], Loss: 0.0153\n",
      "Epoch [259/360], Batch [55/196], Loss: 0.0182\n",
      "Epoch [259/360], Batch [60/196], Loss: 0.0164\n",
      "Epoch [259/360], Batch [65/196], Loss: 0.0154\n",
      "Epoch [259/360], Batch [70/196], Loss: 0.0163\n",
      "Epoch [259/360], Batch [75/196], Loss: 0.0172\n",
      "Epoch [259/360], Batch [80/196], Loss: 0.0110\n",
      "Epoch [259/360], Batch [85/196], Loss: 0.0157\n",
      "Epoch [259/360], Batch [90/196], Loss: 0.0095\n",
      "Epoch [259/360], Batch [95/196], Loss: 0.0116\n",
      "Epoch [259/360], Batch [100/196], Loss: 0.0162\n",
      "Epoch [259/360], Batch [105/196], Loss: 0.0168\n",
      "Epoch [259/360], Batch [110/196], Loss: 0.0157\n",
      "Epoch [259/360], Batch [115/196], Loss: 0.0106\n",
      "Epoch [259/360], Batch [120/196], Loss: 0.0273\n",
      "Epoch [259/360], Batch [125/196], Loss: 0.0224\n",
      "Epoch [259/360], Batch [130/196], Loss: 0.1426\n",
      "Epoch [259/360], Batch [135/196], Loss: 0.0701\n",
      "Epoch [259/360], Batch [140/196], Loss: 0.0572\n",
      "Epoch [259/360], Batch [145/196], Loss: 0.0842\n",
      "Epoch [259/360], Batch [150/196], Loss: 0.0568\n",
      "Epoch [259/360], Batch [155/196], Loss: 0.0990\n",
      "Epoch [259/360], Batch [160/196], Loss: 0.0555\n",
      "Epoch [259/360], Batch [165/196], Loss: 0.0349\n",
      "Epoch [259/360], Batch [170/196], Loss: 0.0628\n",
      "Epoch [259/360], Batch [175/196], Loss: 0.0501\n",
      "Epoch [259/360], Batch [180/196], Loss: 0.0378\n",
      "Epoch [259/360], Batch [185/196], Loss: 0.0793\n",
      "Epoch [259/360], Batch [190/196], Loss: 0.0814\n",
      "Epoch [259/360], Batch [195/196], Loss: 0.0585\n",
      "Epoch [260/360], Batch [5/196], Loss: 0.0801\n",
      "Epoch [260/360], Batch [10/196], Loss: 0.0606\n",
      "Epoch [260/360], Batch [15/196], Loss: 0.0435\n",
      "Epoch [260/360], Batch [20/196], Loss: 0.0416\n",
      "Epoch [260/360], Batch [25/196], Loss: 0.0783\n",
      "Epoch [260/360], Batch [30/196], Loss: 0.1947\n",
      "Epoch [260/360], Batch [35/196], Loss: 0.1036\n",
      "Epoch [260/360], Batch [40/196], Loss: 0.1599\n",
      "Epoch [260/360], Batch [45/196], Loss: 0.1709\n",
      "Epoch [260/360], Batch [50/196], Loss: 0.0799\n",
      "Epoch [260/360], Batch [55/196], Loss: 0.1216\n",
      "Epoch [260/360], Batch [60/196], Loss: 0.0991\n",
      "Epoch [260/360], Batch [65/196], Loss: 0.0831\n",
      "Epoch [260/360], Batch [70/196], Loss: 0.0838\n",
      "Epoch [260/360], Batch [75/196], Loss: 0.0550\n",
      "Epoch [260/360], Batch [80/196], Loss: 0.0847\n",
      "Epoch [260/360], Batch [85/196], Loss: 0.0552\n",
      "Epoch [260/360], Batch [90/196], Loss: 0.0370\n",
      "Epoch [260/360], Batch [95/196], Loss: 0.0458\n",
      "Epoch [260/360], Batch [100/196], Loss: 0.0693\n",
      "Epoch [260/360], Batch [105/196], Loss: 0.0512\n",
      "Epoch [260/360], Batch [110/196], Loss: 0.0433\n",
      "Epoch [260/360], Batch [115/196], Loss: 0.0497\n",
      "Epoch [260/360], Batch [120/196], Loss: 0.0493\n",
      "Epoch [260/360], Batch [125/196], Loss: 0.0451\n",
      "Epoch [260/360], Batch [130/196], Loss: 0.0399\n",
      "Epoch [260/360], Batch [135/196], Loss: 0.0508\n",
      "Epoch [260/360], Batch [140/196], Loss: 0.0497\n",
      "Epoch [260/360], Batch [145/196], Loss: 0.1395\n",
      "Epoch [260/360], Batch [150/196], Loss: 0.0913\n",
      "Epoch [260/360], Batch [155/196], Loss: 0.0756\n",
      "Epoch [260/360], Batch [160/196], Loss: 0.0803\n",
      "Epoch [260/360], Batch [165/196], Loss: 0.0817\n",
      "Epoch [260/360], Batch [170/196], Loss: 0.0690\n",
      "Epoch [260/360], Batch [175/196], Loss: 0.0431\n",
      "Epoch [260/360], Batch [180/196], Loss: 0.0721\n",
      "Epoch [260/360], Batch [185/196], Loss: 0.0903\n",
      "Epoch [260/360], Batch [190/196], Loss: 0.0482\n",
      "Epoch [260/360], Batch [195/196], Loss: 0.0262\n",
      "Epoch [261/360], Batch [5/196], Loss: 0.0595\n",
      "Epoch [261/360], Batch [10/196], Loss: 0.0323\n",
      "Epoch [261/360], Batch [15/196], Loss: 0.0395\n",
      "Epoch [261/360], Batch [20/196], Loss: 0.0431\n",
      "Epoch [261/360], Batch [25/196], Loss: 0.0632\n",
      "Epoch [261/360], Batch [30/196], Loss: 0.0497\n",
      "Epoch [261/360], Batch [35/196], Loss: 0.0631\n",
      "Epoch [261/360], Batch [40/196], Loss: 0.0595\n",
      "Epoch [261/360], Batch [45/196], Loss: 0.0308\n",
      "Epoch [261/360], Batch [50/196], Loss: 0.0372\n",
      "Epoch [261/360], Batch [55/196], Loss: 0.0378\n",
      "Epoch [261/360], Batch [60/196], Loss: 0.0337\n",
      "Epoch [261/360], Batch [65/196], Loss: 0.0390\n",
      "Epoch [261/360], Batch [70/196], Loss: 0.0549\n",
      "Epoch [261/360], Batch [75/196], Loss: 0.0264\n",
      "Epoch [261/360], Batch [80/196], Loss: 0.0612\n",
      "Epoch [261/360], Batch [85/196], Loss: 0.0461\n",
      "Epoch [261/360], Batch [90/196], Loss: 0.0462\n",
      "Epoch [261/360], Batch [95/196], Loss: 0.0251\n",
      "Epoch [261/360], Batch [100/196], Loss: 0.0278\n",
      "Epoch [261/360], Batch [105/196], Loss: 0.0272\n",
      "Epoch [261/360], Batch [110/196], Loss: 0.0406\n",
      "Epoch [261/360], Batch [115/196], Loss: 0.0222\n",
      "Epoch [261/360], Batch [120/196], Loss: 0.0314\n",
      "Epoch [261/360], Batch [125/196], Loss: 0.0279\n",
      "Epoch [261/360], Batch [130/196], Loss: 0.0242\n",
      "Epoch [261/360], Batch [135/196], Loss: 0.0294\n",
      "Epoch [261/360], Batch [140/196], Loss: 0.0307\n",
      "Epoch [261/360], Batch [145/196], Loss: 0.0431\n",
      "Epoch [261/360], Batch [150/196], Loss: 0.1276\n",
      "Epoch [261/360], Batch [155/196], Loss: 0.0340\n",
      "Epoch [261/360], Batch [160/196], Loss: 0.0313\n",
      "Epoch [261/360], Batch [165/196], Loss: 0.0777\n",
      "Epoch [261/360], Batch [170/196], Loss: 0.0399\n",
      "Epoch [261/360], Batch [175/196], Loss: 0.0387\n",
      "Epoch [261/360], Batch [180/196], Loss: 0.0521\n",
      "Epoch [261/360], Batch [185/196], Loss: 0.0399\n",
      "Epoch [261/360], Batch [190/196], Loss: 0.0313\n",
      "Epoch [261/360], Batch [195/196], Loss: 0.0282\n",
      "Epoch [262/360], Batch [5/196], Loss: 0.0201\n",
      "Epoch [262/360], Batch [10/196], Loss: 0.0172\n",
      "Epoch [262/360], Batch [15/196], Loss: 0.0221\n",
      "Epoch [262/360], Batch [20/196], Loss: 0.0209\n",
      "Epoch [262/360], Batch [25/196], Loss: 0.0348\n",
      "Epoch [262/360], Batch [30/196], Loss: 0.0190\n",
      "Epoch [262/360], Batch [35/196], Loss: 0.0190\n",
      "Epoch [262/360], Batch [40/196], Loss: 0.0202\n",
      "Epoch [262/360], Batch [45/196], Loss: 0.0231\n",
      "Epoch [262/360], Batch [50/196], Loss: 0.0205\n",
      "Epoch [262/360], Batch [55/196], Loss: 0.0293\n",
      "Epoch [262/360], Batch [60/196], Loss: 0.0276\n",
      "Epoch [262/360], Batch [65/196], Loss: 0.0213\n",
      "Epoch [262/360], Batch [70/196], Loss: 0.0202\n",
      "Epoch [262/360], Batch [75/196], Loss: 0.0162\n",
      "Epoch [262/360], Batch [80/196], Loss: 0.0299\n",
      "Epoch [262/360], Batch [85/196], Loss: 0.0165\n",
      "Epoch [262/360], Batch [90/196], Loss: 0.0246\n",
      "Epoch [262/360], Batch [95/196], Loss: 0.0161\n",
      "Epoch [262/360], Batch [100/196], Loss: 0.0163\n",
      "Epoch [262/360], Batch [105/196], Loss: 0.0197\n",
      "Epoch [262/360], Batch [110/196], Loss: 0.0106\n",
      "Epoch [262/360], Batch [115/196], Loss: 0.0173\n",
      "Epoch [262/360], Batch [120/196], Loss: 0.0249\n",
      "Epoch [262/360], Batch [125/196], Loss: 0.0265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [262/360], Batch [130/196], Loss: 0.0154\n",
      "Epoch [262/360], Batch [135/196], Loss: 0.0160\n",
      "Epoch [262/360], Batch [140/196], Loss: 0.0197\n",
      "Epoch [262/360], Batch [145/196], Loss: 0.0223\n",
      "Epoch [262/360], Batch [150/196], Loss: 0.0293\n",
      "Epoch [262/360], Batch [155/196], Loss: 0.0238\n",
      "Epoch [262/360], Batch [160/196], Loss: 0.0185\n",
      "Epoch [262/360], Batch [165/196], Loss: 0.0219\n",
      "Epoch [262/360], Batch [170/196], Loss: 0.0295\n",
      "Epoch [262/360], Batch [175/196], Loss: 0.0135\n",
      "Epoch [262/360], Batch [180/196], Loss: 0.0147\n",
      "Epoch [262/360], Batch [185/196], Loss: 0.0187\n",
      "Epoch [262/360], Batch [190/196], Loss: 0.0197\n",
      "Epoch [262/360], Batch [195/196], Loss: 0.0216\n",
      "Epoch [263/360], Batch [5/196], Loss: 0.0163\n",
      "Epoch [263/360], Batch [10/196], Loss: 0.0147\n",
      "Epoch [263/360], Batch [15/196], Loss: 0.0188\n",
      "Epoch [263/360], Batch [20/196], Loss: 0.0179\n",
      "Epoch [263/360], Batch [25/196], Loss: 0.0167\n",
      "Epoch [263/360], Batch [30/196], Loss: 0.0165\n",
      "Epoch [263/360], Batch [35/196], Loss: 0.0116\n",
      "Epoch [263/360], Batch [40/196], Loss: 0.0133\n",
      "Epoch [263/360], Batch [45/196], Loss: 0.0125\n",
      "Epoch [263/360], Batch [50/196], Loss: 0.0113\n",
      "Epoch [263/360], Batch [55/196], Loss: 0.0098\n",
      "Epoch [263/360], Batch [60/196], Loss: 0.0066\n",
      "Epoch [263/360], Batch [65/196], Loss: 0.0219\n",
      "Epoch [263/360], Batch [70/196], Loss: 0.0120\n",
      "Epoch [263/360], Batch [75/196], Loss: 0.0158\n",
      "Epoch [263/360], Batch [80/196], Loss: 0.0234\n",
      "Epoch [263/360], Batch [85/196], Loss: 0.0150\n",
      "Epoch [263/360], Batch [90/196], Loss: 0.0214\n",
      "Epoch [263/360], Batch [95/196], Loss: 0.0612\n",
      "Epoch [263/360], Batch [100/196], Loss: 0.1352\n",
      "Epoch [263/360], Batch [105/196], Loss: 0.2272\n",
      "Epoch [263/360], Batch [110/196], Loss: 0.3212\n",
      "Epoch [263/360], Batch [115/196], Loss: 0.2682\n",
      "Epoch [263/360], Batch [120/196], Loss: 0.2430\n",
      "Epoch [263/360], Batch [125/196], Loss: 0.2177\n",
      "Epoch [263/360], Batch [130/196], Loss: 0.1763\n",
      "Epoch [263/360], Batch [135/196], Loss: 0.2142\n",
      "Epoch [263/360], Batch [140/196], Loss: 0.2133\n",
      "Epoch [263/360], Batch [145/196], Loss: 0.3055\n",
      "Epoch [263/360], Batch [150/196], Loss: 0.2578\n",
      "Epoch [263/360], Batch [155/196], Loss: 0.1126\n",
      "Epoch [263/360], Batch [160/196], Loss: 0.1455\n",
      "Epoch [263/360], Batch [165/196], Loss: 0.1036\n",
      "Epoch [263/360], Batch [170/196], Loss: 0.1384\n",
      "Epoch [263/360], Batch [175/196], Loss: 0.1423\n",
      "Epoch [263/360], Batch [180/196], Loss: 0.1311\n",
      "Epoch [263/360], Batch [185/196], Loss: 0.1496\n",
      "Epoch [263/360], Batch [190/196], Loss: 0.1474\n",
      "Epoch [263/360], Batch [195/196], Loss: 0.0945\n",
      "Epoch [264/360], Batch [5/196], Loss: 0.0963\n",
      "Epoch [264/360], Batch [10/196], Loss: 0.0732\n",
      "Epoch [264/360], Batch [15/196], Loss: 0.0774\n",
      "Epoch [264/360], Batch [20/196], Loss: 0.1104\n",
      "Epoch [264/360], Batch [25/196], Loss: 0.0867\n",
      "Epoch [264/360], Batch [30/196], Loss: 0.0983\n",
      "Epoch [264/360], Batch [35/196], Loss: 0.1013\n",
      "Epoch [264/360], Batch [40/196], Loss: 0.0778\n",
      "Epoch [264/360], Batch [45/196], Loss: 0.0504\n",
      "Epoch [264/360], Batch [50/196], Loss: 0.0652\n",
      "Epoch [264/360], Batch [55/196], Loss: 0.0710\n",
      "Epoch [264/360], Batch [60/196], Loss: 0.0460\n",
      "Epoch [264/360], Batch [65/196], Loss: 0.1074\n",
      "Epoch [264/360], Batch [70/196], Loss: 0.0583\n",
      "Epoch [264/360], Batch [75/196], Loss: 0.0759\n",
      "Epoch [264/360], Batch [80/196], Loss: 0.0824\n",
      "Epoch [264/360], Batch [85/196], Loss: 0.0678\n",
      "Epoch [264/360], Batch [90/196], Loss: 0.0828\n",
      "Epoch [264/360], Batch [95/196], Loss: 0.0858\n",
      "Epoch [264/360], Batch [100/196], Loss: 0.0542\n",
      "Epoch [264/360], Batch [105/196], Loss: 0.0627\n",
      "Epoch [264/360], Batch [110/196], Loss: 0.0676\n",
      "Epoch [264/360], Batch [115/196], Loss: 0.0596\n",
      "Epoch [264/360], Batch [120/196], Loss: 0.0824\n",
      "Epoch [264/360], Batch [125/196], Loss: 0.0542\n",
      "Epoch [264/360], Batch [130/196], Loss: 0.0772\n",
      "Epoch [264/360], Batch [135/196], Loss: 0.0390\n",
      "Epoch [264/360], Batch [140/196], Loss: 0.0552\n",
      "Epoch [264/360], Batch [145/196], Loss: 0.0450\n",
      "Epoch [264/360], Batch [150/196], Loss: 0.0409\n",
      "Epoch [264/360], Batch [155/196], Loss: 0.0602\n",
      "Epoch [264/360], Batch [160/196], Loss: 0.0457\n",
      "Epoch [264/360], Batch [165/196], Loss: 0.0483\n",
      "Epoch [264/360], Batch [170/196], Loss: 0.0413\n",
      "Epoch [264/360], Batch [175/196], Loss: 0.0647\n",
      "Epoch [264/360], Batch [180/196], Loss: 0.0583\n",
      "Epoch [264/360], Batch [185/196], Loss: 0.0468\n",
      "Epoch [264/360], Batch [190/196], Loss: 0.0896\n",
      "Epoch [264/360], Batch [195/196], Loss: 0.0460\n",
      "Epoch [265/360], Batch [5/196], Loss: 0.0420\n",
      "Epoch [265/360], Batch [10/196], Loss: 0.0392\n",
      "Epoch [265/360], Batch [15/196], Loss: 0.0430\n",
      "Epoch [265/360], Batch [20/196], Loss: 0.0428\n",
      "Epoch [265/360], Batch [25/196], Loss: 0.0625\n",
      "Epoch [265/360], Batch [30/196], Loss: 0.0282\n",
      "Epoch [265/360], Batch [35/196], Loss: 0.0312\n",
      "Epoch [265/360], Batch [40/196], Loss: 0.0416\n",
      "Epoch [265/360], Batch [45/196], Loss: 0.0270\n",
      "Epoch [265/360], Batch [50/196], Loss: 0.0181\n",
      "Epoch [265/360], Batch [55/196], Loss: 0.0210\n",
      "Epoch [265/360], Batch [60/196], Loss: 0.0310\n",
      "Epoch [265/360], Batch [65/196], Loss: 0.0295\n",
      "Epoch [265/360], Batch [70/196], Loss: 0.0220\n",
      "Epoch [265/360], Batch [75/196], Loss: 0.0455\n",
      "Epoch [265/360], Batch [80/196], Loss: 0.0253\n",
      "Epoch [265/360], Batch [85/196], Loss: 0.0234\n",
      "Epoch [265/360], Batch [90/196], Loss: 0.0221\n",
      "Epoch [265/360], Batch [95/196], Loss: 0.0238\n",
      "Epoch [265/360], Batch [100/196], Loss: 0.0186\n",
      "Epoch [265/360], Batch [105/196], Loss: 0.0404\n",
      "Epoch [265/360], Batch [110/196], Loss: 0.0263\n",
      "Epoch [265/360], Batch [115/196], Loss: 0.0277\n",
      "Epoch [265/360], Batch [120/196], Loss: 0.0333\n",
      "Epoch [265/360], Batch [125/196], Loss: 0.0302\n",
      "Epoch [265/360], Batch [130/196], Loss: 0.0264\n",
      "Epoch [265/360], Batch [135/196], Loss: 0.0248\n",
      "Epoch [265/360], Batch [140/196], Loss: 0.0274\n",
      "Epoch [265/360], Batch [145/196], Loss: 0.0293\n",
      "Epoch [265/360], Batch [150/196], Loss: 0.0249\n",
      "Epoch [265/360], Batch [155/196], Loss: 0.0226\n",
      "Epoch [265/360], Batch [160/196], Loss: 0.0329\n",
      "Epoch [265/360], Batch [165/196], Loss: 0.0206\n",
      "Epoch [265/360], Batch [170/196], Loss: 0.0206\n",
      "Epoch [265/360], Batch [175/196], Loss: 0.0197\n",
      "Epoch [265/360], Batch [180/196], Loss: 0.0227\n",
      "Epoch [265/360], Batch [185/196], Loss: 0.0307\n",
      "Epoch [265/360], Batch [190/196], Loss: 0.0223\n",
      "Epoch [265/360], Batch [195/196], Loss: 0.0237\n",
      "Epoch [266/360], Batch [5/196], Loss: 0.0113\n",
      "Epoch [266/360], Batch [10/196], Loss: 0.0207\n",
      "Epoch [266/360], Batch [15/196], Loss: 0.0203\n",
      "Epoch [266/360], Batch [20/196], Loss: 0.0201\n",
      "Epoch [266/360], Batch [25/196], Loss: 0.0154\n",
      "Epoch [266/360], Batch [30/196], Loss: 0.0201\n",
      "Epoch [266/360], Batch [35/196], Loss: 0.0117\n",
      "Epoch [266/360], Batch [40/196], Loss: 0.0154\n",
      "Epoch [266/360], Batch [45/196], Loss: 0.0171\n",
      "Epoch [266/360], Batch [50/196], Loss: 0.0570\n",
      "Epoch [266/360], Batch [55/196], Loss: 0.0103\n",
      "Epoch [266/360], Batch [60/196], Loss: 0.0163\n",
      "Epoch [266/360], Batch [65/196], Loss: 0.0198\n",
      "Epoch [266/360], Batch [70/196], Loss: 0.0153\n",
      "Epoch [266/360], Batch [75/196], Loss: 0.0149\n",
      "Epoch [266/360], Batch [80/196], Loss: 0.0153\n",
      "Epoch [266/360], Batch [85/196], Loss: 0.0153\n",
      "Epoch [266/360], Batch [90/196], Loss: 0.0120\n",
      "Epoch [266/360], Batch [95/196], Loss: 0.0096\n",
      "Epoch [266/360], Batch [100/196], Loss: 0.0115\n",
      "Epoch [266/360], Batch [105/196], Loss: 0.0117\n",
      "Epoch [266/360], Batch [110/196], Loss: 0.0157\n",
      "Epoch [266/360], Batch [115/196], Loss: 0.0170\n",
      "Epoch [266/360], Batch [120/196], Loss: 0.0141\n",
      "Epoch [266/360], Batch [125/196], Loss: 0.0126\n",
      "Epoch [266/360], Batch [130/196], Loss: 0.0184\n",
      "Epoch [266/360], Batch [135/196], Loss: 0.0162\n",
      "Epoch [266/360], Batch [140/196], Loss: 0.0128\n",
      "Epoch [266/360], Batch [145/196], Loss: 0.0145\n",
      "Epoch [266/360], Batch [150/196], Loss: 0.0106\n",
      "Epoch [266/360], Batch [155/196], Loss: 0.0148\n",
      "Epoch [266/360], Batch [160/196], Loss: 0.0120\n",
      "Epoch [266/360], Batch [165/196], Loss: 0.0134\n",
      "Epoch [266/360], Batch [170/196], Loss: 0.0131\n",
      "Epoch [266/360], Batch [175/196], Loss: 0.0130\n",
      "Epoch [266/360], Batch [180/196], Loss: 0.0161\n",
      "Epoch [266/360], Batch [185/196], Loss: 0.0111\n",
      "Epoch [266/360], Batch [190/196], Loss: 0.0186\n",
      "Epoch [266/360], Batch [195/196], Loss: 0.0115\n",
      "Epoch [267/360], Batch [5/196], Loss: 0.0092\n",
      "Epoch [267/360], Batch [10/196], Loss: 0.0099\n",
      "Epoch [267/360], Batch [15/196], Loss: 0.0104\n",
      "Epoch [267/360], Batch [20/196], Loss: 0.0084\n",
      "Epoch [267/360], Batch [25/196], Loss: 0.0086\n",
      "Epoch [267/360], Batch [30/196], Loss: 0.0091\n",
      "Epoch [267/360], Batch [35/196], Loss: 0.0131\n",
      "Epoch [267/360], Batch [40/196], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [267/360], Batch [45/196], Loss: 0.0089\n",
      "Epoch [267/360], Batch [50/196], Loss: 0.0106\n",
      "Epoch [267/360], Batch [55/196], Loss: 0.0130\n",
      "Epoch [267/360], Batch [60/196], Loss: 0.0098\n",
      "Epoch [267/360], Batch [65/196], Loss: 0.0128\n",
      "Epoch [267/360], Batch [70/196], Loss: 0.0142\n",
      "Epoch [267/360], Batch [75/196], Loss: 0.0096\n",
      "Epoch [267/360], Batch [80/196], Loss: 0.0123\n",
      "Epoch [267/360], Batch [85/196], Loss: 0.0081\n",
      "Epoch [267/360], Batch [90/196], Loss: 0.0075\n",
      "Epoch [267/360], Batch [95/196], Loss: 0.0093\n",
      "Epoch [267/360], Batch [100/196], Loss: 0.0102\n",
      "Epoch [267/360], Batch [105/196], Loss: 0.0103\n",
      "Epoch [267/360], Batch [110/196], Loss: 0.0130\n",
      "Epoch [267/360], Batch [115/196], Loss: 0.0180\n",
      "Epoch [267/360], Batch [120/196], Loss: 0.0091\n",
      "Epoch [267/360], Batch [125/196], Loss: 0.0089\n",
      "Epoch [267/360], Batch [130/196], Loss: 0.0085\n",
      "Epoch [267/360], Batch [135/196], Loss: 0.0114\n",
      "Epoch [267/360], Batch [140/196], Loss: 0.0077\n",
      "Epoch [267/360], Batch [145/196], Loss: 0.0113\n",
      "Epoch [267/360], Batch [150/196], Loss: 0.0101\n",
      "Epoch [267/360], Batch [155/196], Loss: 0.0085\n",
      "Epoch [267/360], Batch [160/196], Loss: 0.0084\n",
      "Epoch [267/360], Batch [165/196], Loss: 0.0095\n",
      "Epoch [267/360], Batch [170/196], Loss: 0.0101\n",
      "Epoch [267/360], Batch [175/196], Loss: 0.0088\n",
      "Epoch [267/360], Batch [180/196], Loss: 0.0073\n",
      "Epoch [267/360], Batch [185/196], Loss: 0.0121\n",
      "Epoch [267/360], Batch [190/196], Loss: 0.0121\n",
      "Epoch [267/360], Batch [195/196], Loss: 0.0093\n",
      "Epoch [268/360], Batch [5/196], Loss: 0.0048\n",
      "Epoch [268/360], Batch [10/196], Loss: 0.0058\n",
      "Epoch [268/360], Batch [15/196], Loss: 0.0086\n",
      "Epoch [268/360], Batch [20/196], Loss: 0.0084\n",
      "Epoch [268/360], Batch [25/196], Loss: 0.0065\n",
      "Epoch [268/360], Batch [30/196], Loss: 0.0049\n",
      "Epoch [268/360], Batch [35/196], Loss: 0.0077\n",
      "Epoch [268/360], Batch [40/196], Loss: 0.0071\n",
      "Epoch [268/360], Batch [45/196], Loss: 0.0086\n",
      "Epoch [268/360], Batch [50/196], Loss: 0.0065\n",
      "Epoch [268/360], Batch [55/196], Loss: 0.0061\n",
      "Epoch [268/360], Batch [60/196], Loss: 0.0059\n",
      "Epoch [268/360], Batch [65/196], Loss: 0.0089\n",
      "Epoch [268/360], Batch [70/196], Loss: 0.0053\n",
      "Epoch [268/360], Batch [75/196], Loss: 0.0082\n",
      "Epoch [268/360], Batch [80/196], Loss: 0.0047\n",
      "Epoch [268/360], Batch [85/196], Loss: 0.0078\n",
      "Epoch [268/360], Batch [90/196], Loss: 0.0061\n",
      "Epoch [268/360], Batch [95/196], Loss: 0.0078\n",
      "Epoch [268/360], Batch [100/196], Loss: 0.0063\n",
      "Epoch [268/360], Batch [105/196], Loss: 0.0075\n",
      "Epoch [268/360], Batch [110/196], Loss: 0.0078\n",
      "Epoch [268/360], Batch [115/196], Loss: 0.0074\n",
      "Epoch [268/360], Batch [120/196], Loss: 0.0065\n",
      "Epoch [268/360], Batch [125/196], Loss: 0.0063\n",
      "Epoch [268/360], Batch [130/196], Loss: 0.0104\n",
      "Epoch [268/360], Batch [135/196], Loss: 0.0056\n",
      "Epoch [268/360], Batch [140/196], Loss: 0.0050\n",
      "Epoch [268/360], Batch [145/196], Loss: 0.0063\n",
      "Epoch [268/360], Batch [150/196], Loss: 0.0083\n",
      "Epoch [268/360], Batch [155/196], Loss: 0.0065\n",
      "Epoch [268/360], Batch [160/196], Loss: 0.0073\n",
      "Epoch [268/360], Batch [165/196], Loss: 0.0053\n",
      "Epoch [268/360], Batch [170/196], Loss: 0.0083\n",
      "Epoch [268/360], Batch [175/196], Loss: 0.0079\n",
      "Epoch [268/360], Batch [180/196], Loss: 0.0078\n",
      "Epoch [268/360], Batch [185/196], Loss: 0.0044\n",
      "Epoch [268/360], Batch [190/196], Loss: 0.0089\n",
      "Epoch [268/360], Batch [195/196], Loss: 0.0089\n",
      "Epoch [269/360], Batch [5/196], Loss: 0.0052\n",
      "Epoch [269/360], Batch [10/196], Loss: 0.0054\n",
      "Epoch [269/360], Batch [15/196], Loss: 0.0055\n",
      "Epoch [269/360], Batch [20/196], Loss: 0.0040\n",
      "Epoch [269/360], Batch [25/196], Loss: 0.0064\n",
      "Epoch [269/360], Batch [30/196], Loss: 0.0057\n",
      "Epoch [269/360], Batch [35/196], Loss: 0.0046\n",
      "Epoch [269/360], Batch [40/196], Loss: 0.0063\n",
      "Epoch [269/360], Batch [45/196], Loss: 0.0063\n",
      "Epoch [269/360], Batch [50/196], Loss: 0.0070\n",
      "Epoch [269/360], Batch [55/196], Loss: 0.0052\n",
      "Epoch [269/360], Batch [60/196], Loss: 0.0037\n",
      "Epoch [269/360], Batch [65/196], Loss: 0.0057\n",
      "Epoch [269/360], Batch [70/196], Loss: 0.0080\n",
      "Epoch [269/360], Batch [75/196], Loss: 0.0076\n",
      "Epoch [269/360], Batch [80/196], Loss: 0.0052\n",
      "Epoch [269/360], Batch [85/196], Loss: 0.0048\n",
      "Epoch [269/360], Batch [90/196], Loss: 0.0066\n",
      "Epoch [269/360], Batch [95/196], Loss: 0.0072\n",
      "Epoch [269/360], Batch [100/196], Loss: 0.0064\n",
      "Epoch [269/360], Batch [105/196], Loss: 0.0071\n",
      "Epoch [269/360], Batch [110/196], Loss: 0.0059\n",
      "Epoch [269/360], Batch [115/196], Loss: 0.0074\n",
      "Epoch [269/360], Batch [120/196], Loss: 0.0049\n",
      "Epoch [269/360], Batch [125/196], Loss: 0.0054\n",
      "Epoch [269/360], Batch [130/196], Loss: 0.0065\n",
      "Epoch [269/360], Batch [135/196], Loss: 0.0058\n",
      "Epoch [269/360], Batch [140/196], Loss: 0.0051\n",
      "Epoch [269/360], Batch [145/196], Loss: 0.0061\n",
      "Epoch [269/360], Batch [150/196], Loss: 0.0065\n",
      "Epoch [269/360], Batch [155/196], Loss: 0.0061\n",
      "Epoch [269/360], Batch [160/196], Loss: 0.0057\n",
      "Epoch [269/360], Batch [165/196], Loss: 0.0061\n",
      "Epoch [269/360], Batch [170/196], Loss: 0.0077\n",
      "Epoch [269/360], Batch [175/196], Loss: 0.0055\n",
      "Epoch [269/360], Batch [180/196], Loss: 0.0062\n",
      "Epoch [269/360], Batch [185/196], Loss: 0.0066\n",
      "Epoch [269/360], Batch [190/196], Loss: 0.0068\n",
      "Epoch [269/360], Batch [195/196], Loss: 0.0063\n",
      "Epoch [270/360], Batch [5/196], Loss: 0.0038\n",
      "Epoch [270/360], Batch [10/196], Loss: 0.0037\n",
      "Epoch [270/360], Batch [15/196], Loss: 0.0050\n",
      "Epoch [270/360], Batch [20/196], Loss: 0.0048\n",
      "Epoch [270/360], Batch [25/196], Loss: 0.0053\n",
      "Epoch [270/360], Batch [30/196], Loss: 0.0039\n",
      "Epoch [270/360], Batch [35/196], Loss: 0.0058\n",
      "Epoch [270/360], Batch [40/196], Loss: 0.0041\n",
      "Epoch [270/360], Batch [45/196], Loss: 0.0047\n",
      "Epoch [270/360], Batch [50/196], Loss: 0.0064\n",
      "Epoch [270/360], Batch [55/196], Loss: 0.0069\n",
      "Epoch [270/360], Batch [60/196], Loss: 0.0050\n",
      "Epoch [270/360], Batch [65/196], Loss: 0.0060\n",
      "Epoch [270/360], Batch [70/196], Loss: 0.0046\n",
      "Epoch [270/360], Batch [75/196], Loss: 0.0042\n",
      "Epoch [270/360], Batch [80/196], Loss: 0.0080\n",
      "Epoch [270/360], Batch [85/196], Loss: 0.0066\n",
      "Epoch [270/360], Batch [90/196], Loss: 0.0046\n",
      "Epoch [270/360], Batch [95/196], Loss: 0.0085\n",
      "Epoch [270/360], Batch [100/196], Loss: 0.0055\n",
      "Epoch [270/360], Batch [105/196], Loss: 0.0028\n",
      "Epoch [270/360], Batch [110/196], Loss: 0.0065\n",
      "Epoch [270/360], Batch [115/196], Loss: 0.0101\n",
      "Epoch [270/360], Batch [120/196], Loss: 0.0056\n",
      "Epoch [270/360], Batch [125/196], Loss: 0.0055\n",
      "Epoch [270/360], Batch [130/196], Loss: 0.0071\n",
      "Epoch [270/360], Batch [135/196], Loss: 0.0062\n",
      "Epoch [270/360], Batch [140/196], Loss: 0.0086\n",
      "Epoch [270/360], Batch [145/196], Loss: 0.0066\n",
      "Epoch [270/360], Batch [150/196], Loss: 0.0057\n",
      "Epoch [270/360], Batch [155/196], Loss: 0.0084\n",
      "Epoch [270/360], Batch [160/196], Loss: 0.0055\n",
      "Epoch [270/360], Batch [165/196], Loss: 0.0055\n",
      "Epoch [270/360], Batch [170/196], Loss: 0.0081\n",
      "Epoch [270/360], Batch [175/196], Loss: 0.0063\n",
      "Epoch [270/360], Batch [180/196], Loss: 0.0056\n",
      "Epoch [270/360], Batch [185/196], Loss: 0.0094\n",
      "Epoch [270/360], Batch [190/196], Loss: 0.0062\n",
      "Epoch [270/360], Batch [195/196], Loss: 0.0059\n",
      "Epoch [271/360], Batch [5/196], Loss: 0.0066\n",
      "Epoch [271/360], Batch [10/196], Loss: 0.0056\n",
      "Epoch [271/360], Batch [15/196], Loss: 0.0043\n",
      "Epoch [271/360], Batch [20/196], Loss: 0.0084\n",
      "Epoch [271/360], Batch [25/196], Loss: 0.0060\n",
      "Epoch [271/360], Batch [30/196], Loss: 0.0087\n",
      "Epoch [271/360], Batch [35/196], Loss: 0.0083\n",
      "Epoch [271/360], Batch [40/196], Loss: 0.0173\n",
      "Epoch [271/360], Batch [45/196], Loss: 0.0074\n",
      "Epoch [271/360], Batch [50/196], Loss: 0.0077\n",
      "Epoch [271/360], Batch [55/196], Loss: 0.0140\n",
      "Epoch [271/360], Batch [60/196], Loss: 0.0141\n",
      "Epoch [271/360], Batch [65/196], Loss: 0.0290\n",
      "Epoch [271/360], Batch [70/196], Loss: 0.0454\n",
      "Epoch [271/360], Batch [75/196], Loss: 0.0246\n",
      "Epoch [271/360], Batch [80/196], Loss: 0.0259\n",
      "Epoch [271/360], Batch [85/196], Loss: 0.0324\n",
      "Epoch [271/360], Batch [90/196], Loss: 0.0230\n",
      "Epoch [271/360], Batch [95/196], Loss: 0.0367\n",
      "Epoch [271/360], Batch [100/196], Loss: 0.0228\n",
      "Epoch [271/360], Batch [105/196], Loss: 0.0290\n",
      "Epoch [271/360], Batch [110/196], Loss: 0.0188\n",
      "Epoch [271/360], Batch [115/196], Loss: 0.0568\n",
      "Epoch [271/360], Batch [120/196], Loss: 0.0413\n",
      "Epoch [271/360], Batch [125/196], Loss: 0.0246\n",
      "Epoch [271/360], Batch [130/196], Loss: 0.0196\n",
      "Epoch [271/360], Batch [135/196], Loss: 0.0293\n",
      "Epoch [271/360], Batch [140/196], Loss: 0.0241\n",
      "Epoch [271/360], Batch [145/196], Loss: 0.0246\n",
      "Epoch [271/360], Batch [150/196], Loss: 0.0229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [271/360], Batch [155/196], Loss: 0.0352\n",
      "Epoch [271/360], Batch [160/196], Loss: 0.0268\n",
      "Epoch [271/360], Batch [165/196], Loss: 0.0293\n",
      "Epoch [271/360], Batch [170/196], Loss: 0.0196\n",
      "Epoch [271/360], Batch [175/196], Loss: 0.0324\n",
      "Epoch [271/360], Batch [180/196], Loss: 0.0419\n",
      "Epoch [271/360], Batch [185/196], Loss: 0.0317\n",
      "Epoch [271/360], Batch [190/196], Loss: 0.0255\n",
      "Epoch [271/360], Batch [195/196], Loss: 0.0323\n",
      "Epoch [272/360], Batch [5/196], Loss: 0.0230\n",
      "Epoch [272/360], Batch [10/196], Loss: 0.0228\n",
      "Epoch [272/360], Batch [15/196], Loss: 0.0362\n",
      "Epoch [272/360], Batch [20/196], Loss: 0.0224\n",
      "Epoch [272/360], Batch [25/196], Loss: 0.0216\n",
      "Epoch [272/360], Batch [30/196], Loss: 0.0400\n",
      "Epoch [272/360], Batch [35/196], Loss: 0.0404\n",
      "Epoch [272/360], Batch [40/196], Loss: 0.0252\n",
      "Epoch [272/360], Batch [45/196], Loss: 0.0424\n",
      "Epoch [272/360], Batch [50/196], Loss: 0.0334\n",
      "Epoch [272/360], Batch [55/196], Loss: 0.0304\n",
      "Epoch [272/360], Batch [60/196], Loss: 0.0215\n",
      "Epoch [272/360], Batch [65/196], Loss: 0.0297\n",
      "Epoch [272/360], Batch [70/196], Loss: 0.0242\n",
      "Epoch [272/360], Batch [75/196], Loss: 0.0204\n",
      "Epoch [272/360], Batch [80/196], Loss: 0.0281\n",
      "Epoch [272/360], Batch [85/196], Loss: 0.0314\n",
      "Epoch [272/360], Batch [90/196], Loss: 0.0255\n",
      "Epoch [272/360], Batch [95/196], Loss: 0.0244\n",
      "Epoch [272/360], Batch [100/196], Loss: 0.0195\n",
      "Epoch [272/360], Batch [105/196], Loss: 0.0243\n",
      "Epoch [272/360], Batch [110/196], Loss: 0.0159\n",
      "Epoch [272/360], Batch [115/196], Loss: 0.0275\n",
      "Epoch [272/360], Batch [120/196], Loss: 0.0411\n",
      "Epoch [272/360], Batch [125/196], Loss: 0.0446\n",
      "Epoch [272/360], Batch [130/196], Loss: 0.0427\n",
      "Epoch [272/360], Batch [135/196], Loss: 0.0519\n",
      "Epoch [272/360], Batch [140/196], Loss: 0.0250\n",
      "Epoch [272/360], Batch [145/196], Loss: 0.0344\n",
      "Epoch [272/360], Batch [150/196], Loss: 0.0257\n",
      "Epoch [272/360], Batch [155/196], Loss: 0.0448\n",
      "Epoch [272/360], Batch [160/196], Loss: 0.0215\n",
      "Epoch [272/360], Batch [165/196], Loss: 0.0193\n",
      "Epoch [272/360], Batch [170/196], Loss: 0.0176\n",
      "Epoch [272/360], Batch [175/196], Loss: 0.0264\n",
      "Epoch [272/360], Batch [180/196], Loss: 0.0307\n",
      "Epoch [272/360], Batch [185/196], Loss: 0.0622\n",
      "Epoch [272/360], Batch [190/196], Loss: 0.1032\n",
      "Epoch [272/360], Batch [195/196], Loss: 0.0827\n",
      "Epoch [273/360], Batch [5/196], Loss: 0.0449\n",
      "Epoch [273/360], Batch [10/196], Loss: 0.0567\n",
      "Epoch [273/360], Batch [15/196], Loss: 0.0491\n",
      "Epoch [273/360], Batch [20/196], Loss: 0.0694\n",
      "Epoch [273/360], Batch [25/196], Loss: 0.0352\n",
      "Epoch [273/360], Batch [30/196], Loss: 0.0721\n",
      "Epoch [273/360], Batch [35/196], Loss: 0.0520\n",
      "Epoch [273/360], Batch [40/196], Loss: 0.0526\n",
      "Epoch [273/360], Batch [45/196], Loss: 0.0655\n",
      "Epoch [273/360], Batch [50/196], Loss: 0.0611\n",
      "Epoch [273/360], Batch [55/196], Loss: 0.0475\n",
      "Epoch [273/360], Batch [60/196], Loss: 0.0756\n",
      "Epoch [273/360], Batch [65/196], Loss: 0.0403\n",
      "Epoch [273/360], Batch [70/196], Loss: 0.0449\n",
      "Epoch [273/360], Batch [75/196], Loss: 0.0616\n",
      "Epoch [273/360], Batch [80/196], Loss: 0.0418\n",
      "Epoch [273/360], Batch [85/196], Loss: 0.0776\n",
      "Epoch [273/360], Batch [90/196], Loss: 0.0722\n",
      "Epoch [273/360], Batch [95/196], Loss: 0.0648\n",
      "Epoch [273/360], Batch [100/196], Loss: 0.0649\n",
      "Epoch [273/360], Batch [105/196], Loss: 0.0506\n",
      "Epoch [273/360], Batch [110/196], Loss: 0.0456\n",
      "Epoch [273/360], Batch [115/196], Loss: 0.0620\n",
      "Epoch [273/360], Batch [120/196], Loss: 0.0414\n",
      "Epoch [273/360], Batch [125/196], Loss: 0.0368\n",
      "Epoch [273/360], Batch [130/196], Loss: 0.0571\n",
      "Epoch [273/360], Batch [135/196], Loss: 0.0364\n",
      "Epoch [273/360], Batch [140/196], Loss: 0.0341\n",
      "Epoch [273/360], Batch [145/196], Loss: 0.0352\n",
      "Epoch [273/360], Batch [150/196], Loss: 0.0457\n",
      "Epoch [273/360], Batch [155/196], Loss: 0.0464\n",
      "Epoch [273/360], Batch [160/196], Loss: 0.0513\n",
      "Epoch [273/360], Batch [165/196], Loss: 0.0384\n",
      "Epoch [273/360], Batch [170/196], Loss: 0.0408\n",
      "Epoch [273/360], Batch [175/196], Loss: 0.0678\n",
      "Epoch [273/360], Batch [180/196], Loss: 0.0322\n",
      "Epoch [273/360], Batch [185/196], Loss: 0.0261\n",
      "Epoch [273/360], Batch [190/196], Loss: 0.0359\n",
      "Epoch [273/360], Batch [195/196], Loss: 0.0541\n",
      "Epoch [274/360], Batch [5/196], Loss: 0.0559\n",
      "Epoch [274/360], Batch [10/196], Loss: 0.0665\n",
      "Epoch [274/360], Batch [15/196], Loss: 0.0333\n",
      "Epoch [274/360], Batch [20/196], Loss: 0.0275\n",
      "Epoch [274/360], Batch [25/196], Loss: 0.0339\n",
      "Epoch [274/360], Batch [30/196], Loss: 0.0323\n",
      "Epoch [274/360], Batch [35/196], Loss: 0.0503\n",
      "Epoch [274/360], Batch [40/196], Loss: 0.0299\n",
      "Epoch [274/360], Batch [45/196], Loss: 0.0359\n",
      "Epoch [274/360], Batch [50/196], Loss: 0.0212\n",
      "Epoch [274/360], Batch [55/196], Loss: 0.0367\n",
      "Epoch [274/360], Batch [60/196], Loss: 0.0240\n",
      "Epoch [274/360], Batch [65/196], Loss: 0.0759\n",
      "Epoch [274/360], Batch [70/196], Loss: 0.0903\n",
      "Epoch [274/360], Batch [75/196], Loss: 0.0937\n",
      "Epoch [274/360], Batch [80/196], Loss: 0.0545\n",
      "Epoch [274/360], Batch [85/196], Loss: 0.0531\n",
      "Epoch [274/360], Batch [90/196], Loss: 0.0428\n",
      "Epoch [274/360], Batch [95/196], Loss: 0.0365\n",
      "Epoch [274/360], Batch [100/196], Loss: 0.0557\n",
      "Epoch [274/360], Batch [105/196], Loss: 0.0429\n",
      "Epoch [274/360], Batch [110/196], Loss: 0.0332\n",
      "Epoch [274/360], Batch [115/196], Loss: 0.0417\n",
      "Epoch [274/360], Batch [120/196], Loss: 0.0393\n",
      "Epoch [274/360], Batch [125/196], Loss: 0.0441\n",
      "Epoch [274/360], Batch [130/196], Loss: 0.0554\n",
      "Epoch [274/360], Batch [135/196], Loss: 0.0296\n",
      "Epoch [274/360], Batch [140/196], Loss: 0.0421\n",
      "Epoch [274/360], Batch [145/196], Loss: 0.0299\n",
      "Epoch [274/360], Batch [150/196], Loss: 0.0665\n",
      "Epoch [274/360], Batch [155/196], Loss: 0.0341\n",
      "Epoch [274/360], Batch [160/196], Loss: 0.0459\n",
      "Epoch [274/360], Batch [165/196], Loss: 0.0424\n",
      "Epoch [274/360], Batch [170/196], Loss: 0.0473\n",
      "Epoch [274/360], Batch [175/196], Loss: 0.0479\n",
      "Epoch [274/360], Batch [180/196], Loss: 0.0328\n",
      "Epoch [274/360], Batch [185/196], Loss: 0.0287\n",
      "Epoch [274/360], Batch [190/196], Loss: 0.0308\n",
      "Epoch [274/360], Batch [195/196], Loss: 0.0268\n",
      "Epoch [275/360], Batch [5/196], Loss: 0.0263\n",
      "Epoch [275/360], Batch [10/196], Loss: 0.0258\n",
      "Epoch [275/360], Batch [15/196], Loss: 0.0781\n",
      "Epoch [275/360], Batch [20/196], Loss: 0.0408\n",
      "Epoch [275/360], Batch [25/196], Loss: 0.0423\n",
      "Epoch [275/360], Batch [30/196], Loss: 0.0191\n",
      "Epoch [275/360], Batch [35/196], Loss: 0.0240\n",
      "Epoch [275/360], Batch [40/196], Loss: 0.0439\n",
      "Epoch [275/360], Batch [45/196], Loss: 0.0301\n",
      "Epoch [275/360], Batch [50/196], Loss: 0.0382\n",
      "Epoch [275/360], Batch [55/196], Loss: 0.0254\n",
      "Epoch [275/360], Batch [60/196], Loss: 0.0244\n",
      "Epoch [275/360], Batch [65/196], Loss: 0.0332\n",
      "Epoch [275/360], Batch [70/196], Loss: 0.0283\n",
      "Epoch [275/360], Batch [75/196], Loss: 0.0221\n",
      "Epoch [275/360], Batch [80/196], Loss: 0.0240\n",
      "Epoch [275/360], Batch [85/196], Loss: 0.0357\n",
      "Epoch [275/360], Batch [90/196], Loss: 0.0157\n",
      "Epoch [275/360], Batch [95/196], Loss: 0.0309\n",
      "Epoch [275/360], Batch [100/196], Loss: 0.0238\n",
      "Epoch [275/360], Batch [105/196], Loss: 0.0326\n",
      "Epoch [275/360], Batch [110/196], Loss: 0.0336\n",
      "Epoch [275/360], Batch [115/196], Loss: 0.0137\n",
      "Epoch [275/360], Batch [120/196], Loss: 0.0269\n",
      "Epoch [275/360], Batch [125/196], Loss: 0.0190\n",
      "Epoch [275/360], Batch [130/196], Loss: 0.0190\n",
      "Epoch [275/360], Batch [135/196], Loss: 0.0309\n",
      "Epoch [275/360], Batch [140/196], Loss: 0.0301\n",
      "Epoch [275/360], Batch [145/196], Loss: 0.0305\n",
      "Epoch [275/360], Batch [150/196], Loss: 0.0320\n",
      "Epoch [275/360], Batch [155/196], Loss: 0.0230\n",
      "Epoch [275/360], Batch [160/196], Loss: 0.0330\n",
      "Epoch [275/360], Batch [165/196], Loss: 0.0203\n",
      "Epoch [275/360], Batch [170/196], Loss: 0.0156\n",
      "Epoch [275/360], Batch [175/196], Loss: 0.0228\n",
      "Epoch [275/360], Batch [180/196], Loss: 0.0169\n",
      "Epoch [275/360], Batch [185/196], Loss: 0.0147\n",
      "Epoch [275/360], Batch [190/196], Loss: 0.0297\n",
      "Epoch [275/360], Batch [195/196], Loss: 0.0287\n",
      "Epoch [276/360], Batch [5/196], Loss: 0.0226\n",
      "Epoch [276/360], Batch [10/196], Loss: 0.0356\n",
      "Epoch [276/360], Batch [15/196], Loss: 0.0142\n",
      "Epoch [276/360], Batch [20/196], Loss: 0.0143\n",
      "Epoch [276/360], Batch [25/196], Loss: 0.0120\n",
      "Epoch [276/360], Batch [30/196], Loss: 0.0104\n",
      "Epoch [276/360], Batch [35/196], Loss: 0.0119\n",
      "Epoch [276/360], Batch [40/196], Loss: 0.0209\n",
      "Epoch [276/360], Batch [45/196], Loss: 0.0181\n",
      "Epoch [276/360], Batch [50/196], Loss: 0.0160\n",
      "Epoch [276/360], Batch [55/196], Loss: 0.0238\n",
      "Epoch [276/360], Batch [60/196], Loss: 0.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [276/360], Batch [65/196], Loss: 0.0176\n",
      "Epoch [276/360], Batch [70/196], Loss: 0.0145\n",
      "Epoch [276/360], Batch [75/196], Loss: 0.0202\n",
      "Epoch [276/360], Batch [80/196], Loss: 0.0131\n",
      "Epoch [276/360], Batch [85/196], Loss: 0.0217\n",
      "Epoch [276/360], Batch [90/196], Loss: 0.0211\n",
      "Epoch [276/360], Batch [95/196], Loss: 0.0243\n",
      "Epoch [276/360], Batch [100/196], Loss: 0.0307\n",
      "Epoch [276/360], Batch [105/196], Loss: 0.0121\n",
      "Epoch [276/360], Batch [110/196], Loss: 0.0095\n",
      "Epoch [276/360], Batch [115/196], Loss: 0.0130\n",
      "Epoch [276/360], Batch [120/196], Loss: 0.0211\n",
      "Epoch [276/360], Batch [125/196], Loss: 0.0106\n",
      "Epoch [276/360], Batch [130/196], Loss: 0.0152\n",
      "Epoch [276/360], Batch [135/196], Loss: 0.0229\n",
      "Epoch [276/360], Batch [140/196], Loss: 0.0165\n",
      "Epoch [276/360], Batch [145/196], Loss: 0.0092\n",
      "Epoch [276/360], Batch [150/196], Loss: 0.0139\n",
      "Epoch [276/360], Batch [155/196], Loss: 0.0081\n",
      "Epoch [276/360], Batch [160/196], Loss: 0.0160\n",
      "Epoch [276/360], Batch [165/196], Loss: 0.0225\n",
      "Epoch [276/360], Batch [170/196], Loss: 0.0156\n",
      "Epoch [276/360], Batch [175/196], Loss: 0.0288\n",
      "Epoch [276/360], Batch [180/196], Loss: 0.0213\n",
      "Epoch [276/360], Batch [185/196], Loss: 0.0149\n",
      "Epoch [276/360], Batch [190/196], Loss: 0.0177\n",
      "Epoch [276/360], Batch [195/196], Loss: 0.0139\n",
      "Epoch [277/360], Batch [5/196], Loss: 0.0153\n",
      "Epoch [277/360], Batch [10/196], Loss: 0.0077\n",
      "Epoch [277/360], Batch [15/196], Loss: 0.0134\n",
      "Epoch [277/360], Batch [20/196], Loss: 0.0101\n",
      "Epoch [277/360], Batch [25/196], Loss: 0.0128\n",
      "Epoch [277/360], Batch [30/196], Loss: 0.0069\n",
      "Epoch [277/360], Batch [35/196], Loss: 0.0092\n",
      "Epoch [277/360], Batch [40/196], Loss: 0.0149\n",
      "Epoch [277/360], Batch [45/196], Loss: 0.0166\n",
      "Epoch [277/360], Batch [50/196], Loss: 0.0157\n",
      "Epoch [277/360], Batch [55/196], Loss: 0.0097\n",
      "Epoch [277/360], Batch [60/196], Loss: 0.0103\n",
      "Epoch [277/360], Batch [65/196], Loss: 0.0082\n",
      "Epoch [277/360], Batch [70/196], Loss: 0.0134\n",
      "Epoch [277/360], Batch [75/196], Loss: 0.0127\n",
      "Epoch [277/360], Batch [80/196], Loss: 0.0084\n",
      "Epoch [277/360], Batch [85/196], Loss: 0.0106\n",
      "Epoch [277/360], Batch [90/196], Loss: 0.0191\n",
      "Epoch [277/360], Batch [95/196], Loss: 0.0099\n",
      "Epoch [277/360], Batch [100/196], Loss: 0.0118\n",
      "Epoch [277/360], Batch [105/196], Loss: 0.0093\n",
      "Epoch [277/360], Batch [110/196], Loss: 0.0093\n",
      "Epoch [277/360], Batch [115/196], Loss: 0.0161\n",
      "Epoch [277/360], Batch [120/196], Loss: 0.0122\n",
      "Epoch [277/360], Batch [125/196], Loss: 0.0085\n",
      "Epoch [277/360], Batch [130/196], Loss: 0.0138\n",
      "Epoch [277/360], Batch [135/196], Loss: 0.0069\n",
      "Epoch [277/360], Batch [140/196], Loss: 0.0097\n",
      "Epoch [277/360], Batch [145/196], Loss: 0.0083\n",
      "Epoch [277/360], Batch [150/196], Loss: 0.0084\n",
      "Epoch [277/360], Batch [155/196], Loss: 0.0077\n",
      "Epoch [277/360], Batch [160/196], Loss: 0.0079\n",
      "Epoch [277/360], Batch [165/196], Loss: 0.0129\n",
      "Epoch [277/360], Batch [170/196], Loss: 0.0074\n",
      "Epoch [277/360], Batch [175/196], Loss: 0.0150\n",
      "Epoch [277/360], Batch [180/196], Loss: 0.0529\n",
      "Epoch [277/360], Batch [185/196], Loss: 0.0123\n",
      "Epoch [277/360], Batch [190/196], Loss: 0.0183\n",
      "Epoch [277/360], Batch [195/196], Loss: 0.0167\n",
      "Epoch [278/360], Batch [5/196], Loss: 0.0090\n",
      "Epoch [278/360], Batch [10/196], Loss: 0.0091\n",
      "Epoch [278/360], Batch [15/196], Loss: 0.0145\n",
      "Epoch [278/360], Batch [20/196], Loss: 0.0130\n",
      "Epoch [278/360], Batch [25/196], Loss: 0.0272\n",
      "Epoch [278/360], Batch [30/196], Loss: 0.0095\n",
      "Epoch [278/360], Batch [35/196], Loss: 0.0091\n",
      "Epoch [278/360], Batch [40/196], Loss: 0.0058\n",
      "Epoch [278/360], Batch [45/196], Loss: 0.0074\n",
      "Epoch [278/360], Batch [50/196], Loss: 0.0095\n",
      "Epoch [278/360], Batch [55/196], Loss: 0.0087\n",
      "Epoch [278/360], Batch [60/196], Loss: 0.0068\n",
      "Epoch [278/360], Batch [65/196], Loss: 0.0077\n",
      "Epoch [278/360], Batch [70/196], Loss: 0.0099\n",
      "Epoch [278/360], Batch [75/196], Loss: 0.0068\n",
      "Epoch [278/360], Batch [80/196], Loss: 0.0071\n",
      "Epoch [278/360], Batch [85/196], Loss: 0.0169\n",
      "Epoch [278/360], Batch [90/196], Loss: 0.0105\n",
      "Epoch [278/360], Batch [95/196], Loss: 0.0087\n",
      "Epoch [278/360], Batch [100/196], Loss: 0.0063\n",
      "Epoch [278/360], Batch [105/196], Loss: 0.0102\n",
      "Epoch [278/360], Batch [110/196], Loss: 0.0054\n",
      "Epoch [278/360], Batch [115/196], Loss: 0.0077\n",
      "Epoch [278/360], Batch [120/196], Loss: 0.0067\n",
      "Epoch [278/360], Batch [125/196], Loss: 0.0116\n",
      "Epoch [278/360], Batch [130/196], Loss: 0.0083\n",
      "Epoch [278/360], Batch [135/196], Loss: 0.0105\n",
      "Epoch [278/360], Batch [140/196], Loss: 0.0042\n",
      "Epoch [278/360], Batch [145/196], Loss: 0.0117\n",
      "Epoch [278/360], Batch [150/196], Loss: 0.0127\n",
      "Epoch [278/360], Batch [155/196], Loss: 0.0055\n",
      "Epoch [278/360], Batch [160/196], Loss: 0.0080\n",
      "Epoch [278/360], Batch [165/196], Loss: 0.0082\n",
      "Epoch [278/360], Batch [170/196], Loss: 0.0094\n",
      "Epoch [278/360], Batch [175/196], Loss: 0.0087\n",
      "Epoch [278/360], Batch [180/196], Loss: 0.0085\n",
      "Epoch [278/360], Batch [185/196], Loss: 0.0080\n",
      "Epoch [278/360], Batch [190/196], Loss: 0.0089\n",
      "Epoch [278/360], Batch [195/196], Loss: 0.0084\n",
      "Epoch [279/360], Batch [5/196], Loss: 0.0080\n",
      "Epoch [279/360], Batch [10/196], Loss: 0.0075\n",
      "Epoch [279/360], Batch [15/196], Loss: 0.0084\n",
      "Epoch [279/360], Batch [20/196], Loss: 0.0063\n",
      "Epoch [279/360], Batch [25/196], Loss: 0.0094\n",
      "Epoch [279/360], Batch [30/196], Loss: 0.0075\n",
      "Epoch [279/360], Batch [35/196], Loss: 0.0102\n",
      "Epoch [279/360], Batch [40/196], Loss: 0.0061\n",
      "Epoch [279/360], Batch [45/196], Loss: 0.0068\n",
      "Epoch [279/360], Batch [50/196], Loss: 0.0084\n",
      "Epoch [279/360], Batch [55/196], Loss: 0.0087\n",
      "Epoch [279/360], Batch [60/196], Loss: 0.0165\n",
      "Epoch [279/360], Batch [65/196], Loss: 0.0066\n",
      "Epoch [279/360], Batch [70/196], Loss: 0.0100\n",
      "Epoch [279/360], Batch [75/196], Loss: 0.0207\n",
      "Epoch [279/360], Batch [80/196], Loss: 0.0066\n",
      "Epoch [279/360], Batch [85/196], Loss: 0.0080\n",
      "Epoch [279/360], Batch [90/196], Loss: 0.0055\n",
      "Epoch [279/360], Batch [95/196], Loss: 0.0072\n",
      "Epoch [279/360], Batch [100/196], Loss: 0.0100\n",
      "Epoch [279/360], Batch [105/196], Loss: 0.0057\n",
      "Epoch [279/360], Batch [110/196], Loss: 0.0100\n",
      "Epoch [279/360], Batch [115/196], Loss: 0.0110\n",
      "Epoch [279/360], Batch [120/196], Loss: 0.0091\n",
      "Epoch [279/360], Batch [125/196], Loss: 0.0065\n",
      "Epoch [279/360], Batch [130/196], Loss: 0.0083\n",
      "Epoch [279/360], Batch [135/196], Loss: 0.0074\n",
      "Epoch [279/360], Batch [140/196], Loss: 0.0105\n",
      "Epoch [279/360], Batch [145/196], Loss: 0.0105\n",
      "Epoch [279/360], Batch [150/196], Loss: 0.0059\n",
      "Epoch [279/360], Batch [155/196], Loss: 0.0109\n",
      "Epoch [279/360], Batch [160/196], Loss: 0.0087\n",
      "Epoch [279/360], Batch [165/196], Loss: 0.0070\n",
      "Epoch [279/360], Batch [170/196], Loss: 0.0060\n",
      "Epoch [279/360], Batch [175/196], Loss: 0.0088\n",
      "Epoch [279/360], Batch [180/196], Loss: 0.0077\n",
      "Epoch [279/360], Batch [185/196], Loss: 0.0127\n",
      "Epoch [279/360], Batch [190/196], Loss: 0.0091\n",
      "Epoch [279/360], Batch [195/196], Loss: 0.0091\n",
      "Epoch [280/360], Batch [5/196], Loss: 0.0077\n",
      "Epoch [280/360], Batch [10/196], Loss: 0.0072\n",
      "Epoch [280/360], Batch [15/196], Loss: 0.0155\n",
      "Epoch [280/360], Batch [20/196], Loss: 0.0075\n",
      "Epoch [280/360], Batch [25/196], Loss: 0.0075\n",
      "Epoch [280/360], Batch [30/196], Loss: 0.0112\n",
      "Epoch [280/360], Batch [35/196], Loss: 0.0060\n",
      "Epoch [280/360], Batch [40/196], Loss: 0.0071\n",
      "Epoch [280/360], Batch [45/196], Loss: 0.0120\n",
      "Epoch [280/360], Batch [50/196], Loss: 0.0107\n",
      "Epoch [280/360], Batch [55/196], Loss: 0.0069\n",
      "Epoch [280/360], Batch [60/196], Loss: 0.0084\n",
      "Epoch [280/360], Batch [65/196], Loss: 0.0080\n",
      "Epoch [280/360], Batch [70/196], Loss: 0.0080\n",
      "Epoch [280/360], Batch [75/196], Loss: 0.0078\n",
      "Epoch [280/360], Batch [80/196], Loss: 0.0077\n",
      "Epoch [280/360], Batch [85/196], Loss: 0.0081\n",
      "Epoch [280/360], Batch [90/196], Loss: 0.0091\n",
      "Epoch [280/360], Batch [95/196], Loss: 0.0150\n",
      "Epoch [280/360], Batch [100/196], Loss: 0.0105\n",
      "Epoch [280/360], Batch [105/196], Loss: 0.0099\n",
      "Epoch [280/360], Batch [110/196], Loss: 0.0089\n",
      "Epoch [280/360], Batch [115/196], Loss: 0.0116\n",
      "Epoch [280/360], Batch [120/196], Loss: 0.0076\n",
      "Epoch [280/360], Batch [125/196], Loss: 0.0125\n",
      "Epoch [280/360], Batch [130/196], Loss: 0.0065\n",
      "Epoch [280/360], Batch [135/196], Loss: 0.0112\n",
      "Epoch [280/360], Batch [140/196], Loss: 0.0100\n",
      "Epoch [280/360], Batch [145/196], Loss: 0.0062\n",
      "Epoch [280/360], Batch [150/196], Loss: 0.0098\n",
      "Epoch [280/360], Batch [155/196], Loss: 0.0107\n",
      "Epoch [280/360], Batch [160/196], Loss: 0.0125\n",
      "Epoch [280/360], Batch [165/196], Loss: 0.0110\n",
      "Epoch [280/360], Batch [170/196], Loss: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [280/360], Batch [175/196], Loss: 0.0106\n",
      "Epoch [280/360], Batch [180/196], Loss: 0.0114\n",
      "Epoch [280/360], Batch [185/196], Loss: 0.0151\n",
      "Epoch [280/360], Batch [190/196], Loss: 0.0124\n",
      "Epoch [280/360], Batch [195/196], Loss: 0.0105\n",
      "Epoch [281/360], Batch [5/196], Loss: 0.0128\n",
      "Epoch [281/360], Batch [10/196], Loss: 0.0137\n",
      "Epoch [281/360], Batch [15/196], Loss: 0.0137\n",
      "Epoch [281/360], Batch [20/196], Loss: 0.0145\n",
      "Epoch [281/360], Batch [25/196], Loss: 0.0102\n",
      "Epoch [281/360], Batch [30/196], Loss: 0.0164\n",
      "Epoch [281/360], Batch [35/196], Loss: 0.0150\n",
      "Epoch [281/360], Batch [40/196], Loss: 0.0265\n",
      "Epoch [281/360], Batch [45/196], Loss: 0.0182\n",
      "Epoch [281/360], Batch [50/196], Loss: 0.0200\n",
      "Epoch [281/360], Batch [55/196], Loss: 0.0132\n",
      "Epoch [281/360], Batch [60/196], Loss: 0.0191\n",
      "Epoch [281/360], Batch [65/196], Loss: 0.0106\n",
      "Epoch [281/360], Batch [70/196], Loss: 0.0133\n",
      "Epoch [281/360], Batch [75/196], Loss: 0.0102\n",
      "Epoch [281/360], Batch [80/196], Loss: 0.0143\n",
      "Epoch [281/360], Batch [85/196], Loss: 0.0124\n",
      "Epoch [281/360], Batch [90/196], Loss: 0.0178\n",
      "Epoch [281/360], Batch [95/196], Loss: 0.0099\n",
      "Epoch [281/360], Batch [100/196], Loss: 0.0150\n",
      "Epoch [281/360], Batch [105/196], Loss: 0.0125\n",
      "Epoch [281/360], Batch [110/196], Loss: 0.0173\n",
      "Epoch [281/360], Batch [115/196], Loss: 0.0121\n",
      "Epoch [281/360], Batch [120/196], Loss: 0.0125\n",
      "Epoch [281/360], Batch [125/196], Loss: 0.0099\n",
      "Epoch [281/360], Batch [130/196], Loss: 0.0146\n",
      "Epoch [281/360], Batch [135/196], Loss: 0.0165\n",
      "Epoch [281/360], Batch [140/196], Loss: 0.0151\n",
      "Epoch [281/360], Batch [145/196], Loss: 0.0126\n",
      "Epoch [281/360], Batch [150/196], Loss: 0.0156\n",
      "Epoch [281/360], Batch [155/196], Loss: 0.0116\n",
      "Epoch [281/360], Batch [160/196], Loss: 0.0163\n",
      "Epoch [281/360], Batch [165/196], Loss: 0.0148\n",
      "Epoch [281/360], Batch [170/196], Loss: 0.0137\n",
      "Epoch [281/360], Batch [175/196], Loss: 0.0169\n",
      "Epoch [281/360], Batch [180/196], Loss: 0.0148\n",
      "Epoch [281/360], Batch [185/196], Loss: 0.0176\n",
      "Epoch [281/360], Batch [190/196], Loss: 0.0162\n",
      "Epoch [281/360], Batch [195/196], Loss: 0.0142\n",
      "Epoch [282/360], Batch [5/196], Loss: 0.0110\n",
      "Epoch [282/360], Batch [10/196], Loss: 0.0427\n",
      "Epoch [282/360], Batch [15/196], Loss: 0.0241\n",
      "Epoch [282/360], Batch [20/196], Loss: 0.0370\n",
      "Epoch [282/360], Batch [25/196], Loss: 0.0245\n",
      "Epoch [282/360], Batch [30/196], Loss: 0.0412\n",
      "Epoch [282/360], Batch [35/196], Loss: 0.0262\n",
      "Epoch [282/360], Batch [40/196], Loss: 0.0354\n",
      "Epoch [282/360], Batch [45/196], Loss: 0.0424\n",
      "Epoch [282/360], Batch [50/196], Loss: 0.0256\n",
      "Epoch [282/360], Batch [55/196], Loss: 0.0216\n",
      "Epoch [282/360], Batch [60/196], Loss: 0.0212\n",
      "Epoch [282/360], Batch [65/196], Loss: 0.0396\n",
      "Epoch [282/360], Batch [70/196], Loss: 0.0265\n",
      "Epoch [282/360], Batch [75/196], Loss: 0.0232\n",
      "Epoch [282/360], Batch [80/196], Loss: 0.0282\n",
      "Epoch [282/360], Batch [85/196], Loss: 0.0228\n",
      "Epoch [282/360], Batch [90/196], Loss: 0.0249\n",
      "Epoch [282/360], Batch [95/196], Loss: 0.0266\n",
      "Epoch [282/360], Batch [100/196], Loss: 0.0336\n",
      "Epoch [282/360], Batch [105/196], Loss: 0.0267\n",
      "Epoch [282/360], Batch [110/196], Loss: 0.0280\n",
      "Epoch [282/360], Batch [115/196], Loss: 0.0355\n",
      "Epoch [282/360], Batch [120/196], Loss: 0.0276\n",
      "Epoch [282/360], Batch [125/196], Loss: 0.0326\n",
      "Epoch [282/360], Batch [130/196], Loss: 0.0502\n",
      "Epoch [282/360], Batch [135/196], Loss: 0.0390\n",
      "Epoch [282/360], Batch [140/196], Loss: 0.0867\n",
      "Epoch [282/360], Batch [145/196], Loss: 0.1690\n",
      "Epoch [282/360], Batch [150/196], Loss: 0.1384\n",
      "Epoch [282/360], Batch [155/196], Loss: 0.1444\n",
      "Epoch [282/360], Batch [160/196], Loss: 0.1269\n",
      "Epoch [282/360], Batch [165/196], Loss: 0.0648\n",
      "Epoch [282/360], Batch [170/196], Loss: 0.0896\n",
      "Epoch [282/360], Batch [175/196], Loss: 0.0740\n",
      "Epoch [282/360], Batch [180/196], Loss: 0.0850\n",
      "Epoch [282/360], Batch [185/196], Loss: 0.0836\n",
      "Epoch [282/360], Batch [190/196], Loss: 0.0771\n",
      "Epoch [282/360], Batch [195/196], Loss: 0.0543\n",
      "Epoch [283/360], Batch [5/196], Loss: 0.0926\n",
      "Epoch [283/360], Batch [10/196], Loss: 0.0987\n",
      "Epoch [283/360], Batch [15/196], Loss: 0.1016\n",
      "Epoch [283/360], Batch [20/196], Loss: 0.0863\n",
      "Epoch [283/360], Batch [25/196], Loss: 0.1292\n",
      "Epoch [283/360], Batch [30/196], Loss: 0.0915\n",
      "Epoch [283/360], Batch [35/196], Loss: 0.1327\n",
      "Epoch [283/360], Batch [40/196], Loss: 0.0736\n",
      "Epoch [283/360], Batch [45/196], Loss: 0.0550\n",
      "Epoch [283/360], Batch [50/196], Loss: 0.1866\n",
      "Epoch [283/360], Batch [55/196], Loss: 0.0764\n",
      "Epoch [283/360], Batch [60/196], Loss: 0.1123\n",
      "Epoch [283/360], Batch [65/196], Loss: 0.0657\n",
      "Epoch [283/360], Batch [70/196], Loss: 0.0711\n",
      "Epoch [283/360], Batch [75/196], Loss: 0.0648\n",
      "Epoch [283/360], Batch [80/196], Loss: 0.1170\n",
      "Epoch [283/360], Batch [85/196], Loss: 0.0849\n",
      "Epoch [283/360], Batch [90/196], Loss: 0.0684\n",
      "Epoch [283/360], Batch [95/196], Loss: 0.0719\n",
      "Epoch [283/360], Batch [100/196], Loss: 0.0750\n",
      "Epoch [283/360], Batch [105/196], Loss: 0.1072\n",
      "Epoch [283/360], Batch [110/196], Loss: 0.0900\n",
      "Epoch [283/360], Batch [115/196], Loss: 0.0845\n",
      "Epoch [283/360], Batch [120/196], Loss: 0.0415\n",
      "Epoch [283/360], Batch [125/196], Loss: 0.0645\n",
      "Epoch [283/360], Batch [130/196], Loss: 0.0967\n",
      "Epoch [283/360], Batch [135/196], Loss: 0.0358\n",
      "Epoch [283/360], Batch [140/196], Loss: 0.0614\n",
      "Epoch [283/360], Batch [145/196], Loss: 0.0571\n",
      "Epoch [283/360], Batch [150/196], Loss: 0.0883\n",
      "Epoch [283/360], Batch [155/196], Loss: 0.0648\n",
      "Epoch [283/360], Batch [160/196], Loss: 0.0733\n",
      "Epoch [283/360], Batch [165/196], Loss: 0.0360\n",
      "Epoch [283/360], Batch [170/196], Loss: 0.0704\n",
      "Epoch [283/360], Batch [175/196], Loss: 0.0790\n",
      "Epoch [283/360], Batch [180/196], Loss: 0.0521\n",
      "Epoch [283/360], Batch [185/196], Loss: 0.0717\n",
      "Epoch [283/360], Batch [190/196], Loss: 0.0409\n",
      "Epoch [283/360], Batch [195/196], Loss: 0.0344\n",
      "Epoch [284/360], Batch [5/196], Loss: 0.0694\n",
      "Epoch [284/360], Batch [10/196], Loss: 0.0783\n",
      "Epoch [284/360], Batch [15/196], Loss: 0.0407\n",
      "Epoch [284/360], Batch [20/196], Loss: 0.0363\n",
      "Epoch [284/360], Batch [25/196], Loss: 0.0637\n",
      "Epoch [284/360], Batch [30/196], Loss: 0.0731\n",
      "Epoch [284/360], Batch [35/196], Loss: 0.0622\n",
      "Epoch [284/360], Batch [40/196], Loss: 0.0465\n",
      "Epoch [284/360], Batch [45/196], Loss: 0.0972\n",
      "Epoch [284/360], Batch [50/196], Loss: 0.0878\n",
      "Epoch [284/360], Batch [55/196], Loss: 0.0542\n",
      "Epoch [284/360], Batch [60/196], Loss: 0.0699\n",
      "Epoch [284/360], Batch [65/196], Loss: 0.0432\n",
      "Epoch [284/360], Batch [70/196], Loss: 0.0400\n",
      "Epoch [284/360], Batch [75/196], Loss: 0.0635\n",
      "Epoch [284/360], Batch [80/196], Loss: 0.0347\n",
      "Epoch [284/360], Batch [85/196], Loss: 0.0300\n",
      "Epoch [284/360], Batch [90/196], Loss: 0.0410\n",
      "Epoch [284/360], Batch [95/196], Loss: 0.0274\n",
      "Epoch [284/360], Batch [100/196], Loss: 0.0460\n",
      "Epoch [284/360], Batch [105/196], Loss: 0.0280\n",
      "Epoch [284/360], Batch [110/196], Loss: 0.0605\n",
      "Epoch [284/360], Batch [115/196], Loss: 0.0583\n",
      "Epoch [284/360], Batch [120/196], Loss: 0.0328\n",
      "Epoch [284/360], Batch [125/196], Loss: 0.0782\n",
      "Epoch [284/360], Batch [130/196], Loss: 0.0483\n",
      "Epoch [284/360], Batch [135/196], Loss: 0.0408\n",
      "Epoch [284/360], Batch [140/196], Loss: 0.0309\n",
      "Epoch [284/360], Batch [145/196], Loss: 0.0313\n",
      "Epoch [284/360], Batch [150/196], Loss: 0.0373\n",
      "Epoch [284/360], Batch [155/196], Loss: 0.1598\n",
      "Epoch [284/360], Batch [160/196], Loss: 0.0624\n",
      "Epoch [284/360], Batch [165/196], Loss: 0.0636\n",
      "Epoch [284/360], Batch [170/196], Loss: 0.0701\n",
      "Epoch [284/360], Batch [175/196], Loss: 0.0413\n",
      "Epoch [284/360], Batch [180/196], Loss: 0.0358\n",
      "Epoch [284/360], Batch [185/196], Loss: 0.0710\n",
      "Epoch [284/360], Batch [190/196], Loss: 0.0460\n",
      "Epoch [284/360], Batch [195/196], Loss: 0.0518\n",
      "Epoch [285/360], Batch [5/196], Loss: 0.0337\n",
      "Epoch [285/360], Batch [10/196], Loss: 0.0354\n",
      "Epoch [285/360], Batch [15/196], Loss: 0.0233\n",
      "Epoch [285/360], Batch [20/196], Loss: 0.0430\n",
      "Epoch [285/360], Batch [25/196], Loss: 0.0223\n",
      "Epoch [285/360], Batch [30/196], Loss: 0.0263\n",
      "Epoch [285/360], Batch [35/196], Loss: 0.0187\n",
      "Epoch [285/360], Batch [40/196], Loss: 0.0541\n",
      "Epoch [285/360], Batch [45/196], Loss: 0.0355\n",
      "Epoch [285/360], Batch [50/196], Loss: 0.0438\n",
      "Epoch [285/360], Batch [55/196], Loss: 0.0449\n",
      "Epoch [285/360], Batch [60/196], Loss: 0.0200\n",
      "Epoch [285/360], Batch [65/196], Loss: 0.0629\n",
      "Epoch [285/360], Batch [70/196], Loss: 0.0233\n",
      "Epoch [285/360], Batch [75/196], Loss: 0.0981\n",
      "Epoch [285/360], Batch [80/196], Loss: 0.0323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [285/360], Batch [85/196], Loss: 0.0260\n",
      "Epoch [285/360], Batch [90/196], Loss: 0.0313\n",
      "Epoch [285/360], Batch [95/196], Loss: 0.0330\n",
      "Epoch [285/360], Batch [100/196], Loss: 0.1007\n",
      "Epoch [285/360], Batch [105/196], Loss: 0.1450\n",
      "Epoch [285/360], Batch [110/196], Loss: 0.1414\n",
      "Epoch [285/360], Batch [115/196], Loss: 0.1487\n",
      "Epoch [285/360], Batch [120/196], Loss: 0.1619\n",
      "Epoch [285/360], Batch [125/196], Loss: 0.1005\n",
      "Epoch [285/360], Batch [130/196], Loss: 0.0927\n",
      "Epoch [285/360], Batch [135/196], Loss: 0.0680\n",
      "Epoch [285/360], Batch [140/196], Loss: 0.1042\n",
      "Epoch [285/360], Batch [145/196], Loss: 0.0757\n",
      "Epoch [285/360], Batch [150/196], Loss: 0.1175\n",
      "Epoch [285/360], Batch [155/196], Loss: 0.1110\n",
      "Epoch [285/360], Batch [160/196], Loss: 0.0517\n",
      "Epoch [285/360], Batch [165/196], Loss: 0.0812\n",
      "Epoch [285/360], Batch [170/196], Loss: 0.1257\n",
      "Epoch [285/360], Batch [175/196], Loss: 0.0925\n",
      "Epoch [285/360], Batch [180/196], Loss: 0.0954\n",
      "Epoch [285/360], Batch [185/196], Loss: 0.0662\n",
      "Epoch [285/360], Batch [190/196], Loss: 0.0593\n",
      "Epoch [285/360], Batch [195/196], Loss: 0.0706\n",
      "Epoch [286/360], Batch [5/196], Loss: 0.0567\n",
      "Epoch [286/360], Batch [10/196], Loss: 0.0407\n",
      "Epoch [286/360], Batch [15/196], Loss: 0.0666\n",
      "Epoch [286/360], Batch [20/196], Loss: 0.0515\n",
      "Epoch [286/360], Batch [25/196], Loss: 0.0416\n",
      "Epoch [286/360], Batch [30/196], Loss: 0.0334\n",
      "Epoch [286/360], Batch [35/196], Loss: 0.0503\n",
      "Epoch [286/360], Batch [40/196], Loss: 0.0475\n",
      "Epoch [286/360], Batch [45/196], Loss: 0.0372\n",
      "Epoch [286/360], Batch [50/196], Loss: 0.0579\n",
      "Epoch [286/360], Batch [55/196], Loss: 0.0359\n",
      "Epoch [286/360], Batch [60/196], Loss: 0.0646\n",
      "Epoch [286/360], Batch [65/196], Loss: 0.0445\n",
      "Epoch [286/360], Batch [70/196], Loss: 0.0503\n",
      "Epoch [286/360], Batch [75/196], Loss: 0.0259\n",
      "Epoch [286/360], Batch [80/196], Loss: 0.0442\n",
      "Epoch [286/360], Batch [85/196], Loss: 0.0316\n",
      "Epoch [286/360], Batch [90/196], Loss: 0.0232\n",
      "Epoch [286/360], Batch [95/196], Loss: 0.0477\n",
      "Epoch [286/360], Batch [100/196], Loss: 0.0355\n",
      "Epoch [286/360], Batch [105/196], Loss: 0.0706\n",
      "Epoch [286/360], Batch [110/196], Loss: 0.0412\n",
      "Epoch [286/360], Batch [115/196], Loss: 0.0335\n",
      "Epoch [286/360], Batch [120/196], Loss: 0.0478\n",
      "Epoch [286/360], Batch [125/196], Loss: 0.0404\n",
      "Epoch [286/360], Batch [130/196], Loss: 0.0547\n",
      "Epoch [286/360], Batch [135/196], Loss: 0.0256\n",
      "Epoch [286/360], Batch [140/196], Loss: 0.0436\n",
      "Epoch [286/360], Batch [145/196], Loss: 0.0493\n",
      "Epoch [286/360], Batch [150/196], Loss: 0.0402\n",
      "Epoch [286/360], Batch [155/196], Loss: 0.0520\n",
      "Epoch [286/360], Batch [160/196], Loss: 0.0360\n",
      "Epoch [286/360], Batch [165/196], Loss: 0.0339\n",
      "Epoch [286/360], Batch [170/196], Loss: 0.0540\n",
      "Epoch [286/360], Batch [175/196], Loss: 0.0418\n",
      "Epoch [286/360], Batch [180/196], Loss: 0.0270\n",
      "Epoch [286/360], Batch [185/196], Loss: 0.0377\n",
      "Epoch [286/360], Batch [190/196], Loss: 0.0241\n",
      "Epoch [286/360], Batch [195/196], Loss: 0.0234\n",
      "Epoch [287/360], Batch [5/196], Loss: 0.0136\n",
      "Epoch [287/360], Batch [10/196], Loss: 0.0143\n",
      "Epoch [287/360], Batch [15/196], Loss: 0.0547\n",
      "Epoch [287/360], Batch [20/196], Loss: 0.0177\n",
      "Epoch [287/360], Batch [25/196], Loss: 0.0240\n",
      "Epoch [287/360], Batch [30/196], Loss: 0.0169\n",
      "Epoch [287/360], Batch [35/196], Loss: 0.0241\n",
      "Epoch [287/360], Batch [40/196], Loss: 0.0172\n",
      "Epoch [287/360], Batch [45/196], Loss: 0.0197\n",
      "Epoch [287/360], Batch [50/196], Loss: 0.0159\n",
      "Epoch [287/360], Batch [55/196], Loss: 0.0589\n",
      "Epoch [287/360], Batch [60/196], Loss: 0.0214\n",
      "Epoch [287/360], Batch [65/196], Loss: 0.0283\n",
      "Epoch [287/360], Batch [70/196], Loss: 0.0206\n",
      "Epoch [287/360], Batch [75/196], Loss: 0.0252\n",
      "Epoch [287/360], Batch [80/196], Loss: 0.0142\n",
      "Epoch [287/360], Batch [85/196], Loss: 0.0235\n",
      "Epoch [287/360], Batch [90/196], Loss: 0.0205\n",
      "Epoch [287/360], Batch [95/196], Loss: 0.0142\n",
      "Epoch [287/360], Batch [100/196], Loss: 0.0241\n",
      "Epoch [287/360], Batch [105/196], Loss: 0.0460\n",
      "Epoch [287/360], Batch [110/196], Loss: 0.0487\n",
      "Epoch [287/360], Batch [115/196], Loss: 0.0424\n",
      "Epoch [287/360], Batch [120/196], Loss: 0.0730\n",
      "Epoch [287/360], Batch [125/196], Loss: 0.0361\n",
      "Epoch [287/360], Batch [130/196], Loss: 0.0384\n",
      "Epoch [287/360], Batch [135/196], Loss: 0.0391\n",
      "Epoch [287/360], Batch [140/196], Loss: 0.0455\n",
      "Epoch [287/360], Batch [145/196], Loss: 0.0413\n",
      "Epoch [287/360], Batch [150/196], Loss: 0.0498\n",
      "Epoch [287/360], Batch [155/196], Loss: 0.0282\n",
      "Epoch [287/360], Batch [160/196], Loss: 0.0376\n",
      "Epoch [287/360], Batch [165/196], Loss: 0.0293\n",
      "Epoch [287/360], Batch [170/196], Loss: 0.0188\n",
      "Epoch [287/360], Batch [175/196], Loss: 0.0485\n",
      "Epoch [287/360], Batch [180/196], Loss: 0.0218\n",
      "Epoch [287/360], Batch [185/196], Loss: 0.0272\n",
      "Epoch [287/360], Batch [190/196], Loss: 0.0251\n",
      "Epoch [287/360], Batch [195/196], Loss: 0.0285\n",
      "Epoch [288/360], Batch [5/196], Loss: 0.0316\n",
      "Epoch [288/360], Batch [10/196], Loss: 0.0213\n",
      "Epoch [288/360], Batch [15/196], Loss: 0.0218\n",
      "Epoch [288/360], Batch [20/196], Loss: 0.0246\n",
      "Epoch [288/360], Batch [25/196], Loss: 0.0114\n",
      "Epoch [288/360], Batch [30/196], Loss: 0.0715\n",
      "Epoch [288/360], Batch [35/196], Loss: 0.0253\n",
      "Epoch [288/360], Batch [40/196], Loss: 0.0142\n",
      "Epoch [288/360], Batch [45/196], Loss: 0.0285\n",
      "Epoch [288/360], Batch [50/196], Loss: 0.0126\n",
      "Epoch [288/360], Batch [55/196], Loss: 0.0164\n",
      "Epoch [288/360], Batch [60/196], Loss: 0.0178\n",
      "Epoch [288/360], Batch [65/196], Loss: 0.0262\n",
      "Epoch [288/360], Batch [70/196], Loss: 0.0152\n",
      "Epoch [288/360], Batch [75/196], Loss: 0.0174\n",
      "Epoch [288/360], Batch [80/196], Loss: 0.0162\n",
      "Epoch [288/360], Batch [85/196], Loss: 0.0153\n",
      "Epoch [288/360], Batch [90/196], Loss: 0.0136\n",
      "Epoch [288/360], Batch [95/196], Loss: 0.0248\n",
      "Epoch [288/360], Batch [100/196], Loss: 0.0200\n",
      "Epoch [288/360], Batch [105/196], Loss: 0.0277\n",
      "Epoch [288/360], Batch [110/196], Loss: 0.0206\n",
      "Epoch [288/360], Batch [115/196], Loss: 0.0182\n",
      "Epoch [288/360], Batch [120/196], Loss: 0.0204\n",
      "Epoch [288/360], Batch [125/196], Loss: 0.0193\n",
      "Epoch [288/360], Batch [130/196], Loss: 0.0184\n",
      "Epoch [288/360], Batch [135/196], Loss: 0.0268\n",
      "Epoch [288/360], Batch [140/196], Loss: 0.0139\n",
      "Epoch [288/360], Batch [145/196], Loss: 0.0101\n",
      "Epoch [288/360], Batch [150/196], Loss: 0.0181\n",
      "Epoch [288/360], Batch [155/196], Loss: 0.0204\n",
      "Epoch [288/360], Batch [160/196], Loss: 0.0247\n",
      "Epoch [288/360], Batch [165/196], Loss: 0.0137\n",
      "Epoch [288/360], Batch [170/196], Loss: 0.0176\n",
      "Epoch [288/360], Batch [175/196], Loss: 0.0170\n",
      "Epoch [288/360], Batch [180/196], Loss: 0.0114\n",
      "Epoch [288/360], Batch [185/196], Loss: 0.0118\n",
      "Epoch [288/360], Batch [190/196], Loss: 0.0222\n",
      "Epoch [288/360], Batch [195/196], Loss: 0.0234\n",
      "Epoch [289/360], Batch [5/196], Loss: 0.0144\n",
      "Epoch [289/360], Batch [10/196], Loss: 0.0140\n",
      "Epoch [289/360], Batch [15/196], Loss: 0.0167\n",
      "Epoch [289/360], Batch [20/196], Loss: 0.0122\n",
      "Epoch [289/360], Batch [25/196], Loss: 0.0146\n",
      "Epoch [289/360], Batch [30/196], Loss: 0.0082\n",
      "Epoch [289/360], Batch [35/196], Loss: 0.0119\n",
      "Epoch [289/360], Batch [40/196], Loss: 0.0105\n",
      "Epoch [289/360], Batch [45/196], Loss: 0.0152\n",
      "Epoch [289/360], Batch [50/196], Loss: 0.0154\n",
      "Epoch [289/360], Batch [55/196], Loss: 0.0127\n",
      "Epoch [289/360], Batch [60/196], Loss: 0.0152\n",
      "Epoch [289/360], Batch [65/196], Loss: 0.0103\n",
      "Epoch [289/360], Batch [70/196], Loss: 0.0096\n",
      "Epoch [289/360], Batch [75/196], Loss: 0.0085\n",
      "Epoch [289/360], Batch [80/196], Loss: 0.0085\n",
      "Epoch [289/360], Batch [85/196], Loss: 0.0126\n",
      "Epoch [289/360], Batch [90/196], Loss: 0.0106\n",
      "Epoch [289/360], Batch [95/196], Loss: 0.0064\n",
      "Epoch [289/360], Batch [100/196], Loss: 0.0145\n",
      "Epoch [289/360], Batch [105/196], Loss: 0.0075\n",
      "Epoch [289/360], Batch [110/196], Loss: 0.0137\n",
      "Epoch [289/360], Batch [115/196], Loss: 0.0115\n",
      "Epoch [289/360], Batch [120/196], Loss: 0.0084\n",
      "Epoch [289/360], Batch [125/196], Loss: 0.0338\n",
      "Epoch [289/360], Batch [130/196], Loss: 0.0101\n",
      "Epoch [289/360], Batch [135/196], Loss: 0.0114\n",
      "Epoch [289/360], Batch [140/196], Loss: 0.0117\n",
      "Epoch [289/360], Batch [145/196], Loss: 0.0108\n",
      "Epoch [289/360], Batch [150/196], Loss: 0.0130\n",
      "Epoch [289/360], Batch [155/196], Loss: 0.0082\n",
      "Epoch [289/360], Batch [160/196], Loss: 0.0128\n",
      "Epoch [289/360], Batch [165/196], Loss: 0.0085\n",
      "Epoch [289/360], Batch [170/196], Loss: 0.0103\n",
      "Epoch [289/360], Batch [175/196], Loss: 0.0131\n",
      "Epoch [289/360], Batch [180/196], Loss: 0.0092\n",
      "Epoch [289/360], Batch [185/196], Loss: 0.0118\n",
      "Epoch [289/360], Batch [190/196], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [289/360], Batch [195/196], Loss: 0.0115\n",
      "Epoch [290/360], Batch [5/196], Loss: 0.0065\n",
      "Epoch [290/360], Batch [10/196], Loss: 0.0172\n",
      "Epoch [290/360], Batch [15/196], Loss: 0.0056\n",
      "Epoch [290/360], Batch [20/196], Loss: 0.0103\n",
      "Epoch [290/360], Batch [25/196], Loss: 0.0111\n",
      "Epoch [290/360], Batch [30/196], Loss: 0.0056\n",
      "Epoch [290/360], Batch [35/196], Loss: 0.0075\n",
      "Epoch [290/360], Batch [40/196], Loss: 0.0056\n",
      "Epoch [290/360], Batch [45/196], Loss: 0.0089\n",
      "Epoch [290/360], Batch [50/196], Loss: 0.0064\n",
      "Epoch [290/360], Batch [55/196], Loss: 0.0048\n",
      "Epoch [290/360], Batch [60/196], Loss: 0.0075\n",
      "Epoch [290/360], Batch [65/196], Loss: 0.0070\n",
      "Epoch [290/360], Batch [70/196], Loss: 0.0074\n",
      "Epoch [290/360], Batch [75/196], Loss: 0.0074\n",
      "Epoch [290/360], Batch [80/196], Loss: 0.0045\n",
      "Epoch [290/360], Batch [85/196], Loss: 0.0066\n",
      "Epoch [290/360], Batch [90/196], Loss: 0.0070\n",
      "Epoch [290/360], Batch [95/196], Loss: 0.0057\n",
      "Epoch [290/360], Batch [100/196], Loss: 0.0129\n",
      "Epoch [290/360], Batch [105/196], Loss: 0.0054\n",
      "Epoch [290/360], Batch [110/196], Loss: 0.0062\n",
      "Epoch [290/360], Batch [115/196], Loss: 0.0074\n",
      "Epoch [290/360], Batch [120/196], Loss: 0.0053\n",
      "Epoch [290/360], Batch [125/196], Loss: 0.0056\n",
      "Epoch [290/360], Batch [130/196], Loss: 0.0117\n",
      "Epoch [290/360], Batch [135/196], Loss: 0.0070\n",
      "Epoch [290/360], Batch [140/196], Loss: 0.0058\n",
      "Epoch [290/360], Batch [145/196], Loss: 0.0064\n",
      "Epoch [290/360], Batch [150/196], Loss: 0.0050\n",
      "Epoch [290/360], Batch [155/196], Loss: 0.0101\n",
      "Epoch [290/360], Batch [160/196], Loss: 0.0087\n",
      "Epoch [290/360], Batch [165/196], Loss: 0.0072\n",
      "Epoch [290/360], Batch [170/196], Loss: 0.0072\n",
      "Epoch [290/360], Batch [175/196], Loss: 0.0081\n",
      "Epoch [290/360], Batch [180/196], Loss: 0.0082\n",
      "Epoch [290/360], Batch [185/196], Loss: 0.0042\n",
      "Epoch [290/360], Batch [190/196], Loss: 0.0068\n",
      "Epoch [290/360], Batch [195/196], Loss: 0.0080\n",
      "Epoch [291/360], Batch [5/196], Loss: 0.0078\n",
      "Epoch [291/360], Batch [10/196], Loss: 0.0074\n",
      "Epoch [291/360], Batch [15/196], Loss: 0.0090\n",
      "Epoch [291/360], Batch [20/196], Loss: 0.0062\n",
      "Epoch [291/360], Batch [25/196], Loss: 0.0090\n",
      "Epoch [291/360], Batch [30/196], Loss: 0.0068\n",
      "Epoch [291/360], Batch [35/196], Loss: 0.0052\n",
      "Epoch [291/360], Batch [40/196], Loss: 0.0038\n",
      "Epoch [291/360], Batch [45/196], Loss: 0.0056\n",
      "Epoch [291/360], Batch [50/196], Loss: 0.0064\n",
      "Epoch [291/360], Batch [55/196], Loss: 0.0062\n",
      "Epoch [291/360], Batch [60/196], Loss: 0.0068\n",
      "Epoch [291/360], Batch [65/196], Loss: 0.0043\n",
      "Epoch [291/360], Batch [70/196], Loss: 0.0057\n",
      "Epoch [291/360], Batch [75/196], Loss: 0.0048\n",
      "Epoch [291/360], Batch [80/196], Loss: 0.0052\n",
      "Epoch [291/360], Batch [85/196], Loss: 0.0065\n",
      "Epoch [291/360], Batch [90/196], Loss: 0.0056\n",
      "Epoch [291/360], Batch [95/196], Loss: 0.0042\n",
      "Epoch [291/360], Batch [100/196], Loss: 0.0081\n",
      "Epoch [291/360], Batch [105/196], Loss: 0.0100\n",
      "Epoch [291/360], Batch [110/196], Loss: 0.0105\n",
      "Epoch [291/360], Batch [115/196], Loss: 0.0054\n",
      "Epoch [291/360], Batch [120/196], Loss: 0.0127\n",
      "Epoch [291/360], Batch [125/196], Loss: 0.0077\n",
      "Epoch [291/360], Batch [130/196], Loss: 0.0071\n",
      "Epoch [291/360], Batch [135/196], Loss: 0.0089\n",
      "Epoch [291/360], Batch [140/196], Loss: 0.0101\n",
      "Epoch [291/360], Batch [145/196], Loss: 0.0059\n",
      "Epoch [291/360], Batch [150/196], Loss: 0.0069\n",
      "Epoch [291/360], Batch [155/196], Loss: 0.0063\n",
      "Epoch [291/360], Batch [160/196], Loss: 0.0070\n",
      "Epoch [291/360], Batch [165/196], Loss: 0.0051\n",
      "Epoch [291/360], Batch [170/196], Loss: 0.0064\n",
      "Epoch [291/360], Batch [175/196], Loss: 0.0085\n",
      "Epoch [291/360], Batch [180/196], Loss: 0.0080\n",
      "Epoch [291/360], Batch [185/196], Loss: 0.0049\n",
      "Epoch [291/360], Batch [190/196], Loss: 0.0073\n",
      "Epoch [291/360], Batch [195/196], Loss: 0.0099\n",
      "Epoch [292/360], Batch [5/196], Loss: 0.0058\n",
      "Epoch [292/360], Batch [10/196], Loss: 0.0060\n",
      "Epoch [292/360], Batch [15/196], Loss: 0.0061\n",
      "Epoch [292/360], Batch [20/196], Loss: 0.0057\n",
      "Epoch [292/360], Batch [25/196], Loss: 0.0066\n",
      "Epoch [292/360], Batch [30/196], Loss: 0.0060\n",
      "Epoch [292/360], Batch [35/196], Loss: 0.0054\n",
      "Epoch [292/360], Batch [40/196], Loss: 0.0060\n",
      "Epoch [292/360], Batch [45/196], Loss: 0.0030\n",
      "Epoch [292/360], Batch [50/196], Loss: 0.0080\n",
      "Epoch [292/360], Batch [55/196], Loss: 0.0068\n",
      "Epoch [292/360], Batch [60/196], Loss: 0.0055\n",
      "Epoch [292/360], Batch [65/196], Loss: 0.0079\n",
      "Epoch [292/360], Batch [70/196], Loss: 0.0070\n",
      "Epoch [292/360], Batch [75/196], Loss: 0.0067\n",
      "Epoch [292/360], Batch [80/196], Loss: 0.0047\n",
      "Epoch [292/360], Batch [85/196], Loss: 0.0115\n",
      "Epoch [292/360], Batch [90/196], Loss: 0.0078\n",
      "Epoch [292/360], Batch [95/196], Loss: 0.0083\n",
      "Epoch [292/360], Batch [100/196], Loss: 0.0044\n",
      "Epoch [292/360], Batch [105/196], Loss: 0.0045\n",
      "Epoch [292/360], Batch [110/196], Loss: 0.0078\n",
      "Epoch [292/360], Batch [115/196], Loss: 0.0035\n",
      "Epoch [292/360], Batch [120/196], Loss: 0.0070\n",
      "Epoch [292/360], Batch [125/196], Loss: 0.0066\n",
      "Epoch [292/360], Batch [130/196], Loss: 0.0038\n",
      "Epoch [292/360], Batch [135/196], Loss: 0.0067\n",
      "Epoch [292/360], Batch [140/196], Loss: 0.0052\n",
      "Epoch [292/360], Batch [145/196], Loss: 0.0056\n",
      "Epoch [292/360], Batch [150/196], Loss: 0.0072\n",
      "Epoch [292/360], Batch [155/196], Loss: 0.0034\n",
      "Epoch [292/360], Batch [160/196], Loss: 0.0047\n",
      "Epoch [292/360], Batch [165/196], Loss: 0.0069\n",
      "Epoch [292/360], Batch [170/196], Loss: 0.0060\n",
      "Epoch [292/360], Batch [175/196], Loss: 0.0076\n",
      "Epoch [292/360], Batch [180/196], Loss: 0.0052\n",
      "Epoch [292/360], Batch [185/196], Loss: 0.0062\n",
      "Epoch [292/360], Batch [190/196], Loss: 0.0043\n",
      "Epoch [292/360], Batch [195/196], Loss: 0.0070\n",
      "Epoch [293/360], Batch [5/196], Loss: 0.0043\n",
      "Epoch [293/360], Batch [10/196], Loss: 0.0082\n",
      "Epoch [293/360], Batch [15/196], Loss: 0.0056\n",
      "Epoch [293/360], Batch [20/196], Loss: 0.0057\n",
      "Epoch [293/360], Batch [25/196], Loss: 0.0064\n",
      "Epoch [293/360], Batch [30/196], Loss: 0.0043\n",
      "Epoch [293/360], Batch [35/196], Loss: 0.0050\n",
      "Epoch [293/360], Batch [40/196], Loss: 0.0069\n",
      "Epoch [293/360], Batch [45/196], Loss: 0.0048\n",
      "Epoch [293/360], Batch [50/196], Loss: 0.0082\n",
      "Epoch [293/360], Batch [55/196], Loss: 0.0059\n",
      "Epoch [293/360], Batch [60/196], Loss: 0.0074\n",
      "Epoch [293/360], Batch [65/196], Loss: 0.0126\n",
      "Epoch [293/360], Batch [70/196], Loss: 0.0102\n",
      "Epoch [293/360], Batch [75/196], Loss: 0.0073\n",
      "Epoch [293/360], Batch [80/196], Loss: 0.0065\n",
      "Epoch [293/360], Batch [85/196], Loss: 0.0045\n",
      "Epoch [293/360], Batch [90/196], Loss: 0.0066\n",
      "Epoch [293/360], Batch [95/196], Loss: 0.0093\n",
      "Epoch [293/360], Batch [100/196], Loss: 0.0059\n",
      "Epoch [293/360], Batch [105/196], Loss: 0.0066\n",
      "Epoch [293/360], Batch [110/196], Loss: 0.0084\n",
      "Epoch [293/360], Batch [115/196], Loss: 0.0052\n",
      "Epoch [293/360], Batch [120/196], Loss: 0.0056\n",
      "Epoch [293/360], Batch [125/196], Loss: 0.0066\n",
      "Epoch [293/360], Batch [130/196], Loss: 0.0078\n",
      "Epoch [293/360], Batch [135/196], Loss: 0.0056\n",
      "Epoch [293/360], Batch [140/196], Loss: 0.0063\n",
      "Epoch [293/360], Batch [145/196], Loss: 0.0076\n",
      "Epoch [293/360], Batch [150/196], Loss: 0.0042\n",
      "Epoch [293/360], Batch [155/196], Loss: 0.0092\n",
      "Epoch [293/360], Batch [160/196], Loss: 0.0114\n",
      "Epoch [293/360], Batch [165/196], Loss: 0.0082\n",
      "Epoch [293/360], Batch [170/196], Loss: 0.0073\n",
      "Epoch [293/360], Batch [175/196], Loss: 0.0125\n",
      "Epoch [293/360], Batch [180/196], Loss: 0.0061\n",
      "Epoch [293/360], Batch [185/196], Loss: 0.0099\n",
      "Epoch [293/360], Batch [190/196], Loss: 0.0044\n",
      "Epoch [293/360], Batch [195/196], Loss: 0.0087\n",
      "Epoch [294/360], Batch [5/196], Loss: 0.0075\n",
      "Epoch [294/360], Batch [10/196], Loss: 0.0064\n",
      "Epoch [294/360], Batch [15/196], Loss: 0.0058\n",
      "Epoch [294/360], Batch [20/196], Loss: 0.0131\n",
      "Epoch [294/360], Batch [25/196], Loss: 0.0191\n",
      "Epoch [294/360], Batch [30/196], Loss: 0.0796\n",
      "Epoch [294/360], Batch [35/196], Loss: 0.1240\n",
      "Epoch [294/360], Batch [40/196], Loss: 0.1088\n",
      "Epoch [294/360], Batch [45/196], Loss: 0.0579\n",
      "Epoch [294/360], Batch [50/196], Loss: 0.0536\n",
      "Epoch [294/360], Batch [55/196], Loss: 0.0770\n",
      "Epoch [294/360], Batch [60/196], Loss: 0.0572\n",
      "Epoch [294/360], Batch [65/196], Loss: 0.0864\n",
      "Epoch [294/360], Batch [70/196], Loss: 0.0576\n",
      "Epoch [294/360], Batch [75/196], Loss: 0.0597\n",
      "Epoch [294/360], Batch [80/196], Loss: 0.0398\n",
      "Epoch [294/360], Batch [85/196], Loss: 0.0582\n",
      "Epoch [294/360], Batch [90/196], Loss: 0.0822\n",
      "Epoch [294/360], Batch [95/196], Loss: 0.0980\n",
      "Epoch [294/360], Batch [100/196], Loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [294/360], Batch [105/196], Loss: 0.0819\n",
      "Epoch [294/360], Batch [110/196], Loss: 0.0748\n",
      "Epoch [294/360], Batch [115/196], Loss: 0.0823\n",
      "Epoch [294/360], Batch [120/196], Loss: 0.0744\n",
      "Epoch [294/360], Batch [125/196], Loss: 0.1026\n",
      "Epoch [294/360], Batch [130/196], Loss: 0.0890\n",
      "Epoch [294/360], Batch [135/196], Loss: 0.1166\n",
      "Epoch [294/360], Batch [140/196], Loss: 0.0845\n",
      "Epoch [294/360], Batch [145/196], Loss: 0.0629\n",
      "Epoch [294/360], Batch [150/196], Loss: 0.0713\n",
      "Epoch [294/360], Batch [155/196], Loss: 0.0565\n",
      "Epoch [294/360], Batch [160/196], Loss: 0.0836\n",
      "Epoch [294/360], Batch [165/196], Loss: 0.0910\n",
      "Epoch [294/360], Batch [170/196], Loss: 0.1126\n",
      "Epoch [294/360], Batch [175/196], Loss: 0.0417\n",
      "Epoch [294/360], Batch [180/196], Loss: 0.0702\n",
      "Epoch [294/360], Batch [185/196], Loss: 0.0615\n",
      "Epoch [294/360], Batch [190/196], Loss: 0.0821\n",
      "Epoch [294/360], Batch [195/196], Loss: 0.0975\n",
      "Epoch [295/360], Batch [5/196], Loss: 0.0529\n",
      "Epoch [295/360], Batch [10/196], Loss: 0.0865\n",
      "Epoch [295/360], Batch [15/196], Loss: 0.0725\n",
      "Epoch [295/360], Batch [20/196], Loss: 0.0524\n",
      "Epoch [295/360], Batch [25/196], Loss: 0.0516\n",
      "Epoch [295/360], Batch [30/196], Loss: 0.0374\n",
      "Epoch [295/360], Batch [35/196], Loss: 0.0861\n",
      "Epoch [295/360], Batch [40/196], Loss: 0.0545\n",
      "Epoch [295/360], Batch [45/196], Loss: 0.0729\n",
      "Epoch [295/360], Batch [50/196], Loss: 0.0959\n",
      "Epoch [295/360], Batch [55/196], Loss: 0.0350\n",
      "Epoch [295/360], Batch [60/196], Loss: 0.0764\n",
      "Epoch [295/360], Batch [65/196], Loss: 0.0586\n",
      "Epoch [295/360], Batch [70/196], Loss: 0.0536\n",
      "Epoch [295/360], Batch [75/196], Loss: 0.0790\n",
      "Epoch [295/360], Batch [80/196], Loss: 0.0424\n",
      "Epoch [295/360], Batch [85/196], Loss: 0.0529\n",
      "Epoch [295/360], Batch [90/196], Loss: 0.0556\n",
      "Epoch [295/360], Batch [95/196], Loss: 0.0745\n",
      "Epoch [295/360], Batch [100/196], Loss: 0.0459\n",
      "Epoch [295/360], Batch [105/196], Loss: 0.0788\n",
      "Epoch [295/360], Batch [110/196], Loss: 0.0655\n",
      "Epoch [295/360], Batch [115/196], Loss: 0.0431\n",
      "Epoch [295/360], Batch [120/196], Loss: 0.0561\n",
      "Epoch [295/360], Batch [125/196], Loss: 0.0685\n",
      "Epoch [295/360], Batch [130/196], Loss: 0.0898\n",
      "Epoch [295/360], Batch [135/196], Loss: 0.0645\n",
      "Epoch [295/360], Batch [140/196], Loss: 0.0929\n",
      "Epoch [295/360], Batch [145/196], Loss: 0.0446\n",
      "Epoch [295/360], Batch [150/196], Loss: 0.0397\n",
      "Epoch [295/360], Batch [155/196], Loss: 0.0719\n",
      "Epoch [295/360], Batch [160/196], Loss: 0.0655\n",
      "Epoch [295/360], Batch [165/196], Loss: 0.0569\n",
      "Epoch [295/360], Batch [170/196], Loss: 0.0800\n",
      "Epoch [295/360], Batch [175/196], Loss: 0.0590\n",
      "Epoch [295/360], Batch [180/196], Loss: 0.0330\n",
      "Epoch [295/360], Batch [185/196], Loss: 0.0578\n",
      "Epoch [295/360], Batch [190/196], Loss: 0.0620\n",
      "Epoch [295/360], Batch [195/196], Loss: 0.0706\n",
      "Epoch [296/360], Batch [5/196], Loss: 0.0398\n",
      "Epoch [296/360], Batch [10/196], Loss: 0.0277\n",
      "Epoch [296/360], Batch [15/196], Loss: 0.0269\n",
      "Epoch [296/360], Batch [20/196], Loss: 0.0318\n",
      "Epoch [296/360], Batch [25/196], Loss: 0.0336\n",
      "Epoch [296/360], Batch [30/196], Loss: 0.0448\n",
      "Epoch [296/360], Batch [35/196], Loss: 0.0302\n",
      "Epoch [296/360], Batch [40/196], Loss: 0.0287\n",
      "Epoch [296/360], Batch [45/196], Loss: 0.0532\n",
      "Epoch [296/360], Batch [50/196], Loss: 0.0340\n",
      "Epoch [296/360], Batch [55/196], Loss: 0.0352\n",
      "Epoch [296/360], Batch [60/196], Loss: 0.0229\n",
      "Epoch [296/360], Batch [65/196], Loss: 0.0343\n",
      "Epoch [296/360], Batch [70/196], Loss: 0.0225\n",
      "Epoch [296/360], Batch [75/196], Loss: 0.0175\n",
      "Epoch [296/360], Batch [80/196], Loss: 0.0327\n",
      "Epoch [296/360], Batch [85/196], Loss: 0.0368\n",
      "Epoch [296/360], Batch [90/196], Loss: 0.0358\n",
      "Epoch [296/360], Batch [95/196], Loss: 0.0286\n",
      "Epoch [296/360], Batch [100/196], Loss: 0.0301\n",
      "Epoch [296/360], Batch [105/196], Loss: 0.0164\n",
      "Epoch [296/360], Batch [110/196], Loss: 0.0416\n",
      "Epoch [296/360], Batch [115/196], Loss: 0.0264\n",
      "Epoch [296/360], Batch [120/196], Loss: 0.0264\n",
      "Epoch [296/360], Batch [125/196], Loss: 0.0410\n",
      "Epoch [296/360], Batch [130/196], Loss: 0.0332\n",
      "Epoch [296/360], Batch [135/196], Loss: 0.0212\n",
      "Epoch [296/360], Batch [140/196], Loss: 0.0253\n",
      "Epoch [296/360], Batch [145/196], Loss: 0.0303\n",
      "Epoch [296/360], Batch [150/196], Loss: 0.0344\n",
      "Epoch [296/360], Batch [155/196], Loss: 0.0175\n",
      "Epoch [296/360], Batch [160/196], Loss: 0.0278\n",
      "Epoch [296/360], Batch [165/196], Loss: 0.0310\n",
      "Epoch [296/360], Batch [170/196], Loss: 0.0200\n",
      "Epoch [296/360], Batch [175/196], Loss: 0.0316\n",
      "Epoch [296/360], Batch [180/196], Loss: 0.0325\n",
      "Epoch [296/360], Batch [185/196], Loss: 0.0225\n",
      "Epoch [296/360], Batch [190/196], Loss: 0.0351\n",
      "Epoch [296/360], Batch [195/196], Loss: 0.0361\n",
      "Epoch [297/360], Batch [5/196], Loss: 0.0365\n",
      "Epoch [297/360], Batch [10/196], Loss: 0.0258\n",
      "Epoch [297/360], Batch [15/196], Loss: 0.0167\n",
      "Epoch [297/360], Batch [20/196], Loss: 0.0268\n",
      "Epoch [297/360], Batch [25/196], Loss: 0.0493\n",
      "Epoch [297/360], Batch [30/196], Loss: 0.0186\n",
      "Epoch [297/360], Batch [35/196], Loss: 0.0186\n",
      "Epoch [297/360], Batch [40/196], Loss: 0.0145\n",
      "Epoch [297/360], Batch [45/196], Loss: 0.0337\n",
      "Epoch [297/360], Batch [50/196], Loss: 0.0227\n",
      "Epoch [297/360], Batch [55/196], Loss: 0.0227\n",
      "Epoch [297/360], Batch [60/196], Loss: 0.0159\n",
      "Epoch [297/360], Batch [65/196], Loss: 0.0210\n",
      "Epoch [297/360], Batch [70/196], Loss: 0.0156\n",
      "Epoch [297/360], Batch [75/196], Loss: 0.0133\n",
      "Epoch [297/360], Batch [80/196], Loss: 0.0219\n",
      "Epoch [297/360], Batch [85/196], Loss: 0.0125\n",
      "Epoch [297/360], Batch [90/196], Loss: 0.0160\n",
      "Epoch [297/360], Batch [95/196], Loss: 0.0182\n",
      "Epoch [297/360], Batch [100/196], Loss: 0.0180\n",
      "Epoch [297/360], Batch [105/196], Loss: 0.0125\n",
      "Epoch [297/360], Batch [110/196], Loss: 0.0162\n",
      "Epoch [297/360], Batch [115/196], Loss: 0.0164\n",
      "Epoch [297/360], Batch [120/196], Loss: 0.0130\n",
      "Epoch [297/360], Batch [125/196], Loss: 0.0167\n",
      "Epoch [297/360], Batch [130/196], Loss: 0.0104\n",
      "Epoch [297/360], Batch [135/196], Loss: 0.0217\n",
      "Epoch [297/360], Batch [140/196], Loss: 0.0121\n",
      "Epoch [297/360], Batch [145/196], Loss: 0.0210\n",
      "Epoch [297/360], Batch [150/196], Loss: 0.0161\n",
      "Epoch [297/360], Batch [155/196], Loss: 0.0223\n",
      "Epoch [297/360], Batch [160/196], Loss: 0.0232\n",
      "Epoch [297/360], Batch [165/196], Loss: 0.0171\n",
      "Epoch [297/360], Batch [170/196], Loss: 0.0106\n",
      "Epoch [297/360], Batch [175/196], Loss: 0.0235\n",
      "Epoch [297/360], Batch [180/196], Loss: 0.0140\n",
      "Epoch [297/360], Batch [185/196], Loss: 0.0168\n",
      "Epoch [297/360], Batch [190/196], Loss: 0.0176\n",
      "Epoch [297/360], Batch [195/196], Loss: 0.0240\n",
      "Epoch [298/360], Batch [5/196], Loss: 0.0175\n",
      "Epoch [298/360], Batch [10/196], Loss: 0.0220\n",
      "Epoch [298/360], Batch [15/196], Loss: 0.0197\n",
      "Epoch [298/360], Batch [20/196], Loss: 0.0214\n",
      "Epoch [298/360], Batch [25/196], Loss: 0.0149\n",
      "Epoch [298/360], Batch [30/196], Loss: 0.0112\n",
      "Epoch [298/360], Batch [35/196], Loss: 0.0083\n",
      "Epoch [298/360], Batch [40/196], Loss: 0.0136\n",
      "Epoch [298/360], Batch [45/196], Loss: 0.0110\n",
      "Epoch [298/360], Batch [50/196], Loss: 0.0172\n",
      "Epoch [298/360], Batch [55/196], Loss: 0.0203\n",
      "Epoch [298/360], Batch [60/196], Loss: 0.0076\n",
      "Epoch [298/360], Batch [65/196], Loss: 0.0166\n",
      "Epoch [298/360], Batch [70/196], Loss: 0.0125\n",
      "Epoch [298/360], Batch [75/196], Loss: 0.0124\n",
      "Epoch [298/360], Batch [80/196], Loss: 0.0132\n",
      "Epoch [298/360], Batch [85/196], Loss: 0.0126\n",
      "Epoch [298/360], Batch [90/196], Loss: 0.0120\n",
      "Epoch [298/360], Batch [95/196], Loss: 0.0099\n",
      "Epoch [298/360], Batch [100/196], Loss: 0.0104\n",
      "Epoch [298/360], Batch [105/196], Loss: 0.0125\n",
      "Epoch [298/360], Batch [110/196], Loss: 0.0127\n",
      "Epoch [298/360], Batch [115/196], Loss: 0.0161\n",
      "Epoch [298/360], Batch [120/196], Loss: 0.0132\n",
      "Epoch [298/360], Batch [125/196], Loss: 0.0095\n",
      "Epoch [298/360], Batch [130/196], Loss: 0.0202\n",
      "Epoch [298/360], Batch [135/196], Loss: 0.0131\n",
      "Epoch [298/360], Batch [140/196], Loss: 0.0118\n",
      "Epoch [298/360], Batch [145/196], Loss: 0.0160\n",
      "Epoch [298/360], Batch [150/196], Loss: 0.0320\n",
      "Epoch [298/360], Batch [155/196], Loss: 0.0130\n",
      "Epoch [298/360], Batch [160/196], Loss: 0.0104\n",
      "Epoch [298/360], Batch [165/196], Loss: 0.0110\n",
      "Epoch [298/360], Batch [170/196], Loss: 0.0059\n",
      "Epoch [298/360], Batch [175/196], Loss: 0.0094\n",
      "Epoch [298/360], Batch [180/196], Loss: 0.0135\n",
      "Epoch [298/360], Batch [185/196], Loss: 0.0093\n",
      "Epoch [298/360], Batch [190/196], Loss: 0.0099\n",
      "Epoch [298/360], Batch [195/196], Loss: 0.0095\n",
      "Epoch [299/360], Batch [5/196], Loss: 0.0068\n",
      "Epoch [299/360], Batch [10/196], Loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [299/360], Batch [15/196], Loss: 0.0088\n",
      "Epoch [299/360], Batch [20/196], Loss: 0.0122\n",
      "Epoch [299/360], Batch [25/196], Loss: 0.0070\n",
      "Epoch [299/360], Batch [30/196], Loss: 0.0086\n",
      "Epoch [299/360], Batch [35/196], Loss: 0.0216\n",
      "Epoch [299/360], Batch [40/196], Loss: 0.0070\n",
      "Epoch [299/360], Batch [45/196], Loss: 0.0077\n",
      "Epoch [299/360], Batch [50/196], Loss: 0.0065\n",
      "Epoch [299/360], Batch [55/196], Loss: 0.0074\n",
      "Epoch [299/360], Batch [60/196], Loss: 0.0065\n",
      "Epoch [299/360], Batch [65/196], Loss: 0.0096\n",
      "Epoch [299/360], Batch [70/196], Loss: 0.0085\n",
      "Epoch [299/360], Batch [75/196], Loss: 0.0101\n",
      "Epoch [299/360], Batch [80/196], Loss: 0.0057\n",
      "Epoch [299/360], Batch [85/196], Loss: 0.0071\n",
      "Epoch [299/360], Batch [90/196], Loss: 0.0077\n",
      "Epoch [299/360], Batch [95/196], Loss: 0.0092\n",
      "Epoch [299/360], Batch [100/196], Loss: 0.0094\n",
      "Epoch [299/360], Batch [105/196], Loss: 0.0080\n",
      "Epoch [299/360], Batch [110/196], Loss: 0.0072\n",
      "Epoch [299/360], Batch [115/196], Loss: 0.0075\n",
      "Epoch [299/360], Batch [120/196], Loss: 0.0066\n",
      "Epoch [299/360], Batch [125/196], Loss: 0.0054\n",
      "Epoch [299/360], Batch [130/196], Loss: 0.0074\n",
      "Epoch [299/360], Batch [135/196], Loss: 0.0063\n",
      "Epoch [299/360], Batch [140/196], Loss: 0.0092\n",
      "Epoch [299/360], Batch [145/196], Loss: 0.0061\n",
      "Epoch [299/360], Batch [150/196], Loss: 0.0073\n",
      "Epoch [299/360], Batch [155/196], Loss: 0.0089\n",
      "Epoch [299/360], Batch [160/196], Loss: 0.0101\n",
      "Epoch [299/360], Batch [165/196], Loss: 0.0101\n",
      "Epoch [299/360], Batch [170/196], Loss: 0.0068\n",
      "Epoch [299/360], Batch [175/196], Loss: 0.0066\n",
      "Epoch [299/360], Batch [180/196], Loss: 0.0080\n",
      "Epoch [299/360], Batch [185/196], Loss: 0.0085\n",
      "Epoch [299/360], Batch [190/196], Loss: 0.0118\n",
      "Epoch [299/360], Batch [195/196], Loss: 0.0061\n",
      "Epoch [300/360], Batch [5/196], Loss: 0.0056\n",
      "Epoch [300/360], Batch [10/196], Loss: 0.0055\n",
      "Epoch [300/360], Batch [15/196], Loss: 0.0228\n",
      "Epoch [300/360], Batch [20/196], Loss: 0.0055\n",
      "Epoch [300/360], Batch [25/196], Loss: 0.0053\n",
      "Epoch [300/360], Batch [30/196], Loss: 0.0068\n",
      "Epoch [300/360], Batch [35/196], Loss: 0.0077\n",
      "Epoch [300/360], Batch [40/196], Loss: 0.0062\n",
      "Epoch [300/360], Batch [45/196], Loss: 0.0068\n",
      "Epoch [300/360], Batch [50/196], Loss: 0.0112\n",
      "Epoch [300/360], Batch [55/196], Loss: 0.0097\n",
      "Epoch [300/360], Batch [60/196], Loss: 0.0056\n",
      "Epoch [300/360], Batch [65/196], Loss: 0.0052\n",
      "Epoch [300/360], Batch [70/196], Loss: 0.0067\n",
      "Epoch [300/360], Batch [75/196], Loss: 0.0119\n",
      "Epoch [300/360], Batch [80/196], Loss: 0.0093\n",
      "Epoch [300/360], Batch [85/196], Loss: 0.0054\n",
      "Epoch [300/360], Batch [90/196], Loss: 0.0067\n",
      "Epoch [300/360], Batch [95/196], Loss: 0.0060\n",
      "Epoch [300/360], Batch [100/196], Loss: 0.0098\n",
      "Epoch [300/360], Batch [105/196], Loss: 0.0083\n",
      "Epoch [300/360], Batch [110/196], Loss: 0.0072\n",
      "Epoch [300/360], Batch [115/196], Loss: 0.0075\n",
      "Epoch [300/360], Batch [120/196], Loss: 0.0067\n",
      "Epoch [300/360], Batch [125/196], Loss: 0.0064\n",
      "Epoch [300/360], Batch [130/196], Loss: 0.0086\n",
      "Epoch [300/360], Batch [135/196], Loss: 0.0071\n",
      "Epoch [300/360], Batch [140/196], Loss: 0.0072\n",
      "Epoch [300/360], Batch [145/196], Loss: 0.0083\n",
      "Epoch [300/360], Batch [150/196], Loss: 0.0064\n",
      "Epoch [300/360], Batch [155/196], Loss: 0.0048\n",
      "Epoch [300/360], Batch [160/196], Loss: 0.0089\n",
      "Epoch [300/360], Batch [165/196], Loss: 0.0070\n",
      "Epoch [300/360], Batch [170/196], Loss: 0.0074\n",
      "Epoch [300/360], Batch [175/196], Loss: 0.0108\n",
      "Epoch [300/360], Batch [180/196], Loss: 0.0110\n",
      "Epoch [300/360], Batch [185/196], Loss: 0.0067\n",
      "Epoch [300/360], Batch [190/196], Loss: 0.0071\n",
      "Epoch [300/360], Batch [195/196], Loss: 0.0073\n",
      "Epoch [301/360], Batch [5/196], Loss: 0.0079\n",
      "Epoch [301/360], Batch [10/196], Loss: 0.0082\n",
      "Epoch [301/360], Batch [15/196], Loss: 0.0072\n",
      "Epoch [301/360], Batch [20/196], Loss: 0.0092\n",
      "Epoch [301/360], Batch [25/196], Loss: 0.0079\n",
      "Epoch [301/360], Batch [30/196], Loss: 0.0100\n",
      "Epoch [301/360], Batch [35/196], Loss: 0.0076\n",
      "Epoch [301/360], Batch [40/196], Loss: 0.0056\n",
      "Epoch [301/360], Batch [45/196], Loss: 0.0100\n",
      "Epoch [301/360], Batch [50/196], Loss: 0.0070\n",
      "Epoch [301/360], Batch [55/196], Loss: 0.0085\n",
      "Epoch [301/360], Batch [60/196], Loss: 0.0059\n",
      "Epoch [301/360], Batch [65/196], Loss: 0.0122\n",
      "Epoch [301/360], Batch [70/196], Loss: 0.0099\n",
      "Epoch [301/360], Batch [75/196], Loss: 0.0063\n",
      "Epoch [301/360], Batch [80/196], Loss: 0.0079\n",
      "Epoch [301/360], Batch [85/196], Loss: 0.0114\n",
      "Epoch [301/360], Batch [90/196], Loss: 0.0116\n",
      "Epoch [301/360], Batch [95/196], Loss: 0.0063\n",
      "Epoch [301/360], Batch [100/196], Loss: 0.0077\n",
      "Epoch [301/360], Batch [105/196], Loss: 0.0075\n",
      "Epoch [301/360], Batch [110/196], Loss: 0.0096\n",
      "Epoch [301/360], Batch [115/196], Loss: 0.0089\n",
      "Epoch [301/360], Batch [120/196], Loss: 0.0082\n",
      "Epoch [301/360], Batch [125/196], Loss: 0.0103\n",
      "Epoch [301/360], Batch [130/196], Loss: 0.0137\n",
      "Epoch [301/360], Batch [135/196], Loss: 0.0078\n",
      "Epoch [301/360], Batch [140/196], Loss: 0.0120\n",
      "Epoch [301/360], Batch [145/196], Loss: 0.0065\n",
      "Epoch [301/360], Batch [150/196], Loss: 0.0102\n",
      "Epoch [301/360], Batch [155/196], Loss: 0.0068\n",
      "Epoch [301/360], Batch [160/196], Loss: 0.0096\n",
      "Epoch [301/360], Batch [165/196], Loss: 0.0088\n",
      "Epoch [301/360], Batch [170/196], Loss: 0.0091\n",
      "Epoch [301/360], Batch [175/196], Loss: 0.0089\n",
      "Epoch [301/360], Batch [180/196], Loss: 0.0081\n",
      "Epoch [301/360], Batch [185/196], Loss: 0.0096\n",
      "Epoch [301/360], Batch [190/196], Loss: 0.0076\n",
      "Epoch [301/360], Batch [195/196], Loss: 0.0103\n",
      "Epoch [302/360], Batch [5/196], Loss: 0.0132\n",
      "Epoch [302/360], Batch [10/196], Loss: 0.0101\n",
      "Epoch [302/360], Batch [15/196], Loss: 0.0078\n",
      "Epoch [302/360], Batch [20/196], Loss: 0.0113\n",
      "Epoch [302/360], Batch [25/196], Loss: 0.0203\n",
      "Epoch [302/360], Batch [30/196], Loss: 0.0118\n",
      "Epoch [302/360], Batch [35/196], Loss: 0.0067\n",
      "Epoch [302/360], Batch [40/196], Loss: 0.0155\n",
      "Epoch [302/360], Batch [45/196], Loss: 0.0185\n",
      "Epoch [302/360], Batch [50/196], Loss: 0.0108\n",
      "Epoch [302/360], Batch [55/196], Loss: 0.0150\n",
      "Epoch [302/360], Batch [60/196], Loss: 0.0128\n",
      "Epoch [302/360], Batch [65/196], Loss: 0.0110\n",
      "Epoch [302/360], Batch [70/196], Loss: 0.0125\n",
      "Epoch [302/360], Batch [75/196], Loss: 0.0161\n",
      "Epoch [302/360], Batch [80/196], Loss: 0.0108\n",
      "Epoch [302/360], Batch [85/196], Loss: 0.0099\n",
      "Epoch [302/360], Batch [90/196], Loss: 0.0097\n",
      "Epoch [302/360], Batch [95/196], Loss: 0.0110\n",
      "Epoch [302/360], Batch [100/196], Loss: 0.0117\n",
      "Epoch [302/360], Batch [105/196], Loss: 0.0177\n",
      "Epoch [302/360], Batch [110/196], Loss: 0.0104\n",
      "Epoch [302/360], Batch [115/196], Loss: 0.0084\n",
      "Epoch [302/360], Batch [120/196], Loss: 0.0124\n",
      "Epoch [302/360], Batch [125/196], Loss: 0.0119\n",
      "Epoch [302/360], Batch [130/196], Loss: 0.0118\n",
      "Epoch [302/360], Batch [135/196], Loss: 0.0160\n",
      "Epoch [302/360], Batch [140/196], Loss: 0.0155\n",
      "Epoch [302/360], Batch [145/196], Loss: 0.0140\n",
      "Epoch [302/360], Batch [150/196], Loss: 0.0159\n",
      "Epoch [302/360], Batch [155/196], Loss: 0.0109\n",
      "Epoch [302/360], Batch [160/196], Loss: 0.0082\n",
      "Epoch [302/360], Batch [165/196], Loss: 0.0081\n",
      "Epoch [302/360], Batch [170/196], Loss: 0.0100\n",
      "Epoch [302/360], Batch [175/196], Loss: 0.0099\n",
      "Epoch [302/360], Batch [180/196], Loss: 0.0098\n",
      "Epoch [302/360], Batch [185/196], Loss: 0.0096\n",
      "Epoch [302/360], Batch [190/196], Loss: 0.0126\n",
      "Epoch [302/360], Batch [195/196], Loss: 0.0093\n",
      "Epoch [303/360], Batch [5/196], Loss: 0.0082\n",
      "Epoch [303/360], Batch [10/196], Loss: 0.0091\n",
      "Epoch [303/360], Batch [15/196], Loss: 0.0202\n",
      "Epoch [303/360], Batch [20/196], Loss: 0.0160\n",
      "Epoch [303/360], Batch [25/196], Loss: 0.0127\n",
      "Epoch [303/360], Batch [30/196], Loss: 0.0205\n",
      "Epoch [303/360], Batch [35/196], Loss: 0.0179\n",
      "Epoch [303/360], Batch [40/196], Loss: 0.0191\n",
      "Epoch [303/360], Batch [45/196], Loss: 0.0246\n",
      "Epoch [303/360], Batch [50/196], Loss: 0.0155\n",
      "Epoch [303/360], Batch [55/196], Loss: 0.0264\n",
      "Epoch [303/360], Batch [60/196], Loss: 0.0160\n",
      "Epoch [303/360], Batch [65/196], Loss: 0.0186\n",
      "Epoch [303/360], Batch [70/196], Loss: 0.0221\n",
      "Epoch [303/360], Batch [75/196], Loss: 0.0166\n",
      "Epoch [303/360], Batch [80/196], Loss: 0.0159\n",
      "Epoch [303/360], Batch [85/196], Loss: 0.0288\n",
      "Epoch [303/360], Batch [90/196], Loss: 0.0245\n",
      "Epoch [303/360], Batch [95/196], Loss: 0.0224\n",
      "Epoch [303/360], Batch [100/196], Loss: 0.0259\n",
      "Epoch [303/360], Batch [105/196], Loss: 0.0217\n",
      "Epoch [303/360], Batch [110/196], Loss: 0.0118\n",
      "Epoch [303/360], Batch [115/196], Loss: 0.0139\n",
      "Epoch [303/360], Batch [120/196], Loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [303/360], Batch [125/196], Loss: 0.0261\n",
      "Epoch [303/360], Batch [130/196], Loss: 0.0294\n",
      "Epoch [303/360], Batch [135/196], Loss: 0.0259\n",
      "Epoch [303/360], Batch [140/196], Loss: 0.0155\n",
      "Epoch [303/360], Batch [145/196], Loss: 0.0135\n",
      "Epoch [303/360], Batch [150/196], Loss: 0.0166\n",
      "Epoch [303/360], Batch [155/196], Loss: 0.0167\n",
      "Epoch [303/360], Batch [160/196], Loss: 0.0180\n",
      "Epoch [303/360], Batch [165/196], Loss: 0.0239\n",
      "Epoch [303/360], Batch [170/196], Loss: 0.0255\n",
      "Epoch [303/360], Batch [175/196], Loss: 0.0111\n",
      "Epoch [303/360], Batch [180/196], Loss: 0.0241\n",
      "Epoch [303/360], Batch [185/196], Loss: 0.0218\n",
      "Epoch [303/360], Batch [190/196], Loss: 0.0412\n",
      "Epoch [303/360], Batch [195/196], Loss: 0.0260\n",
      "Epoch [304/360], Batch [5/196], Loss: 0.0156\n",
      "Epoch [304/360], Batch [10/196], Loss: 0.0336\n",
      "Epoch [304/360], Batch [15/196], Loss: 0.0934\n",
      "Epoch [304/360], Batch [20/196], Loss: 0.0388\n",
      "Epoch [304/360], Batch [25/196], Loss: 0.0515\n",
      "Epoch [304/360], Batch [30/196], Loss: 0.0422\n",
      "Epoch [304/360], Batch [35/196], Loss: 0.0441\n",
      "Epoch [304/360], Batch [40/196], Loss: 0.0394\n",
      "Epoch [304/360], Batch [45/196], Loss: 0.0341\n",
      "Epoch [304/360], Batch [50/196], Loss: 0.0425\n",
      "Epoch [304/360], Batch [55/196], Loss: 0.0218\n",
      "Epoch [304/360], Batch [60/196], Loss: 0.0302\n",
      "Epoch [304/360], Batch [65/196], Loss: 0.0274\n",
      "Epoch [304/360], Batch [70/196], Loss: 0.0449\n",
      "Epoch [304/360], Batch [75/196], Loss: 0.0351\n",
      "Epoch [304/360], Batch [80/196], Loss: 0.0474\n",
      "Epoch [304/360], Batch [85/196], Loss: 0.0401\n",
      "Epoch [304/360], Batch [90/196], Loss: 0.0502\n",
      "Epoch [304/360], Batch [95/196], Loss: 0.0374\n",
      "Epoch [304/360], Batch [100/196], Loss: 0.0254\n",
      "Epoch [304/360], Batch [105/196], Loss: 0.0437\n",
      "Epoch [304/360], Batch [110/196], Loss: 0.0279\n",
      "Epoch [304/360], Batch [115/196], Loss: 0.0233\n",
      "Epoch [304/360], Batch [120/196], Loss: 0.0178\n",
      "Epoch [304/360], Batch [125/196], Loss: 0.0371\n",
      "Epoch [304/360], Batch [130/196], Loss: 0.0280\n",
      "Epoch [304/360], Batch [135/196], Loss: 0.0249\n",
      "Epoch [304/360], Batch [140/196], Loss: 0.0349\n",
      "Epoch [304/360], Batch [145/196], Loss: 0.0386\n",
      "Epoch [304/360], Batch [150/196], Loss: 0.0390\n",
      "Epoch [304/360], Batch [155/196], Loss: 0.0878\n",
      "Epoch [304/360], Batch [160/196], Loss: 0.0822\n",
      "Epoch [304/360], Batch [165/196], Loss: 0.0703\n",
      "Epoch [304/360], Batch [170/196], Loss: 0.0500\n",
      "Epoch [304/360], Batch [175/196], Loss: 0.0687\n",
      "Epoch [304/360], Batch [180/196], Loss: 0.0427\n",
      "Epoch [304/360], Batch [185/196], Loss: 0.0689\n",
      "Epoch [304/360], Batch [190/196], Loss: 0.1205\n",
      "Epoch [304/360], Batch [195/196], Loss: 0.0557\n",
      "Epoch [305/360], Batch [5/196], Loss: 0.0605\n",
      "Epoch [305/360], Batch [10/196], Loss: 0.0923\n",
      "Epoch [305/360], Batch [15/196], Loss: 0.1096\n",
      "Epoch [305/360], Batch [20/196], Loss: 0.0768\n",
      "Epoch [305/360], Batch [25/196], Loss: 0.0734\n",
      "Epoch [305/360], Batch [30/196], Loss: 0.0891\n",
      "Epoch [305/360], Batch [35/196], Loss: 0.0629\n",
      "Epoch [305/360], Batch [40/196], Loss: 0.0728\n",
      "Epoch [305/360], Batch [45/196], Loss: 0.0407\n",
      "Epoch [305/360], Batch [50/196], Loss: 0.0710\n",
      "Epoch [305/360], Batch [55/196], Loss: 0.0705\n",
      "Epoch [305/360], Batch [60/196], Loss: 0.1057\n",
      "Epoch [305/360], Batch [65/196], Loss: 0.1123\n",
      "Epoch [305/360], Batch [70/196], Loss: 0.0608\n",
      "Epoch [305/360], Batch [75/196], Loss: 0.0580\n",
      "Epoch [305/360], Batch [80/196], Loss: 0.0726\n",
      "Epoch [305/360], Batch [85/196], Loss: 0.0592\n",
      "Epoch [305/360], Batch [90/196], Loss: 0.0456\n",
      "Epoch [305/360], Batch [95/196], Loss: 0.0720\n",
      "Epoch [305/360], Batch [100/196], Loss: 0.0740\n",
      "Epoch [305/360], Batch [105/196], Loss: 0.0316\n",
      "Epoch [305/360], Batch [110/196], Loss: 0.0638\n",
      "Epoch [305/360], Batch [115/196], Loss: 0.3234\n",
      "Epoch [305/360], Batch [120/196], Loss: 0.0732\n",
      "Epoch [305/360], Batch [125/196], Loss: 0.0624\n",
      "Epoch [305/360], Batch [130/196], Loss: 0.0403\n",
      "Epoch [305/360], Batch [135/196], Loss: 0.0391\n",
      "Epoch [305/360], Batch [140/196], Loss: 0.0655\n",
      "Epoch [305/360], Batch [145/196], Loss: 0.0456\n",
      "Epoch [305/360], Batch [150/196], Loss: 0.0606\n",
      "Epoch [305/360], Batch [155/196], Loss: 0.0602\n",
      "Epoch [305/360], Batch [160/196], Loss: 0.0308\n",
      "Epoch [305/360], Batch [165/196], Loss: 0.0665\n",
      "Epoch [305/360], Batch [170/196], Loss: 0.0420\n",
      "Epoch [305/360], Batch [175/196], Loss: 0.0510\n",
      "Epoch [305/360], Batch [180/196], Loss: 0.0581\n",
      "Epoch [305/360], Batch [185/196], Loss: 0.0564\n",
      "Epoch [305/360], Batch [190/196], Loss: 0.0711\n",
      "Epoch [305/360], Batch [195/196], Loss: 0.0796\n",
      "Epoch [306/360], Batch [5/196], Loss: 0.0559\n",
      "Epoch [306/360], Batch [10/196], Loss: 0.0318\n",
      "Epoch [306/360], Batch [15/196], Loss: 0.0278\n",
      "Epoch [306/360], Batch [20/196], Loss: 0.0368\n",
      "Epoch [306/360], Batch [25/196], Loss: 0.0333\n",
      "Epoch [306/360], Batch [30/196], Loss: 0.0404\n",
      "Epoch [306/360], Batch [35/196], Loss: 0.0500\n",
      "Epoch [306/360], Batch [40/196], Loss: 0.0192\n",
      "Epoch [306/360], Batch [45/196], Loss: 0.0627\n",
      "Epoch [306/360], Batch [50/196], Loss: 0.0333\n",
      "Epoch [306/360], Batch [55/196], Loss: 0.0291\n",
      "Epoch [306/360], Batch [60/196], Loss: 0.0474\n",
      "Epoch [306/360], Batch [65/196], Loss: 0.0624\n",
      "Epoch [306/360], Batch [70/196], Loss: 0.0561\n",
      "Epoch [306/360], Batch [75/196], Loss: 0.0822\n",
      "Epoch [306/360], Batch [80/196], Loss: 0.0383\n",
      "Epoch [306/360], Batch [85/196], Loss: 0.0540\n",
      "Epoch [306/360], Batch [90/196], Loss: 0.0464\n",
      "Epoch [306/360], Batch [95/196], Loss: 0.0513\n",
      "Epoch [306/360], Batch [100/196], Loss: 0.0465\n",
      "Epoch [306/360], Batch [105/196], Loss: 0.0439\n",
      "Epoch [306/360], Batch [110/196], Loss: 0.0398\n",
      "Epoch [306/360], Batch [115/196], Loss: 0.0573\n",
      "Epoch [306/360], Batch [120/196], Loss: 0.0987\n",
      "Epoch [306/360], Batch [125/196], Loss: 0.1464\n",
      "Epoch [306/360], Batch [130/196], Loss: 0.0404\n",
      "Epoch [306/360], Batch [135/196], Loss: 0.0601\n",
      "Epoch [306/360], Batch [140/196], Loss: 0.0375\n",
      "Epoch [306/360], Batch [145/196], Loss: 0.0575\n",
      "Epoch [306/360], Batch [150/196], Loss: 0.0532\n",
      "Epoch [306/360], Batch [155/196], Loss: 0.0481\n",
      "Epoch [306/360], Batch [160/196], Loss: 0.0434\n",
      "Epoch [306/360], Batch [165/196], Loss: 0.0834\n",
      "Epoch [306/360], Batch [170/196], Loss: 0.0345\n",
      "Epoch [306/360], Batch [175/196], Loss: 0.0515\n",
      "Epoch [306/360], Batch [180/196], Loss: 0.0628\n",
      "Epoch [306/360], Batch [185/196], Loss: 0.0439\n",
      "Epoch [306/360], Batch [190/196], Loss: 0.0242\n",
      "Epoch [306/360], Batch [195/196], Loss: 0.0520\n",
      "Epoch [307/360], Batch [5/196], Loss: 0.0216\n",
      "Epoch [307/360], Batch [10/196], Loss: 0.0228\n",
      "Epoch [307/360], Batch [15/196], Loss: 0.0400\n",
      "Epoch [307/360], Batch [20/196], Loss: 0.0457\n",
      "Epoch [307/360], Batch [25/196], Loss: 0.0379\n",
      "Epoch [307/360], Batch [30/196], Loss: 0.0334\n",
      "Epoch [307/360], Batch [35/196], Loss: 0.0373\n",
      "Epoch [307/360], Batch [40/196], Loss: 0.0279\n",
      "Epoch [307/360], Batch [45/196], Loss: 0.0276\n",
      "Epoch [307/360], Batch [50/196], Loss: 0.0392\n",
      "Epoch [307/360], Batch [55/196], Loss: 0.0420\n",
      "Epoch [307/360], Batch [60/196], Loss: 0.0343\n",
      "Epoch [307/360], Batch [65/196], Loss: 0.0368\n",
      "Epoch [307/360], Batch [70/196], Loss: 0.0236\n",
      "Epoch [307/360], Batch [75/196], Loss: 0.0290\n",
      "Epoch [307/360], Batch [80/196], Loss: 0.0286\n",
      "Epoch [307/360], Batch [85/196], Loss: 0.0419\n",
      "Epoch [307/360], Batch [90/196], Loss: 0.0521\n",
      "Epoch [307/360], Batch [95/196], Loss: 0.0265\n",
      "Epoch [307/360], Batch [100/196], Loss: 0.0452\n",
      "Epoch [307/360], Batch [105/196], Loss: 0.0294\n",
      "Epoch [307/360], Batch [110/196], Loss: 0.0244\n",
      "Epoch [307/360], Batch [115/196], Loss: 0.0283\n",
      "Epoch [307/360], Batch [120/196], Loss: 0.0239\n",
      "Epoch [307/360], Batch [125/196], Loss: 0.0218\n",
      "Epoch [307/360], Batch [130/196], Loss: 0.0372\n",
      "Epoch [307/360], Batch [135/196], Loss: 0.0318\n",
      "Epoch [307/360], Batch [140/196], Loss: 0.0532\n",
      "Epoch [307/360], Batch [145/196], Loss: 0.0255\n",
      "Epoch [307/360], Batch [150/196], Loss: 0.0405\n",
      "Epoch [307/360], Batch [155/196], Loss: 0.0340\n",
      "Epoch [307/360], Batch [160/196], Loss: 0.0332\n",
      "Epoch [307/360], Batch [165/196], Loss: 0.0257\n",
      "Epoch [307/360], Batch [170/196], Loss: 0.0402\n",
      "Epoch [307/360], Batch [175/196], Loss: 0.0202\n",
      "Epoch [307/360], Batch [180/196], Loss: 0.0182\n",
      "Epoch [307/360], Batch [185/196], Loss: 0.0385\n",
      "Epoch [307/360], Batch [190/196], Loss: 0.0356\n",
      "Epoch [307/360], Batch [195/196], Loss: 0.0287\n",
      "Epoch [308/360], Batch [5/196], Loss: 0.0256\n",
      "Epoch [308/360], Batch [10/196], Loss: 0.0281\n",
      "Epoch [308/360], Batch [15/196], Loss: 0.0287\n",
      "Epoch [308/360], Batch [20/196], Loss: 0.0205\n",
      "Epoch [308/360], Batch [25/196], Loss: 0.0233\n",
      "Epoch [308/360], Batch [30/196], Loss: 0.0451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [308/360], Batch [35/196], Loss: 0.0266\n",
      "Epoch [308/360], Batch [40/196], Loss: 0.0192\n",
      "Epoch [308/360], Batch [45/196], Loss: 0.0217\n",
      "Epoch [308/360], Batch [50/196], Loss: 0.0345\n",
      "Epoch [308/360], Batch [55/196], Loss: 0.0241\n",
      "Epoch [308/360], Batch [60/196], Loss: 0.0121\n",
      "Epoch [308/360], Batch [65/196], Loss: 0.0201\n",
      "Epoch [308/360], Batch [70/196], Loss: 0.0196\n",
      "Epoch [308/360], Batch [75/196], Loss: 0.0198\n",
      "Epoch [308/360], Batch [80/196], Loss: 0.0192\n",
      "Epoch [308/360], Batch [85/196], Loss: 0.0333\n",
      "Epoch [308/360], Batch [90/196], Loss: 0.0197\n",
      "Epoch [308/360], Batch [95/196], Loss: 0.0123\n",
      "Epoch [308/360], Batch [100/196], Loss: 0.0162\n",
      "Epoch [308/360], Batch [105/196], Loss: 0.0392\n",
      "Epoch [308/360], Batch [110/196], Loss: 0.0135\n",
      "Epoch [308/360], Batch [115/196], Loss: 0.0141\n",
      "Epoch [308/360], Batch [120/196], Loss: 0.0156\n",
      "Epoch [308/360], Batch [125/196], Loss: 0.0191\n",
      "Epoch [308/360], Batch [130/196], Loss: 0.0146\n",
      "Epoch [308/360], Batch [135/196], Loss: 0.0318\n",
      "Epoch [308/360], Batch [140/196], Loss: 0.0158\n",
      "Epoch [308/360], Batch [145/196], Loss: 0.0207\n",
      "Epoch [308/360], Batch [150/196], Loss: 0.0203\n",
      "Epoch [308/360], Batch [155/196], Loss: 0.0540\n",
      "Epoch [308/360], Batch [160/196], Loss: 0.0152\n",
      "Epoch [308/360], Batch [165/196], Loss: 0.0206\n",
      "Epoch [308/360], Batch [170/196], Loss: 0.0226\n",
      "Epoch [308/360], Batch [175/196], Loss: 0.0152\n",
      "Epoch [308/360], Batch [180/196], Loss: 0.0138\n",
      "Epoch [308/360], Batch [185/196], Loss: 0.0195\n",
      "Epoch [308/360], Batch [190/196], Loss: 0.0153\n",
      "Epoch [308/360], Batch [195/196], Loss: 0.0136\n",
      "Epoch [309/360], Batch [5/196], Loss: 0.0100\n",
      "Epoch [309/360], Batch [10/196], Loss: 0.0252\n",
      "Epoch [309/360], Batch [15/196], Loss: 0.0145\n",
      "Epoch [309/360], Batch [20/196], Loss: 0.0086\n",
      "Epoch [309/360], Batch [25/196], Loss: 0.0107\n",
      "Epoch [309/360], Batch [30/196], Loss: 0.0100\n",
      "Epoch [309/360], Batch [35/196], Loss: 0.0129\n",
      "Epoch [309/360], Batch [40/196], Loss: 0.0101\n",
      "Epoch [309/360], Batch [45/196], Loss: 0.0125\n",
      "Epoch [309/360], Batch [50/196], Loss: 0.0143\n",
      "Epoch [309/360], Batch [55/196], Loss: 0.0271\n",
      "Epoch [309/360], Batch [60/196], Loss: 0.0104\n",
      "Epoch [309/360], Batch [65/196], Loss: 0.0161\n",
      "Epoch [309/360], Batch [70/196], Loss: 0.0097\n",
      "Epoch [309/360], Batch [75/196], Loss: 0.0150\n",
      "Epoch [309/360], Batch [80/196], Loss: 0.0155\n",
      "Epoch [309/360], Batch [85/196], Loss: 0.0170\n",
      "Epoch [309/360], Batch [90/196], Loss: 0.0098\n",
      "Epoch [309/360], Batch [95/196], Loss: 0.0113\n",
      "Epoch [309/360], Batch [100/196], Loss: 0.0074\n",
      "Epoch [309/360], Batch [105/196], Loss: 0.0092\n",
      "Epoch [309/360], Batch [110/196], Loss: 0.0150\n",
      "Epoch [309/360], Batch [115/196], Loss: 0.0078\n",
      "Epoch [309/360], Batch [120/196], Loss: 0.0089\n",
      "Epoch [309/360], Batch [125/196], Loss: 0.0101\n",
      "Epoch [309/360], Batch [130/196], Loss: 0.0202\n",
      "Epoch [309/360], Batch [135/196], Loss: 0.0079\n",
      "Epoch [309/360], Batch [140/196], Loss: 0.0104\n",
      "Epoch [309/360], Batch [145/196], Loss: 0.0120\n",
      "Epoch [309/360], Batch [150/196], Loss: 0.0088\n",
      "Epoch [309/360], Batch [155/196], Loss: 0.0110\n",
      "Epoch [309/360], Batch [160/196], Loss: 0.0113\n",
      "Epoch [309/360], Batch [165/196], Loss: 0.0089\n",
      "Epoch [309/360], Batch [170/196], Loss: 0.0065\n",
      "Epoch [309/360], Batch [175/196], Loss: 0.0130\n",
      "Epoch [309/360], Batch [180/196], Loss: 0.0420\n",
      "Epoch [309/360], Batch [185/196], Loss: 0.0113\n",
      "Epoch [309/360], Batch [190/196], Loss: 0.0096\n",
      "Epoch [309/360], Batch [195/196], Loss: 0.0112\n",
      "Epoch [310/360], Batch [5/196], Loss: 0.0126\n",
      "Epoch [310/360], Batch [10/196], Loss: 0.0067\n",
      "Epoch [310/360], Batch [15/196], Loss: 0.0097\n",
      "Epoch [310/360], Batch [20/196], Loss: 0.0059\n",
      "Epoch [310/360], Batch [25/196], Loss: 0.0131\n",
      "Epoch [310/360], Batch [30/196], Loss: 0.0075\n",
      "Epoch [310/360], Batch [35/196], Loss: 0.0134\n",
      "Epoch [310/360], Batch [40/196], Loss: 0.0115\n",
      "Epoch [310/360], Batch [45/196], Loss: 0.0158\n",
      "Epoch [310/360], Batch [50/196], Loss: 0.0081\n",
      "Epoch [310/360], Batch [55/196], Loss: 0.0075\n",
      "Epoch [310/360], Batch [60/196], Loss: 0.0082\n",
      "Epoch [310/360], Batch [65/196], Loss: 0.0085\n",
      "Epoch [310/360], Batch [70/196], Loss: 0.0088\n",
      "Epoch [310/360], Batch [75/196], Loss: 0.0050\n",
      "Epoch [310/360], Batch [80/196], Loss: 0.0082\n",
      "Epoch [310/360], Batch [85/196], Loss: 0.0069\n",
      "Epoch [310/360], Batch [90/196], Loss: 0.0077\n",
      "Epoch [310/360], Batch [95/196], Loss: 0.0059\n",
      "Epoch [310/360], Batch [100/196], Loss: 0.0116\n",
      "Epoch [310/360], Batch [105/196], Loss: 0.0072\n",
      "Epoch [310/360], Batch [110/196], Loss: 0.0073\n",
      "Epoch [310/360], Batch [115/196], Loss: 0.0056\n",
      "Epoch [310/360], Batch [120/196], Loss: 0.0104\n",
      "Epoch [310/360], Batch [125/196], Loss: 0.0059\n",
      "Epoch [310/360], Batch [130/196], Loss: 0.0097\n",
      "Epoch [310/360], Batch [135/196], Loss: 0.0061\n",
      "Epoch [310/360], Batch [140/196], Loss: 0.0084\n",
      "Epoch [310/360], Batch [145/196], Loss: 0.0072\n",
      "Epoch [310/360], Batch [150/196], Loss: 0.0074\n",
      "Epoch [310/360], Batch [155/196], Loss: 0.0050\n",
      "Epoch [310/360], Batch [160/196], Loss: 0.0057\n",
      "Epoch [310/360], Batch [165/196], Loss: 0.0074\n",
      "Epoch [310/360], Batch [170/196], Loss: 0.0064\n",
      "Epoch [310/360], Batch [175/196], Loss: 0.0109\n",
      "Epoch [310/360], Batch [180/196], Loss: 0.0126\n",
      "Epoch [310/360], Batch [185/196], Loss: 0.0202\n",
      "Epoch [310/360], Batch [190/196], Loss: 0.0226\n",
      "Epoch [310/360], Batch [195/196], Loss: 0.0257\n",
      "Epoch [311/360], Batch [5/196], Loss: 0.0198\n",
      "Epoch [311/360], Batch [10/196], Loss: 0.0205\n",
      "Epoch [311/360], Batch [15/196], Loss: 0.0195\n",
      "Epoch [311/360], Batch [20/196], Loss: 0.0218\n",
      "Epoch [311/360], Batch [25/196], Loss: 0.0170\n",
      "Epoch [311/360], Batch [30/196], Loss: 0.0100\n",
      "Epoch [311/360], Batch [35/196], Loss: 0.0204\n",
      "Epoch [311/360], Batch [40/196], Loss: 0.0287\n",
      "Epoch [311/360], Batch [45/196], Loss: 0.0216\n",
      "Epoch [311/360], Batch [50/196], Loss: 0.0118\n",
      "Epoch [311/360], Batch [55/196], Loss: 0.0252\n",
      "Epoch [311/360], Batch [60/196], Loss: 0.0160\n",
      "Epoch [311/360], Batch [65/196], Loss: 0.0183\n",
      "Epoch [311/360], Batch [70/196], Loss: 0.0182\n",
      "Epoch [311/360], Batch [75/196], Loss: 0.0277\n",
      "Epoch [311/360], Batch [80/196], Loss: 0.0258\n",
      "Epoch [311/360], Batch [85/196], Loss: 0.0181\n",
      "Epoch [311/360], Batch [90/196], Loss: 0.0198\n",
      "Epoch [311/360], Batch [95/196], Loss: 0.0269\n",
      "Epoch [311/360], Batch [100/196], Loss: 0.0146\n",
      "Epoch [311/360], Batch [105/196], Loss: 0.0245\n",
      "Epoch [311/360], Batch [110/196], Loss: 0.0156\n",
      "Epoch [311/360], Batch [115/196], Loss: 0.0112\n",
      "Epoch [311/360], Batch [120/196], Loss: 0.0163\n",
      "Epoch [311/360], Batch [125/196], Loss: 0.0152\n",
      "Epoch [311/360], Batch [130/196], Loss: 0.0189\n",
      "Epoch [311/360], Batch [135/196], Loss: 0.0126\n",
      "Epoch [311/360], Batch [140/196], Loss: 0.0179\n",
      "Epoch [311/360], Batch [145/196], Loss: 0.0153\n",
      "Epoch [311/360], Batch [150/196], Loss: 0.0104\n",
      "Epoch [311/360], Batch [155/196], Loss: 0.0155\n",
      "Epoch [311/360], Batch [160/196], Loss: 0.0115\n",
      "Epoch [311/360], Batch [165/196], Loss: 0.0210\n",
      "Epoch [311/360], Batch [170/196], Loss: 0.0126\n",
      "Epoch [311/360], Batch [175/196], Loss: 0.0218\n",
      "Epoch [311/360], Batch [180/196], Loss: 0.0257\n",
      "Epoch [311/360], Batch [185/196], Loss: 0.0145\n",
      "Epoch [311/360], Batch [190/196], Loss: 0.0203\n",
      "Epoch [311/360], Batch [195/196], Loss: 0.0115\n",
      "Epoch [312/360], Batch [5/196], Loss: 0.0203\n",
      "Epoch [312/360], Batch [10/196], Loss: 0.0120\n",
      "Epoch [312/360], Batch [15/196], Loss: 0.0170\n",
      "Epoch [312/360], Batch [20/196], Loss: 0.0235\n",
      "Epoch [312/360], Batch [25/196], Loss: 0.0249\n",
      "Epoch [312/360], Batch [30/196], Loss: 0.0110\n",
      "Epoch [312/360], Batch [35/196], Loss: 0.0129\n",
      "Epoch [312/360], Batch [40/196], Loss: 0.0199\n",
      "Epoch [312/360], Batch [45/196], Loss: 0.0173\n",
      "Epoch [312/360], Batch [50/196], Loss: 0.0119\n",
      "Epoch [312/360], Batch [55/196], Loss: 0.0192\n",
      "Epoch [312/360], Batch [60/196], Loss: 0.0138\n",
      "Epoch [312/360], Batch [65/196], Loss: 0.0151\n",
      "Epoch [312/360], Batch [70/196], Loss: 0.0120\n",
      "Epoch [312/360], Batch [75/196], Loss: 0.0208\n",
      "Epoch [312/360], Batch [80/196], Loss: 0.0192\n",
      "Epoch [312/360], Batch [85/196], Loss: 0.0165\n",
      "Epoch [312/360], Batch [90/196], Loss: 0.0215\n",
      "Epoch [312/360], Batch [95/196], Loss: 0.0167\n",
      "Epoch [312/360], Batch [100/196], Loss: 0.0164\n",
      "Epoch [312/360], Batch [105/196], Loss: 0.0135\n",
      "Epoch [312/360], Batch [110/196], Loss: 0.0158\n",
      "Epoch [312/360], Batch [115/196], Loss: 0.0157\n",
      "Epoch [312/360], Batch [120/196], Loss: 0.0201\n",
      "Epoch [312/360], Batch [125/196], Loss: 0.0121\n",
      "Epoch [312/360], Batch [130/196], Loss: 0.0174\n",
      "Epoch [312/360], Batch [135/196], Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [312/360], Batch [140/196], Loss: 0.0132\n",
      "Epoch [312/360], Batch [145/196], Loss: 0.0145\n",
      "Epoch [312/360], Batch [150/196], Loss: 0.0139\n",
      "Epoch [312/360], Batch [155/196], Loss: 0.0107\n",
      "Epoch [312/360], Batch [160/196], Loss: 0.0238\n",
      "Epoch [312/360], Batch [165/196], Loss: 0.0253\n",
      "Epoch [312/360], Batch [170/196], Loss: 0.0143\n",
      "Epoch [312/360], Batch [175/196], Loss: 0.0102\n",
      "Epoch [312/360], Batch [180/196], Loss: 0.0129\n",
      "Epoch [312/360], Batch [185/196], Loss: 0.0335\n",
      "Epoch [312/360], Batch [190/196], Loss: 0.0096\n",
      "Epoch [312/360], Batch [195/196], Loss: 0.0129\n",
      "Epoch [313/360], Batch [5/196], Loss: 0.0149\n",
      "Epoch [313/360], Batch [10/196], Loss: 0.0210\n",
      "Epoch [313/360], Batch [15/196], Loss: 0.0191\n",
      "Epoch [313/360], Batch [20/196], Loss: 0.0179\n",
      "Epoch [313/360], Batch [25/196], Loss: 0.0163\n",
      "Epoch [313/360], Batch [30/196], Loss: 0.0330\n",
      "Epoch [313/360], Batch [35/196], Loss: 0.0182\n",
      "Epoch [313/360], Batch [40/196], Loss: 0.0101\n",
      "Epoch [313/360], Batch [45/196], Loss: 0.0376\n",
      "Epoch [313/360], Batch [50/196], Loss: 0.0193\n",
      "Epoch [313/360], Batch [55/196], Loss: 0.0115\n",
      "Epoch [313/360], Batch [60/196], Loss: 0.0210\n",
      "Epoch [313/360], Batch [65/196], Loss: 0.0142\n",
      "Epoch [313/360], Batch [70/196], Loss: 0.0142\n",
      "Epoch [313/360], Batch [75/196], Loss: 0.0195\n",
      "Epoch [313/360], Batch [80/196], Loss: 0.0183\n",
      "Epoch [313/360], Batch [85/196], Loss: 0.0223\n",
      "Epoch [313/360], Batch [90/196], Loss: 0.0286\n",
      "Epoch [313/360], Batch [95/196], Loss: 0.0149\n",
      "Epoch [313/360], Batch [100/196], Loss: 0.0175\n",
      "Epoch [313/360], Batch [105/196], Loss: 0.0187\n",
      "Epoch [313/360], Batch [110/196], Loss: 0.0244\n",
      "Epoch [313/360], Batch [115/196], Loss: 0.0198\n",
      "Epoch [313/360], Batch [120/196], Loss: 0.0177\n",
      "Epoch [313/360], Batch [125/196], Loss: 0.0200\n",
      "Epoch [313/360], Batch [130/196], Loss: 0.0249\n",
      "Epoch [313/360], Batch [135/196], Loss: 0.0183\n",
      "Epoch [313/360], Batch [140/196], Loss: 0.0266\n",
      "Epoch [313/360], Batch [145/196], Loss: 0.0150\n",
      "Epoch [313/360], Batch [150/196], Loss: 0.0218\n",
      "Epoch [313/360], Batch [155/196], Loss: 0.0205\n",
      "Epoch [313/360], Batch [160/196], Loss: 0.0250\n",
      "Epoch [313/360], Batch [165/196], Loss: 0.0228\n",
      "Epoch [313/360], Batch [170/196], Loss: 0.0184\n",
      "Epoch [313/360], Batch [175/196], Loss: 0.0143\n",
      "Epoch [313/360], Batch [180/196], Loss: 0.0257\n",
      "Epoch [313/360], Batch [185/196], Loss: 0.0170\n",
      "Epoch [313/360], Batch [190/196], Loss: 0.0118\n",
      "Epoch [313/360], Batch [195/196], Loss: 0.0192\n",
      "Epoch [314/360], Batch [5/196], Loss: 0.0101\n",
      "Epoch [314/360], Batch [10/196], Loss: 0.0180\n",
      "Epoch [314/360], Batch [15/196], Loss: 0.0237\n",
      "Epoch [314/360], Batch [20/196], Loss: 0.0275\n",
      "Epoch [314/360], Batch [25/196], Loss: 0.0146\n",
      "Epoch [314/360], Batch [30/196], Loss: 0.0102\n",
      "Epoch [314/360], Batch [35/196], Loss: 0.0152\n",
      "Epoch [314/360], Batch [40/196], Loss: 0.0118\n",
      "Epoch [314/360], Batch [45/196], Loss: 0.0253\n",
      "Epoch [314/360], Batch [50/196], Loss: 0.0142\n",
      "Epoch [314/360], Batch [55/196], Loss: 0.0179\n",
      "Epoch [314/360], Batch [60/196], Loss: 0.0159\n",
      "Epoch [314/360], Batch [65/196], Loss: 0.0157\n",
      "Epoch [314/360], Batch [70/196], Loss: 0.0151\n",
      "Epoch [314/360], Batch [75/196], Loss: 0.0129\n",
      "Epoch [314/360], Batch [80/196], Loss: 0.0113\n",
      "Epoch [314/360], Batch [85/196], Loss: 0.0123\n",
      "Epoch [314/360], Batch [90/196], Loss: 0.0165\n",
      "Epoch [314/360], Batch [95/196], Loss: 0.0174\n",
      "Epoch [314/360], Batch [100/196], Loss: 0.0113\n",
      "Epoch [314/360], Batch [105/196], Loss: 0.0141\n",
      "Epoch [314/360], Batch [110/196], Loss: 0.0301\n",
      "Epoch [314/360], Batch [115/196], Loss: 0.0127\n",
      "Epoch [314/360], Batch [120/196], Loss: 0.0163\n",
      "Epoch [314/360], Batch [125/196], Loss: 0.0227\n",
      "Epoch [314/360], Batch [130/196], Loss: 0.0261\n",
      "Epoch [314/360], Batch [135/196], Loss: 0.0167\n",
      "Epoch [314/360], Batch [140/196], Loss: 0.0158\n",
      "Epoch [314/360], Batch [145/196], Loss: 0.0312\n",
      "Epoch [314/360], Batch [150/196], Loss: 0.0288\n",
      "Epoch [314/360], Batch [155/196], Loss: 0.0192\n",
      "Epoch [314/360], Batch [160/196], Loss: 0.0193\n",
      "Epoch [314/360], Batch [165/196], Loss: 0.0290\n",
      "Epoch [314/360], Batch [170/196], Loss: 0.0279\n",
      "Epoch [314/360], Batch [175/196], Loss: 0.0210\n",
      "Epoch [314/360], Batch [180/196], Loss: 0.0176\n",
      "Epoch [314/360], Batch [185/196], Loss: 0.0240\n",
      "Epoch [314/360], Batch [190/196], Loss: 0.0223\n",
      "Epoch [314/360], Batch [195/196], Loss: 0.0125\n",
      "Epoch [315/360], Batch [5/196], Loss: 0.0266\n",
      "Epoch [315/360], Batch [10/196], Loss: 0.0231\n",
      "Epoch [315/360], Batch [15/196], Loss: 0.0235\n",
      "Epoch [315/360], Batch [20/196], Loss: 0.0241\n",
      "Epoch [315/360], Batch [25/196], Loss: 0.0189\n",
      "Epoch [315/360], Batch [30/196], Loss: 0.0211\n",
      "Epoch [315/360], Batch [35/196], Loss: 0.0218\n",
      "Epoch [315/360], Batch [40/196], Loss: 0.0213\n",
      "Epoch [315/360], Batch [45/196], Loss: 0.0137\n",
      "Epoch [315/360], Batch [50/196], Loss: 0.0263\n",
      "Epoch [315/360], Batch [55/196], Loss: 0.0170\n",
      "Epoch [315/360], Batch [60/196], Loss: 0.0174\n",
      "Epoch [315/360], Batch [65/196], Loss: 0.0126\n",
      "Epoch [315/360], Batch [70/196], Loss: 0.0324\n",
      "Epoch [315/360], Batch [75/196], Loss: 0.0160\n",
      "Epoch [315/360], Batch [80/196], Loss: 0.0241\n",
      "Epoch [315/360], Batch [85/196], Loss: 0.0276\n",
      "Epoch [315/360], Batch [90/196], Loss: 0.0183\n",
      "Epoch [315/360], Batch [95/196], Loss: 0.0198\n",
      "Epoch [315/360], Batch [100/196], Loss: 0.0197\n",
      "Epoch [315/360], Batch [105/196], Loss: 0.0148\n",
      "Epoch [315/360], Batch [110/196], Loss: 0.0202\n",
      "Epoch [315/360], Batch [115/196], Loss: 0.0296\n",
      "Epoch [315/360], Batch [120/196], Loss: 0.0170\n",
      "Epoch [315/360], Batch [125/196], Loss: 0.0223\n",
      "Epoch [315/360], Batch [130/196], Loss: 0.0200\n",
      "Epoch [315/360], Batch [135/196], Loss: 0.0153\n",
      "Epoch [315/360], Batch [140/196], Loss: 0.0124\n",
      "Epoch [315/360], Batch [145/196], Loss: 0.0215\n",
      "Epoch [315/360], Batch [150/196], Loss: 0.0172\n",
      "Epoch [315/360], Batch [155/196], Loss: 0.0247\n",
      "Epoch [315/360], Batch [160/196], Loss: 0.0221\n",
      "Epoch [315/360], Batch [165/196], Loss: 0.0384\n",
      "Epoch [315/360], Batch [170/196], Loss: 0.0719\n",
      "Epoch [315/360], Batch [175/196], Loss: 0.2214\n",
      "Epoch [315/360], Batch [180/196], Loss: 0.1568\n",
      "Epoch [315/360], Batch [185/196], Loss: 0.0790\n",
      "Epoch [315/360], Batch [190/196], Loss: 0.0974\n",
      "Epoch [315/360], Batch [195/196], Loss: 0.0852\n",
      "Epoch [316/360], Batch [5/196], Loss: 0.1126\n",
      "Epoch [316/360], Batch [10/196], Loss: 0.0909\n",
      "Epoch [316/360], Batch [15/196], Loss: 0.0748\n",
      "Epoch [316/360], Batch [20/196], Loss: 0.0777\n",
      "Epoch [316/360], Batch [25/196], Loss: 0.0370\n",
      "Epoch [316/360], Batch [30/196], Loss: 0.0693\n",
      "Epoch [316/360], Batch [35/196], Loss: 0.0969\n",
      "Epoch [316/360], Batch [40/196], Loss: 0.0459\n",
      "Epoch [316/360], Batch [45/196], Loss: 0.0603\n",
      "Epoch [316/360], Batch [50/196], Loss: 0.0641\n",
      "Epoch [316/360], Batch [55/196], Loss: 0.0804\n",
      "Epoch [316/360], Batch [60/196], Loss: 0.0533\n",
      "Epoch [316/360], Batch [65/196], Loss: 0.0473\n",
      "Epoch [316/360], Batch [70/196], Loss: 0.0613\n",
      "Epoch [316/360], Batch [75/196], Loss: 0.0624\n",
      "Epoch [316/360], Batch [80/196], Loss: 0.0561\n",
      "Epoch [316/360], Batch [85/196], Loss: 0.0522\n",
      "Epoch [316/360], Batch [90/196], Loss: 0.0404\n",
      "Epoch [316/360], Batch [95/196], Loss: 0.0406\n",
      "Epoch [316/360], Batch [100/196], Loss: 0.0428\n",
      "Epoch [316/360], Batch [105/196], Loss: 0.0328\n",
      "Epoch [316/360], Batch [110/196], Loss: 0.0376\n",
      "Epoch [316/360], Batch [115/196], Loss: 0.0509\n",
      "Epoch [316/360], Batch [120/196], Loss: 0.0478\n",
      "Epoch [316/360], Batch [125/196], Loss: 0.0453\n",
      "Epoch [316/360], Batch [130/196], Loss: 0.0452\n",
      "Epoch [316/360], Batch [135/196], Loss: 0.0438\n",
      "Epoch [316/360], Batch [140/196], Loss: 0.0612\n",
      "Epoch [316/360], Batch [145/196], Loss: 0.0490\n",
      "Epoch [316/360], Batch [150/196], Loss: 0.0432\n",
      "Epoch [316/360], Batch [155/196], Loss: 0.0569\n",
      "Epoch [316/360], Batch [160/196], Loss: 0.0452\n",
      "Epoch [316/360], Batch [165/196], Loss: 0.0461\n",
      "Epoch [316/360], Batch [170/196], Loss: 0.0362\n",
      "Epoch [316/360], Batch [175/196], Loss: 0.0453\n",
      "Epoch [316/360], Batch [180/196], Loss: 0.0391\n",
      "Epoch [316/360], Batch [185/196], Loss: 0.0326\n",
      "Epoch [316/360], Batch [190/196], Loss: 0.0572\n",
      "Epoch [316/360], Batch [195/196], Loss: 0.0469\n",
      "Epoch [317/360], Batch [5/196], Loss: 0.0279\n",
      "Epoch [317/360], Batch [10/196], Loss: 0.0466\n",
      "Epoch [317/360], Batch [15/196], Loss: 0.0403\n",
      "Epoch [317/360], Batch [20/196], Loss: 0.0356\n",
      "Epoch [317/360], Batch [25/196], Loss: 0.0483\n",
      "Epoch [317/360], Batch [30/196], Loss: 0.0485\n",
      "Epoch [317/360], Batch [35/196], Loss: 0.0348\n",
      "Epoch [317/360], Batch [40/196], Loss: 0.0588\n",
      "Epoch [317/360], Batch [45/196], Loss: 0.0343\n",
      "Epoch [317/360], Batch [50/196], Loss: 0.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [317/360], Batch [55/196], Loss: 0.0266\n",
      "Epoch [317/360], Batch [60/196], Loss: 0.0285\n",
      "Epoch [317/360], Batch [65/196], Loss: 0.0235\n",
      "Epoch [317/360], Batch [70/196], Loss: 0.0367\n",
      "Epoch [317/360], Batch [75/196], Loss: 0.0441\n",
      "Epoch [317/360], Batch [80/196], Loss: 0.0284\n",
      "Epoch [317/360], Batch [85/196], Loss: 0.0308\n",
      "Epoch [317/360], Batch [90/196], Loss: 0.0464\n",
      "Epoch [317/360], Batch [95/196], Loss: 0.0362\n",
      "Epoch [317/360], Batch [100/196], Loss: 0.0341\n",
      "Epoch [317/360], Batch [105/196], Loss: 0.0257\n",
      "Epoch [317/360], Batch [110/196], Loss: 0.0438\n",
      "Epoch [317/360], Batch [115/196], Loss: 0.0247\n",
      "Epoch [317/360], Batch [120/196], Loss: 0.0309\n",
      "Epoch [317/360], Batch [125/196], Loss: 0.0455\n",
      "Epoch [317/360], Batch [130/196], Loss: 0.0205\n",
      "Epoch [317/360], Batch [135/196], Loss: 0.0230\n",
      "Epoch [317/360], Batch [140/196], Loss: 0.0330\n",
      "Epoch [317/360], Batch [145/196], Loss: 0.0219\n",
      "Epoch [317/360], Batch [150/196], Loss: 0.0372\n",
      "Epoch [317/360], Batch [155/196], Loss: 0.0267\n",
      "Epoch [317/360], Batch [160/196], Loss: 0.0269\n",
      "Epoch [317/360], Batch [165/196], Loss: 0.0245\n",
      "Epoch [317/360], Batch [170/196], Loss: 0.0290\n",
      "Epoch [317/360], Batch [175/196], Loss: 0.0301\n",
      "Epoch [317/360], Batch [180/196], Loss: 0.0214\n",
      "Epoch [317/360], Batch [185/196], Loss: 0.0350\n",
      "Epoch [317/360], Batch [190/196], Loss: 0.0410\n",
      "Epoch [317/360], Batch [195/196], Loss: 0.0249\n",
      "Epoch [318/360], Batch [5/196], Loss: 0.0240\n",
      "Epoch [318/360], Batch [10/196], Loss: 0.0155\n",
      "Epoch [318/360], Batch [15/196], Loss: 0.0169\n",
      "Epoch [318/360], Batch [20/196], Loss: 0.0139\n",
      "Epoch [318/360], Batch [25/196], Loss: 0.0200\n",
      "Epoch [318/360], Batch [30/196], Loss: 0.0353\n",
      "Epoch [318/360], Batch [35/196], Loss: 0.0187\n",
      "Epoch [318/360], Batch [40/196], Loss: 0.0157\n",
      "Epoch [318/360], Batch [45/196], Loss: 0.0162\n",
      "Epoch [318/360], Batch [50/196], Loss: 0.0168\n",
      "Epoch [318/360], Batch [55/196], Loss: 0.0181\n",
      "Epoch [318/360], Batch [60/196], Loss: 0.0154\n",
      "Epoch [318/360], Batch [65/196], Loss: 0.0144\n",
      "Epoch [318/360], Batch [70/196], Loss: 0.0158\n",
      "Epoch [318/360], Batch [75/196], Loss: 0.0197\n",
      "Epoch [318/360], Batch [80/196], Loss: 0.0206\n",
      "Epoch [318/360], Batch [85/196], Loss: 0.0213\n",
      "Epoch [318/360], Batch [90/196], Loss: 0.0178\n",
      "Epoch [318/360], Batch [95/196], Loss: 0.0181\n",
      "Epoch [318/360], Batch [100/196], Loss: 0.0164\n",
      "Epoch [318/360], Batch [105/196], Loss: 0.0145\n",
      "Epoch [318/360], Batch [110/196], Loss: 0.0227\n",
      "Epoch [318/360], Batch [115/196], Loss: 0.0318\n",
      "Epoch [318/360], Batch [120/196], Loss: 0.0166\n",
      "Epoch [318/360], Batch [125/196], Loss: 0.0171\n",
      "Epoch [318/360], Batch [130/196], Loss: 0.0137\n",
      "Epoch [318/360], Batch [135/196], Loss: 0.0193\n",
      "Epoch [318/360], Batch [140/196], Loss: 0.0230\n",
      "Epoch [318/360], Batch [145/196], Loss: 0.0193\n",
      "Epoch [318/360], Batch [150/196], Loss: 0.0115\n",
      "Epoch [318/360], Batch [155/196], Loss: 0.0163\n",
      "Epoch [318/360], Batch [160/196], Loss: 0.0149\n",
      "Epoch [318/360], Batch [165/196], Loss: 0.0149\n",
      "Epoch [318/360], Batch [170/196], Loss: 0.0076\n",
      "Epoch [318/360], Batch [175/196], Loss: 0.0171\n",
      "Epoch [318/360], Batch [180/196], Loss: 0.0143\n",
      "Epoch [318/360], Batch [185/196], Loss: 0.0149\n",
      "Epoch [318/360], Batch [190/196], Loss: 0.0127\n",
      "Epoch [318/360], Batch [195/196], Loss: 0.0175\n",
      "Epoch [319/360], Batch [5/196], Loss: 0.0147\n",
      "Epoch [319/360], Batch [10/196], Loss: 0.0091\n",
      "Epoch [319/360], Batch [15/196], Loss: 0.0116\n",
      "Epoch [319/360], Batch [20/196], Loss: 0.0121\n",
      "Epoch [319/360], Batch [25/196], Loss: 0.0095\n",
      "Epoch [319/360], Batch [30/196], Loss: 0.0065\n",
      "Epoch [319/360], Batch [35/196], Loss: 0.0109\n",
      "Epoch [319/360], Batch [40/196], Loss: 0.0141\n",
      "Epoch [319/360], Batch [45/196], Loss: 0.0134\n",
      "Epoch [319/360], Batch [50/196], Loss: 0.0111\n",
      "Epoch [319/360], Batch [55/196], Loss: 0.0080\n",
      "Epoch [319/360], Batch [60/196], Loss: 0.0356\n",
      "Epoch [319/360], Batch [65/196], Loss: 0.0103\n",
      "Epoch [319/360], Batch [70/196], Loss: 0.0139\n",
      "Epoch [319/360], Batch [75/196], Loss: 0.0143\n",
      "Epoch [319/360], Batch [80/196], Loss: 0.0101\n",
      "Epoch [319/360], Batch [85/196], Loss: 0.0140\n",
      "Epoch [319/360], Batch [90/196], Loss: 0.0083\n",
      "Epoch [319/360], Batch [95/196], Loss: 0.0096\n",
      "Epoch [319/360], Batch [100/196], Loss: 0.0108\n",
      "Epoch [319/360], Batch [105/196], Loss: 0.0085\n",
      "Epoch [319/360], Batch [110/196], Loss: 0.0125\n",
      "Epoch [319/360], Batch [115/196], Loss: 0.0084\n",
      "Epoch [319/360], Batch [120/196], Loss: 0.0071\n",
      "Epoch [319/360], Batch [125/196], Loss: 0.0071\n",
      "Epoch [319/360], Batch [130/196], Loss: 0.0123\n",
      "Epoch [319/360], Batch [135/196], Loss: 0.0097\n",
      "Epoch [319/360], Batch [140/196], Loss: 0.0099\n",
      "Epoch [319/360], Batch [145/196], Loss: 0.0099\n",
      "Epoch [319/360], Batch [150/196], Loss: 0.0092\n",
      "Epoch [319/360], Batch [155/196], Loss: 0.0081\n",
      "Epoch [319/360], Batch [160/196], Loss: 0.0192\n",
      "Epoch [319/360], Batch [165/196], Loss: 0.0059\n",
      "Epoch [319/360], Batch [170/196], Loss: 0.0082\n",
      "Epoch [319/360], Batch [175/196], Loss: 0.0100\n",
      "Epoch [319/360], Batch [180/196], Loss: 0.0181\n",
      "Epoch [319/360], Batch [185/196], Loss: 0.0118\n",
      "Epoch [319/360], Batch [190/196], Loss: 0.0107\n",
      "Epoch [319/360], Batch [195/196], Loss: 0.0084\n",
      "Epoch [320/360], Batch [5/196], Loss: 0.0061\n",
      "Epoch [320/360], Batch [10/196], Loss: 0.0076\n",
      "Epoch [320/360], Batch [15/196], Loss: 0.0075\n",
      "Epoch [320/360], Batch [20/196], Loss: 0.0125\n",
      "Epoch [320/360], Batch [25/196], Loss: 0.0047\n",
      "Epoch [320/360], Batch [30/196], Loss: 0.0062\n",
      "Epoch [320/360], Batch [35/196], Loss: 0.0058\n",
      "Epoch [320/360], Batch [40/196], Loss: 0.0056\n",
      "Epoch [320/360], Batch [45/196], Loss: 0.0086\n",
      "Epoch [320/360], Batch [50/196], Loss: 0.0182\n",
      "Epoch [320/360], Batch [55/196], Loss: 0.0280\n",
      "Epoch [320/360], Batch [60/196], Loss: 0.0147\n",
      "Epoch [320/360], Batch [65/196], Loss: 0.0253\n",
      "Epoch [320/360], Batch [70/196], Loss: 0.0163\n",
      "Epoch [320/360], Batch [75/196], Loss: 0.0185\n",
      "Epoch [320/360], Batch [80/196], Loss: 0.0169\n",
      "Epoch [320/360], Batch [85/196], Loss: 0.0250\n",
      "Epoch [320/360], Batch [90/196], Loss: 0.0131\n",
      "Epoch [320/360], Batch [95/196], Loss: 0.0176\n",
      "Epoch [320/360], Batch [100/196], Loss: 0.0170\n",
      "Epoch [320/360], Batch [105/196], Loss: 0.0110\n",
      "Epoch [320/360], Batch [110/196], Loss: 0.0120\n",
      "Epoch [320/360], Batch [115/196], Loss: 0.0178\n",
      "Epoch [320/360], Batch [120/196], Loss: 0.0083\n",
      "Epoch [320/360], Batch [125/196], Loss: 0.0121\n",
      "Epoch [320/360], Batch [130/196], Loss: 0.0171\n",
      "Epoch [320/360], Batch [135/196], Loss: 0.0152\n",
      "Epoch [320/360], Batch [140/196], Loss: 0.0123\n",
      "Epoch [320/360], Batch [145/196], Loss: 0.0078\n",
      "Epoch [320/360], Batch [150/196], Loss: 0.0091\n",
      "Epoch [320/360], Batch [155/196], Loss: 0.0076\n",
      "Epoch [320/360], Batch [160/196], Loss: 0.0169\n",
      "Epoch [320/360], Batch [165/196], Loss: 0.0136\n",
      "Epoch [320/360], Batch [170/196], Loss: 0.0208\n",
      "Epoch [320/360], Batch [175/196], Loss: 0.0113\n",
      "Epoch [320/360], Batch [180/196], Loss: 0.0097\n",
      "Epoch [320/360], Batch [185/196], Loss: 0.0078\n",
      "Epoch [320/360], Batch [190/196], Loss: 0.0117\n",
      "Epoch [320/360], Batch [195/196], Loss: 0.0125\n",
      "Epoch [321/360], Batch [5/196], Loss: 0.0071\n",
      "Epoch [321/360], Batch [10/196], Loss: 0.0088\n",
      "Epoch [321/360], Batch [15/196], Loss: 0.0097\n",
      "Epoch [321/360], Batch [20/196], Loss: 0.0115\n",
      "Epoch [321/360], Batch [25/196], Loss: 0.0076\n",
      "Epoch [321/360], Batch [30/196], Loss: 0.0106\n",
      "Epoch [321/360], Batch [35/196], Loss: 0.0118\n",
      "Epoch [321/360], Batch [40/196], Loss: 0.0109\n",
      "Epoch [321/360], Batch [45/196], Loss: 0.0229\n",
      "Epoch [321/360], Batch [50/196], Loss: 0.0167\n",
      "Epoch [321/360], Batch [55/196], Loss: 0.0216\n",
      "Epoch [321/360], Batch [60/196], Loss: 0.0125\n",
      "Epoch [321/360], Batch [65/196], Loss: 0.0156\n",
      "Epoch [321/360], Batch [70/196], Loss: 0.0140\n",
      "Epoch [321/360], Batch [75/196], Loss: 0.0169\n",
      "Epoch [321/360], Batch [80/196], Loss: 0.0198\n",
      "Epoch [321/360], Batch [85/196], Loss: 0.0133\n",
      "Epoch [321/360], Batch [90/196], Loss: 0.0102\n",
      "Epoch [321/360], Batch [95/196], Loss: 0.0156\n",
      "Epoch [321/360], Batch [100/196], Loss: 0.0136\n",
      "Epoch [321/360], Batch [105/196], Loss: 0.0158\n",
      "Epoch [321/360], Batch [110/196], Loss: 0.0129\n",
      "Epoch [321/360], Batch [115/196], Loss: 0.0129\n",
      "Epoch [321/360], Batch [120/196], Loss: 0.0138\n",
      "Epoch [321/360], Batch [125/196], Loss: 0.0106\n",
      "Epoch [321/360], Batch [130/196], Loss: 0.0138\n",
      "Epoch [321/360], Batch [135/196], Loss: 0.0174\n",
      "Epoch [321/360], Batch [140/196], Loss: 0.0116\n",
      "Epoch [321/360], Batch [145/196], Loss: 0.0089\n",
      "Epoch [321/360], Batch [150/196], Loss: 0.0180\n",
      "Epoch [321/360], Batch [155/196], Loss: 0.0083\n",
      "Epoch [321/360], Batch [160/196], Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [321/360], Batch [165/196], Loss: 0.0104\n",
      "Epoch [321/360], Batch [170/196], Loss: 0.0100\n",
      "Epoch [321/360], Batch [175/196], Loss: 0.0135\n",
      "Epoch [321/360], Batch [180/196], Loss: 0.0112\n",
      "Epoch [321/360], Batch [185/196], Loss: 0.0115\n",
      "Epoch [321/360], Batch [190/196], Loss: 0.0160\n",
      "Epoch [321/360], Batch [195/196], Loss: 0.0098\n",
      "Epoch [322/360], Batch [5/196], Loss: 0.0091\n",
      "Epoch [322/360], Batch [10/196], Loss: 0.0093\n",
      "Epoch [322/360], Batch [15/196], Loss: 0.0071\n",
      "Epoch [322/360], Batch [20/196], Loss: 0.0171\n",
      "Epoch [322/360], Batch [25/196], Loss: 0.0108\n",
      "Epoch [322/360], Batch [30/196], Loss: 0.0111\n",
      "Epoch [322/360], Batch [35/196], Loss: 0.0106\n",
      "Epoch [322/360], Batch [40/196], Loss: 0.0134\n",
      "Epoch [322/360], Batch [45/196], Loss: 0.0110\n",
      "Epoch [322/360], Batch [50/196], Loss: 0.0113\n",
      "Epoch [322/360], Batch [55/196], Loss: 0.0149\n",
      "Epoch [322/360], Batch [60/196], Loss: 0.0173\n",
      "Epoch [322/360], Batch [65/196], Loss: 0.0163\n",
      "Epoch [322/360], Batch [70/196], Loss: 0.0098\n",
      "Epoch [322/360], Batch [75/196], Loss: 0.0178\n",
      "Epoch [322/360], Batch [80/196], Loss: 0.0083\n",
      "Epoch [322/360], Batch [85/196], Loss: 0.0237\n",
      "Epoch [322/360], Batch [90/196], Loss: 0.0133\n",
      "Epoch [322/360], Batch [95/196], Loss: 0.0192\n",
      "Epoch [322/360], Batch [100/196], Loss: 0.0189\n",
      "Epoch [322/360], Batch [105/196], Loss: 0.0196\n",
      "Epoch [322/360], Batch [110/196], Loss: 0.0240\n",
      "Epoch [322/360], Batch [115/196], Loss: 0.0283\n",
      "Epoch [322/360], Batch [120/196], Loss: 0.0198\n",
      "Epoch [322/360], Batch [125/196], Loss: 0.0195\n",
      "Epoch [322/360], Batch [130/196], Loss: 0.0283\n",
      "Epoch [322/360], Batch [135/196], Loss: 0.0168\n",
      "Epoch [322/360], Batch [140/196], Loss: 0.0169\n",
      "Epoch [322/360], Batch [145/196], Loss: 0.0142\n",
      "Epoch [322/360], Batch [150/196], Loss: 0.0074\n",
      "Epoch [322/360], Batch [155/196], Loss: 0.0121\n",
      "Epoch [322/360], Batch [160/196], Loss: 0.0129\n",
      "Epoch [322/360], Batch [165/196], Loss: 0.0141\n",
      "Epoch [322/360], Batch [170/196], Loss: 0.0221\n",
      "Epoch [322/360], Batch [175/196], Loss: 0.0149\n",
      "Epoch [322/360], Batch [180/196], Loss: 0.0156\n",
      "Epoch [322/360], Batch [185/196], Loss: 0.0110\n",
      "Epoch [322/360], Batch [190/196], Loss: 0.0141\n",
      "Epoch [322/360], Batch [195/196], Loss: 0.0155\n",
      "Epoch [323/360], Batch [5/196], Loss: 0.0312\n",
      "Epoch [323/360], Batch [10/196], Loss: 0.0247\n",
      "Epoch [323/360], Batch [15/196], Loss: 0.0207\n",
      "Epoch [323/360], Batch [20/196], Loss: 0.0259\n",
      "Epoch [323/360], Batch [25/196], Loss: 0.0189\n",
      "Epoch [323/360], Batch [30/196], Loss: 0.0125\n",
      "Epoch [323/360], Batch [35/196], Loss: 0.0180\n",
      "Epoch [323/360], Batch [40/196], Loss: 0.0184\n",
      "Epoch [323/360], Batch [45/196], Loss: 0.0148\n",
      "Epoch [323/360], Batch [50/196], Loss: 0.0128\n",
      "Epoch [323/360], Batch [55/196], Loss: 0.0191\n",
      "Epoch [323/360], Batch [60/196], Loss: 0.0343\n",
      "Epoch [323/360], Batch [65/196], Loss: 0.0192\n",
      "Epoch [323/360], Batch [70/196], Loss: 0.0148\n",
      "Epoch [323/360], Batch [75/196], Loss: 0.0327\n",
      "Epoch [323/360], Batch [80/196], Loss: 0.0211\n",
      "Epoch [323/360], Batch [85/196], Loss: 0.0207\n",
      "Epoch [323/360], Batch [90/196], Loss: 0.0137\n",
      "Epoch [323/360], Batch [95/196], Loss: 0.0150\n",
      "Epoch [323/360], Batch [100/196], Loss: 0.0127\n",
      "Epoch [323/360], Batch [105/196], Loss: 0.0159\n",
      "Epoch [323/360], Batch [110/196], Loss: 0.0134\n",
      "Epoch [323/360], Batch [115/196], Loss: 0.0163\n",
      "Epoch [323/360], Batch [120/196], Loss: 0.0097\n",
      "Epoch [323/360], Batch [125/196], Loss: 0.0126\n",
      "Epoch [323/360], Batch [130/196], Loss: 0.0148\n",
      "Epoch [323/360], Batch [135/196], Loss: 0.0233\n",
      "Epoch [323/360], Batch [140/196], Loss: 0.0229\n",
      "Epoch [323/360], Batch [145/196], Loss: 0.0231\n",
      "Epoch [323/360], Batch [150/196], Loss: 0.0131\n",
      "Epoch [323/360], Batch [155/196], Loss: 0.0175\n",
      "Epoch [323/360], Batch [160/196], Loss: 0.0176\n",
      "Epoch [323/360], Batch [165/196], Loss: 0.0144\n",
      "Epoch [323/360], Batch [170/196], Loss: 0.0143\n",
      "Epoch [323/360], Batch [175/196], Loss: 0.0218\n",
      "Epoch [323/360], Batch [180/196], Loss: 0.0167\n",
      "Epoch [323/360], Batch [185/196], Loss: 0.0154\n",
      "Epoch [323/360], Batch [190/196], Loss: 0.0121\n",
      "Epoch [323/360], Batch [195/196], Loss: 0.0154\n",
      "Epoch [324/360], Batch [5/196], Loss: 0.0092\n",
      "Epoch [324/360], Batch [10/196], Loss: 0.0111\n",
      "Epoch [324/360], Batch [15/196], Loss: 0.0184\n",
      "Epoch [324/360], Batch [20/196], Loss: 0.0159\n",
      "Epoch [324/360], Batch [25/196], Loss: 0.0153\n",
      "Epoch [324/360], Batch [30/196], Loss: 0.0178\n",
      "Epoch [324/360], Batch [35/196], Loss: 0.0133\n",
      "Epoch [324/360], Batch [40/196], Loss: 0.0212\n",
      "Epoch [324/360], Batch [45/196], Loss: 0.0139\n",
      "Epoch [324/360], Batch [50/196], Loss: 0.0187\n",
      "Epoch [324/360], Batch [55/196], Loss: 0.0157\n",
      "Epoch [324/360], Batch [60/196], Loss: 0.0201\n",
      "Epoch [324/360], Batch [65/196], Loss: 0.0094\n",
      "Epoch [324/360], Batch [70/196], Loss: 0.0104\n",
      "Epoch [324/360], Batch [75/196], Loss: 0.0206\n",
      "Epoch [324/360], Batch [80/196], Loss: 0.0088\n",
      "Epoch [324/360], Batch [85/196], Loss: 0.0161\n",
      "Epoch [324/360], Batch [90/196], Loss: 0.0203\n",
      "Epoch [324/360], Batch [95/196], Loss: 0.0142\n",
      "Epoch [324/360], Batch [100/196], Loss: 0.0108\n",
      "Epoch [324/360], Batch [105/196], Loss: 0.0181\n",
      "Epoch [324/360], Batch [110/196], Loss: 0.0152\n",
      "Epoch [324/360], Batch [115/196], Loss: 0.0117\n",
      "Epoch [324/360], Batch [120/196], Loss: 0.0116\n",
      "Epoch [324/360], Batch [125/196], Loss: 0.0145\n",
      "Epoch [324/360], Batch [130/196], Loss: 0.0180\n",
      "Epoch [324/360], Batch [135/196], Loss: 0.0196\n",
      "Epoch [324/360], Batch [140/196], Loss: 0.0207\n",
      "Epoch [324/360], Batch [145/196], Loss: 0.0135\n",
      "Epoch [324/360], Batch [150/196], Loss: 0.0155\n",
      "Epoch [324/360], Batch [155/196], Loss: 0.0147\n",
      "Epoch [324/360], Batch [160/196], Loss: 0.0141\n",
      "Epoch [324/360], Batch [165/196], Loss: 0.0180\n",
      "Epoch [324/360], Batch [170/196], Loss: 0.0162\n",
      "Epoch [324/360], Batch [175/196], Loss: 0.0172\n",
      "Epoch [324/360], Batch [180/196], Loss: 0.0186\n",
      "Epoch [324/360], Batch [185/196], Loss: 0.0184\n",
      "Epoch [324/360], Batch [190/196], Loss: 0.0190\n",
      "Epoch [324/360], Batch [195/196], Loss: 0.0162\n",
      "Epoch [325/360], Batch [5/196], Loss: 0.0173\n",
      "Epoch [325/360], Batch [10/196], Loss: 0.0187\n",
      "Epoch [325/360], Batch [15/196], Loss: 0.0198\n",
      "Epoch [325/360], Batch [20/196], Loss: 0.0181\n",
      "Epoch [325/360], Batch [25/196], Loss: 0.0176\n",
      "Epoch [325/360], Batch [30/196], Loss: 0.0142\n",
      "Epoch [325/360], Batch [35/196], Loss: 0.0294\n",
      "Epoch [325/360], Batch [40/196], Loss: 0.0228\n",
      "Epoch [325/360], Batch [45/196], Loss: 0.0137\n",
      "Epoch [325/360], Batch [50/196], Loss: 0.0192\n",
      "Epoch [325/360], Batch [55/196], Loss: 0.0306\n",
      "Epoch [325/360], Batch [60/196], Loss: 0.0164\n",
      "Epoch [325/360], Batch [65/196], Loss: 0.0221\n",
      "Epoch [325/360], Batch [70/196], Loss: 0.0137\n",
      "Epoch [325/360], Batch [75/196], Loss: 0.0190\n",
      "Epoch [325/360], Batch [80/196], Loss: 0.0202\n",
      "Epoch [325/360], Batch [85/196], Loss: 0.0188\n",
      "Epoch [325/360], Batch [90/196], Loss: 0.0192\n",
      "Epoch [325/360], Batch [95/196], Loss: 0.0239\n",
      "Epoch [325/360], Batch [100/196], Loss: 0.0180\n",
      "Epoch [325/360], Batch [105/196], Loss: 0.0146\n",
      "Epoch [325/360], Batch [110/196], Loss: 0.0199\n",
      "Epoch [325/360], Batch [115/196], Loss: 0.0403\n",
      "Epoch [325/360], Batch [120/196], Loss: 0.0241\n",
      "Epoch [325/360], Batch [125/196], Loss: 0.0199\n",
      "Epoch [325/360], Batch [130/196], Loss: 0.0230\n",
      "Epoch [325/360], Batch [135/196], Loss: 0.0154\n",
      "Epoch [325/360], Batch [140/196], Loss: 0.0178\n",
      "Epoch [325/360], Batch [145/196], Loss: 0.0191\n",
      "Epoch [325/360], Batch [150/196], Loss: 0.0145\n",
      "Epoch [325/360], Batch [155/196], Loss: 0.0233\n",
      "Epoch [325/360], Batch [160/196], Loss: 0.0215\n",
      "Epoch [325/360], Batch [165/196], Loss: 0.0220\n",
      "Epoch [325/360], Batch [170/196], Loss: 0.0162\n",
      "Epoch [325/360], Batch [175/196], Loss: 0.0172\n",
      "Epoch [325/360], Batch [180/196], Loss: 0.0276\n",
      "Epoch [325/360], Batch [185/196], Loss: 0.0171\n",
      "Epoch [325/360], Batch [190/196], Loss: 0.0197\n",
      "Epoch [325/360], Batch [195/196], Loss: 0.0178\n",
      "Epoch [326/360], Batch [5/196], Loss: 0.0418\n",
      "Epoch [326/360], Batch [10/196], Loss: 0.0243\n",
      "Epoch [326/360], Batch [15/196], Loss: 0.0222\n",
      "Epoch [326/360], Batch [20/196], Loss: 0.0165\n",
      "Epoch [326/360], Batch [25/196], Loss: 0.0389\n",
      "Epoch [326/360], Batch [30/196], Loss: 0.0237\n",
      "Epoch [326/360], Batch [35/196], Loss: 0.0198\n",
      "Epoch [326/360], Batch [40/196], Loss: 0.0241\n",
      "Epoch [326/360], Batch [45/196], Loss: 0.0268\n",
      "Epoch [326/360], Batch [50/196], Loss: 0.0242\n",
      "Epoch [326/360], Batch [55/196], Loss: 0.0217\n",
      "Epoch [326/360], Batch [60/196], Loss: 0.0313\n",
      "Epoch [326/360], Batch [65/196], Loss: 0.0240\n",
      "Epoch [326/360], Batch [70/196], Loss: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/360], Batch [75/196], Loss: 0.0211\n",
      "Epoch [326/360], Batch [80/196], Loss: 0.0358\n",
      "Epoch [326/360], Batch [85/196], Loss: 0.0192\n",
      "Epoch [326/360], Batch [90/196], Loss: 0.0222\n",
      "Epoch [326/360], Batch [95/196], Loss: 0.0240\n",
      "Epoch [326/360], Batch [100/196], Loss: 0.0213\n",
      "Epoch [326/360], Batch [105/196], Loss: 0.0213\n",
      "Epoch [326/360], Batch [110/196], Loss: 0.0209\n",
      "Epoch [326/360], Batch [115/196], Loss: 0.0328\n",
      "Epoch [326/360], Batch [120/196], Loss: 0.0163\n",
      "Epoch [326/360], Batch [125/196], Loss: 0.0271\n",
      "Epoch [326/360], Batch [130/196], Loss: 0.0290\n",
      "Epoch [326/360], Batch [135/196], Loss: 0.0207\n",
      "Epoch [326/360], Batch [140/196], Loss: 0.0254\n",
      "Epoch [326/360], Batch [145/196], Loss: 0.0219\n",
      "Epoch [326/360], Batch [150/196], Loss: 0.0183\n",
      "Epoch [326/360], Batch [155/196], Loss: 0.0261\n",
      "Epoch [326/360], Batch [160/196], Loss: 0.0215\n",
      "Epoch [326/360], Batch [165/196], Loss: 0.0252\n",
      "Epoch [326/360], Batch [170/196], Loss: 0.0212\n",
      "Epoch [326/360], Batch [175/196], Loss: 0.0219\n",
      "Epoch [326/360], Batch [180/196], Loss: 0.0164\n",
      "Epoch [326/360], Batch [185/196], Loss: 0.0165\n",
      "Epoch [326/360], Batch [190/196], Loss: 0.0428\n",
      "Epoch [326/360], Batch [195/196], Loss: 0.0194\n",
      "Epoch [327/360], Batch [5/196], Loss: 0.0156\n",
      "Epoch [327/360], Batch [10/196], Loss: 0.0220\n",
      "Epoch [327/360], Batch [15/196], Loss: 0.0348\n",
      "Epoch [327/360], Batch [20/196], Loss: 0.0232\n",
      "Epoch [327/360], Batch [25/196], Loss: 0.0138\n",
      "Epoch [327/360], Batch [30/196], Loss: 0.0252\n",
      "Epoch [327/360], Batch [35/196], Loss: 0.0300\n",
      "Epoch [327/360], Batch [40/196], Loss: 0.0179\n",
      "Epoch [327/360], Batch [45/196], Loss: 0.0188\n",
      "Epoch [327/360], Batch [50/196], Loss: 0.0244\n",
      "Epoch [327/360], Batch [55/196], Loss: 0.0169\n",
      "Epoch [327/360], Batch [60/196], Loss: 0.0195\n",
      "Epoch [327/360], Batch [65/196], Loss: 0.0127\n",
      "Epoch [327/360], Batch [70/196], Loss: 0.0280\n",
      "Epoch [327/360], Batch [75/196], Loss: 0.0164\n",
      "Epoch [327/360], Batch [80/196], Loss: 0.0274\n",
      "Epoch [327/360], Batch [85/196], Loss: 0.0219\n",
      "Epoch [327/360], Batch [90/196], Loss: 0.0148\n",
      "Epoch [327/360], Batch [95/196], Loss: 0.0123\n",
      "Epoch [327/360], Batch [100/196], Loss: 0.0196\n",
      "Epoch [327/360], Batch [105/196], Loss: 0.0182\n",
      "Epoch [327/360], Batch [110/196], Loss: 0.0234\n",
      "Epoch [327/360], Batch [115/196], Loss: 0.0175\n",
      "Epoch [327/360], Batch [120/196], Loss: 0.0188\n",
      "Epoch [327/360], Batch [125/196], Loss: 0.0177\n",
      "Epoch [327/360], Batch [130/196], Loss: 0.0231\n",
      "Epoch [327/360], Batch [135/196], Loss: 0.0191\n",
      "Epoch [327/360], Batch [140/196], Loss: 0.0214\n",
      "Epoch [327/360], Batch [145/196], Loss: 0.0183\n",
      "Epoch [327/360], Batch [150/196], Loss: 0.0115\n",
      "Epoch [327/360], Batch [155/196], Loss: 0.0238\n",
      "Epoch [327/360], Batch [160/196], Loss: 0.0209\n",
      "Epoch [327/360], Batch [165/196], Loss: 0.0124\n",
      "Epoch [327/360], Batch [170/196], Loss: 0.0219\n",
      "Epoch [327/360], Batch [175/196], Loss: 0.0252\n",
      "Epoch [327/360], Batch [180/196], Loss: 0.0156\n",
      "Epoch [327/360], Batch [185/196], Loss: 0.0266\n",
      "Epoch [327/360], Batch [190/196], Loss: 0.0195\n",
      "Epoch [327/360], Batch [195/196], Loss: 0.0254\n",
      "Epoch [328/360], Batch [5/196], Loss: 0.0194\n",
      "Epoch [328/360], Batch [10/196], Loss: 0.0145\n",
      "Epoch [328/360], Batch [15/196], Loss: 0.0327\n",
      "Epoch [328/360], Batch [20/196], Loss: 0.0178\n",
      "Epoch [328/360], Batch [25/196], Loss: 0.0160\n",
      "Epoch [328/360], Batch [30/196], Loss: 0.0193\n",
      "Epoch [328/360], Batch [35/196], Loss: 0.0226\n",
      "Epoch [328/360], Batch [40/196], Loss: 0.0356\n",
      "Epoch [328/360], Batch [45/196], Loss: 0.0155\n",
      "Epoch [328/360], Batch [50/196], Loss: 0.0169\n",
      "Epoch [328/360], Batch [55/196], Loss: 0.0209\n",
      "Epoch [328/360], Batch [60/196], Loss: 0.0108\n",
      "Epoch [328/360], Batch [65/196], Loss: 0.0279\n",
      "Epoch [328/360], Batch [70/196], Loss: 0.0313\n",
      "Epoch [328/360], Batch [75/196], Loss: 0.0123\n",
      "Epoch [328/360], Batch [80/196], Loss: 0.0244\n",
      "Epoch [328/360], Batch [85/196], Loss: 0.0231\n",
      "Epoch [328/360], Batch [90/196], Loss: 0.0142\n",
      "Epoch [328/360], Batch [95/196], Loss: 0.0272\n",
      "Epoch [328/360], Batch [100/196], Loss: 0.0322\n",
      "Epoch [328/360], Batch [105/196], Loss: 0.0166\n",
      "Epoch [328/360], Batch [110/196], Loss: 0.0232\n",
      "Epoch [328/360], Batch [115/196], Loss: 0.0261\n",
      "Epoch [328/360], Batch [120/196], Loss: 0.0266\n",
      "Epoch [328/360], Batch [125/196], Loss: 0.0118\n",
      "Epoch [328/360], Batch [130/196], Loss: 0.0240\n",
      "Epoch [328/360], Batch [135/196], Loss: 0.0229\n",
      "Epoch [328/360], Batch [140/196], Loss: 0.0293\n",
      "Epoch [328/360], Batch [145/196], Loss: 0.0156\n",
      "Epoch [328/360], Batch [150/196], Loss: 0.0191\n",
      "Epoch [328/360], Batch [155/196], Loss: 0.0219\n",
      "Epoch [328/360], Batch [160/196], Loss: 0.0348\n",
      "Epoch [328/360], Batch [165/196], Loss: 0.0627\n",
      "Epoch [328/360], Batch [170/196], Loss: 0.0437\n",
      "Epoch [328/360], Batch [175/196], Loss: 0.0424\n",
      "Epoch [328/360], Batch [180/196], Loss: 0.0426\n",
      "Epoch [328/360], Batch [185/196], Loss: 0.0479\n",
      "Epoch [328/360], Batch [190/196], Loss: 0.0340\n",
      "Epoch [328/360], Batch [195/196], Loss: 0.0265\n",
      "Epoch [329/360], Batch [5/196], Loss: 0.0351\n",
      "Epoch [329/360], Batch [10/196], Loss: 0.0244\n",
      "Epoch [329/360], Batch [15/196], Loss: 0.0532\n",
      "Epoch [329/360], Batch [20/196], Loss: 0.0374\n",
      "Epoch [329/360], Batch [25/196], Loss: 0.1000\n",
      "Epoch [329/360], Batch [30/196], Loss: 0.0287\n",
      "Epoch [329/360], Batch [35/196], Loss: 0.0262\n",
      "Epoch [329/360], Batch [40/196], Loss: 0.0306\n",
      "Epoch [329/360], Batch [45/196], Loss: 0.0175\n",
      "Epoch [329/360], Batch [50/196], Loss: 0.0296\n",
      "Epoch [329/360], Batch [55/196], Loss: 0.0439\n",
      "Epoch [329/360], Batch [60/196], Loss: 0.0265\n",
      "Epoch [329/360], Batch [65/196], Loss: 0.0441\n",
      "Epoch [329/360], Batch [70/196], Loss: 0.0278\n",
      "Epoch [329/360], Batch [75/196], Loss: 0.0358\n",
      "Epoch [329/360], Batch [80/196], Loss: 0.0482\n",
      "Epoch [329/360], Batch [85/196], Loss: 0.0374\n",
      "Epoch [329/360], Batch [90/196], Loss: 0.0399\n",
      "Epoch [329/360], Batch [95/196], Loss: 0.0268\n",
      "Epoch [329/360], Batch [100/196], Loss: 0.0256\n",
      "Epoch [329/360], Batch [105/196], Loss: 0.0301\n",
      "Epoch [329/360], Batch [110/196], Loss: 0.0332\n",
      "Epoch [329/360], Batch [115/196], Loss: 0.0204\n",
      "Epoch [329/360], Batch [120/196], Loss: 0.0325\n",
      "Epoch [329/360], Batch [125/196], Loss: 0.0403\n",
      "Epoch [329/360], Batch [130/196], Loss: 0.0261\n",
      "Epoch [329/360], Batch [135/196], Loss: 0.0250\n",
      "Epoch [329/360], Batch [140/196], Loss: 0.0262\n",
      "Epoch [329/360], Batch [145/196], Loss: 0.0320\n",
      "Epoch [329/360], Batch [150/196], Loss: 0.0338\n",
      "Epoch [329/360], Batch [155/196], Loss: 0.0245\n",
      "Epoch [329/360], Batch [160/196], Loss: 0.0346\n",
      "Epoch [329/360], Batch [165/196], Loss: 0.0288\n",
      "Epoch [329/360], Batch [170/196], Loss: 0.0352\n",
      "Epoch [329/360], Batch [175/196], Loss: 0.0343\n",
      "Epoch [329/360], Batch [180/196], Loss: 0.0410\n",
      "Epoch [329/360], Batch [185/196], Loss: 0.0306\n",
      "Epoch [329/360], Batch [190/196], Loss: 0.0579\n",
      "Epoch [329/360], Batch [195/196], Loss: 0.0342\n",
      "Epoch [330/360], Batch [5/196], Loss: 0.0328\n",
      "Epoch [330/360], Batch [10/196], Loss: 0.0461\n",
      "Epoch [330/360], Batch [15/196], Loss: 0.0455\n",
      "Epoch [330/360], Batch [20/196], Loss: 0.0354\n",
      "Epoch [330/360], Batch [25/196], Loss: 0.0337\n",
      "Epoch [330/360], Batch [30/196], Loss: 0.0599\n",
      "Epoch [330/360], Batch [35/196], Loss: 0.0349\n",
      "Epoch [330/360], Batch [40/196], Loss: 0.0374\n",
      "Epoch [330/360], Batch [45/196], Loss: 0.0242\n",
      "Epoch [330/360], Batch [50/196], Loss: 0.0310\n",
      "Epoch [330/360], Batch [55/196], Loss: 0.0536\n",
      "Epoch [330/360], Batch [60/196], Loss: 0.0401\n",
      "Epoch [330/360], Batch [65/196], Loss: 0.0318\n",
      "Epoch [330/360], Batch [70/196], Loss: 0.0638\n",
      "Epoch [330/360], Batch [75/196], Loss: 0.0281\n",
      "Epoch [330/360], Batch [80/196], Loss: 0.0275\n",
      "Epoch [330/360], Batch [85/196], Loss: 0.0361\n",
      "Epoch [330/360], Batch [90/196], Loss: 0.0350\n",
      "Epoch [330/360], Batch [95/196], Loss: 0.0677\n",
      "Epoch [330/360], Batch [100/196], Loss: 0.0492\n",
      "Epoch [330/360], Batch [105/196], Loss: 0.0308\n",
      "Epoch [330/360], Batch [110/196], Loss: 0.0396\n",
      "Epoch [330/360], Batch [115/196], Loss: 0.0326\n",
      "Epoch [330/360], Batch [120/196], Loss: 0.0469\n",
      "Epoch [330/360], Batch [125/196], Loss: 0.0371\n",
      "Epoch [330/360], Batch [130/196], Loss: 0.0386\n",
      "Epoch [330/360], Batch [135/196], Loss: 0.0259\n",
      "Epoch [330/360], Batch [140/196], Loss: 0.0350\n",
      "Epoch [330/360], Batch [145/196], Loss: 0.0218\n",
      "Epoch [330/360], Batch [150/196], Loss: 0.0388\n",
      "Epoch [330/360], Batch [155/196], Loss: 0.0479\n",
      "Epoch [330/360], Batch [160/196], Loss: 0.0288\n",
      "Epoch [330/360], Batch [165/196], Loss: 0.0294\n",
      "Epoch [330/360], Batch [170/196], Loss: 0.0230\n",
      "Epoch [330/360], Batch [175/196], Loss: 0.0271\n",
      "Epoch [330/360], Batch [180/196], Loss: 0.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [330/360], Batch [185/196], Loss: 0.0193\n",
      "Epoch [330/360], Batch [190/196], Loss: 0.0267\n",
      "Epoch [330/360], Batch [195/196], Loss: 0.0298\n",
      "Epoch [331/360], Batch [5/196], Loss: 0.0272\n",
      "Epoch [331/360], Batch [10/196], Loss: 0.0326\n",
      "Epoch [331/360], Batch [15/196], Loss: 0.0290\n",
      "Epoch [331/360], Batch [20/196], Loss: 0.0236\n",
      "Epoch [331/360], Batch [25/196], Loss: 0.0383\n",
      "Epoch [331/360], Batch [30/196], Loss: 0.0300\n",
      "Epoch [331/360], Batch [35/196], Loss: 0.0478\n",
      "Epoch [331/360], Batch [40/196], Loss: 0.0251\n",
      "Epoch [331/360], Batch [45/196], Loss: 0.0476\n",
      "Epoch [331/360], Batch [50/196], Loss: 0.0351\n",
      "Epoch [331/360], Batch [55/196], Loss: 0.0450\n",
      "Epoch [331/360], Batch [60/196], Loss: 0.0452\n",
      "Epoch [331/360], Batch [65/196], Loss: 0.0604\n",
      "Epoch [331/360], Batch [70/196], Loss: 0.0370\n",
      "Epoch [331/360], Batch [75/196], Loss: 0.0273\n",
      "Epoch [331/360], Batch [80/196], Loss: 0.0491\n",
      "Epoch [331/360], Batch [85/196], Loss: 0.0254\n",
      "Epoch [331/360], Batch [90/196], Loss: 0.0277\n",
      "Epoch [331/360], Batch [95/196], Loss: 0.0317\n",
      "Epoch [331/360], Batch [100/196], Loss: 0.0271\n",
      "Epoch [331/360], Batch [105/196], Loss: 0.0237\n",
      "Epoch [331/360], Batch [110/196], Loss: 0.0301\n",
      "Epoch [331/360], Batch [115/196], Loss: 0.0210\n",
      "Epoch [331/360], Batch [120/196], Loss: 0.0242\n",
      "Epoch [331/360], Batch [125/196], Loss: 0.0348\n",
      "Epoch [331/360], Batch [130/196], Loss: 0.0216\n",
      "Epoch [331/360], Batch [135/196], Loss: 0.0306\n",
      "Epoch [331/360], Batch [140/196], Loss: 0.0233\n",
      "Epoch [331/360], Batch [145/196], Loss: 0.0281\n",
      "Epoch [331/360], Batch [150/196], Loss: 0.0250\n",
      "Epoch [331/360], Batch [155/196], Loss: 0.0484\n",
      "Epoch [331/360], Batch [160/196], Loss: 0.0274\n",
      "Epoch [331/360], Batch [165/196], Loss: 0.0234\n",
      "Epoch [331/360], Batch [170/196], Loss: 0.0485\n",
      "Epoch [331/360], Batch [175/196], Loss: 0.0364\n",
      "Epoch [331/360], Batch [180/196], Loss: 0.0343\n",
      "Epoch [331/360], Batch [185/196], Loss: 0.0478\n",
      "Epoch [331/360], Batch [190/196], Loss: 0.0289\n",
      "Epoch [331/360], Batch [195/196], Loss: 0.0356\n",
      "Epoch [332/360], Batch [5/196], Loss: 0.0514\n",
      "Epoch [332/360], Batch [10/196], Loss: 0.0489\n",
      "Epoch [332/360], Batch [15/196], Loss: 0.0327\n",
      "Epoch [332/360], Batch [20/196], Loss: 0.0315\n",
      "Epoch [332/360], Batch [25/196], Loss: 0.0210\n",
      "Epoch [332/360], Batch [30/196], Loss: 0.0579\n",
      "Epoch [332/360], Batch [35/196], Loss: 0.0444\n",
      "Epoch [332/360], Batch [40/196], Loss: 0.0329\n",
      "Epoch [332/360], Batch [45/196], Loss: 0.0332\n",
      "Epoch [332/360], Batch [50/196], Loss: 0.0333\n",
      "Epoch [332/360], Batch [55/196], Loss: 0.0297\n",
      "Epoch [332/360], Batch [60/196], Loss: 0.0343\n",
      "Epoch [332/360], Batch [65/196], Loss: 0.0203\n",
      "Epoch [332/360], Batch [70/196], Loss: 0.0233\n",
      "Epoch [332/360], Batch [75/196], Loss: 0.0350\n",
      "Epoch [332/360], Batch [80/196], Loss: 0.0276\n",
      "Epoch [332/360], Batch [85/196], Loss: 0.0265\n",
      "Epoch [332/360], Batch [90/196], Loss: 0.0394\n",
      "Epoch [332/360], Batch [95/196], Loss: 0.0474\n",
      "Epoch [332/360], Batch [100/196], Loss: 0.0205\n",
      "Epoch [332/360], Batch [105/196], Loss: 0.0257\n",
      "Epoch [332/360], Batch [110/196], Loss: 0.0288\n",
      "Epoch [332/360], Batch [115/196], Loss: 0.0237\n",
      "Epoch [332/360], Batch [120/196], Loss: 0.0264\n",
      "Epoch [332/360], Batch [125/196], Loss: 0.0270\n",
      "Epoch [332/360], Batch [130/196], Loss: 0.0301\n",
      "Epoch [332/360], Batch [135/196], Loss: 0.0382\n",
      "Epoch [332/360], Batch [140/196], Loss: 0.0422\n",
      "Epoch [332/360], Batch [145/196], Loss: 0.0282\n",
      "Epoch [332/360], Batch [150/196], Loss: 0.0302\n",
      "Epoch [332/360], Batch [155/196], Loss: 0.0278\n",
      "Epoch [332/360], Batch [160/196], Loss: 0.0214\n",
      "Epoch [332/360], Batch [165/196], Loss: 0.0346\n",
      "Epoch [332/360], Batch [170/196], Loss: 0.0309\n",
      "Epoch [332/360], Batch [175/196], Loss: 0.0198\n",
      "Epoch [332/360], Batch [180/196], Loss: 0.0331\n",
      "Epoch [332/360], Batch [185/196], Loss: 0.0417\n",
      "Epoch [332/360], Batch [190/196], Loss: 0.0331\n",
      "Epoch [332/360], Batch [195/196], Loss: 0.0296\n",
      "Epoch [333/360], Batch [5/196], Loss: 0.0241\n",
      "Epoch [333/360], Batch [10/196], Loss: 0.0145\n",
      "Epoch [333/360], Batch [15/196], Loss: 0.0280\n",
      "Epoch [333/360], Batch [20/196], Loss: 0.1007\n",
      "Epoch [333/360], Batch [25/196], Loss: 0.0312\n",
      "Epoch [333/360], Batch [30/196], Loss: 0.0200\n",
      "Epoch [333/360], Batch [35/196], Loss: 0.0215\n",
      "Epoch [333/360], Batch [40/196], Loss: 0.0184\n",
      "Epoch [333/360], Batch [45/196], Loss: 0.0244\n",
      "Epoch [333/360], Batch [50/196], Loss: 0.0316\n",
      "Epoch [333/360], Batch [55/196], Loss: 0.0249\n",
      "Epoch [333/360], Batch [60/196], Loss: 0.0364\n",
      "Epoch [333/360], Batch [65/196], Loss: 0.0219\n",
      "Epoch [333/360], Batch [70/196], Loss: 0.0202\n",
      "Epoch [333/360], Batch [75/196], Loss: 0.0274\n",
      "Epoch [333/360], Batch [80/196], Loss: 0.0203\n",
      "Epoch [333/360], Batch [85/196], Loss: 0.0252\n",
      "Epoch [333/360], Batch [90/196], Loss: 0.0308\n",
      "Epoch [333/360], Batch [95/196], Loss: 0.0226\n",
      "Epoch [333/360], Batch [100/196], Loss: 0.0286\n",
      "Epoch [333/360], Batch [105/196], Loss: 0.0248\n",
      "Epoch [333/360], Batch [110/196], Loss: 0.0268\n",
      "Epoch [333/360], Batch [115/196], Loss: 0.0220\n",
      "Epoch [333/360], Batch [120/196], Loss: 0.0186\n",
      "Epoch [333/360], Batch [125/196], Loss: 0.0168\n",
      "Epoch [333/360], Batch [130/196], Loss: 0.0225\n",
      "Epoch [333/360], Batch [135/196], Loss: 0.0199\n",
      "Epoch [333/360], Batch [140/196], Loss: 0.0165\n",
      "Epoch [333/360], Batch [145/196], Loss: 0.0341\n",
      "Epoch [333/360], Batch [150/196], Loss: 0.0196\n",
      "Epoch [333/360], Batch [155/196], Loss: 0.0238\n",
      "Epoch [333/360], Batch [160/196], Loss: 0.0210\n",
      "Epoch [333/360], Batch [165/196], Loss: 0.0207\n",
      "Epoch [333/360], Batch [170/196], Loss: 0.0258\n",
      "Epoch [333/360], Batch [175/196], Loss: 0.0166\n",
      "Epoch [333/360], Batch [180/196], Loss: 0.0157\n",
      "Epoch [333/360], Batch [185/196], Loss: 0.0157\n",
      "Epoch [333/360], Batch [190/196], Loss: 0.0177\n",
      "Epoch [333/360], Batch [195/196], Loss: 0.0170\n",
      "Epoch [334/360], Batch [5/196], Loss: 0.0317\n",
      "Epoch [334/360], Batch [10/196], Loss: 0.0166\n",
      "Epoch [334/360], Batch [15/196], Loss: 0.0164\n",
      "Epoch [334/360], Batch [20/196], Loss: 0.0105\n",
      "Epoch [334/360], Batch [25/196], Loss: 0.0125\n",
      "Epoch [334/360], Batch [30/196], Loss: 0.0130\n",
      "Epoch [334/360], Batch [35/196], Loss: 0.0132\n",
      "Epoch [334/360], Batch [40/196], Loss: 0.0141\n",
      "Epoch [334/360], Batch [45/196], Loss: 0.0134\n",
      "Epoch [334/360], Batch [50/196], Loss: 0.0238\n",
      "Epoch [334/360], Batch [55/196], Loss: 0.0168\n",
      "Epoch [334/360], Batch [60/196], Loss: 0.0139\n",
      "Epoch [334/360], Batch [65/196], Loss: 0.0118\n",
      "Epoch [334/360], Batch [70/196], Loss: 0.0188\n",
      "Epoch [334/360], Batch [75/196], Loss: 0.0149\n",
      "Epoch [334/360], Batch [80/196], Loss: 0.0198\n",
      "Epoch [334/360], Batch [85/196], Loss: 0.0124\n",
      "Epoch [334/360], Batch [90/196], Loss: 0.0160\n",
      "Epoch [334/360], Batch [95/196], Loss: 0.0154\n",
      "Epoch [334/360], Batch [100/196], Loss: 0.0104\n",
      "Epoch [334/360], Batch [105/196], Loss: 0.0141\n",
      "Epoch [334/360], Batch [110/196], Loss: 0.0132\n",
      "Epoch [334/360], Batch [115/196], Loss: 0.0170\n",
      "Epoch [334/360], Batch [120/196], Loss: 0.0309\n",
      "Epoch [334/360], Batch [125/196], Loss: 0.0163\n",
      "Epoch [334/360], Batch [130/196], Loss: 0.0128\n",
      "Epoch [334/360], Batch [135/196], Loss: 0.0115\n",
      "Epoch [334/360], Batch [140/196], Loss: 0.0118\n",
      "Epoch [334/360], Batch [145/196], Loss: 0.0182\n",
      "Epoch [334/360], Batch [150/196], Loss: 0.0178\n",
      "Epoch [334/360], Batch [155/196], Loss: 0.0172\n",
      "Epoch [334/360], Batch [160/196], Loss: 0.0155\n",
      "Epoch [334/360], Batch [165/196], Loss: 0.0142\n",
      "Epoch [334/360], Batch [170/196], Loss: 0.0157\n",
      "Epoch [334/360], Batch [175/196], Loss: 0.0103\n",
      "Epoch [334/360], Batch [180/196], Loss: 0.0132\n",
      "Epoch [334/360], Batch [185/196], Loss: 0.0136\n",
      "Epoch [334/360], Batch [190/196], Loss: 0.0172\n",
      "Epoch [334/360], Batch [195/196], Loss: 0.0182\n",
      "Epoch [335/360], Batch [5/196], Loss: 0.0163\n",
      "Epoch [335/360], Batch [10/196], Loss: 0.0170\n",
      "Epoch [335/360], Batch [15/196], Loss: 0.0127\n",
      "Epoch [335/360], Batch [20/196], Loss: 0.0130\n",
      "Epoch [335/360], Batch [25/196], Loss: 0.0210\n",
      "Epoch [335/360], Batch [30/196], Loss: 0.0229\n",
      "Epoch [335/360], Batch [35/196], Loss: 0.0117\n",
      "Epoch [335/360], Batch [40/196], Loss: 0.0114\n",
      "Epoch [335/360], Batch [45/196], Loss: 0.0122\n",
      "Epoch [335/360], Batch [50/196], Loss: 0.0235\n",
      "Epoch [335/360], Batch [55/196], Loss: 0.0128\n",
      "Epoch [335/360], Batch [60/196], Loss: 0.0115\n",
      "Epoch [335/360], Batch [65/196], Loss: 0.0200\n",
      "Epoch [335/360], Batch [70/196], Loss: 0.0113\n",
      "Epoch [335/360], Batch [75/196], Loss: 0.0097\n",
      "Epoch [335/360], Batch [80/196], Loss: 0.0144\n",
      "Epoch [335/360], Batch [85/196], Loss: 0.0088\n",
      "Epoch [335/360], Batch [90/196], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [335/360], Batch [95/196], Loss: 0.0104\n",
      "Epoch [335/360], Batch [100/196], Loss: 0.0085\n",
      "Epoch [335/360], Batch [105/196], Loss: 0.0239\n",
      "Epoch [335/360], Batch [110/196], Loss: 0.0205\n",
      "Epoch [335/360], Batch [115/196], Loss: 0.0182\n",
      "Epoch [335/360], Batch [120/196], Loss: 0.0288\n",
      "Epoch [335/360], Batch [125/196], Loss: 0.0135\n",
      "Epoch [335/360], Batch [130/196], Loss: 0.0211\n",
      "Epoch [335/360], Batch [135/196], Loss: 0.0174\n",
      "Epoch [335/360], Batch [140/196], Loss: 0.0161\n",
      "Epoch [335/360], Batch [145/196], Loss: 0.0136\n",
      "Epoch [335/360], Batch [150/196], Loss: 0.0192\n",
      "Epoch [335/360], Batch [155/196], Loss: 0.0161\n",
      "Epoch [335/360], Batch [160/196], Loss: 0.0213\n",
      "Epoch [335/360], Batch [165/196], Loss: 0.0155\n",
      "Epoch [335/360], Batch [170/196], Loss: 0.0172\n",
      "Epoch [335/360], Batch [175/196], Loss: 0.0122\n",
      "Epoch [335/360], Batch [180/196], Loss: 0.0133\n",
      "Epoch [335/360], Batch [185/196], Loss: 0.0148\n",
      "Epoch [335/360], Batch [190/196], Loss: 0.0161\n",
      "Epoch [335/360], Batch [195/196], Loss: 0.0205\n",
      "Epoch [336/360], Batch [5/196], Loss: 0.0120\n",
      "Epoch [336/360], Batch [10/196], Loss: 0.0335\n",
      "Epoch [336/360], Batch [15/196], Loss: 0.0250\n",
      "Epoch [336/360], Batch [20/196], Loss: 0.0107\n",
      "Epoch [336/360], Batch [25/196], Loss: 0.0177\n",
      "Epoch [336/360], Batch [30/196], Loss: 0.0107\n",
      "Epoch [336/360], Batch [35/196], Loss: 0.0151\n",
      "Epoch [336/360], Batch [40/196], Loss: 0.0121\n",
      "Epoch [336/360], Batch [45/196], Loss: 0.0138\n",
      "Epoch [336/360], Batch [50/196], Loss: 0.0193\n",
      "Epoch [336/360], Batch [55/196], Loss: 0.0130\n",
      "Epoch [336/360], Batch [60/196], Loss: 0.0158\n",
      "Epoch [336/360], Batch [65/196], Loss: 0.0149\n",
      "Epoch [336/360], Batch [70/196], Loss: 0.0180\n",
      "Epoch [336/360], Batch [75/196], Loss: 0.0163\n",
      "Epoch [336/360], Batch [80/196], Loss: 0.0157\n",
      "Epoch [336/360], Batch [85/196], Loss: 0.0164\n",
      "Epoch [336/360], Batch [90/196], Loss: 0.0172\n",
      "Epoch [336/360], Batch [95/196], Loss: 0.0132\n",
      "Epoch [336/360], Batch [100/196], Loss: 0.0146\n",
      "Epoch [336/360], Batch [105/196], Loss: 0.0171\n",
      "Epoch [336/360], Batch [110/196], Loss: 0.0134\n",
      "Epoch [336/360], Batch [115/196], Loss: 0.0125\n",
      "Epoch [336/360], Batch [120/196], Loss: 0.0144\n",
      "Epoch [336/360], Batch [125/196], Loss: 0.0283\n",
      "Epoch [336/360], Batch [130/196], Loss: 0.0153\n",
      "Epoch [336/360], Batch [135/196], Loss: 0.0169\n",
      "Epoch [336/360], Batch [140/196], Loss: 0.0179\n",
      "Epoch [336/360], Batch [145/196], Loss: 0.0090\n",
      "Epoch [336/360], Batch [150/196], Loss: 0.0124\n",
      "Epoch [336/360], Batch [155/196], Loss: 0.0100\n",
      "Epoch [336/360], Batch [160/196], Loss: 0.0151\n",
      "Epoch [336/360], Batch [165/196], Loss: 0.0145\n",
      "Epoch [336/360], Batch [170/196], Loss: 0.0213\n",
      "Epoch [336/360], Batch [175/196], Loss: 0.0090\n",
      "Epoch [336/360], Batch [180/196], Loss: 0.0129\n",
      "Epoch [336/360], Batch [185/196], Loss: 0.0457\n",
      "Epoch [336/360], Batch [190/196], Loss: 0.0208\n",
      "Epoch [336/360], Batch [195/196], Loss: 0.0286\n",
      "Epoch [337/360], Batch [5/196], Loss: 0.0266\n",
      "Epoch [337/360], Batch [10/196], Loss: 0.0154\n",
      "Epoch [337/360], Batch [15/196], Loss: 0.0133\n",
      "Epoch [337/360], Batch [20/196], Loss: 0.0115\n",
      "Epoch [337/360], Batch [25/196], Loss: 0.0188\n",
      "Epoch [337/360], Batch [30/196], Loss: 0.0151\n",
      "Epoch [337/360], Batch [35/196], Loss: 0.0186\n",
      "Epoch [337/360], Batch [40/196], Loss: 0.0128\n",
      "Epoch [337/360], Batch [45/196], Loss: 0.0113\n",
      "Epoch [337/360], Batch [50/196], Loss: 0.0144\n",
      "Epoch [337/360], Batch [55/196], Loss: 0.0137\n",
      "Epoch [337/360], Batch [60/196], Loss: 0.0150\n",
      "Epoch [337/360], Batch [65/196], Loss: 0.0166\n",
      "Epoch [337/360], Batch [70/196], Loss: 0.0136\n",
      "Epoch [337/360], Batch [75/196], Loss: 0.0105\n",
      "Epoch [337/360], Batch [80/196], Loss: 0.0191\n",
      "Epoch [337/360], Batch [85/196], Loss: 0.0174\n",
      "Epoch [337/360], Batch [90/196], Loss: 0.0237\n",
      "Epoch [337/360], Batch [95/196], Loss: 0.0097\n",
      "Epoch [337/360], Batch [100/196], Loss: 0.0219\n",
      "Epoch [337/360], Batch [105/196], Loss: 0.0126\n",
      "Epoch [337/360], Batch [110/196], Loss: 0.0161\n",
      "Epoch [337/360], Batch [115/196], Loss: 0.0210\n",
      "Epoch [337/360], Batch [120/196], Loss: 0.0165\n",
      "Epoch [337/360], Batch [125/196], Loss: 0.0205\n",
      "Epoch [337/360], Batch [130/196], Loss: 0.0130\n",
      "Epoch [337/360], Batch [135/196], Loss: 0.0197\n",
      "Epoch [337/360], Batch [140/196], Loss: 0.0153\n",
      "Epoch [337/360], Batch [145/196], Loss: 0.0147\n",
      "Epoch [337/360], Batch [150/196], Loss: 0.0216\n",
      "Epoch [337/360], Batch [155/196], Loss: 0.0194\n",
      "Epoch [337/360], Batch [160/196], Loss: 0.0126\n",
      "Epoch [337/360], Batch [165/196], Loss: 0.0180\n",
      "Epoch [337/360], Batch [170/196], Loss: 0.0108\n",
      "Epoch [337/360], Batch [175/196], Loss: 0.0174\n",
      "Epoch [337/360], Batch [180/196], Loss: 0.0166\n",
      "Epoch [337/360], Batch [185/196], Loss: 0.0204\n",
      "Epoch [337/360], Batch [190/196], Loss: 0.0114\n",
      "Epoch [337/360], Batch [195/196], Loss: 0.0178\n",
      "Epoch [338/360], Batch [5/196], Loss: 0.0205\n",
      "Epoch [338/360], Batch [10/196], Loss: 0.0083\n",
      "Epoch [338/360], Batch [15/196], Loss: 0.0201\n",
      "Epoch [338/360], Batch [20/196], Loss: 0.2173\n",
      "Epoch [338/360], Batch [25/196], Loss: 0.0267\n",
      "Epoch [338/360], Batch [30/196], Loss: 0.0303\n",
      "Epoch [338/360], Batch [35/196], Loss: 0.0467\n",
      "Epoch [338/360], Batch [40/196], Loss: 0.0378\n",
      "Epoch [338/360], Batch [45/196], Loss: 0.0451\n",
      "Epoch [338/360], Batch [50/196], Loss: 0.0418\n",
      "Epoch [338/360], Batch [55/196], Loss: 0.0294\n",
      "Epoch [338/360], Batch [60/196], Loss: 0.0302\n",
      "Epoch [338/360], Batch [65/196], Loss: 0.0277\n",
      "Epoch [338/360], Batch [70/196], Loss: 0.0171\n",
      "Epoch [338/360], Batch [75/196], Loss: 0.0216\n",
      "Epoch [338/360], Batch [80/196], Loss: 0.0263\n",
      "Epoch [338/360], Batch [85/196], Loss: 0.0233\n",
      "Epoch [338/360], Batch [90/196], Loss: 0.0149\n",
      "Epoch [338/360], Batch [95/196], Loss: 0.0272\n",
      "Epoch [338/360], Batch [100/196], Loss: 0.0224\n",
      "Epoch [338/360], Batch [105/196], Loss: 0.0222\n",
      "Epoch [338/360], Batch [110/196], Loss: 0.0148\n",
      "Epoch [338/360], Batch [115/196], Loss: 0.0205\n",
      "Epoch [338/360], Batch [120/196], Loss: 0.0227\n",
      "Epoch [338/360], Batch [125/196], Loss: 0.0288\n",
      "Epoch [338/360], Batch [130/196], Loss: 0.0346\n",
      "Epoch [338/360], Batch [135/196], Loss: 0.0235\n",
      "Epoch [338/360], Batch [140/196], Loss: 0.0209\n",
      "Epoch [338/360], Batch [145/196], Loss: 0.0190\n",
      "Epoch [338/360], Batch [150/196], Loss: 0.0270\n",
      "Epoch [338/360], Batch [155/196], Loss: 0.0155\n",
      "Epoch [338/360], Batch [160/196], Loss: 0.0229\n",
      "Epoch [338/360], Batch [165/196], Loss: 0.0190\n",
      "Epoch [338/360], Batch [170/196], Loss: 0.0184\n",
      "Epoch [338/360], Batch [175/196], Loss: 0.0171\n",
      "Epoch [338/360], Batch [180/196], Loss: 0.0206\n",
      "Epoch [338/360], Batch [185/196], Loss: 0.0181\n",
      "Epoch [338/360], Batch [190/196], Loss: 0.0211\n",
      "Epoch [338/360], Batch [195/196], Loss: 0.0089\n",
      "Epoch [339/360], Batch [5/196], Loss: 0.0123\n",
      "Epoch [339/360], Batch [10/196], Loss: 0.0247\n",
      "Epoch [339/360], Batch [15/196], Loss: 0.0196\n",
      "Epoch [339/360], Batch [20/196], Loss: 0.0108\n",
      "Epoch [339/360], Batch [25/196], Loss: 0.0204\n",
      "Epoch [339/360], Batch [30/196], Loss: 0.0141\n",
      "Epoch [339/360], Batch [35/196], Loss: 0.0200\n",
      "Epoch [339/360], Batch [40/196], Loss: 0.0150\n",
      "Epoch [339/360], Batch [45/196], Loss: 0.0170\n",
      "Epoch [339/360], Batch [50/196], Loss: 0.0150\n",
      "Epoch [339/360], Batch [55/196], Loss: 0.0173\n",
      "Epoch [339/360], Batch [60/196], Loss: 0.0162\n",
      "Epoch [339/360], Batch [65/196], Loss: 0.0187\n",
      "Epoch [339/360], Batch [70/196], Loss: 0.0240\n",
      "Epoch [339/360], Batch [75/196], Loss: 0.0240\n",
      "Epoch [339/360], Batch [80/196], Loss: 0.0234\n",
      "Epoch [339/360], Batch [85/196], Loss: 0.0134\n",
      "Epoch [339/360], Batch [90/196], Loss: 0.0145\n",
      "Epoch [339/360], Batch [95/196], Loss: 0.0174\n",
      "Epoch [339/360], Batch [100/196], Loss: 0.0103\n",
      "Epoch [339/360], Batch [105/196], Loss: 0.0279\n",
      "Epoch [339/360], Batch [110/196], Loss: 0.0234\n",
      "Epoch [339/360], Batch [115/196], Loss: 0.0182\n",
      "Epoch [339/360], Batch [120/196], Loss: 0.0121\n",
      "Epoch [339/360], Batch [125/196], Loss: 0.0257\n",
      "Epoch [339/360], Batch [130/196], Loss: 0.0192\n",
      "Epoch [339/360], Batch [135/196], Loss: 0.0112\n",
      "Epoch [339/360], Batch [140/196], Loss: 0.0117\n",
      "Epoch [339/360], Batch [145/196], Loss: 0.0202\n",
      "Epoch [339/360], Batch [150/196], Loss: 0.0118\n",
      "Epoch [339/360], Batch [155/196], Loss: 0.0186\n",
      "Epoch [339/360], Batch [160/196], Loss: 0.1344\n",
      "Epoch [339/360], Batch [165/196], Loss: 0.0179\n",
      "Epoch [339/360], Batch [170/196], Loss: 0.0131\n",
      "Epoch [339/360], Batch [175/196], Loss: 0.0224\n",
      "Epoch [339/360], Batch [180/196], Loss: 0.0439\n",
      "Epoch [339/360], Batch [185/196], Loss: 0.0235\n",
      "Epoch [339/360], Batch [190/196], Loss: 0.0235\n",
      "Epoch [339/360], Batch [195/196], Loss: 0.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [340/360], Batch [5/196], Loss: 0.0128\n",
      "Epoch [340/360], Batch [10/196], Loss: 0.0260\n",
      "Epoch [340/360], Batch [15/196], Loss: 0.0319\n",
      "Epoch [340/360], Batch [20/196], Loss: 0.0356\n",
      "Epoch [340/360], Batch [25/196], Loss: 0.0204\n",
      "Epoch [340/360], Batch [30/196], Loss: 0.0343\n",
      "Epoch [340/360], Batch [35/196], Loss: 0.0276\n",
      "Epoch [340/360], Batch [40/196], Loss: 0.0286\n",
      "Epoch [340/360], Batch [45/196], Loss: 0.0118\n",
      "Epoch [340/360], Batch [50/196], Loss: 0.0191\n",
      "Epoch [340/360], Batch [55/196], Loss: 0.0186\n",
      "Epoch [340/360], Batch [60/196], Loss: 0.0167\n",
      "Epoch [340/360], Batch [65/196], Loss: 0.0240\n",
      "Epoch [340/360], Batch [70/196], Loss: 0.0545\n",
      "Epoch [340/360], Batch [75/196], Loss: 0.0314\n",
      "Epoch [340/360], Batch [80/196], Loss: 0.0214\n",
      "Epoch [340/360], Batch [85/196], Loss: 0.0233\n",
      "Epoch [340/360], Batch [90/196], Loss: 0.0205\n",
      "Epoch [340/360], Batch [95/196], Loss: 0.0183\n",
      "Epoch [340/360], Batch [100/196], Loss: 0.0149\n",
      "Epoch [340/360], Batch [105/196], Loss: 0.0204\n",
      "Epoch [340/360], Batch [110/196], Loss: 0.0175\n",
      "Epoch [340/360], Batch [115/196], Loss: 0.0184\n",
      "Epoch [340/360], Batch [120/196], Loss: 0.0171\n",
      "Epoch [340/360], Batch [125/196], Loss: 0.0228\n",
      "Epoch [340/360], Batch [130/196], Loss: 0.0167\n",
      "Epoch [340/360], Batch [135/196], Loss: 0.0121\n",
      "Epoch [340/360], Batch [140/196], Loss: 0.0167\n",
      "Epoch [340/360], Batch [145/196], Loss: 0.0169\n",
      "Epoch [340/360], Batch [150/196], Loss: 0.0131\n",
      "Epoch [340/360], Batch [155/196], Loss: 0.0164\n",
      "Epoch [340/360], Batch [160/196], Loss: 0.0193\n",
      "Epoch [340/360], Batch [165/196], Loss: 0.0155\n",
      "Epoch [340/360], Batch [170/196], Loss: 0.0181\n",
      "Epoch [340/360], Batch [175/196], Loss: 0.0187\n",
      "Epoch [340/360], Batch [180/196], Loss: 0.0206\n",
      "Epoch [340/360], Batch [185/196], Loss: 0.0159\n",
      "Epoch [340/360], Batch [190/196], Loss: 0.0166\n",
      "Epoch [340/360], Batch [195/196], Loss: 0.0174\n",
      "Epoch [341/360], Batch [5/196], Loss: 0.0169\n",
      "Epoch [341/360], Batch [10/196], Loss: 0.0258\n",
      "Epoch [341/360], Batch [15/196], Loss: 0.0203\n",
      "Epoch [341/360], Batch [20/196], Loss: 0.0308\n",
      "Epoch [341/360], Batch [25/196], Loss: 0.0172\n",
      "Epoch [341/360], Batch [30/196], Loss: 0.0180\n",
      "Epoch [341/360], Batch [35/196], Loss: 0.0240\n",
      "Epoch [341/360], Batch [40/196], Loss: 0.0170\n",
      "Epoch [341/360], Batch [45/196], Loss: 0.0195\n",
      "Epoch [341/360], Batch [50/196], Loss: 0.0302\n",
      "Epoch [341/360], Batch [55/196], Loss: 0.0213\n",
      "Epoch [341/360], Batch [60/196], Loss: 0.0243\n",
      "Epoch [341/360], Batch [65/196], Loss: 0.0213\n",
      "Epoch [341/360], Batch [70/196], Loss: 0.0163\n",
      "Epoch [341/360], Batch [75/196], Loss: 0.0128\n",
      "Epoch [341/360], Batch [80/196], Loss: 0.0232\n",
      "Epoch [341/360], Batch [85/196], Loss: 0.0138\n",
      "Epoch [341/360], Batch [90/196], Loss: 0.0590\n",
      "Epoch [341/360], Batch [95/196], Loss: 0.0118\n",
      "Epoch [341/360], Batch [100/196], Loss: 0.0222\n",
      "Epoch [341/360], Batch [105/196], Loss: 0.0136\n",
      "Epoch [341/360], Batch [110/196], Loss: 0.0202\n",
      "Epoch [341/360], Batch [115/196], Loss: 0.0165\n",
      "Epoch [341/360], Batch [120/196], Loss: 0.0235\n",
      "Epoch [341/360], Batch [125/196], Loss: 0.0181\n",
      "Epoch [341/360], Batch [130/196], Loss: 0.0142\n",
      "Epoch [341/360], Batch [135/196], Loss: 0.0113\n",
      "Epoch [341/360], Batch [140/196], Loss: 0.0147\n",
      "Epoch [341/360], Batch [145/196], Loss: 0.0159\n",
      "Epoch [341/360], Batch [150/196], Loss: 0.0161\n",
      "Epoch [341/360], Batch [155/196], Loss: 0.0132\n",
      "Epoch [341/360], Batch [160/196], Loss: 0.0299\n",
      "Epoch [341/360], Batch [165/196], Loss: 0.0146\n",
      "Epoch [341/360], Batch [170/196], Loss: 0.0314\n",
      "Epoch [341/360], Batch [175/196], Loss: 0.0162\n",
      "Epoch [341/360], Batch [180/196], Loss: 0.0178\n",
      "Epoch [341/360], Batch [185/196], Loss: 0.0180\n",
      "Epoch [341/360], Batch [190/196], Loss: 0.0141\n",
      "Epoch [341/360], Batch [195/196], Loss: 0.0249\n",
      "Epoch [342/360], Batch [5/196], Loss: 0.0266\n",
      "Epoch [342/360], Batch [10/196], Loss: 0.0295\n",
      "Epoch [342/360], Batch [15/196], Loss: 0.0149\n",
      "Epoch [342/360], Batch [20/196], Loss: 0.0351\n",
      "Epoch [342/360], Batch [25/196], Loss: 0.0131\n",
      "Epoch [342/360], Batch [30/196], Loss: 0.0160\n",
      "Epoch [342/360], Batch [35/196], Loss: 0.0212\n",
      "Epoch [342/360], Batch [40/196], Loss: 0.0284\n",
      "Epoch [342/360], Batch [45/196], Loss: 0.0076\n",
      "Epoch [342/360], Batch [50/196], Loss: 0.0386\n",
      "Epoch [342/360], Batch [55/196], Loss: 0.0251\n",
      "Epoch [342/360], Batch [60/196], Loss: 0.0138\n",
      "Epoch [342/360], Batch [65/196], Loss: 0.0231\n",
      "Epoch [342/360], Batch [70/196], Loss: 0.0527\n",
      "Epoch [342/360], Batch [75/196], Loss: 0.0231\n",
      "Epoch [342/360], Batch [80/196], Loss: 0.0203\n",
      "Epoch [342/360], Batch [85/196], Loss: 0.0254\n",
      "Epoch [342/360], Batch [90/196], Loss: 0.0260\n",
      "Epoch [342/360], Batch [95/196], Loss: 0.0360\n",
      "Epoch [342/360], Batch [100/196], Loss: 0.0417\n",
      "Epoch [342/360], Batch [105/196], Loss: 0.0204\n",
      "Epoch [342/360], Batch [110/196], Loss: 0.0258\n",
      "Epoch [342/360], Batch [115/196], Loss: 0.0433\n",
      "Epoch [342/360], Batch [120/196], Loss: 0.0318\n",
      "Epoch [342/360], Batch [125/196], Loss: 0.0222\n",
      "Epoch [342/360], Batch [130/196], Loss: 0.0237\n",
      "Epoch [342/360], Batch [135/196], Loss: 0.0270\n",
      "Epoch [342/360], Batch [140/196], Loss: 0.0237\n",
      "Epoch [342/360], Batch [145/196], Loss: 0.0271\n",
      "Epoch [342/360], Batch [150/196], Loss: 0.0170\n",
      "Epoch [342/360], Batch [155/196], Loss: 0.0235\n",
      "Epoch [342/360], Batch [160/196], Loss: 0.0361\n",
      "Epoch [342/360], Batch [165/196], Loss: 0.0146\n",
      "Epoch [342/360], Batch [170/196], Loss: 0.0378\n",
      "Epoch [342/360], Batch [175/196], Loss: 0.0303\n",
      "Epoch [342/360], Batch [180/196], Loss: 0.0165\n",
      "Epoch [342/360], Batch [185/196], Loss: 0.0324\n",
      "Epoch [342/360], Batch [190/196], Loss: 0.0291\n",
      "Epoch [342/360], Batch [195/196], Loss: 0.0233\n",
      "Epoch [343/360], Batch [5/196], Loss: 0.0287\n",
      "Epoch [343/360], Batch [10/196], Loss: 0.0420\n",
      "Epoch [343/360], Batch [15/196], Loss: 0.0410\n",
      "Epoch [343/360], Batch [20/196], Loss: 0.0250\n",
      "Epoch [343/360], Batch [25/196], Loss: 0.0366\n",
      "Epoch [343/360], Batch [30/196], Loss: 0.0152\n",
      "Epoch [343/360], Batch [35/196], Loss: 0.0366\n",
      "Epoch [343/360], Batch [40/196], Loss: 0.0175\n",
      "Epoch [343/360], Batch [45/196], Loss: 0.0281\n",
      "Epoch [343/360], Batch [50/196], Loss: 0.0144\n",
      "Epoch [343/360], Batch [55/196], Loss: 0.0246\n",
      "Epoch [343/360], Batch [60/196], Loss: 0.0239\n",
      "Epoch [343/360], Batch [65/196], Loss: 0.0249\n",
      "Epoch [343/360], Batch [70/196], Loss: 0.0312\n",
      "Epoch [343/360], Batch [75/196], Loss: 0.0202\n",
      "Epoch [343/360], Batch [80/196], Loss: 0.0254\n",
      "Epoch [343/360], Batch [85/196], Loss: 0.0200\n",
      "Epoch [343/360], Batch [90/196], Loss: 0.0194\n",
      "Epoch [343/360], Batch [95/196], Loss: 0.0299\n",
      "Epoch [343/360], Batch [100/196], Loss: 0.0154\n",
      "Epoch [343/360], Batch [105/196], Loss: 0.0239\n",
      "Epoch [343/360], Batch [110/196], Loss: 0.0214\n",
      "Epoch [343/360], Batch [115/196], Loss: 0.0319\n",
      "Epoch [343/360], Batch [120/196], Loss: 0.0362\n",
      "Epoch [343/360], Batch [125/196], Loss: 0.0243\n",
      "Epoch [343/360], Batch [130/196], Loss: 0.0226\n",
      "Epoch [343/360], Batch [135/196], Loss: 0.0178\n",
      "Epoch [343/360], Batch [140/196], Loss: 0.0256\n",
      "Epoch [343/360], Batch [145/196], Loss: 0.0212\n",
      "Epoch [343/360], Batch [150/196], Loss: 0.0170\n",
      "Epoch [343/360], Batch [155/196], Loss: 0.0099\n",
      "Epoch [343/360], Batch [160/196], Loss: 0.0148\n",
      "Epoch [343/360], Batch [165/196], Loss: 0.0279\n",
      "Epoch [343/360], Batch [170/196], Loss: 0.0340\n",
      "Epoch [343/360], Batch [175/196], Loss: 0.0245\n",
      "Epoch [343/360], Batch [180/196], Loss: 0.0169\n",
      "Epoch [343/360], Batch [185/196], Loss: 0.0177\n",
      "Epoch [343/360], Batch [190/196], Loss: 0.0151\n",
      "Epoch [343/360], Batch [195/196], Loss: 0.0226\n",
      "Epoch [344/360], Batch [5/196], Loss: 0.0120\n",
      "Epoch [344/360], Batch [10/196], Loss: 0.0170\n",
      "Epoch [344/360], Batch [15/196], Loss: 0.0217\n",
      "Epoch [344/360], Batch [20/196], Loss: 0.0275\n",
      "Epoch [344/360], Batch [25/196], Loss: 0.0163\n",
      "Epoch [344/360], Batch [30/196], Loss: 0.0186\n",
      "Epoch [344/360], Batch [35/196], Loss: 0.0206\n",
      "Epoch [344/360], Batch [40/196], Loss: 0.0204\n",
      "Epoch [344/360], Batch [45/196], Loss: 0.0134\n",
      "Epoch [344/360], Batch [50/196], Loss: 0.0300\n",
      "Epoch [344/360], Batch [55/196], Loss: 0.0206\n",
      "Epoch [344/360], Batch [60/196], Loss: 0.0222\n",
      "Epoch [344/360], Batch [65/196], Loss: 0.0113\n",
      "Epoch [344/360], Batch [70/196], Loss: 0.0204\n",
      "Epoch [344/360], Batch [75/196], Loss: 0.0248\n",
      "Epoch [344/360], Batch [80/196], Loss: 0.0216\n",
      "Epoch [344/360], Batch [85/196], Loss: 0.0142\n",
      "Epoch [344/360], Batch [90/196], Loss: 0.0150\n",
      "Epoch [344/360], Batch [95/196], Loss: 0.0167\n",
      "Epoch [344/360], Batch [100/196], Loss: 0.0136\n",
      "Epoch [344/360], Batch [105/196], Loss: 0.0183\n",
      "Epoch [344/360], Batch [110/196], Loss: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [344/360], Batch [115/196], Loss: 0.0135\n",
      "Epoch [344/360], Batch [120/196], Loss: 0.0156\n",
      "Epoch [344/360], Batch [125/196], Loss: 0.0146\n",
      "Epoch [344/360], Batch [130/196], Loss: 0.0154\n",
      "Epoch [344/360], Batch [135/196], Loss: 0.0111\n",
      "Epoch [344/360], Batch [140/196], Loss: 0.0187\n",
      "Epoch [344/360], Batch [145/196], Loss: 0.0158\n",
      "Epoch [344/360], Batch [150/196], Loss: 0.0170\n",
      "Epoch [344/360], Batch [155/196], Loss: 0.0309\n",
      "Epoch [344/360], Batch [160/196], Loss: 0.0161\n",
      "Epoch [344/360], Batch [165/196], Loss: 0.0209\n",
      "Epoch [344/360], Batch [170/196], Loss: 0.0171\n",
      "Epoch [344/360], Batch [175/196], Loss: 0.0279\n",
      "Epoch [344/360], Batch [180/196], Loss: 0.0204\n",
      "Epoch [344/360], Batch [185/196], Loss: 0.0117\n",
      "Epoch [344/360], Batch [190/196], Loss: 0.0115\n",
      "Epoch [344/360], Batch [195/196], Loss: 0.0154\n",
      "Epoch [345/360], Batch [5/196], Loss: 0.0154\n",
      "Epoch [345/360], Batch [10/196], Loss: 0.0462\n",
      "Epoch [345/360], Batch [15/196], Loss: 0.0113\n",
      "Epoch [345/360], Batch [20/196], Loss: 0.0380\n",
      "Epoch [345/360], Batch [25/196], Loss: 0.0174\n",
      "Epoch [345/360], Batch [30/196], Loss: 0.0208\n",
      "Epoch [345/360], Batch [35/196], Loss: 0.0156\n",
      "Epoch [345/360], Batch [40/196], Loss: 0.0153\n",
      "Epoch [345/360], Batch [45/196], Loss: 0.0252\n",
      "Epoch [345/360], Batch [50/196], Loss: 0.0158\n",
      "Epoch [345/360], Batch [55/196], Loss: 0.0228\n",
      "Epoch [345/360], Batch [60/196], Loss: 0.0242\n",
      "Epoch [345/360], Batch [65/196], Loss: 0.0133\n",
      "Epoch [345/360], Batch [70/196], Loss: 0.0164\n",
      "Epoch [345/360], Batch [75/196], Loss: 0.0208\n",
      "Epoch [345/360], Batch [80/196], Loss: 0.0245\n",
      "Epoch [345/360], Batch [85/196], Loss: 0.0167\n",
      "Epoch [345/360], Batch [90/196], Loss: 0.0204\n",
      "Epoch [345/360], Batch [95/196], Loss: 0.0222\n",
      "Epoch [345/360], Batch [100/196], Loss: 0.0138\n",
      "Epoch [345/360], Batch [105/196], Loss: 0.0280\n",
      "Epoch [345/360], Batch [110/196], Loss: 0.0197\n",
      "Epoch [345/360], Batch [115/196], Loss: 0.0204\n",
      "Epoch [345/360], Batch [120/196], Loss: 0.0141\n",
      "Epoch [345/360], Batch [125/196], Loss: 0.0249\n",
      "Epoch [345/360], Batch [130/196], Loss: 0.0157\n",
      "Epoch [345/360], Batch [135/196], Loss: 0.0135\n",
      "Epoch [345/360], Batch [140/196], Loss: 0.0149\n",
      "Epoch [345/360], Batch [145/196], Loss: 0.0132\n",
      "Epoch [345/360], Batch [150/196], Loss: 0.0208\n",
      "Epoch [345/360], Batch [155/196], Loss: 0.0177\n",
      "Epoch [345/360], Batch [160/196], Loss: 0.0174\n",
      "Epoch [345/360], Batch [165/196], Loss: 0.0145\n",
      "Epoch [345/360], Batch [170/196], Loss: 0.0097\n",
      "Epoch [345/360], Batch [175/196], Loss: 0.0225\n",
      "Epoch [345/360], Batch [180/196], Loss: 0.0189\n",
      "Epoch [345/360], Batch [185/196], Loss: 0.0202\n",
      "Epoch [345/360], Batch [190/196], Loss: 0.0217\n",
      "Epoch [345/360], Batch [195/196], Loss: 0.0136\n",
      "Epoch [346/360], Batch [5/196], Loss: 0.0184\n",
      "Epoch [346/360], Batch [10/196], Loss: 0.0208\n",
      "Epoch [346/360], Batch [15/196], Loss: 0.0282\n",
      "Epoch [346/360], Batch [20/196], Loss: 0.0217\n",
      "Epoch [346/360], Batch [25/196], Loss: 0.0154\n",
      "Epoch [346/360], Batch [30/196], Loss: 0.0237\n",
      "Epoch [346/360], Batch [35/196], Loss: 0.0135\n",
      "Epoch [346/360], Batch [40/196], Loss: 0.0225\n",
      "Epoch [346/360], Batch [45/196], Loss: 0.0249\n",
      "Epoch [346/360], Batch [50/196], Loss: 0.0217\n",
      "Epoch [346/360], Batch [55/196], Loss: 0.0177\n",
      "Epoch [346/360], Batch [60/196], Loss: 0.0157\n",
      "Epoch [346/360], Batch [65/196], Loss: 0.0205\n",
      "Epoch [346/360], Batch [70/196], Loss: 0.0162\n",
      "Epoch [346/360], Batch [75/196], Loss: 0.0222\n",
      "Epoch [346/360], Batch [80/196], Loss: 0.0222\n",
      "Epoch [346/360], Batch [85/196], Loss: 0.0456\n",
      "Epoch [346/360], Batch [90/196], Loss: 0.0456\n",
      "Epoch [346/360], Batch [95/196], Loss: 0.0491\n",
      "Epoch [346/360], Batch [100/196], Loss: 0.0312\n",
      "Epoch [346/360], Batch [105/196], Loss: 0.0227\n",
      "Epoch [346/360], Batch [110/196], Loss: 0.0445\n",
      "Epoch [346/360], Batch [115/196], Loss: 0.0303\n",
      "Epoch [346/360], Batch [120/196], Loss: 0.0264\n",
      "Epoch [346/360], Batch [125/196], Loss: 0.0208\n",
      "Epoch [346/360], Batch [130/196], Loss: 0.0230\n",
      "Epoch [346/360], Batch [135/196], Loss: 0.0216\n",
      "Epoch [346/360], Batch [140/196], Loss: 0.0405\n",
      "Epoch [346/360], Batch [145/196], Loss: 0.0109\n",
      "Epoch [346/360], Batch [150/196], Loss: 0.0218\n",
      "Epoch [346/360], Batch [155/196], Loss: 0.0203\n",
      "Epoch [346/360], Batch [160/196], Loss: 0.0200\n",
      "Epoch [346/360], Batch [165/196], Loss: 0.0240\n",
      "Epoch [346/360], Batch [170/196], Loss: 0.0210\n",
      "Epoch [346/360], Batch [175/196], Loss: 0.0143\n",
      "Epoch [346/360], Batch [180/196], Loss: 0.0189\n",
      "Epoch [346/360], Batch [185/196], Loss: 0.0272\n",
      "Epoch [346/360], Batch [190/196], Loss: 0.0232\n",
      "Epoch [346/360], Batch [195/196], Loss: 0.0234\n",
      "Epoch [347/360], Batch [5/196], Loss: 0.0144\n",
      "Epoch [347/360], Batch [10/196], Loss: 0.0235\n",
      "Epoch [347/360], Batch [15/196], Loss: 0.0198\n",
      "Epoch [347/360], Batch [20/196], Loss: 0.0174\n",
      "Epoch [347/360], Batch [25/196], Loss: 0.0302\n",
      "Epoch [347/360], Batch [30/196], Loss: 0.0105\n",
      "Epoch [347/360], Batch [35/196], Loss: 0.0174\n",
      "Epoch [347/360], Batch [40/196], Loss: 0.0303\n",
      "Epoch [347/360], Batch [45/196], Loss: 0.0118\n",
      "Epoch [347/360], Batch [50/196], Loss: 0.0247\n",
      "Epoch [347/360], Batch [55/196], Loss: 0.0172\n",
      "Epoch [347/360], Batch [60/196], Loss: 0.0239\n",
      "Epoch [347/360], Batch [65/196], Loss: 0.0262\n",
      "Epoch [347/360], Batch [70/196], Loss: 0.0346\n",
      "Epoch [347/360], Batch [75/196], Loss: 0.0198\n",
      "Epoch [347/360], Batch [80/196], Loss: 0.0287\n",
      "Epoch [347/360], Batch [85/196], Loss: 0.0164\n",
      "Epoch [347/360], Batch [90/196], Loss: 0.0190\n",
      "Epoch [347/360], Batch [95/196], Loss: 0.0275\n",
      "Epoch [347/360], Batch [100/196], Loss: 0.0279\n",
      "Epoch [347/360], Batch [105/196], Loss: 0.0176\n",
      "Epoch [347/360], Batch [110/196], Loss: 0.0172\n",
      "Epoch [347/360], Batch [115/196], Loss: 0.0232\n",
      "Epoch [347/360], Batch [120/196], Loss: 0.0115\n",
      "Epoch [347/360], Batch [125/196], Loss: 0.0164\n",
      "Epoch [347/360], Batch [130/196], Loss: 0.0224\n",
      "Epoch [347/360], Batch [135/196], Loss: 0.0222\n",
      "Epoch [347/360], Batch [140/196], Loss: 0.0194\n",
      "Epoch [347/360], Batch [145/196], Loss: 0.0174\n",
      "Epoch [347/360], Batch [150/196], Loss: 0.0237\n",
      "Epoch [347/360], Batch [155/196], Loss: 0.0178\n",
      "Epoch [347/360], Batch [160/196], Loss: 0.0234\n",
      "Epoch [347/360], Batch [165/196], Loss: 0.0254\n",
      "Epoch [347/360], Batch [170/196], Loss: 0.0172\n",
      "Epoch [347/360], Batch [175/196], Loss: 0.0110\n",
      "Epoch [347/360], Batch [180/196], Loss: 0.0217\n",
      "Epoch [347/360], Batch [185/196], Loss: 0.0241\n",
      "Epoch [347/360], Batch [190/196], Loss: 0.0333\n",
      "Epoch [347/360], Batch [195/196], Loss: 0.0222\n",
      "Epoch [348/360], Batch [5/196], Loss: 0.0174\n",
      "Epoch [348/360], Batch [10/196], Loss: 0.0311\n",
      "Epoch [348/360], Batch [15/196], Loss: 0.0194\n",
      "Epoch [348/360], Batch [20/196], Loss: 0.0141\n",
      "Epoch [348/360], Batch [25/196], Loss: 0.0158\n",
      "Epoch [348/360], Batch [30/196], Loss: 0.0170\n",
      "Epoch [348/360], Batch [35/196], Loss: 0.0154\n",
      "Epoch [348/360], Batch [40/196], Loss: 0.0136\n",
      "Epoch [348/360], Batch [45/196], Loss: 0.0218\n",
      "Epoch [348/360], Batch [50/196], Loss: 0.0220\n",
      "Epoch [348/360], Batch [55/196], Loss: 0.0143\n",
      "Epoch [348/360], Batch [60/196], Loss: 0.0236\n",
      "Epoch [348/360], Batch [65/196], Loss: 0.0234\n",
      "Epoch [348/360], Batch [70/196], Loss: 0.0239\n",
      "Epoch [348/360], Batch [75/196], Loss: 0.0210\n",
      "Epoch [348/360], Batch [80/196], Loss: 0.0369\n",
      "Epoch [348/360], Batch [85/196], Loss: 0.0306\n",
      "Epoch [348/360], Batch [90/196], Loss: 0.0130\n",
      "Epoch [348/360], Batch [95/196], Loss: 0.0152\n",
      "Epoch [348/360], Batch [100/196], Loss: 0.0140\n",
      "Epoch [348/360], Batch [105/196], Loss: 0.0286\n",
      "Epoch [348/360], Batch [110/196], Loss: 0.0154\n",
      "Epoch [348/360], Batch [115/196], Loss: 0.0228\n",
      "Epoch [348/360], Batch [120/196], Loss: 0.0224\n",
      "Epoch [348/360], Batch [125/196], Loss: 0.0223\n",
      "Epoch [348/360], Batch [130/196], Loss: 0.0099\n",
      "Epoch [348/360], Batch [135/196], Loss: 0.0111\n",
      "Epoch [348/360], Batch [140/196], Loss: 0.0151\n",
      "Epoch [348/360], Batch [145/196], Loss: 0.0338\n",
      "Epoch [348/360], Batch [150/196], Loss: 0.0159\n",
      "Epoch [348/360], Batch [155/196], Loss: 0.0154\n",
      "Epoch [348/360], Batch [160/196], Loss: 0.0253\n",
      "Epoch [348/360], Batch [165/196], Loss: 0.0126\n",
      "Epoch [348/360], Batch [170/196], Loss: 0.0207\n",
      "Epoch [348/360], Batch [175/196], Loss: 0.0151\n",
      "Epoch [348/360], Batch [180/196], Loss: 0.0222\n",
      "Epoch [348/360], Batch [185/196], Loss: 0.0171\n",
      "Epoch [348/360], Batch [190/196], Loss: 0.0138\n",
      "Epoch [348/360], Batch [195/196], Loss: 0.0152\n",
      "Epoch [349/360], Batch [5/196], Loss: 0.0226\n",
      "Epoch [349/360], Batch [10/196], Loss: 0.0131\n",
      "Epoch [349/360], Batch [15/196], Loss: 0.0206\n",
      "Epoch [349/360], Batch [20/196], Loss: 0.0128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [349/360], Batch [25/196], Loss: 0.0240\n",
      "Epoch [349/360], Batch [30/196], Loss: 0.0145\n",
      "Epoch [349/360], Batch [35/196], Loss: 0.0226\n",
      "Epoch [349/360], Batch [40/196], Loss: 0.0554\n",
      "Epoch [349/360], Batch [45/196], Loss: 0.0352\n",
      "Epoch [349/360], Batch [50/196], Loss: 0.0413\n",
      "Epoch [349/360], Batch [55/196], Loss: 0.0266\n",
      "Epoch [349/360], Batch [60/196], Loss: 0.0351\n",
      "Epoch [349/360], Batch [65/196], Loss: 0.0239\n",
      "Epoch [349/360], Batch [70/196], Loss: 0.0382\n",
      "Epoch [349/360], Batch [75/196], Loss: 0.0207\n",
      "Epoch [349/360], Batch [80/196], Loss: 0.0251\n",
      "Epoch [349/360], Batch [85/196], Loss: 0.0341\n",
      "Epoch [349/360], Batch [90/196], Loss: 0.0254\n",
      "Epoch [349/360], Batch [95/196], Loss: 0.0253\n",
      "Epoch [349/360], Batch [100/196], Loss: 0.0265\n",
      "Epoch [349/360], Batch [105/196], Loss: 0.0228\n",
      "Epoch [349/360], Batch [110/196], Loss: 0.0300\n",
      "Epoch [349/360], Batch [115/196], Loss: 0.0156\n",
      "Epoch [349/360], Batch [120/196], Loss: 0.0294\n",
      "Epoch [349/360], Batch [125/196], Loss: 0.0187\n",
      "Epoch [349/360], Batch [130/196], Loss: 0.0257\n",
      "Epoch [349/360], Batch [135/196], Loss: 0.0204\n",
      "Epoch [349/360], Batch [140/196], Loss: 0.0327\n",
      "Epoch [349/360], Batch [145/196], Loss: 0.0203\n",
      "Epoch [349/360], Batch [150/196], Loss: 0.0260\n",
      "Epoch [349/360], Batch [155/196], Loss: 0.0269\n",
      "Epoch [349/360], Batch [160/196], Loss: 0.0204\n",
      "Epoch [349/360], Batch [165/196], Loss: 0.0292\n",
      "Epoch [349/360], Batch [170/196], Loss: 0.0232\n",
      "Epoch [349/360], Batch [175/196], Loss: 0.0136\n",
      "Epoch [349/360], Batch [180/196], Loss: 0.0395\n",
      "Epoch [349/360], Batch [185/196], Loss: 0.0209\n",
      "Epoch [349/360], Batch [190/196], Loss: 0.0290\n",
      "Epoch [349/360], Batch [195/196], Loss: 0.0282\n",
      "Epoch [350/360], Batch [5/196], Loss: 0.0292\n",
      "Epoch [350/360], Batch [10/196], Loss: 0.0237\n",
      "Epoch [350/360], Batch [15/196], Loss: 0.0172\n",
      "Epoch [350/360], Batch [20/196], Loss: 0.0454\n",
      "Epoch [350/360], Batch [25/196], Loss: 0.0219\n",
      "Epoch [350/360], Batch [30/196], Loss: 0.0210\n",
      "Epoch [350/360], Batch [35/196], Loss: 0.0329\n",
      "Epoch [350/360], Batch [40/196], Loss: 0.0302\n",
      "Epoch [350/360], Batch [45/196], Loss: 0.0208\n",
      "Epoch [350/360], Batch [50/196], Loss: 0.0220\n",
      "Epoch [350/360], Batch [55/196], Loss: 0.0367\n",
      "Epoch [350/360], Batch [60/196], Loss: 0.0342\n",
      "Epoch [350/360], Batch [65/196], Loss: 0.0386\n",
      "Epoch [350/360], Batch [70/196], Loss: 0.0382\n",
      "Epoch [350/360], Batch [75/196], Loss: 0.0333\n",
      "Epoch [350/360], Batch [80/196], Loss: 0.0411\n",
      "Epoch [350/360], Batch [85/196], Loss: 0.0337\n",
      "Epoch [350/360], Batch [90/196], Loss: 0.0595\n",
      "Epoch [350/360], Batch [95/196], Loss: 0.0270\n",
      "Epoch [350/360], Batch [100/196], Loss: 0.0303\n",
      "Epoch [350/360], Batch [105/196], Loss: 0.0261\n",
      "Epoch [350/360], Batch [110/196], Loss: 0.0203\n",
      "Epoch [350/360], Batch [115/196], Loss: 0.0172\n",
      "Epoch [350/360], Batch [120/196], Loss: 0.0278\n",
      "Epoch [350/360], Batch [125/196], Loss: 0.0189\n",
      "Epoch [350/360], Batch [130/196], Loss: 0.0330\n",
      "Epoch [350/360], Batch [135/196], Loss: 0.0275\n",
      "Epoch [350/360], Batch [140/196], Loss: 0.0180\n",
      "Epoch [350/360], Batch [145/196], Loss: 0.0196\n",
      "Epoch [350/360], Batch [150/196], Loss: 0.0167\n",
      "Epoch [350/360], Batch [155/196], Loss: 0.0206\n",
      "Epoch [350/360], Batch [160/196], Loss: 0.0254\n",
      "Epoch [350/360], Batch [165/196], Loss: 0.0188\n",
      "Epoch [350/360], Batch [170/196], Loss: 0.0298\n",
      "Epoch [350/360], Batch [175/196], Loss: 0.0298\n",
      "Epoch [350/360], Batch [180/196], Loss: 0.0289\n",
      "Epoch [350/360], Batch [185/196], Loss: 0.0232\n",
      "Epoch [350/360], Batch [190/196], Loss: 0.0184\n",
      "Epoch [350/360], Batch [195/196], Loss: 0.0237\n",
      "Epoch [351/360], Batch [5/196], Loss: 0.0142\n",
      "Epoch [351/360], Batch [10/196], Loss: 0.0248\n",
      "Epoch [351/360], Batch [15/196], Loss: 0.0193\n",
      "Epoch [351/360], Batch [20/196], Loss: 0.0266\n",
      "Epoch [351/360], Batch [25/196], Loss: 0.0152\n",
      "Epoch [351/360], Batch [30/196], Loss: 0.0181\n",
      "Epoch [351/360], Batch [35/196], Loss: 0.0172\n",
      "Epoch [351/360], Batch [40/196], Loss: 0.0289\n",
      "Epoch [351/360], Batch [45/196], Loss: 0.0205\n",
      "Epoch [351/360], Batch [50/196], Loss: 0.0414\n",
      "Epoch [351/360], Batch [55/196], Loss: 0.0472\n",
      "Epoch [351/360], Batch [60/196], Loss: 0.0546\n",
      "Epoch [351/360], Batch [65/196], Loss: 0.0622\n",
      "Epoch [351/360], Batch [70/196], Loss: 0.0400\n",
      "Epoch [351/360], Batch [75/196], Loss: 0.0412\n",
      "Epoch [351/360], Batch [80/196], Loss: 0.0349\n",
      "Epoch [351/360], Batch [85/196], Loss: 0.0469\n",
      "Epoch [351/360], Batch [90/196], Loss: 0.0297\n",
      "Epoch [351/360], Batch [95/196], Loss: 0.0319\n",
      "Epoch [351/360], Batch [100/196], Loss: 0.0307\n",
      "Epoch [351/360], Batch [105/196], Loss: 0.0421\n",
      "Epoch [351/360], Batch [110/196], Loss: 0.0352\n",
      "Epoch [351/360], Batch [115/196], Loss: 0.0493\n",
      "Epoch [351/360], Batch [120/196], Loss: 0.0315\n",
      "Epoch [351/360], Batch [125/196], Loss: 0.0273\n",
      "Epoch [351/360], Batch [130/196], Loss: 0.0381\n",
      "Epoch [351/360], Batch [135/196], Loss: 0.0329\n",
      "Epoch [351/360], Batch [140/196], Loss: 0.0391\n",
      "Epoch [351/360], Batch [145/196], Loss: 0.0386\n",
      "Epoch [351/360], Batch [150/196], Loss: 0.0220\n",
      "Epoch [351/360], Batch [155/196], Loss: 0.0234\n",
      "Epoch [351/360], Batch [160/196], Loss: 0.0249\n",
      "Epoch [351/360], Batch [165/196], Loss: 0.0207\n",
      "Epoch [351/360], Batch [170/196], Loss: 0.0240\n",
      "Epoch [351/360], Batch [175/196], Loss: 0.0284\n",
      "Epoch [351/360], Batch [180/196], Loss: 0.0212\n",
      "Epoch [351/360], Batch [185/196], Loss: 0.0295\n",
      "Epoch [351/360], Batch [190/196], Loss: 0.0195\n",
      "Epoch [351/360], Batch [195/196], Loss: 0.0469\n",
      "Epoch [352/360], Batch [5/196], Loss: 0.0213\n",
      "Epoch [352/360], Batch [10/196], Loss: 0.0242\n",
      "Epoch [352/360], Batch [15/196], Loss: 0.0222\n",
      "Epoch [352/360], Batch [20/196], Loss: 0.0325\n",
      "Epoch [352/360], Batch [25/196], Loss: 0.0174\n",
      "Epoch [352/360], Batch [30/196], Loss: 0.0182\n",
      "Epoch [352/360], Batch [35/196], Loss: 0.0197\n",
      "Epoch [352/360], Batch [40/196], Loss: 0.0230\n",
      "Epoch [352/360], Batch [45/196], Loss: 0.0223\n",
      "Epoch [352/360], Batch [50/196], Loss: 0.0242\n",
      "Epoch [352/360], Batch [55/196], Loss: 0.0166\n",
      "Epoch [352/360], Batch [60/196], Loss: 0.0198\n",
      "Epoch [352/360], Batch [65/196], Loss: 0.0184\n",
      "Epoch [352/360], Batch [70/196], Loss: 0.0230\n",
      "Epoch [352/360], Batch [75/196], Loss: 0.0203\n",
      "Epoch [352/360], Batch [80/196], Loss: 0.0206\n",
      "Epoch [352/360], Batch [85/196], Loss: 0.0254\n",
      "Epoch [352/360], Batch [90/196], Loss: 0.0335\n",
      "Epoch [352/360], Batch [95/196], Loss: 0.0212\n",
      "Epoch [352/360], Batch [100/196], Loss: 0.0164\n",
      "Epoch [352/360], Batch [105/196], Loss: 0.0185\n",
      "Epoch [352/360], Batch [110/196], Loss: 0.0179\n",
      "Epoch [352/360], Batch [115/196], Loss: 0.0212\n",
      "Epoch [352/360], Batch [120/196], Loss: 0.0136\n",
      "Epoch [352/360], Batch [125/196], Loss: 0.0218\n",
      "Epoch [352/360], Batch [130/196], Loss: 0.0212\n",
      "Epoch [352/360], Batch [135/196], Loss: 0.0229\n",
      "Epoch [352/360], Batch [140/196], Loss: 0.0206\n",
      "Epoch [352/360], Batch [145/196], Loss: 0.0254\n",
      "Epoch [352/360], Batch [150/196], Loss: 0.0166\n",
      "Epoch [352/360], Batch [155/196], Loss: 0.0216\n",
      "Epoch [352/360], Batch [160/196], Loss: 0.0177\n",
      "Epoch [352/360], Batch [165/196], Loss: 0.0200\n",
      "Epoch [352/360], Batch [170/196], Loss: 0.0273\n",
      "Epoch [352/360], Batch [175/196], Loss: 0.0221\n",
      "Epoch [352/360], Batch [180/196], Loss: 0.0100\n",
      "Epoch [352/360], Batch [185/196], Loss: 0.0275\n",
      "Epoch [352/360], Batch [190/196], Loss: 0.0231\n",
      "Epoch [352/360], Batch [195/196], Loss: 0.0136\n",
      "Epoch [353/360], Batch [5/196], Loss: 0.0228\n",
      "Epoch [353/360], Batch [10/196], Loss: 0.0138\n",
      "Epoch [353/360], Batch [15/196], Loss: 0.0217\n",
      "Epoch [353/360], Batch [20/196], Loss: 0.0273\n",
      "Epoch [353/360], Batch [25/196], Loss: 0.0169\n",
      "Epoch [353/360], Batch [30/196], Loss: 0.0142\n",
      "Epoch [353/360], Batch [35/196], Loss: 0.0131\n",
      "Epoch [353/360], Batch [40/196], Loss: 0.0229\n",
      "Epoch [353/360], Batch [45/196], Loss: 0.0131\n",
      "Epoch [353/360], Batch [50/196], Loss: 0.0100\n",
      "Epoch [353/360], Batch [55/196], Loss: 0.0096\n",
      "Epoch [353/360], Batch [60/196], Loss: 0.0150\n",
      "Epoch [353/360], Batch [65/196], Loss: 0.0252\n",
      "Epoch [353/360], Batch [70/196], Loss: 0.0187\n",
      "Epoch [353/360], Batch [75/196], Loss: 0.0136\n",
      "Epoch [353/360], Batch [80/196], Loss: 0.0199\n",
      "Epoch [353/360], Batch [85/196], Loss: 0.0148\n",
      "Epoch [353/360], Batch [90/196], Loss: 0.0131\n",
      "Epoch [353/360], Batch [95/196], Loss: 0.0153\n",
      "Epoch [353/360], Batch [100/196], Loss: 0.0172\n",
      "Epoch [353/360], Batch [105/196], Loss: 0.0105\n",
      "Epoch [353/360], Batch [110/196], Loss: 0.0193\n",
      "Epoch [353/360], Batch [115/196], Loss: 0.0113\n",
      "Epoch [353/360], Batch [120/196], Loss: 0.0171\n",
      "Epoch [353/360], Batch [125/196], Loss: 0.0236\n",
      "Epoch [353/360], Batch [130/196], Loss: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [353/360], Batch [135/196], Loss: 0.0280\n",
      "Epoch [353/360], Batch [140/196], Loss: 0.0139\n",
      "Epoch [353/360], Batch [145/196], Loss: 0.0107\n",
      "Epoch [353/360], Batch [150/196], Loss: 0.0129\n",
      "Epoch [353/360], Batch [155/196], Loss: 0.0099\n",
      "Epoch [353/360], Batch [160/196], Loss: 0.0148\n",
      "Epoch [353/360], Batch [165/196], Loss: 0.0181\n",
      "Epoch [353/360], Batch [170/196], Loss: 0.0192\n",
      "Epoch [353/360], Batch [175/196], Loss: 0.0121\n",
      "Epoch [353/360], Batch [180/196], Loss: 0.0143\n",
      "Epoch [353/360], Batch [185/196], Loss: 0.0145\n",
      "Epoch [353/360], Batch [190/196], Loss: 0.0136\n",
      "Epoch [353/360], Batch [195/196], Loss: 0.0161\n",
      "Epoch [354/360], Batch [5/196], Loss: 0.0122\n",
      "Epoch [354/360], Batch [10/196], Loss: 0.0220\n",
      "Epoch [354/360], Batch [15/196], Loss: 0.0148\n",
      "Epoch [354/360], Batch [20/196], Loss: 0.0151\n",
      "Epoch [354/360], Batch [25/196], Loss: 0.0134\n",
      "Epoch [354/360], Batch [30/196], Loss: 0.0121\n",
      "Epoch [354/360], Batch [35/196], Loss: 0.0135\n",
      "Epoch [354/360], Batch [40/196], Loss: 0.0192\n",
      "Epoch [354/360], Batch [45/196], Loss: 0.0141\n",
      "Epoch [354/360], Batch [50/196], Loss: 0.0117\n",
      "Epoch [354/360], Batch [55/196], Loss: 0.0209\n",
      "Epoch [354/360], Batch [60/196], Loss: 0.0138\n",
      "Epoch [354/360], Batch [65/196], Loss: 0.0136\n",
      "Epoch [354/360], Batch [70/196], Loss: 0.0100\n",
      "Epoch [354/360], Batch [75/196], Loss: 0.0088\n",
      "Epoch [354/360], Batch [80/196], Loss: 0.0154\n",
      "Epoch [354/360], Batch [85/196], Loss: 0.0110\n",
      "Epoch [354/360], Batch [90/196], Loss: 0.0126\n",
      "Epoch [354/360], Batch [95/196], Loss: 0.0095\n",
      "Epoch [354/360], Batch [100/196], Loss: 0.0100\n",
      "Epoch [354/360], Batch [105/196], Loss: 0.0141\n",
      "Epoch [354/360], Batch [110/196], Loss: 0.0127\n",
      "Epoch [354/360], Batch [115/196], Loss: 0.0294\n",
      "Epoch [354/360], Batch [120/196], Loss: 0.0162\n",
      "Epoch [354/360], Batch [125/196], Loss: 0.0232\n",
      "Epoch [354/360], Batch [130/196], Loss: 0.0169\n",
      "Epoch [354/360], Batch [135/196], Loss: 0.0302\n",
      "Epoch [354/360], Batch [140/196], Loss: 0.0166\n",
      "Epoch [354/360], Batch [145/196], Loss: 0.0273\n",
      "Epoch [354/360], Batch [150/196], Loss: 0.0258\n",
      "Epoch [354/360], Batch [155/196], Loss: 0.0264\n",
      "Epoch [354/360], Batch [160/196], Loss: 0.0288\n",
      "Epoch [354/360], Batch [165/196], Loss: 0.0142\n",
      "Epoch [354/360], Batch [170/196], Loss: 0.0184\n",
      "Epoch [354/360], Batch [175/196], Loss: 0.0166\n",
      "Epoch [354/360], Batch [180/196], Loss: 0.0247\n",
      "Epoch [354/360], Batch [185/196], Loss: 0.0197\n",
      "Epoch [354/360], Batch [190/196], Loss: 0.0178\n",
      "Epoch [354/360], Batch [195/196], Loss: 0.0205\n",
      "Epoch [355/360], Batch [5/196], Loss: 0.0121\n",
      "Epoch [355/360], Batch [10/196], Loss: 0.0167\n",
      "Epoch [355/360], Batch [15/196], Loss: 0.0237\n",
      "Epoch [355/360], Batch [20/196], Loss: 0.0233\n",
      "Epoch [355/360], Batch [25/196], Loss: 0.0265\n",
      "Epoch [355/360], Batch [30/196], Loss: 0.0207\n",
      "Epoch [355/360], Batch [35/196], Loss: 0.0217\n",
      "Epoch [355/360], Batch [40/196], Loss: 0.0435\n",
      "Epoch [355/360], Batch [45/196], Loss: 0.0154\n",
      "Epoch [355/360], Batch [50/196], Loss: 0.0110\n",
      "Epoch [355/360], Batch [55/196], Loss: 0.0189\n",
      "Epoch [355/360], Batch [60/196], Loss: 0.0382\n",
      "Epoch [355/360], Batch [65/196], Loss: 0.0132\n",
      "Epoch [355/360], Batch [70/196], Loss: 0.0094\n",
      "Epoch [355/360], Batch [75/196], Loss: 0.0220\n",
      "Epoch [355/360], Batch [80/196], Loss: 0.0277\n",
      "Epoch [355/360], Batch [85/196], Loss: 0.0150\n",
      "Epoch [355/360], Batch [90/196], Loss: 0.0247\n",
      "Epoch [355/360], Batch [95/196], Loss: 0.0174\n",
      "Epoch [355/360], Batch [100/196], Loss: 0.0201\n",
      "Epoch [355/360], Batch [105/196], Loss: 0.0234\n",
      "Epoch [355/360], Batch [110/196], Loss: 0.0152\n",
      "Epoch [355/360], Batch [115/196], Loss: 0.0178\n",
      "Epoch [355/360], Batch [120/196], Loss: 0.0128\n",
      "Epoch [355/360], Batch [125/196], Loss: 0.0210\n",
      "Epoch [355/360], Batch [130/196], Loss: 0.0145\n",
      "Epoch [355/360], Batch [135/196], Loss: 0.0228\n",
      "Epoch [355/360], Batch [140/196], Loss: 0.0309\n",
      "Epoch [355/360], Batch [145/196], Loss: 0.0173\n",
      "Epoch [355/360], Batch [150/196], Loss: 0.0165\n",
      "Epoch [355/360], Batch [155/196], Loss: 0.0122\n",
      "Epoch [355/360], Batch [160/196], Loss: 0.0151\n",
      "Epoch [355/360], Batch [165/196], Loss: 0.0238\n",
      "Epoch [355/360], Batch [170/196], Loss: 0.0225\n",
      "Epoch [355/360], Batch [175/196], Loss: 0.0360\n",
      "Epoch [355/360], Batch [180/196], Loss: 0.0493\n",
      "Epoch [355/360], Batch [185/196], Loss: 0.0266\n",
      "Epoch [355/360], Batch [190/196], Loss: 0.0748\n",
      "Epoch [355/360], Batch [195/196], Loss: 0.0527\n",
      "Epoch [356/360], Batch [5/196], Loss: 0.0340\n",
      "Epoch [356/360], Batch [10/196], Loss: 0.0398\n",
      "Epoch [356/360], Batch [15/196], Loss: 0.0331\n",
      "Epoch [356/360], Batch [20/196], Loss: 0.0238\n",
      "Epoch [356/360], Batch [25/196], Loss: 0.0394\n",
      "Epoch [356/360], Batch [30/196], Loss: 0.0389\n",
      "Epoch [356/360], Batch [35/196], Loss: 0.0406\n",
      "Epoch [356/360], Batch [40/196], Loss: 0.0275\n",
      "Epoch [356/360], Batch [45/196], Loss: 0.0203\n",
      "Epoch [356/360], Batch [50/196], Loss: 0.0204\n",
      "Epoch [356/360], Batch [55/196], Loss: 0.0283\n",
      "Epoch [356/360], Batch [60/196], Loss: 0.0395\n",
      "Epoch [356/360], Batch [65/196], Loss: 0.0283\n",
      "Epoch [356/360], Batch [70/196], Loss: 0.0372\n",
      "Epoch [356/360], Batch [75/196], Loss: 0.0307\n",
      "Epoch [356/360], Batch [80/196], Loss: 0.0318\n",
      "Epoch [356/360], Batch [85/196], Loss: 0.0249\n",
      "Epoch [356/360], Batch [90/196], Loss: 0.0275\n",
      "Epoch [356/360], Batch [95/196], Loss: 0.0323\n",
      "Epoch [356/360], Batch [100/196], Loss: 0.0249\n",
      "Epoch [356/360], Batch [105/196], Loss: 0.0247\n",
      "Epoch [356/360], Batch [110/196], Loss: 0.0357\n",
      "Epoch [356/360], Batch [115/196], Loss: 0.0259\n",
      "Epoch [356/360], Batch [120/196], Loss: 0.0324\n",
      "Epoch [356/360], Batch [125/196], Loss: 0.0189\n",
      "Epoch [356/360], Batch [130/196], Loss: 0.0217\n",
      "Epoch [356/360], Batch [135/196], Loss: 0.0333\n",
      "Epoch [356/360], Batch [140/196], Loss: 0.0239\n",
      "Epoch [356/360], Batch [145/196], Loss: 0.0287\n",
      "Epoch [356/360], Batch [150/196], Loss: 0.0233\n",
      "Epoch [356/360], Batch [155/196], Loss: 0.0299\n",
      "Epoch [356/360], Batch [160/196], Loss: 0.0269\n",
      "Epoch [356/360], Batch [165/196], Loss: 0.0681\n",
      "Epoch [356/360], Batch [170/196], Loss: 0.0302\n",
      "Epoch [356/360], Batch [175/196], Loss: 0.0319\n",
      "Epoch [356/360], Batch [180/196], Loss: 0.0167\n",
      "Epoch [356/360], Batch [185/196], Loss: 0.0258\n",
      "Epoch [356/360], Batch [190/196], Loss: 0.0150\n",
      "Epoch [356/360], Batch [195/196], Loss: 0.0270\n",
      "Epoch [357/360], Batch [5/196], Loss: 0.0267\n",
      "Epoch [357/360], Batch [10/196], Loss: 0.0160\n",
      "Epoch [357/360], Batch [15/196], Loss: 0.0182\n",
      "Epoch [357/360], Batch [20/196], Loss: 0.0288\n",
      "Epoch [357/360], Batch [25/196], Loss: 0.0315\n",
      "Epoch [357/360], Batch [30/196], Loss: 0.0180\n",
      "Epoch [357/360], Batch [35/196], Loss: 0.0433\n",
      "Epoch [357/360], Batch [40/196], Loss: 0.0177\n",
      "Epoch [357/360], Batch [45/196], Loss: 0.0209\n",
      "Epoch [357/360], Batch [50/196], Loss: 0.0166\n",
      "Epoch [357/360], Batch [55/196], Loss: 0.0154\n",
      "Epoch [357/360], Batch [60/196], Loss: 0.0206\n",
      "Epoch [357/360], Batch [65/196], Loss: 0.0433\n",
      "Epoch [357/360], Batch [70/196], Loss: 0.0263\n",
      "Epoch [357/360], Batch [75/196], Loss: 0.0218\n",
      "Epoch [357/360], Batch [80/196], Loss: 0.0370\n",
      "Epoch [357/360], Batch [85/196], Loss: 0.0248\n",
      "Epoch [357/360], Batch [90/196], Loss: 0.0154\n",
      "Epoch [357/360], Batch [95/196], Loss: 0.0528\n",
      "Epoch [357/360], Batch [100/196], Loss: 0.0187\n",
      "Epoch [357/360], Batch [105/196], Loss: 0.0186\n",
      "Epoch [357/360], Batch [110/196], Loss: 0.0264\n",
      "Epoch [357/360], Batch [115/196], Loss: 0.0323\n",
      "Epoch [357/360], Batch [120/196], Loss: 0.0239\n",
      "Epoch [357/360], Batch [125/196], Loss: 0.0335\n",
      "Epoch [357/360], Batch [130/196], Loss: 0.0156\n",
      "Epoch [357/360], Batch [135/196], Loss: 0.0154\n",
      "Epoch [357/360], Batch [140/196], Loss: 0.0248\n",
      "Epoch [357/360], Batch [145/196], Loss: 0.0224\n",
      "Epoch [357/360], Batch [150/196], Loss: 0.0213\n",
      "Epoch [357/360], Batch [155/196], Loss: 0.0335\n",
      "Epoch [357/360], Batch [160/196], Loss: 0.0229\n",
      "Epoch [357/360], Batch [165/196], Loss: 0.0438\n",
      "Epoch [357/360], Batch [170/196], Loss: 0.0299\n",
      "Epoch [357/360], Batch [175/196], Loss: 0.0231\n",
      "Epoch [357/360], Batch [180/196], Loss: 0.0271\n",
      "Epoch [357/360], Batch [185/196], Loss: 0.0292\n",
      "Epoch [357/360], Batch [190/196], Loss: 0.0207\n",
      "Epoch [357/360], Batch [195/196], Loss: 0.0260\n",
      "Epoch [358/360], Batch [5/196], Loss: 0.0244\n",
      "Epoch [358/360], Batch [10/196], Loss: 0.0176\n",
      "Epoch [358/360], Batch [15/196], Loss: 0.0450\n",
      "Epoch [358/360], Batch [20/196], Loss: 0.0223\n",
      "Epoch [358/360], Batch [25/196], Loss: 0.0178\n",
      "Epoch [358/360], Batch [30/196], Loss: 0.0400\n",
      "Epoch [358/360], Batch [35/196], Loss: 0.0192\n",
      "Epoch [358/360], Batch [40/196], Loss: 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [358/360], Batch [45/196], Loss: 0.0426\n",
      "Epoch [358/360], Batch [50/196], Loss: 0.0212\n",
      "Epoch [358/360], Batch [55/196], Loss: 0.0247\n",
      "Epoch [358/360], Batch [60/196], Loss: 0.0602\n",
      "Epoch [358/360], Batch [65/196], Loss: 0.0292\n",
      "Epoch [358/360], Batch [70/196], Loss: 0.0183\n",
      "Epoch [358/360], Batch [75/196], Loss: 0.0146\n",
      "Epoch [358/360], Batch [80/196], Loss: 0.0307\n",
      "Epoch [358/360], Batch [85/196], Loss: 0.0255\n",
      "Epoch [358/360], Batch [90/196], Loss: 0.0150\n",
      "Epoch [358/360], Batch [95/196], Loss: 0.0120\n",
      "Epoch [358/360], Batch [100/196], Loss: 0.0182\n",
      "Epoch [358/360], Batch [105/196], Loss: 0.0125\n",
      "Epoch [358/360], Batch [110/196], Loss: 0.0249\n",
      "Epoch [358/360], Batch [115/196], Loss: 0.0299\n",
      "Epoch [358/360], Batch [120/196], Loss: 0.0189\n",
      "Epoch [358/360], Batch [125/196], Loss: 0.0142\n",
      "Epoch [358/360], Batch [130/196], Loss: 0.0189\n",
      "Epoch [358/360], Batch [135/196], Loss: 0.0621\n",
      "Epoch [358/360], Batch [140/196], Loss: 0.0194\n",
      "Epoch [358/360], Batch [145/196], Loss: 0.0181\n",
      "Epoch [358/360], Batch [150/196], Loss: 0.0266\n",
      "Epoch [358/360], Batch [155/196], Loss: 0.0279\n",
      "Epoch [358/360], Batch [160/196], Loss: 0.0174\n",
      "Epoch [358/360], Batch [165/196], Loss: 0.0176\n",
      "Epoch [358/360], Batch [170/196], Loss: 0.0210\n",
      "Epoch [358/360], Batch [175/196], Loss: 0.0295\n",
      "Epoch [358/360], Batch [180/196], Loss: 0.0129\n",
      "Epoch [358/360], Batch [185/196], Loss: 0.0304\n",
      "Epoch [358/360], Batch [190/196], Loss: 0.0155\n",
      "Epoch [358/360], Batch [195/196], Loss: 0.0165\n",
      "Epoch [359/360], Batch [5/196], Loss: 0.0204\n",
      "Epoch [359/360], Batch [10/196], Loss: 0.0201\n",
      "Epoch [359/360], Batch [15/196], Loss: 0.0128\n",
      "Epoch [359/360], Batch [20/196], Loss: 0.0111\n",
      "Epoch [359/360], Batch [25/196], Loss: 0.0201\n",
      "Epoch [359/360], Batch [30/196], Loss: 0.0125\n",
      "Epoch [359/360], Batch [35/196], Loss: 0.0154\n",
      "Epoch [359/360], Batch [40/196], Loss: 0.0168\n",
      "Epoch [359/360], Batch [45/196], Loss: 0.0217\n",
      "Epoch [359/360], Batch [50/196], Loss: 0.0195\n",
      "Epoch [359/360], Batch [55/196], Loss: 0.0321\n",
      "Epoch [359/360], Batch [60/196], Loss: 0.0330\n",
      "Epoch [359/360], Batch [65/196], Loss: 0.0170\n",
      "Epoch [359/360], Batch [70/196], Loss: 0.0268\n",
      "Epoch [359/360], Batch [75/196], Loss: 0.0264\n",
      "Epoch [359/360], Batch [80/196], Loss: 0.0184\n",
      "Epoch [359/360], Batch [85/196], Loss: 0.0374\n",
      "Epoch [359/360], Batch [90/196], Loss: 0.0321\n",
      "Epoch [359/360], Batch [95/196], Loss: 0.0293\n",
      "Epoch [359/360], Batch [100/196], Loss: 0.0269\n",
      "Epoch [359/360], Batch [105/196], Loss: 0.0394\n",
      "Epoch [359/360], Batch [110/196], Loss: 0.0488\n",
      "Epoch [359/360], Batch [115/196], Loss: 0.0751\n",
      "Epoch [359/360], Batch [120/196], Loss: 0.0505\n",
      "Epoch [359/360], Batch [125/196], Loss: 0.0668\n",
      "Epoch [359/360], Batch [130/196], Loss: 0.0506\n",
      "Epoch [359/360], Batch [135/196], Loss: 0.0630\n",
      "Epoch [359/360], Batch [140/196], Loss: 0.0674\n",
      "Epoch [359/360], Batch [145/196], Loss: 0.0451\n",
      "Epoch [359/360], Batch [150/196], Loss: 0.0451\n",
      "Epoch [359/360], Batch [155/196], Loss: 0.0462\n",
      "Epoch [359/360], Batch [160/196], Loss: 0.0564\n",
      "Epoch [359/360], Batch [165/196], Loss: 0.0301\n",
      "Epoch [359/360], Batch [170/196], Loss: 0.0295\n",
      "Epoch [359/360], Batch [175/196], Loss: 0.0479\n",
      "Epoch [359/360], Batch [180/196], Loss: 0.0329\n",
      "Epoch [359/360], Batch [185/196], Loss: 0.0342\n",
      "Epoch [359/360], Batch [190/196], Loss: 0.0291\n",
      "Epoch [359/360], Batch [195/196], Loss: 0.0413\n",
      "Epoch [360/360], Batch [5/196], Loss: 0.0361\n",
      "Epoch [360/360], Batch [10/196], Loss: 0.0277\n",
      "Epoch [360/360], Batch [15/196], Loss: 0.0326\n",
      "Epoch [360/360], Batch [20/196], Loss: 0.0385\n",
      "Epoch [360/360], Batch [25/196], Loss: 0.0266\n",
      "Epoch [360/360], Batch [30/196], Loss: 0.0490\n",
      "Epoch [360/360], Batch [35/196], Loss: 0.0286\n",
      "Epoch [360/360], Batch [40/196], Loss: 0.0413\n",
      "Epoch [360/360], Batch [45/196], Loss: 0.0220\n",
      "Epoch [360/360], Batch [50/196], Loss: 0.0256\n",
      "Epoch [360/360], Batch [55/196], Loss: 0.0202\n",
      "Epoch [360/360], Batch [60/196], Loss: 0.0267\n",
      "Epoch [360/360], Batch [65/196], Loss: 0.0225\n",
      "Epoch [360/360], Batch [70/196], Loss: 0.0239\n",
      "Epoch [360/360], Batch [75/196], Loss: 0.0351\n",
      "Epoch [360/360], Batch [80/196], Loss: 0.0402\n",
      "Epoch [360/360], Batch [85/196], Loss: 0.0242\n",
      "Epoch [360/360], Batch [90/196], Loss: 0.0320\n",
      "Epoch [360/360], Batch [95/196], Loss: 0.0322\n",
      "Epoch [360/360], Batch [100/196], Loss: 0.0355\n",
      "Epoch [360/360], Batch [105/196], Loss: 0.0276\n",
      "Epoch [360/360], Batch [110/196], Loss: 0.0194\n",
      "Epoch [360/360], Batch [115/196], Loss: 0.0352\n",
      "Epoch [360/360], Batch [120/196], Loss: 0.0191\n",
      "Epoch [360/360], Batch [125/196], Loss: 0.0265\n",
      "Epoch [360/360], Batch [130/196], Loss: 0.0270\n",
      "Epoch [360/360], Batch [135/196], Loss: 0.0236\n",
      "Epoch [360/360], Batch [140/196], Loss: 0.0223\n",
      "Epoch [360/360], Batch [145/196], Loss: 0.0312\n",
      "Epoch [360/360], Batch [150/196], Loss: 0.0677\n",
      "Epoch [360/360], Batch [155/196], Loss: 0.0255\n",
      "Epoch [360/360], Batch [160/196], Loss: 0.0236\n",
      "Epoch [360/360], Batch [165/196], Loss: 0.0325\n",
      "Epoch [360/360], Batch [170/196], Loss: 0.0374\n",
      "Epoch [360/360], Batch [175/196], Loss: 0.0358\n",
      "Epoch [360/360], Batch [180/196], Loss: 0.0239\n",
      "Epoch [360/360], Batch [185/196], Loss: 0.0380\n",
      "Epoch [360/360], Batch [190/196], Loss: 0.0404\n",
      "Epoch [360/360], Batch [195/196], Loss: 0.0315\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 360\n",
    "for epoch in range(num_epochs):\n",
    "    xlstmtime.train()\n",
    "    for batch_idx, (X_b, y_b) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        y_b_pred = xlstmtime(X_b)\n",
    "        y_b_pred = y_b_pred[:,-1,:] # select state for last element in sequence\n",
    "        loss = criterion(y_b_pred, y_b)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd1253",
   "metadata": {},
   "source": [
    "## Test sequence predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "524d43cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 36\n",
    "# start_idx = 550\n",
    "start_idx = 2050\n",
    "\n",
    "X_for_seq = torch.from_numpy(X_examples[start_idx:start_idx+1,:].astype('float32')).to(device=device).reshape(-1, 100 , 1)\n",
    "y_for_seq = y_examples[start_idx:start_idx + num_steps]\n",
    "\n",
    "y_for_seq_pred = xlstmtime.forecast(X_for_seq, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "97196d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_for_seq_pred = y_for_seq_pred.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60c3db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_for_seq = y_for_seq.reshape(num_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7e4006c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 1)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_seq_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f812282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ca1716e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0061, dtype=torch.float64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(torch.from_numpy(y_for_seq_pred), torch.from_numpy(y_for_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "acdd4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_vs_target = pd.DataFrame(\n",
    "    {\n",
    "        'target': y_for_seq.reshape(num_steps, ),\n",
    "        'pred': y_for_seq_pred.reshape(num_steps, )\n",
    "    }\n",
    ")\n",
    "df_pred_vs_target['step'] = np.arange(1, num_steps + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f818fd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.377299</td>\n",
       "      <td>0.459125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011063</td>\n",
       "      <td>-0.102285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044357</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077651</td>\n",
       "      <td>0.126635</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155408</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target      pred  step\n",
       "0  0.377299  0.459125     1\n",
       "1  0.011063 -0.102285     2\n",
       "2  0.044357  0.032816     3\n",
       "3  0.077651  0.126635     4\n",
       "4 -0.155408  0.073416     5"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_vs_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "28592ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='step'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_vs_target.plot(x='step', y=['pred', 'target'], figsize=(18, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c11bd8",
   "metadata": {},
   "source": [
    "## Examine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "748626cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_after_train = torch.from_numpy(X_examples[228:229,:].astype('float32')).to(device=device).reshape(-1, 50 , 1)\n",
    "y_after_train = y_examples[228:229]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff5c65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_after_train = xlstmtime(X_after_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c62430d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2171.7285]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_after_train[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d26570a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2151.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_after_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "576df898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2384.5, 2350. , 2240.5, 2257. , 2266. , 2260.5, 2260. , 2241. ,\n",
       "        2255. , 2142. , 2134. , 2140. , 2165. , 2142. , 2105.5, 2123.5,\n",
       "        2108. , 2125. , 2163.5, 2150. , 2118. , 2142. , 2158. , 2159. ,\n",
       "        2170. , 2132. , 2159. , 2183.5, 2170. , 2122.5, 2080. , 2100.5,\n",
       "        2123.5, 2097. , 2070.5, 2145. , 2192. , 2117. , 2140. , 2152.5,\n",
       "        2178. , 2202.5, 2196.5, 2213. , 2194. , 2195. , 2168. , 2136. ,\n",
       "        2143.5, 2185.5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_examples[228:229,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35cc3848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2350. , 2240.5, 2257. , 2266. , 2260.5, 2260. , 2241. , 2255. ,\n",
       "        2142. , 2134. , 2140. , 2165. , 2142. , 2105.5, 2123.5, 2108. ,\n",
       "        2125. , 2163.5, 2150. , 2118. , 2142. , 2158. , 2159. , 2170. ,\n",
       "        2132. , 2159. , 2183.5, 2170. , 2122.5, 2080. , 2100.5, 2123.5,\n",
       "        2097. , 2070.5, 2145. , 2192. , 2117. , 2140. , 2152.5, 2178. ,\n",
       "        2202.5, 2196.5, 2213. , 2194. , 2195. , 2168. , 2136. , 2143.5,\n",
       "        2185.5, 2151. ],\n",
       "       [2240.5, 2257. , 2266. , 2260.5, 2260. , 2241. , 2255. , 2142. ,\n",
       "        2134. , 2140. , 2165. , 2142. , 2105.5, 2123.5, 2108. , 2125. ,\n",
       "        2163.5, 2150. , 2118. , 2142. , 2158. , 2159. , 2170. , 2132. ,\n",
       "        2159. , 2183.5, 2170. , 2122.5, 2080. , 2100.5, 2123.5, 2097. ,\n",
       "        2070.5, 2145. , 2192. , 2117. , 2140. , 2152.5, 2178. , 2202.5,\n",
       "        2196.5, 2213. , 2194. , 2195. , 2168. , 2136. , 2143.5, 2185.5,\n",
       "        2151. , 2143. ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_examples[229:231,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3344286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_t = torch.randn(1, 50, 1)\n",
    "right_t = torch.randn(1, 1, 1)\n",
    "\n",
    "res_t = torch.cat((left_t, right_t), dim=1)[:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580ef274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b86243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10 (nxai_xlstm)",
   "language": "python",
   "name": "nxai_xlstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
